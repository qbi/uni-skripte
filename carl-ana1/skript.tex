% Einige zusätzliche Informationen für rubber
%  rubber erkennt nicht, dass die Datei weg kann, daher sagen wir es ihm
% rubber: clean $base.thm
%  rubber soll nach Änderungen an der Datei nochmal bauen
% rubber: watch $base.thm
% rubber: makeidx.tool      xindy
% rubber: makeidx.language  german-din
%
% scrreprt trifft am Besten die Bedürfnisse eines Skripts, das ganze wird
% zweiseitig (twoside), d.h. es wird zwischen linker und rechter Seite
% unterschieden, und wir verwenden zwischen den Absätzen einen Abstand
% von einer halben Zeile (halfparskip) und dafür keinen Absatzeinzug,
% wobei die letzte Zeile eines Absatzes zu min. 1/4 leer ist.

\RequirePackage[l2tabu,orthodox]{nag}  % nag überprüft den Text auf veraltete
                   % Befehle oder solche, die man nicht in LaTeX verwenden
                   % soll -- l2tabu-Checker in LaTeX

\documentclass[ngerman,titlepage,twoside, parskip=half*]{scrreprt}

\usepackage[ngerman]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage[all,warning]{onlyamsmath}  % warnt bei Verwendung von nicht
                                       % amsmath-Umgebungen z.\,B. $$...$$
\usepackage{fixmath}     % ISO-konforme griech. Buchstaben

\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{wasysym}
\usepackage{fancyhdr}
\usepackage{enumerate}
\usepackage{makeidx}
\usepackage{pst-plot}
\usepackage{nicefrac}
\usepackage{svn}         % Zum Auswerten und ordentlichen Darstellen der
                         % SVN-Schlüsselwörter (s. vor \begin{document})
\usepackage[draft=false,colorlinks,urlcolor=blue,breaklinks]{hyperref}
\usepackage{paralist}
\usepackage{ellipsis}

\newcommand*{\N}{\mathbb{N}}
\newcommand*{\Z}{\mathbb{Z}}
\newcommand*{\Q}{\mathbb{Q}}
\newcommand*{\R}{\mathbb{R}}
\newcommand*{\C}{\mathbb{C}}
\newcommand*{\ZZ}{\mathfrak{Z}}
\newcommand*{\RR}{\mathcal{R}}
\newcommand*{\perdef}{:\Leftrightarrow}

% Befehl für die Darstellung der Gliederungsüberschriften im Index
\newcommand*{\lettergroup}[1]{\minisec{#1}}

\theoremstyle{plain}
%\newtheorem{satz}{Satz}[section]
% \newtheorem*{satz*}{Satz o.\,B.}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Satz}[section]

\theoremstyle{definition}
\newtheorem{definition}{Definition}
%\newtheorem{proof}{Beweis}
\newtheorem{Folg}{Folgerung}

\theoremstyle{remark}
\newtheorem*{remark}{Bemerkung}
\newtheorem*{beispiel}{Beispiel}

% Hier die Definition, wie \autoref die Umgebungen nennen soll, die mit
% \newtheorem definiert wurden
\newcommand*{\lemmaautorefname}{Lemma}
\renewcommand*{\theoremautorefname}{Satz}
\newcommand*{\definitionautorefname}{Definition}
\newcommand*{\Folgautorefname}{Folgerung}

% Um wichtige Begriffe im Text überall gleich vorzuheben (gleiches
% Markup), sollte dieser Befehl verwendet werden. Das Argument wird
% automatisch als Indexeintrag verwendet. Dieser kann aber auch als
% optionales Argument selbst bestimmt werden.
\newcommand*{\highl}[2][]{\textbf{\boldmath{#2}}%
  \ifthenelse{\equal{#1}{}}{\index{#2}}{\index{#1}}%
}

% Wenn irgendwo Unklarheiten zum Inhalt im Skript auftreten, können sie
% einfach mit \help{Ich verstehe das nicht} hervorgehoben werden. Dies
% macht es leichter sie alle zu finden und auch ganz einfach
% auszublenden, indem man den Befehl einfach leer definiert
\newcommand*{\help}[1]{\textcolor{green}{help: #1}}
\newcommand*{\todo}[1]{\textcolor{red}{todo: #1}}

% Um sicherzustellen, dass jeder Betrag-/jede Norm links und rechts die
% Striche bekommt, sind diese Befehle da. Damit kann man nicht die
% rechten Striche vergessen und es wird etwas übersichtlicher. (Vorschlag
% ist aus amsldoc) \abs[\big]{\abs{a}-\abs{b}} \leq \abs{a+b}
\newcommand*{\abs}[2][]{#1\lvert#2#1\rvert}
\newcommand*{\norm}[2][]{#1\lVert#2#1\rVert}

% ordentliches :=
\newcommand*{\coloneqq}{\mathrel{\mathop:}=}


% In der Vorlesung werden offene Intervallenden durch umgekehrte Klammern
% dargestellt. In TeX hat wohnt aber dem Klammerzeichen bereits eine Bedeutung
% inne, sprich es gehört zu einer der Klassen öffnenede Klammer oder
% schließende Klammer. Dementsprechend werden die Abstände um das Zeichen
% herum gewählt. Damit man nicht immer die Zeichenklasse von Hand ändern muss,
% sollen diese Befehle verwendet werden.
\newcommand*{\lsofint}[1]{\mathopen{]}#1]}   % linksseitig offenes Intervall
\newcommand*{\rsofint}[1]{[#1\mathclose{[}}  % rechtsseitig offenes Intervall
\newcommand*{\bsofint}[1]{\mathopen{]}#1\mathclose{[}} % beidseitig off. Int.

\makeindex

\SVN $LastChangedRevision$
\SVN $LastChangedDate$

\begin{document}
\title{Analysis 1}
\author{Prof.\,Dr.\,Bernd Carl}
\date{Wintersemester 2003/04}

\maketitle

\clearpage
\chapter*{Vorwort}

{\itshape
  Dieses Dokument wurde als Skript für die auf der Titelseite genannte
  Vorlesung erstellt und wird jetzt im Rahmen des Projekts "`Vorlesungsskripte
  der Fakultät für Mathematik und Informatik"' weiter betreut. Das Dokument
  wurde nach bestem Wissen und Gewissen angefertigt. Dennoch garantiert weder
  der auf der Titelseite genannte Dozent, die Personen, die an dem Dokument
  mitgewirkt haben, noch die Mitglieder des Projekts für dessen
  Fehlerfreiheit. Für etwaige Fehler und dessen Folgen wird von keiner der
  genannten Personen eine Haftung übernommen. Es steht jeder Person frei,
  dieses Dokument zu lesen, zu verändern oder auf anderen Medien verfügbar zu
  machen, solange ein Verweis auf die Internetadresse des Projekts
  \url{http://uni-skripte.lug-jena.de/} enthalten ist.

  Diese Ausgabe trägt die Versionsnummer~\SVNLastChangedRevision{} und ist vom
  \SVNDate{}. Eine neue Ausgabe könnte auf der Webseite des Projekts
  verfügbar sein.

  Jeder ist dazu aufgerufen, Verbesserungen, Erweiterungen und
  Fehlerkorrekturen für das Skript einzureichen bzw. zu melden oder diese
  selbst einzupflegen -- einfach eine E-Mail an die Mailingliste
  \texttt{<uni-skripte@lug-jena.de>} senden. Weitere Informationen sind
  unter der oben genannten Internetadresse verfügbar.

  Hiermit möchten wir allen Personen, die an diesem Skript mitgewirkt haben,
  vielmals danken:
  \begin{itemize}
   \item Jens Kubieziel \texttt{<jens@kubieziel.de>} (2003/04)
   \item Stilianos Louca \texttt{<stelllaras@gmail.com>} (2007)
   \item Jörg Sommer \texttt{<joerg@alea.gnuu.de>} (2007)
  \end{itemize}
}

\tableofcontents{}

\chapter{Elemente der Logik und Mengenlehre}

Im folgenden werden einige der Grundlagen der Logik und Mengenlehre
vorgestellt. Eine tiefergehende Einführung zu der Thematik ist in den
Vorlesungsunterlagen für Lineare Algebra und analytische Geometrie zu finden.

Wenn du gerade mit deinem Studium beginnst, solltest du dir diese Grundlagen
genau anschauen. Denn das ist die Basis für das weitere Matematikstudium. In
der Regel werden in den Veranstaltungen sehr viele Aussagen bewiesen. Diese
Aussagen sind durch Verbindungen miteinander verknüpft. Bei der Verknüpfung
muss immer sicher gestellt sein, dass die Wahrheitswerte erhalten bleiben.
Diese Beziehungen erlernt man durch das Studium der Logik.

\section{Aussagen}

Das grundlegende Element in der Mengenlehre ist eine \highl{Aussage}. Dies ist
ein Satz, der wahr oder falsch sein kann. In der Regel bezeichnet man eine
Aussage mit $p$ oder den folgenden Buchstaben im Alphabet und weist einer
wahren Aussage den Buchstaben $w$ oder einer falschen Aussage den Buchstaben
$f$ zu. In Formeln heißt das $p\equiv w$ oder $p\equiv f$. Wenn wir nun zwei
Aussagen $p$ und $q$ betrachten, lassen sich durch Verbindung dieser neue
Aussagen gewinnen:\index{Aussageverbindung}

\begin{description}
\item[\highl{Negation}] Als Negation wird die Verneinung einer Aussage
  bezeichnet. Wir bezeichnen die Negation der Aussage $p$ mit $\overline{p}$.
  Manchmal wird $\overline{p}$ auch mit $\neg p$ bezeichnet. Formal:
  $\overline{p}\equiv w\colon p\equiv f$ und  $\overline{\overline{p}}=p$
\item[\highl{Konjunktion}] Konjunktion heißt, dass die Aussagen $p$ \emph{und}
  $q$ wahr sein müssen. Formal:
  $q\wedge q\coloneqq w$ genau dann, wenn $p\equiv w$ und $q\equiv w$.
\item[\highl{Disjunktion}] Disjunktion heißt, dass die Aussagen $p$
  \emph{oder} $q$ bzw. beide wahr sind. Formal:
  $p\vee q\equiv f\coloneqq p\equiv f$ und $q\equiv f$
\item[\highl{Implikation}] Die Implikation ist einer der am häufigsten
  benutzten logischen Mittel im weiteren Verlauf des Studiums. Sie bezeichnet
  die Schlussfolgerung, dass aus der Aussage $p$ die Aussage $q$ folgt.
  Insbesondere ist anfangs verwirrend, dass aus einer falschen Aussage eine
  wahre folgen kann. Nur aus einer wahren Aussage kann keine falsche folgen.
  Formal: $(p\Rightarrow q)\equiv f$ genau dann, wenn $p\equiv w$ und $q\equiv
  f$. Daraus können wir folgern: $(\overline{p\Rightarrow q})\equiv p\wedge
  \overline{q}$ und  $(p\Rightarrow q) \equiv \overline{p\wedge
    \overline{q}}=\overline{q}\vee q$
\item[\highl{Äquivalenz}] Die Äquivalenz ist eine stärkere Verknüpfung als die
  Implikation. Die Aussage $p$ gilt genau dann, wenn $q$ gilt. Formal:
  $(p\Leftrightarrow q)\equiv w \perdef p$ und $q$ haben den gleichen
  Wahrheitswert.
\end{description}

\section{Grundbegriffe der Prädikatenlogik (Quantorenlogik)}

Unter einer \highl{Aussageform} $p(x,y,\ldots)$ versteht
man einen Satz, in dem eine oder mehrere Variablen $x,y,\dotsc$
auftreten. Wenn man für die Variablen Objekte einer festliegenden
Gesamtheit einsetzt, erhält man immer eine Aussage.

\paragraph{Quantifizierung von Aussageformen}
Durch folgende sprachliche Gebilde wird die Aussageform
quantifiziert:
\begin{itemize}
\item $\forall\,x$: für alle (wird manchmal auch mit $\bigwedge$ bezeichnet)
\item $\exists\,x$: es gibt (mind.) ein (wird manchmal auch mit $\bigvee$
  bezeichnet)
\end{itemize}

\paragraph{Bausteine der Prädikatenlogik (Quantorenlogik)}
Diese Bausteine erlauben es uns, Aussagen zu formalisieren und dann auf
Gültigkeit zu prüfen. Die einzelnen Aussagen werden so zu größeren Einheiten
verbunden.
\begin{itemize}
\item $\forall x (p(x)\Rightarrow q(x))$ Bedeutung: Für jedes $x$ mit der
  Eigenschaft $p(x)$ folgt die Eigenschaft $q(x)$.
\item $\exists x (p(x)\wedge q(x))$ Bedeutung: Es gibt ein $x$ mit der Eigenschaft
  $p(x)$ \emph{und} der Eigenschaft $q(x)$.
\end{itemize}

\paragraph{Negation quantorenlogischer Aussagen}
Es ist sehr oft sinnvoll, die Negation der obigen Aussagen zu betrachten.
Unten finden sich die aussagenlogischen Äquivalente der Bausteine der
Prädikatenlogik.
\begin{align*}
  \overline{\forall x (p(x)\Rightarrow q(x))} &\equiv \exists x (p(x)\wedge
\overline{q(x)}) &
  \overline{\exists x (p(x) \wedge q(x))}&\equiv \forall x
(p(x)\Rightarrow \overline{q(x)})   
\end{align*}

\section{Abbildungen (Funktionen)}

\begin{definition}
  Seien $X,Y$ zwei nichtleere Mengen. Eine \highl{Teilmenge}
  $f\subseteq X\times Y\coloneqq \{(x,y)\colon x\in X \wedge y\in Y\}$ mit der
  Eigenschaft
  \begin{gather*}
    \forall x \in X\,\forall y_1\in Y\,\forall y_2\in Y (((x,y_1)\in
    f\wedge (x,y_2)\in f)\Rightarrow y_1=y_2)
  \end{gather*}
  heißt \highl{Abbildung} oder \highl{Funktion} von $X$ in $Y$.
\end{definition}

Wir schreiben hierfür: $f\colon X\rightarrow Y, x\mapsto f(x)$

In Worten: Unter einer Abbildung (Funktion) $f$ von $X$ in $Y$
versteht man eine Vorschrift, die jedem $x\in X$ \emph{genau ein} $y
\in Y$ zuordnet und nennen es \highl{Bild} oder
\highl{Wert} der Abbildung $f$ an der Stelle $x$. Die Menge
$X$ heißt \highl{Urbildmenge} oder \highl{Definitionsbereich}.

\paragraph{Komposition (Hintereinanderausführung, Verkettung)}
\begin{definition}
  Seien $X,Y,Z$ nichtleere Mengen und $f\colon X\rightarrow Y,
  g\colon Y\rightarrow Z$ zwei Abbildungen. Dann heißt die Abbildung $g\circ
  f\colon X\rightarrow Z$, wobei $(g\circ f)(x)\coloneqq g(f(x))$ mit $x\in X$
  \highl{Komposition} oder \highl{Hintereinanderausführung} der
  Abbildung $f$ und $g$.
\end{definition}

\paragraph{Inverse Abbildungen (Funktionen)}
\begin{definition}
  Seien $X,Y$ zwei nichtleere Mengen und $f\colon X\rightarrow Y$
  bijektiv. Dann heißt $f^{-1}\colon Y\rightarrow X, f(x)\mapsto x$
  \highl[Abbildung!inverse]{inverse Abbildung} oder
  \highl{Umkehrabbildung}.
\end{definition}

\chapter{Zahlen}

Zahlen sind abstrakte mathematische Objekte. Sie werden zum Zählen, Ordnen und
anderen verwendet. Es gibt verschiedene Möglichkeiten, die Zahlen zu
konstruieren. Die Konstruktionen werden eventuell in weiteren Vorlesungen
vorgestellt.

In dem Kapitel werden wir meist Eigenschaften der reellen Zahlen
studieren. Dabei sind insbesondere Beziehungen zwischen Zahlen, die
Konstruktion von Intervallen und die Betragsfunktion von
Interesse. Einen weiteren Teil der Betrachtungen bilden die Teilmengen
reeller Zahlen sowie das Prinzip der vollständigen Induktion.

\section{Reelle Zahlen}
Für die Mathematik und insbesondere für die Analysis sind die reellen Zahlen
der wichtigste Zahlenbereich. Ohne diese wäre die Analysis in der weiterhin
vorgestellten Form kaum denkbar. Bildlich gesprochen ist das der erste
Zahlenbegriff, der keine Lücken aufweist. Hierdurch wird insbesondere
eine sinnvolle Definition des Limes möglich.

Neben den reellen Zahlen gibt es noch die natürlichen Zahlen $\N$, die
ganzen Zahlen $\Z$ sowie die rationalen Zahlen $\Q$. Unten sind
beispielhaft die Zahlenmengen aufgeführt.
\begin{align*}
\N &\coloneqq \{1,2,3,\ldots\} &
\Z &\coloneqq \{\ldots ,-2,-1,0,1,2,\ldots\} &
\Q &\coloneqq \left\{\frac{a}{b}\colon a,b\in \Z, b \neq 0\right\}
\end{align*}

Damit kommen wir zum ersten Satz:
\begin{theorem}[$\sqrt{2}\notin \Q$]
  \label{the:2-11}
  Es existiert keine rationale Zahl $x\in \Q$ mit der Eigenschaft
  $x^2=2$.
\end{theorem}

\begin{lemma}
  Sei $m$ eine natürliche Zahl, so dass $m^2$ eine gerade Zahl
  ist. Dann ist $m$ auch eine gerade Zahl.
  \begin{gather*}\forall m \in \N (m^2 \text{ gerade}\Rightarrow m \text{ gerade})\end{gather*}
  \begin{proof}
    Nehmen wir an, $m$ sei ungerade. Dann gilt für ein $k \in\N$ folgende
    Darstellung: $m=2k+1$. Also folgt: $m^{2}= (2k+1)^{2} = 4k^{2}+ 4k+1=
    2(2k^{2}+2k)+1$. Wenn nun $2k^{2}+2k=n$ setzen, haben wir $2n+1$. Also ist
    $m^{2}$ wieder eine ungerade Zahl. Wir haben durch einfache Umformungen
    einen Widerspruch erzeugt. Also gilt die Annahme im Lemma. Damit
    kann auch der \autoref{the:2-11} bewiesen werden.
  \end{proof}
\end{lemma}

\subsection{Körperaxiome}

Für den Zahlkörper $\R$ lassen sich einige Axiome feststellen:

\begin{description}
\item[Kommutativgesetz] $a \cdot{} b = b \cdot{} a$
\item[Assoziativgesetz] $(a \cdot{} b) \cdot{} c = a \cdot{} (b
  \cdot{} c)$
\item[Existenz und Eindeutigkeit des neutralen Elements] Es gibt eine
  von $0$ verschiedene Zahl $1$: $\forall a \in \R \colon a \cdot 1 = a$
\item[Eindeutigkeit der Lösbarkeit der Gleichung] $a \cdot x = 1, a
  \neq 0, \forall a \in \R, a \neq 0, \exists{}^1 x \in \R \colon a \cdot x
  = 1, x = a^{-1}$
\item[Distributivgesetz] $a \cdot (b+c) = a \cdot b + a \cdot c$
\end{description}

\subsection{Anordnungsaxiome}

In $\R$ gibt es eine "`Kleinerbeziehung"' $<$ mit folgenden
Eigenschaften:
\begin{itemize}
\item Entweder gilt $a=b$ oder $a<b$ oder $b<a$.
\item Transitivgesetz: $a<b \wedge b<c \Rightarrow a<c$
\item Monotoniegesetz der Addition: $a<b \Rightarrow a+c<b+c$
\item Monotoniegesetz der Multiplikation: $a<b \wedge 0<c \Rightarrow
  a \cdot c < b \cdot c$\\
  Gilt $0<a$, so heißt $a$ positiv. Gilt $a<0$, so heißt $a$ negativ.
\end{itemize}

\begin{description}
\item[Größerbeziehung] $a>b\perdef b<a$
\item[Kleinergleichbeziehung] $a \leq b \perdef a<b \vee
  a=b$
\item[Größergleichbeziehung] $a \geq b \perdef a>b \vee a=b$
\end{description}

\subsubsection{Intervalle}

Als Intervall wird eine zusammenhängende Teilmenge einer geordneten Menge
bezeichnet. Unten stehen die verschiedenen Arten von Intervallen:
\begin{itemize}
\item $[a,b] \coloneqq \{x \in \R \colon a \leq x \leq b\}$
  \highl[Intervall!abgeschlossenes]{abgeschlossenes Intervall}
\item $[a,a] \coloneqq \{a\}$
\item $\rsofint{a,b} \coloneqq \{x \in \R \colon a \leq x < b\}$
  \highl[Intervall!halboffenes]{halboffenes Intervall} (wird manchmal auch mit
  $[a,b)$ bezeichnet)
\item $\lsofint{a,b} \coloneqq \{x \in \R \colon a < x \leq b\}= (a,b]$
\item $\bsofint{a,b} \coloneqq \{x \in \R \colon a<x<b\}= (a,b)$ \highl[Intervall!offenes]{offenes
  Intervall}
\item $b-a$ Länge des Intervalls
\item $\rsofint{a,\infty} \coloneqq \{x \in \R \colon x \geq a\}$
\item $\lsofint{\infty,a} \coloneqq \{x \in \R \colon x \leq a\}$
\end{itemize}

\subsubsection{Absoluter Betrag}

Der Betrag einer reellen Zahl stellt den Abstand zur Null dar. Für $a \in \R$
gilt:
\begin{gather*}\abs{a} \coloneqq
\begin{cases}
  a & \text{falls } a \geq 0 \\
  -a & \text{falls } a<0
\end{cases}\end{gather*}

Man nennt $\abs{a}$ den \highl[Betrag!absoluter]{absoluten Betrag} oder einfach
\highl{Betrag} von $a$. Der Betrag ist immer größer oder gleich Null
und entspricht dem Maximum von $a$ und $-a$.

\paragraph{Eigenschaften des Betrages}

\begin{enumerate}
\item $\abs{a} =0 \Leftrightarrow a=0$. Dies ergibt sich sofort aus
  der obigen Definition.
\item Homogenität: $\abs{ab} = \abs{a}\abs{b}$. Dazu machen wir klar,
  dass die Beziehung $\abs{a} = \abs{-a}$ gilt. Denn $\abs{a}=
  \max\{a,-a\}=\max\{-a,-(-a)\}=\abs{-a}$.
  \begin{enumerate}[1.~F{a}ll]
  \item Seien $a$ und $b$ eine reelle Zahlen, die beide größer oder
    gleich Null sind. Dann gilt: $\abs{ab}=ab=\abs{a}\abs{b}$.
  \item Sei nun $a<0$ und $b \geq 0$. Dann gilt, $\abs{ab} =-(ab)
    =(-a)b=\abs{a}\abs{b}$.
  \item Sei $a$ eine beliebige reelle Zahl und $b <0$. Es gilt,
    $\abs{ab}= \abs{-(ab)}=\abs{a(-b)}$. Jetzt ist $-b$ eine positive
    Zahl und wir können die Erkenntnis aus dem ersten Fall von oben
    anwenden: $\abs{a}\abs{-b}= \abs{a}\abs{b}$.
  \end{enumerate}
\item Die \highl{Dreiecksungleichung} besagt:
  \begin{gather*}
    \abs{a+b} \leq \abs{a} + \abs{b}
  \end{gather*}
  Für den Beweis dieser Aussage sind wieder einige Vorarbeiten zu
  leisten. Eine beliebige reelle Zahl $a$ ist immer kleiner oder
  gleich dem Maximum der Zahlen $a$ und $-a$. Die Kleinerrelation gilt
  für den Fall $a<0$. Weiterhin ist auch $-a\leq\max\{a,-a\}$. Für $a,b\in\R$
  gilt dann: $a+b\leq\max\{a,-a\}+\max\{b,-b\}=\abs{a}+\abs{b}$ und
  $-a-b= (-a)+(-b)\leq\max\{a,-a\}+\max\{b\}= \abs{a}+ \abs{b}$.
  Nun folgt aus beiden Aussagen, $\abs{a+b}= \max\{a+b, -a-b=-(a+b)\}=
  \leq\max\{\abs{a}+\abs{b}, \abs{a}+\abs{b}\}= \abs{a}+\abs{b}$.
  \begin{enumerate}
  \item[$3'$] $\abs{\abs{a}-\abs{b}} \leq \abs{a-b}, \abs{\abs{a}-\abs{b}} \leq \abs{a+b}$\\
    Vorbereitend halten wir fest: $\abs{a}= \abs{a+0}= \abs{a+b-b}\leq
    \abs{a-b}+ \abs{b}= \abs{a+ (-b)}+ \abs{b}= \abs{a}+ \abs{b}+ \abs{b}$.
    Insgesamt ergibt sich die Aussage, $\abs{a}\leq \abs{a}+ \abs{b}+
    \abs{b}\Rightarrow \abs{a}- \abs{b} \leq\abs{a}+ \abs{b}$. Nun können wir
    die Aussage beweisen: $\abs{\abs{a}- \abs{b}}= \max\{\abs{a}- \abs{b},
    -(\abs{a}- \abs{b})\}\leq \max\{\abs{a}+ \abs{b}, \abs{a}+ \abs{b}\}=
    \abs{a+b}$.
  \end{enumerate}
\end{enumerate}

\subsection{Vollständigkeitsaxiom}
\begin{definition}
  Eine Menge $M \subset \R$ heißt genau dann \highl[beschränkt!nach oben]{nach oben
    beschränkt}, wenn es eine reelle Zahl $S \in \R$ gibt, dass  $x \leq S$
  für alle $x \in M$ gilt:
  \begin{gather*}M\subset\R\perdef\,\exists S\in\R\,\forall x \in M\colon x\leq S\end{gather*}
\end{definition}

\begin{definition}
  In dem Fall heißt $S$ \highl[Schranke!obere]{obere Schranke} von $M$.
\end{definition}

\begin{definition}
  Weiterhin heißt $S \in \R$ genau dann \highl{Supremum}\footnote{Bezeichnung:
  $S=\sup M$} oder \highl[Schranke!kleinste obere]{kleinste obere Schranke}
  von $M$, wenn gilt:
  \begin{enumerate}
    \item $S$ ist eine obere Schranke von $M$.
    \item Für jede obere Schranke $S'$ von $M$ gilt, $S \leq S'$
  \end{enumerate}
\end{definition}

Es existiert genau eine obere Schranke für $M$. Denn sind $S_1, S_2$
kleinste obere Schranken von $M$, dann gilt sowohl $S_1 \leq S_2$ wie
auch $S_2 \leq S_1$. Daraus folgt nun aber $S_1= S_2$.

\begin{theorem}[\highl{Vollständigkeitsaxiom}] Jede
  nichtleere, nach oben beschränkte Menge reeller Zahlen besitzt ein
  Supremum. $\forall M(M \subset \R \text{ n.\,o.\,b. } M \neq \emptyset
  \Rightarrow \sup M \in \R)$
\end{theorem}

\begin{remark}
  Über die Zugehörigkeit von $S=\sup M$ zur Menge $M$ wird nichts
  ausgesagt. Gilt $S \in M$, so schreibt man auch $\max M$ und $S$
  heißt \highl{Maximum} von $M$ oder formal  $S=\max M
  \Leftrightarrow S \in M \wedge \forall x \in M\colon x \leq S$.
\end{remark}

\begin{beispiel}
  Für die Menge $M\coloneqq\{x \in \R\colon x < 1\}$ ist $\sup M=1$. Ändert
  man $M\coloneqq\{x \in \R \colon x \leq 1\}$, so gilt $\sup M=1$ und  $\max
  M=1$.
\end{beispiel}

\begin{remark}
  Die Aussage, "`$S$ ist Supremum von $M \subset \R$"', kann auch durch
  folgende Äquivalenz charakterisiert werden:
  \begin{enumerate}
  \item $\forall x \in M \colon x \leq S$
  \item $\forall \varepsilon > 0 \exists x \in M\colon S - \varepsilon <
    x$
  \end{enumerate}
  \begin{proof}
    \begin{itemize}
    \item[$1\Rightarrow2$]  Sei $S=\sup M \Rightarrow \forall x \in M \colon x
      \leq S$. Wegen $S-\varepsilon < S$ ($S$ ist kleinste obere Schranke)
      existiert ein $x \in M$ mit $S - \varepsilon < x$.
    \item[$2\Leftarrow1$] Sei $S'$ obere Schranke von $M$. Wir müssen zeigen:
      $S \leq S'$. Nehmen wir an $S'<S \Rightarrow \exists \varepsilon > 0
      \colon S'+\varepsilon < S \stackrel{\text{(2.)}}{\Rightarrow} \exists x
      \in M\colon S'<S<\varepsilon <x \Rightarrow x$ ist echt größer als $S'$.
      \lightning Also folgt, $ S'$ ist keine obere Schranke von $M$.
\end{itemize}
  \end{proof}
\end{remark}

\subsubsection{Untere Schranke und Infimum}
Eine Menge $M \subset \R$ heißt \highl[beschränkt!nach unten]{nach unten
beschränkt}: $\Leftrightarrow \exists s\in\R \forall x \in M \colon x \geq S$.
Dann heißt $s \in \R$ \highl{Infimum}\footnote{Schreibweise:
  $s=\inf M$}: $\Leftrightarrow$
\begin{enumerate}
\item $s$ ist untere Schranke
\item $s$ ist größte untere Schranke
\end{enumerate}

\begin{theorem}
  Jede nichtleere nach unten beschränkte Menge besitzt ein Infimum.
\end{theorem}

\section{Teilmengen von reellen Zahlen}
\subsection{Natürliche Zahlen und Prinzip der vollständigen Induktion}
Das unten vorgestellte Prinzip der vollständigen Induktion gehört zum
grundlegenden Handwerkszeug der Mathematiker. Die Idee dahinter ist
vergleichbar mit einer unendlich großen Leiter. Wenn man wissen will, ob man
jede Stufe erklimmen kann, wäre der naheliegende Versuch, einfach
loszuklettern. Da die Leiter kein Ende hat, kann man also nie sicher sein, ob
da nicht doch kaputte Stufen enthalten sind. Also wendet man das Prinzip der
vollständigen Induktion an. Zunächst probiert man, ob man die Leiter überhaupt
besteigen kann (Induktionsanfang). Danach zeigt man, dass man von jeder Stufe
auf die nächste steigen kann (Induktionsbeweis).

\begin{definition}
  Eine Menge $I \subseteq \R$ heißt \highl{induktiv}$\perdef$
  \begin{enumerate}
  \item $1 \in I$
  \item $\forall x (x \in I \Rightarrow x+1 \in I)$
  \end{enumerate}
\end{definition}

\begin{beispiel}
  Sei $J\coloneqq\{I\colon I \subset \R, I \text{ ist induktiv}\}$ die
  Menge aller induktiven Mengen aus $\R$.
\end{beispiel}

\begin{definition}
  Die natürlichen Zahlen $\N$ sind der Durchschnitt über die oben definierten
  $J$:
  \begin{gather*}\N \coloneqq \bigcap J \coloneqq \bigcap_{I \in J} I = \{x \in \R \colon
  \forall I \in J x \in J\}\end{gather*}
\end{definition}

\begin{theorem}
  $\N$ ist die kleinste induktive Teilmenge von $\R$.
\begin{proof}
Wenn $A \in J \colon \bigcap_{I \in J} I \subset A$, genügt es zu zeigen,
dass $\N$  induktiv ist.
\begin{enumerate}
\item $\forall I \in J \colon 1 \in I \Rightarrow 1 \in \N = \bigcap_{I \in
    J} I$
\item Für $x \in \N = \bigcap_{I \in J} \Rightarrow \forall I \in J \colon x
  \in I \stackrel{I \text{ induktiv}}{\Longrightarrow} x+1 \in I\Rightarrow I
  \in J \colon x+1 \in I \Rightarrow x+1 \in \N = \bigcap_{I \in J} I$.
\end{enumerate}
\end{proof}
\end{theorem}

\begin{definition}
  Die zu $\N$ gehörenden Elemente heißen \highl[Zahlen!natürliche]{natürliche
    Zahlen}.
\end{definition}

\begin{theorem}
  \begin{enumerate}
  \item $\forall n \in \N \colon n \geq 1$
  \item $\forall n,m \in \N \colon n+m \in \N$ und  $n \cdot m \in \N$
  \item $\forall n > 1 \Rightarrow n-1 \in \N$
  \item $\forall n \in \N \forall x \in \R \colon n<x<n+1 \Rightarrow x
    \notin \N$
  \item Jede nichtleere Teilmenge $A \subset \N$ enthält eine kleinste
    natürliche Zahl.
  \end{enumerate}
\begin{proof}
  Die Beweise dazu finden sich in \cite{barner}.
\end{proof}
\end{theorem}

\begin{theorem}[Satz von Archimedes]
 $\N$ ist nicht beschränkt.
\begin{proof}
  Da wir wissen, dass $\R$ nicht beschränkt ist, genügt es zu zeigen,
  dass es für jedes $a\geq 0$ aus $\R$ ein $n$ aus $\N$ mit der
  Eigenschaft $n\geq a$ gibt:
  \begin{gather*}\forall a \in \R\text{ mit } a  \geq 0 \exists n \in \N\colon n \geq a\end{gather*}
  Zum Beweis nehmen wir das Gegenteil an und müssen nach den Gesetzen
  der Logik auf einen Widerspruch stossen:
  \begin{gather*}\exists a \in \R \text{ mit } a \geq 0\forall n \in \N\colon n < a\end{gather*}
  Damit folgt, dass $\N$ beschränkt und nach dem Vollständigkeitsaxiom
  muss es ein $b=\sup\N \in \R$ geben. Sei nun $\varepsilon =
  \nicefrac{1}{2}$. Dann existiert ein $n_0 \in \N$ mit
  $b-\varepsilon<n_0$. Damit folgt nun,
  $b<(b-\varepsilon)+1<n_0+1$. Natürlich muss $n_0+1$ in den
  natürlichen Zahlen liegen, da diese ja induktiv sind. \lightning
\end{proof}
\end{theorem}

\subsubsection{Das Prinzip der vollständigen Induktion}

\begin{theorem}
  Sei $A \subseteq \N$ mit folgenden Eigenschaften:
  \begin{enumerate}
  \item $1 \in A$
  \item Für alle $n \in \N$ liegt $n+1$ wieder in $A$. Dann gilt
    $A=\N$.
  \end{enumerate}
\begin{proof}
  $A \subseteq \N$ ist induktiv. Da  $\N$ die kleinste induktive Menge
  ist, gilt  $A=\N$.
\end{proof}
\end{theorem}

\begin{remark}
  Das Prinzip der vollständigen Induktion kann o.\,B.\,d.\,A. für Mengen der
  Form $\{n \in \Z\colon n \geq m\}$ mit dem Induktionsanfang $m \in
  \Z$ formuliert werden.
\end{remark}

\begin{definition}
  Sei $A$ eine Menge. Eine Abbildung $a\colon\N \rightarrow A$ heißt
  \highl{Folge}\footnote{Schreibweise: $(a_k)_{k \in \N},
    (a_k), (a_1,a_2,a_3, \ldots)$}.
\end{definition}

Eine Folge der form $(a_n)\colon\N \rightarrow \R$ wird als
\highl[Zahlenfolge!reelle]{reelle Zahlenfolge} bezeichnet. Folgen werden
üblicherweise als Summe oder Produkt formuliert:
\begin{align*}
  \sum_{k=m}^{n} a_k & \coloneqq a_m+a_{m+1}+\cdots + a_n &
  \prod_{k=m}^{n} a_k & \coloneqq a_m \cdot a_{m+1} \cdot \ldots \cdot a_n
\end{align*}

\subsubsection{Ganzzahlige Potenzen}
Sei $a \in \R$ und  $n \in \N$. Dann können wir die ganzzahligen Potenzen
definieren: $a^1\coloneqq a$ und  $a^{n+1}\coloneqq a^na$. Weiterhin haben wir
für $a\neq0$ die Potenz $a^{0}=1$.

Für die Potenzen gelten folgende Rechenregeln:
\begin{align*}
a^n a^m &=a^{n+m} & (a^n)^m &=a^{nm} & a^n b^n &=(ab)^n
\end{align*}

\subsubsection{Allgemeines Distributivgesetz}
\begin{align*}
  \left( \sum_{k=1}^m a_k\right) \left( \sum_{l=1}^n b_l\right) &=
     (a_{1}+a_{2}+\dotsb+ a_{n})(b_{1}+b_{2}+\dotsb+ b_{n})\\
  &= (a_{1}b_{1}+a_{1}b_{2}+\dotsb+ a_{1}b_{n})+ (a_{2}b_{1}+
     a_{2}b_{2}+\dotsb+ a_{2}b_{n})+\dotsb+(a_{n}b_{1}+ a_{n}b_{2}+\dotsb+
     a_{n}b_{n})\\
  &=\sum_{k=1}^n \sum_{l=1}^n a_k b_l
\end{align*}

\begin{beispiel}
Summenformel für die \highl[Reihe!geometrische]{geometrische Reihe}\\
  Sei $1 \neq q \in \R$ und  $n \in \N$. Dann ist die geometrische Reihe wie
  folgt definiert:
  \begin{gather*}
    \sum_{k=0}^n q^k=\frac{1-q^{n+1}}{1-q}
  \end{gather*}
  
Eine wichtige Formel ist die \highl[Ungleichung!Bernoullische]{Bernoullische
  Ungleichung}. Für alle  $x \geq -1$ und alle $n \in \N$
  \begin{gather*}
    (1+x)^n \geq 1+n+x
  \end{gather*}
  
Weiterhin haben wir die aus der Schule bekannte
  \highl[Formel!Binomische]{Binomische Formel} für alle  $a,b \in \R$ und alle
  $n \in \N$.
  \begin{gather*}
    (a+b)^n= \sum_{k=0}^n \binom{n}{k} a^k b^{n-k}
  \end{gather*}
\end{beispiel}

\subsection{Endliche und unendliche Teilmengen von \texorpdfstring{$\R$}{R}}
\begin{definition}
  Sei $A$ eine nichtleere Teilmenge von $\R$. Formal schreiben wir hierfür:
  $\emptyset \neq A \subset \R$. Dann heißt diese Menge:
  \begin{enumerate}
  \item endlich $\perdef \exists n \in \N \exists
    \varphi \colon \{1, \ldots , n\} \rightarrow A$ bijektiv
  \item unendlich $\perdef A$ ist nicht endlich
  \end{enumerate}
\end{definition}

\begin{definition}
  \begin{enumerate}
  \item Eine Teilmenge $\emptyset \neq A \subset \R$ heißt abzählbar
    $\perdef \exists \varphi \colon \N \rightarrow A$ surjektiv. Also mit
    $\varphi (\N)=A$.
  \item $\emptyset \neq A \subset \R$ heißt überabzählbar $\perdef A$ ist
    nicht abzählbar.
  \end{enumerate}
\end{definition}

\begin{beispiel}
  Sei $A=\{1,\ldots ,a_n\}$. Wir definieren die Abbildung $\varphi \colon \N
  \rightarrow A, \varphi (k) =
    \begin{cases}
      a_k &  1 \leq k \leq n\\
      a_n &  k=n+1,\ldots
    \end{cases}$.
\end{beispiel}

\begin{theorem}
  Die Vereinigung abzählbar vieler abzählbarer Mengen $A_n$ mit $n \in \N$
  ist wieder abzählbar, d.\,h.
  \begin{gather*}\bigcup_{n \in \N} A_n \coloneqq \{x \colon \exists n \in \N \colon x \in
  A\}\end{gather*}
\begin{proof}
  \begin{gather*}A_n \coloneqq\{a_{nm}\colon m\in \N\} \qquad \varphi_n(m)\coloneqq a_{nm} \qquad
  \varphi_n\colon\N \rightarrow A_n\end{gather*}
\end{proof}
\end{theorem}

\begin{theorem}
  $\R$ ist überabzählbar.
\begin{proof}
  Sei $f\colon\N \rightarrow \R, f(n) = b_n,a_{n1}a_{n2}a_{n3}\ldots$ mit
  $b_n \in \Z$ und  $a_{nk} \in \{0,\ldots ,9\}$.
\begin{gather*}\begin{array}{ccc}
  f(1) & = & b_{1},a_{11}a_{12}a_{13}\ldots\\
  f(2) & = & b_{2},a_{21}a_{22}a_{23}\ldots\\
  f(3) & = & b_{3},a_{31}a_{32}a_{33}\ldots\\
  \vdots & = & \vdots \\
  f(n) & = & b_{n},a_{n1}a_{n2}a_{n3}\ldots
\end{array}\end{gather*}
\begin{gather*}c_n =
\begin{cases}
  1 & \text{falls } a_{nn} \neq 1\\
  2 & \text{falls } a_{nn} = 1
\end{cases}\end{gather*}
Dann ist $c=0,c_{1}c_{2}c_{3}\ldots \in \R$ mit $\forall n \in \N\colon
f(n) \neq c$. Das
$c$ und $f(n)$ unterscheiden sich mindestens in der $n$-ten Stelle
nach dem Komma. Also gilt:
\begin{gather*}\forall f\colon \N \rightarrow \R \colon f(\N) \subset \R\end{gather*}
\end{proof}
\end{theorem}

\chapter{Konvergenz}
\todo{evtl. etwas zum Inhalt des Kapitels schreiben}
\section{Metrische Räume}

\begin{definition}
  Sei $X$ eine nichtleere Menge oder formal $X\neq\emptyset$. Eine Abbildung
  $d\colon X \times X \rightarrow \rsofint{0,\infty}$ heißt \highl{Metrik} oder
  \highl{Abstand} auf $X$, wenn folgende drei Eigenschaften erfüllt sind:
  \begin{enumerate}[(M1)]
  \item $d(x,y)= 0 \Leftrightarrow x=y$ (\highl{Definitheit})
  \item $\forall x,y \in X \colon d(x,y)=d(y,x)$ (\highl{Symmetrie})
  \item $\forall x,y,z \in X \colon d(x,y) \leq d(x,z)+d(z,y)$
    (\highl{Dreiecksungleichung})
  \end{enumerate}
  Das Paar $(X,d)$  heißt \highl[Raum!metrischer]{metrischer Raum}.
\end{definition}

\begin{beispiel}
\begin{enumerate}
\item Sei $(\R,d)$ der metrische Raum der reellen Zahlen mit der
  Betragsmetrik: $d(x,y) \coloneqq \abs{x-y}$. Die drei Eigenschaften lassen sich
  einfach nachweisen.
  \begin{enumerate}[(M1)]
  \item $d(x,y)=\abs{x-y}=0 \Leftrightarrow x=y$
  \item $d(x,y)=\abs{x-y}=\abs{-(x-y)}=\abs{y-x}=d(y,x)$
  \item $d(x,y)=\abs{x-y}=\abs{(x-z)+(z-y)}\leq
    \abs{x-z}+\abs{z-y}=d(x,z)+d(z,y)$
  \end{enumerate}
\item Die reellen Zahlen in der $n$"~ten Dimension bilden mit dem euklidischen
  Abstand einen metrischen Raum $(\R^n,d)$. Dabei ist $\R^n=\R \times \cdots
  \times \R \coloneqq \{x=(\xi_{1}, \ldots ,\xi_{n})\colon\xi_{i} \in \R\},
  x=(\xi_{1},\xi_{2},\ldots ,\xi_{n})$ und $y=(\eta_{1},\eta_{2},\ldots
  ,\eta_{n}) \in \R^n$. Der \highl[Abstand!euklidischer]{euklidischer Abstand}
  ist wie folgt definiert:
  \begin{gather*}d(x,y)=\sqrt{\left( \sum_{i=1}^n \abs{\xi_{i}-\eta_{i}}^2 \right)}\end{gather*}
  Nachweis der Eigenschaften:
  \begin{enumerate}[(M1)]
  \item $d(x,y)=0 \Leftrightarrow \xi_{1}=\eta_{1},\xi_{2}=\eta_{2}, \ldots
    ,\xi_{n}=\eta_{n} \Leftrightarrow x=y$
  \item Man sieht sofort, dass gilt $d(x,y)=d(y,x)$. Denn jeder Summand
    besteht aus der Betragsfunktion. Hier hatten wir bereits gezeigt, dass die
    Eigenschaft (M2) gilt.
  \item Zum Nachweis der Dreiecksungleichung verwenden wir folgende
    Ungleichung:
    \begin{gather*}\sqrt{\sum_{i=1}^n \abs{a_i + b_i}^2} \leq \sqrt{\sum_{i=1}^n
    \abs{a_i}^2} + \sqrt{\sum_{i=1}^n \abs{b_i}^2}\end{gather*}
    Sei $x= (\xi_1 ,\ldots , \xi_n), y= (\eta_1 ,\ldots ,\eta_n)$ und $z=
    (\zeta_1 ,\ldots ,\zeta_n)$. Wir setzen $a_i \coloneqq \xi_i -\zeta_i,
    b_i\coloneqq\zeta_i -\eta_i$. Damit ist $a_i +b_i= \xi_i -\eta_i$ und
    weiter ergibt sich:
    \begin{align*}
      d(x,y) & = \sqrt{\sum_{i=1}^n \abs{\xi_i -\eta_i}^2} =
	 \sqrt{\sum_{i=1}^n \abs{a_i +b_i}^2}\\
      &\leq \sqrt{\sum_{i=1}^n \abs{a_i}^2} + \sqrt{\sum_{i=1}^n \abs{b_i}^2}
	 = \sqrt{\sum_{i=1}^n \abs{\xi_i -\zeta_i}^2} + \sqrt{\sum_{i=1}^n
	 \abs{\zeta_i -\eta_i}^2}\\
      & = d(x,z)+d(y,z)
    \end{align*}

    Die folgenden Ungleichungen sind für die weiteren Beweise und für das
    allgemeine Verständnis der Analysis sehr wichtig. Sie werden uns im
    Verlauf dieser Vorlesung sowie auch in weiteren Vorlesungen immer wieder
    begegnen.
    \begin{description}
    \item[Cauchy-Schwartzsche Ungleichung]\footnote{Augustin Louis Cauchy (*
      1789-08-21, \textdagger 1857-05-23), französischer Mathematiker}
      \footnote{Laurent Schwartz (* 1915-03-05, \textdagger 2002-07-04),
	französischer Mathematiker und Träger der \textsc{Fields}"~Medaille}
      Für alle $n\in\N$ und alle $a_1 ,\ldots ,a_n \in \R$ sowie
      $b_{1},\dotsc, ,b_n \in \R$
      gilt:
      \begin{gather*}
	\abs[\bigg]{\sum_{i=1}^n a_i b_i} \leq \sqrt{\sum_{i=1}^n a_i^2}
	   \sqrt{\sum_{i=1}^n a_i^2}
      \end{gather*}
      \begin{proof}
	Sei $xy \leq\nicefrac{x^2}{2}+\nicefrac{y^2}{2}$ für alle $x,y \geq
	0$. Dann folgt, $2xy\leq x^{2}+y^{2}\Rightarrow0 \leq = x^2-2xy+y^2=
	(x-y)^{2}$. Seien o.\,B.\,d.\,A. $A\coloneqq\sqrt{\sum_{i=1}^n
	\abs{a_i}^2}>0$ und $B\coloneqq\sqrt{\sum_{i=1}^n \abs{b_i}^2}>0$. Wir
	setzen $x_i \coloneqq \nicefrac{\abs{a_i}}{A}$ und  $y_i
	\coloneqq\frac{\abs{b_i}}{B}$.  Dann ist:
      \begin{align*}
        \frac{1}{AB}\abs[\bigg]{\sum_{i=1}^n a_i b_i} &\leq
	   \frac{1}{AB}\sum_{i=1}^n \abs{a_i}\abs{b_i} = \sum_{i=1}^n
	   \frac{\abs{a_i}}{A} \frac{\abs{b_i}}{B} = \sum_{i=1}^n x_i y_i
	   \leq \sum_{i=1}^n \left(\frac{x_i^2}{2}+\frac{y_i^2}{2}\right)\\
	&= \frac{1}{2}\left(\sum_{i=1}^n x_i^2 + \sum_{i=1}^n y_i^2\right) =
	   \frac{1}{2} \left( \sum_{i=1}^n \frac{\abs{a_i}^2}{A^2} +
	   \sum_{i=1}^n \frac{\abs{b_i}^2}{B^2}\right)\\
        & = \frac{1}{2} \left( \frac{1}{A^2} \sum_{i=1}^n \abs{a_i}^2 +
	   \frac{1}{B^2} \sum_{i=1}^n \abs{b_i}^2\right) = \frac{1}{2} \left(
	   \frac{A^2}{A^2} + \frac{B^2}{B^2} \right)  = 1
      \end{align*}
	Wir haben also $\frac{1}{AB}\abs{\sum_{i=1}^{n} a_{i}
	b_{i}\leq1}\Rightarrow \abs{\sum_{i=1}^{n}a_{i} b_{i}}\leq AB=
	\sqrt{\sum\abs{a_{i}}} \sqrt{\sum\abs{b_{i}}}$.
      \end{proof}
    \item[Minkowskische Ungleichung]\footnote{\textsc{Hermann Minkowski} (* 1864-06-22, \textdagger
      1909-01-12), deutscher Mathematiker und Physiker}
      \begin{gather*}\sqrt{\sum_{i=1}^n \abs{a_i + b_i}^2} \leq \sqrt{\sum_{i=1}^n
      \abs{a_i}^2} + \sqrt{\sum_{i=1}^n \abs{b_i}^2}\end{gather*}
      \begin{proof}
	Sei o.\,B.\,d.\,A. $\sum_{i=1}^n \abs{a_i +b_i}^2 > 0$.
      \begin{align*}
        \sum_{i=1}^n \abs{a_i +b_i}^2 & = \sum_{i=1}^n \abs{a_i +b_i} \abs{a_i
	   +b_i} \leq \sum_{i=1}^n (\abs{a_i}+ \abs{b_i}) \abs{a_i +b_i}\\
        & = \sum_{i=1}^n \abs{a_i} \abs{a_i +b_i} + \sum_{i=1}^n \abs{b_i}
	   \abs{a_i +b_i}\\
        & \leq \sqrt{\sum_{i=1}^n \abs{a_i}^2} \sqrt{\sum_{i=1}^n \abs{a_i
	   +b_i}^2} + \sqrt{\sum_{i=1}^n \abs{b_i}^2} \sqrt{\sum_{i=1}^n
	   \abs{a_i +b_i}^2}\\
	& \Rightarrow \sqrt{\sum_{i=1}^n \abs{a_i +b_i}^2} \leq
	   \sqrt{\sum_{i=1}^n \abs{a_i}^2} + \sqrt{\sum_{i=1}^n \abs{b_i}^2}
      \end{align*}
      \end{proof}
    \end{description}
  \end{enumerate}
\item Maximummetrik: $d(x,y)\coloneqq \max_{1 \leq i \leq n}
  \abs{\xi_{i}-\eta_{i}}$
\item Summenmetrik: $d(x,y) \coloneqq \sum_{i=1}^n \abs{\xi_{i}-\eta_{i}}$
\end{enumerate}
  Der Nachweis der Metrikseigenschaften der letzten beiden bleibt dem Leser
  als Übung überlassen.
\end{beispiel}

\subsubsection{Geometrische Interpretation der Metrik im $(\R^2,d)$}

\setlength{\unitlength}{1cm}
\begin{picture}(-10,2.5)
\put(0.5,0.5){\line(3,2){1.5}}
\put(0.5,0.5){\circle*{0.1}}
\put(0.4,0.2){x}
\put(2,1.5){\circle*{0.1}}
\put(1.9,1.2){y}
\put(0,0){\vector(1,0){2.5}}
\put(0,0){\vector(0,1){2.5}}
\end{picture}

Seien $x=(\xi_1 ,\xi_2), y=(\eta_1 ,\eta_2)$ zwei Punkte im $\R^{2}$. Dann ist
$d(x,y)$ die Länge der Strecke zwischen beiden Punkten. Man kann sich die
Punkte als diagonal gegenüberliegende Eckpunkte eines Vierecks vorstellen.
Wenn dieses die Kantenlängen $a$ und $b$ hat, ergibt sich für die Länge nach
dem Satz des Pythagoras: $a^{2}+b^{2}= (d(x,y))^{2}\Rightarrow d(x,y) =
\sqrt{a^{2}+ b^{2}}$.

Die Aussage der Dreiecksungleichung ergibt sich aus der untenstehenden
Abbildung. Sie besagt, dass sich der Abstand zwischen den Punkten $x$ und $y$
verlängert oder bestenfalls gleich bleibt, wenn man die Strecke von $x$ nach
$y$ mit einem "`Umweg"' vermisst: $d(x,y) \leq d(x,z)+d(z,y)$
\begin{picture}(0,3)
\put(8,1){\line(-1,0){5}}
\put(3,1){\line(1,1){2}}
\put(5,3){\line(3,-2){3}}

\put(3,0.7){x}
\put(8,0.7){y}
\put(5,3.3){z}

\put(5,0.7){d(x,y)}
\put(6.4,2.1){d(y,z)}
\put(3.1,2.1){d(x,z)}
\end{picture}

\begin{definition}[Kugel]
  Sei $(X,d)$ ein metrischer Raum mit $a \in X$ und $r \geq 0$. Dann
  ist
  \begin{gather*}B_r(a) \coloneqq \{x \in X \colon d(a,x) \leq r\}\end{gather*}
  eine \highl[Kugel!abgeschlossene]{abgeschlossene Kugel} mit Mittelpunkt $a$
  und Radius $r$ sowie 
  \begin{gather*}\stackrel{\circ}{B_{r}}(a) \coloneqq \{x \in X \colon d(a,x) < r\}\end{gather*}
  eine \highl[Kugel!offene]{offene Kugel} mit Mittelpunkt $a$ und
  Radius $r$.
\end{definition}
Im metrischen Raum der reellen Zahlen $\R^{2}$ versehen mit dem euklidischen
Abstand lässt sich die abgeschlossene Kugel wie folgt interpretieren: Sei
$(a_1,a_2) \in \R^2$. Der Abstand ist definiert als
$d(a,x)=\sqrt{\abs{a_1-x_1}^2+ \abs{a_2-x_2}^2}$. Die abgeschlossene Kugel
besteht dann aus $B_r(a)=\{x \in \R^2 \colon
d(a,x)=\sqrt{\abs{a_1-x_1}^2+ \abs{a_2-x_2}^2} \leq r\}$. Somit ist hier die
Kugel auch im geometrischen Sinne eine Kugel. Sobald andere Metriken
vorliegen, ändert sich auch das Aussehen der Kugel. Diese muss dann keine
Kugel im bekannten Sinne mehr sein.

\section{Folgen}
\begin{definition}
  Sei $X$ eine Menge. Eine Abbildung $a\colon\N \rightarrow X$ heißt
  \highl{Folge}\footnote{Schreibweise: $(a_n)_{n  \in \N}, (a_n),
  (a_n)_{n=1}^\infty,  (a(n))_{n \in \N}, (a_1,a_2,\ldots)$; Verallgemeinert
  kann man auch schreiben: $(a_n)_{n \geq n_0}$ für $n_0 \in \Z$}.
\end{definition}

\begin{beispiel}[reelle Zahlenfolgen]
\begin{align*}
  a_n & = a & \text{\highl[Folge!konstante]{konstante Zahlenfolge}}\\
  a_n & = \nicefrac{1}{n} & \text{\highl{Nullfolge}}\\
  a_n & = (-1)^n & \text{\highl[Folge!alternierende]{alternierende
     Zahlenfolge}}\\
  a_n & = q^n & q \in \R
\end{align*}
\end{beispiel}

\subsection{Konvergente Folgen}
\begin{definition}
  Sei $(X,d)$ ein metrischer Raum. Eine Folge $(a_n) \subset X$ heißt
  genau dann \highl[Folge!konvergente]{konvergent\index{Konvergenz}}, wenn es
  ein $a \in X$ gibt, dass für alle $\varepsilon > 0$ ein $n_{\varepsilon} \in
  \N$ mit der Eigenschaft $d(a,a_n)\leq \varepsilon$ für alle $n \geq
  n_{\varepsilon}$ existiert oder formal:
  \begin{gather*}\exists a \in X\ \forall \varepsilon > 0\ \exists n_{\varepsilon}
  \in \N\ \forall n \geq n_{\varepsilon}\colon d(a,a_n)\leq \varepsilon\end{gather*}
\end{definition}
Man sagt $(a_n)$ konvertiert gegen $a$. Das Gegenteil von konvergenten
Folgen sind \highl[Folge!divergente]{divergente Folgen}.

\todo{eventuell Beispiel einfügen}

Die Konvergenz lässt sich geometrisch so interpretieren, dass in jeder
$\varepsilon$-Kugel $B_{\varepsilon}(a)$ unendlich viele Glieder der Folge
$(a_n)$ liegen und ausserhalb $B_{\varepsilon}(a)$ höchstens endlich viele
Glieder der Folge $(a_n)$ sind.

\begin{theorem}[Grenzwert einer Folge]
  Sei $(a_n) \subset X$ konvergent gegen $a$. Dann ist $a$ eindeutig
  bestimmt und heißt \highl{Grenzwert}\footnote{Schreibweise:
  $\lim_{n\rightarrow \infty} a_n =a, a_n \rightarrow a, (a_n) \rightarrow
  a$} oder \highl{Limes} von $(a_n)$.
  \begin{proof}
    Es ist zu zeigen, wenn $(a_n)$ gegen $b$ und $c$ konvergiert, so ist
    $b=c$. Sei dazu $\varepsilon > 0$. Dann existieren $n_{\varepsilon}^{(1)},
    n_{\varepsilon}^{(2)} \in \N$ mit $d(b,a_n) \leq
    \nicefrac{\varepsilon}{2}$ für $n \geq n_{\varepsilon}^{(1)}$ und
    $d(c,a_n) \leq \frac{\varepsilon}{2}$ für $n \geq n_{\varepsilon}^{(2)}$.
    Wir setzen $n_{\varepsilon} \coloneqq\max\{n_{\varepsilon}^{(1)},
    n_{\varepsilon}^{(2)}\}$. Dann ist $d(b,a_n) \leq\frac{\varepsilon}{2}$
    und $d(c,a_n) \leq\frac{\varepsilon}{2}$ für $n\geq n_{\varepsilon}$. Nach
    der Dreiecksungleichung haben wir $d(b,c) \leq d(b,a_n)+d(a_n,c)
    \leq\nicefrac{\varepsilon}{2} +\nicefrac{\varepsilon}{2}=\varepsilon$ für
    $n\geq n_{\varepsilon}$. Also gilt:
    \begin{gather*}\underbrace{\forall \varepsilon > 0 \colon d(b,c) \leq \varepsilon}_{p}
    \Rightarrow \underbrace{d(b,c)=0}_{q} \Rightarrow a=c\end{gather*}
    wegen der Beziehung $\overline{p \Rightarrow q} \equiv p \wedge
    \overline{q}$ gilt:
    \begin{gather*}\forall \varepsilon >0\colon d(b,c) \leq \varepsilon \wedge d(b,c)>0\end{gather*}
    Wir setzen $\varepsilon \coloneqq \frac{1}{2} d(b,c) >0$. Dann ist
    \begin{gather*}d(b,c) \leq \frac{1}{2} d(b,c) \Rightarrow 1 \leq \frac{1}{2}
    \text{\lightning}\end{gather*}
\end{proof}
\end{theorem}


\paragraph{Teilfolgen}

\begin{definition}
  Sei $X$ eine nichtleere Menge und $(a_{n})\subset X$ eine Folge. Diese heißt
  \begin{itemize}
   \item monoton wachsend, wenn gilt, $a_{n}\leq a_{n+1}$,
   \item streng monoton wachsend, wenn gilt, $a_{n}<a_{n+1}$,
   \item monoton fallend, wenn gilt, $a_{n}\geq a_{n+1}$,
   \item streng monoton fallend, wenn gilt, $a_{n}>a_{n+1}$
  \end{itemize}
\end{definition}

\begin{remark}
  Manchmal wird anstatt der strengen Varianten auch gesagt, monoton nicht
  steigend bzw. monoton nicht fallend.
\end{remark}

\begin{definition}
  Sei $X$ eine nichtleere Menge, $(a_n) \subset X$ eine Folge und $\varphi
  \colon \N \rightarrow \N$ streng monoton wachsend. Dann heißt die Folge
  $(a_{\varphi(k)})_{k \in \N}$ \highl{Teilfolge}\footnote{Schreibweise: $n_k
  \coloneqq \varphi(k), n_1 < n_2 < n_3, (a_{n_k})\subset (a_n)$} von $(a_n)$.
\end{definition}

\begin{theorem}
  Sei $(X,d)$ ein metrischer Raum. Eine Folge $(a_n)$ konvergiert genau dann
  gegen $a \in X$, wenn jede Teilfolge von $(a_n)$ gegen $a$ konvergiert.
  \begin{proof}
\begin{itemize}
\item["`$\Rightarrow$"'] Es ist zu zeigen, dass aus $a_n \rightarrow a$,
  folgt, dass $a_{n_k} \rightarrow a$. 
  Sei $\varepsilon > 0$. Dann existiert $n_{\varepsilon} \in \N$ mit
  $d(a,a_n)<\varepsilon$ für $n \geq n_{\varepsilon}$. Wähle ein
  $k_{\varepsilon} \in \N$ mit $n_{k_{\varepsilon}}\geq n_{\varepsilon}$.
  Für $k \geq k_{\varepsilon} \Rightarrow n_k \geq n_{k_{\varepsilon}}$ und
  aus $d(a,a_{n_k})<\varepsilon \Rightarrow a_{n_k} \rightarrow a$.
\item["`$\Leftarrow$"'] Es ist zu zeigen, dass für alle $(a_{n_k}) \subset
  (a_n)$ mit $a_{n_k} \rightarrow a$ ist. Insbesondere gilt dies für $(a_n)$
  selbst: $a_n \rightarrow a$.
\end{itemize}
\end{proof}
\end{theorem}

\begin{definition}
  Sei $(X,d)$ ein metrischer Raum. Die Folge $(a_n) \subset X$ heißt
  genau dann \highl[Folge!beschränkte]{beschränkt}, wenn gilt:
  \begin{gather*}\exists a \in X\ \exists M \geq 0\ \forall n \in \R \colon d(a,a_n)
  \leq M\end{gather*}
\end{definition}

\begin{theorem}
  \label{satz:beschraenkt}
  Jede konvergente Folge in $(X,d)$ ist beschränkt.
  \begin{proof}
    Sei $a \in X$ der Grenzwert der Folge $(a_n)$. Für $\varepsilon = 1$ gibt
    es ein $n_{\varepsilon} \in \N$, so dass für alle  $n \geq \varepsilon$
    gilt: $d(a_n,a) \leq 1$. Für $M \coloneqq \max\{d(a,a_1),\ldots,
    d(a,a_{n_{\varepsilon}}), 1\}$ und für alle $n\in\N$ gilt $d(a,a_n) \leq
    M$.
\end{proof}
\end{theorem}

\subsection{Sätze über reelle Zahlenfolgen}

Im folgenden sei $X = \R$ und $d(x,y) = \abs{x-y}$  für $x,y \in\R$. Aus dem
vorigen Abschnitt folgt:
\begin{enumerate}
\item $a \in \R$ ist Grenzwert von $(a_n) \subset \R \Leftrightarrow
  \forall \varepsilon > 0\ \exists n_{\varepsilon} \in \N\ \forall
  n \geq n_{\varepsilon}\colon \abs{a_n-a} \leq \varepsilon$
\item Eine konvergente Folge $(a_n) \subset \R$ ist beschränkt,
  d.\,h. es existiert ein $M \geq 0$ mit $\abs{a_n}\leq M$ für alle $n\in\N$.
  Denn sei $a = \lim a_n$. Dann existiert $M_1 \geq 0$ mit $\abs{a-a_n} \leq
  M_1$ für alle $n\in\N$ und es folgt, $\abs{a_n}= \abs{(a_n-a)+a}\leq
  \abs{a_n-a}+ \abs{a}\leq M_1+\abs{a}$. Für $M\coloneqq M_1+ \abs{a}$ gilt
  $\abs{a_n}\leq M$ für alle $n\in\N$.
\end{enumerate}

\begin{remark}
  \begin{enumerate}
  \item Eine Folge $(a_n) \subset \R$ heißt \highl{Nullfolge} $\Leftrightarrow
    \lim a_n =0 \Leftrightarrow \lim \abs{a_n}=0$.
  \item $\lim a_n =a \Leftrightarrow \lim (a_n-a)=0$, d.\,h. $a_n -a$
    ist Nullfolge.
  \end{enumerate}
\end{remark}

\begin{beispiel}
  Die Folge $a_n=\nicefrac{1}{n}$ ist eine Nullfolge. Denn sei
  $\varepsilon > 0$ und wähle $n_{\varepsilon} \in \R$, so dass
  $\nicefrac{1}{n_{\varepsilon}} \leq \varepsilon$. Dann $n \geq
  n_{\varepsilon} \Rightarrow \abs{\nicefrac{1}{n}-0}=\nicefrac{1}{n}\leq
  \nicefrac{1}{n_{\varepsilon}} \leq \varepsilon$.
\end{beispiel}

\paragraph{Rechenregeln für konvergente Folgen}
\begin{theorem}
  \label{satz:rechenregel}
  Seien $(a_n),(b_n) \subset \R$ konvergent, $a\coloneqq\lim a_n$ und
  $b\coloneqq\lim b_n$. Dann:
  \begin{enumerate}
  \item $\lim (a_n +b_n)=\lim a_n+\lim b_n=a+b$
  \item $\lim (a_nb_n)=\lim a_n \lim b_n =ab$
  \item $\lim \left(\frac{a_n}{b_n}\right)=\frac{\lim a_n}{\lim
      b_n}=\frac{a}{b} \text{ falls } b \neq 0 \quad b_n \neq 0$
  \item $\lim \abs{a_n}=\abs{\lim a_n} =\abs{a}$
  \item \highl{Vergleichssatz}:
    $\exists m \in \N \forall n \geq m\colon a_n
    \leq b_n \Rightarrow \lim a_n \leq \lim b_n \Rightarrow a \leq b$
  \item $\exists m \in \N  \forall n \geq m\colon a_n \leq c_n \leq b_n
    \wedge \lim a_n =\lim b_n \Rightarrow (c_n) \text{ konvergent und
    } \lim c_n = \lim a_n$
  \item $\lim \frac{a_1+\cdots +a_n}{n}=\lim a_n$
  \item $a_n>0 \Rightarrow \lim \sqrt[n]{a_1\ldots a_n}=\lim a_n$
  \item $a_n>0, \lim \frac{a_{n+1}}{a_n} \text{ existiert }
    \Rightarrow \sqrt[n]{a_n}=\frac{\lim a_{n+1}}{\lim a_n}$
  \end{enumerate}
\end{theorem}
\begin{proof}
\begin{enumerate}
\item Übung
\item zu zeigen: $\forall \varepsilon >0 \exists n_{\varepsilon}
  \in \N\forall n \geq n_{\varepsilon}\colon a_nb_n-ab=a_n(b_n-b)+(a_n-a)b$\\
  Nach \autoref{satz:beschraenkt} folgt, dass $(a_n)$ beschränkt ist,
  d.\,h. $\exists M \geq 0 \forall n \in \N\colon \abs{a_n} \leq M$. Sei
  $\varepsilon > 0$. Dann existiert $n_0,n_1 \in \N$, so dass $\abs{a-a_n}
  \leq \frac{\varepsilon}{2(\abs{b}+1)}$ für $n \geq n_1$ und $\abs{b-b_n}
  \leq \frac{\varepsilon}{2M}$ für $n \geq n_0$. Für $n \geq
  n_{\varepsilon} = \max \{n_0,n_1\}$ gilt
  \begin{align*}
    \left.
      \begin{array}{rcl}
        \abs{a_n-a} & \leq & \frac{\varepsilon}{2(\abs{b}+1)}\\
        \abs{b_n-b} & \leq & \frac{\varepsilon}{2M}
      \end{array}
    \right\}&
    \forall n \geq n_{\varepsilon}\\
    \abs{a_nb_n-ab} & \leq \abs{a_n}\abs{b_n-b}+\abs{a_n-a}\abs{b} &\leq M
    \frac{\varepsilon}{2M}+\frac{\varepsilon}{2(\abs{b}+1)}\abs{b}\\
    & \leq \frac{\varepsilon}{2}+\frac{\varepsilon}{2}=\varepsilon
  \end{align*}
\item Seien $b$ und $ b_n \neq 0$. Man zeigt zunächst: $\lim
  \nicefrac{1}{b_n}=\nicefrac{1}{\lim b}=\nicefrac{1}{b}$. Aus der
  Tatsache, dass $\exists n_0 \forall n \geq n_0 \colon \abs{b_n-b}\leq
  \nicefrac{\abs{b}}{2}$ für $b\neq 0$ folgt nach der Dreiecksungleichung,
  dass $\abs{b}-\abs{b_n} \leq \abs{b_n-b} \leq \nicefrac{\abs{b}}{2}$ für $n \geq
  n_0$. Daraus kann man nun für alle $n\geq n_0$ schließen, dass
  $\nicefrac{\abs{b}}{2} \leq \abs{b_n}$\\
  Sei $\varepsilon > 0$. Dann $\exists n_1 \in \N \colon \abs{b_n-b} \leq
  \frac{\varepsilon \abs{b}^2}{2}$ und für $n \geq \max \{n_0,n_1\}$
  gilt:
  \begin{gather*}
    \abs{\frac{1}{b_n}-\frac{1}{b}}
    =\frac{\abs{b_n-b}}{\abs{b_n} \abs{b}}\leq \frac{\varepsilon
    \nicefrac{\abs{b}^2}{2}}{\nicefrac{\abs{b}}{2}\abs{b}}=\varepsilon
  \end{gather*}
  Damit ist nach Regel~2 $\lim \frac{a_n}{b_n}=\frac{\lim a_n}{\lim b_n}$.
\item Sei $\varepsilon > 0$. Dann $\exists n_{\varepsilon} \in
  \N\colon\abs{a_n-a}< \varepsilon \forall n \geq n_{\varepsilon}$. Nach der
  Dreiecksungleichung folgt für alle $n\geq n_\varepsilon\colon
  \abs{\abs{a_n}-\abs{a}} \leq \abs{a_n-a} < \varepsilon \Rightarrow
  \lim \abs{a_n} =\abs{a}$.
\item Annahme: $\lim a_n > \lim b_n$. Dann ist $\varepsilon =
  \nicefrac{a-b}{2}$ und es existieren $n_0,n_1 \in \N$, so dass
  $\abs{a_n-a} < \varepsilon$ für $n \geq n_0$ und $\abs{b_n-b} < \varepsilon$
  für $n \geq n_1$. Wir definieren $n_{\varepsilon} \coloneqq \max
  \{n_0,n_1\}\colon\abs{a_n-a}<\varepsilon, \abs{b_n-b}<\varepsilon$. Insbesondere
  da $\varepsilon = \nicefrac{a-b}{2}$ ist, folgt für alle $n\geq n_0\colon
  a-\varepsilon = b + \nicefrac{a-b}{2}= \nicefrac{a+b}{2}<a_n$ und
  $b_n<b+\varepsilon=\nicefrac{a+b}{2}$
  $\Rightarrow b_n < a_n \quad \forall n \geq n_{\varepsilon}$\lightning\\
  \qed
\item Sei $\varepsilon > 0$. Dann $\exists n_0, n_1 \in \N$,
  $\abs{a_n-a}<\varepsilon$ und $\abs{b_n-a}<\varepsilon$. Sei
  $n_{\varepsilon}\coloneqq \max \{n_0,n_1\}$.
  \begin{align*}
    a-\varepsilon &\leq a_n \leq c_n \leq b_n \leq a+\varepsilon\\
    &\Rightarrow \abs{c_n-a} \leq \varepsilon & \forall n \geq n_{\varepsilon}\\
    &\Rightarrow \lim c_n = a
  \end{align*}
\end{enumerate}
\end{proof}

\begin{beispiel}
  Sei $q \in \R$ und $a_n \coloneqq q^n$.
  \begin{gather*}\lim q^n =
  \begin{cases}
    0 \qquad \abs{q} < 1\\
    1 \qquad q = 1\\
    divergent \qquad & \abs{q}>1 \vee q=-1
  \end{cases}\end{gather*}
\begin{proof}
  \begin{enumerate}[1.~F{a}ll]
  \item $q=0 \Rightarrow q^n=0 \Rightarrow \lim q^n=0$
  \item $0<\abs{q}<1$\\
    Man setzt:
    \begin{align*}
      h &\coloneqq \nicefrac{1}{\abs{q}}-1>0\Rightarrow \abs{q} =
      \frac{1}{1+h}\\
      0 &<\abs{q}^n = \frac{1}{(1+h)^n} \leq \frac{1}{1+nh} \leq
      \frac{1}{nh}
    \end{align*}
    Nach \autoref{satz:rechenregel} Punkt~6 folgt damit, $\lim \abs{q}^n=0
    \Rightarrow \lim q^n=0$.
  \item $q=1 \Rightarrow q^n =1 \Rightarrow \lim q^n=1$
  \item $q=-1$\\
    $a_n=q^n=(-1)^n$ ist divergent. Angenommen, es existiert ein $a
    \in \R \colon a_n \rightarrow a$. Für $\varepsilon=\nicefrac{1}{2}
    \Rightarrow \exists n_0 \in \N \forall n \geq n_0 \colon
    \abs{a_n-a}<\nicefrac{1}{2}$. Somit gilt:
    \begin{align*}
      a_{n+1}-a_n& = (-1)^{n+1}-(-1)^n = (-1)^n(-1)-(-1)^n =
      (-1)^n(-2)\\ \
      \abs{-2}=2 &= \abs{a_{n+1}-a_n} \leq \abs{a_{n+1}-a} + \abs{a-a_n} \leq
      \nicefrac{1}{2} +\nicefrac{1}{2}=1
    \end{align*}
    für $n \geq n_0$ \lightning
  \item $\abs{q}>1$\\
    Annahme: $q^n$ ist konvergent. Dann ist nach
    \autoref{satz:beschraenkt} $q^n$ beschränkt, d.\,h. $\exists M >
    0 \forall n \in \N \colon \abs{q^n} \leq M \Rightarrow M \geq
    \abs{q^n} = \abs{q}^n
    =\underbrace{(1+\abs{q}-1)^n}_{>0} \geq 1+n(\abs{q}-1) \geq n(\abs{q}-1)$\\
    $\Rightarrow n \leq \frac{M}{\abs{q}-1} \Rightarrow \N$ ist beschränkt
    \lightning
\end{enumerate}
\end{proof}
\end{beispiel}

\begin{remark}
  \emph{Bestimmte
    Divergenz\index{Divergenz!bestimmte}}\footnote{Schreibweise: $\lim
    a_n = +\infty \qquad a_n \rightarrow \infty$\\} (=uneigentliche
  Konvergenz\index{Konvergenz!uneigentliche}) gegen $+\infty$ bzw.
  $-\infty$: Eine Folge $(a_n) \subset \R$ heißt \emph{bestimmt
    divergent} gegen $+\infty\ (-\infty) \perdef \forall M
  \in \R  \exists n_M \in \N  \forall n \geq n_M \colon a_n \geq M (a_n
  \leq M)$
\end{remark}

\begin{beispiel}
\begin{align*}
  a_n& =n & \lim a_n &=\infty\\
  a_n &=-n  & \lim a_n &=-\infty\\
  a_n &=(-1)^n & \text{nicht bestimmt divergent}
\end{align*}
\end{beispiel}

\begin{remark}
  $\infty$ ist keine relle Zahl. Denn wäre $\infty$ eine reelle Zahl,
  so würde für die Folgen $a_n=a$ und $b_n=1$ gelten, dass $\lim
  (a_n+b_n) = \lim a_n + \lim b_n\Rightarrow\infty=\lim(n+1)=\lim n +
  \lim 1 = \infty +1 \Rightarrow 0=1$ \lightning.
\end{remark}

\subsubsection{Monotone Folgen}
\begin{definition}[monotone Folgen] Eine Zahlenfolge $(a_n) \subset \R$
  heißt \emph{monoton wachsend (fallend)}\index{monoton}
  \index{Folge!monotone} $\perdef \forall n,m \in \N\colon n<m \Rightarrow a_n
  \leq a_m (a_n \geq a_m)$.
\end{definition}

\begin{theorem}
  \label{satz:monotoneFolge}
  \begin{enumerate}
  \item Für eine monoton wachsende und nach oben beschränkte Folge
    $(a_n) \subset \R$ gilt: $\lim a_n = \sup \{a_n\}$
  \item Für eine monoton fallende und nach unten beschränkte Folge $(a_n)
    \subset \R$ gilt: $\lim a_n = \inf \{a_n\}$
  \end{enumerate}
\end{theorem}
\begin{proof}
\begin{enumerate}
\item Sei $a \coloneqq \sup \{a_n\} \in \R$. Dies existiert nach dem
  Vollständigkeitsaxiom. Sei $\varepsilon > 0$. Dann existiert ein
  $n_{\varepsilon} \in \N \colon a-\varepsilon < a_{n_{\varepsilon}}$. Für
  $n \geq n_{\varepsilon} \colon a-\varepsilon \leq a_{n_{\varepsilon}}
  \leq a_n \leq a+\varepsilon\Rightarrow \abs{a_n-a} \leq \varepsilon$ für
  $n \geq n_{\varepsilon} \Rightarrow \lim a_n= \sup \{a_n\}$
\item Der Beweis erfolgt analog zum ersten Fall.
\end{enumerate}
\end{proof}
%%Hier weiter das Skript anpassen.

\begin{beispiel}
\begin{align*}
  \lim_{n \rightarrow \infty} \sum_{k=0}^n \frac{1}{k!} &= e & a_n=
  1+1+\frac{1}{2!}+\frac{1}{3!}+\cdots + \frac{1}{n!}\\
  \lim_{n \rightarrow \infty} \left(1+\frac{1}{n}\right)^n &= \lim_{n \rightarrow
    \infty} \sum_{k=0}^n \frac{1}{k!}=e
\end{align*}
\end{beispiel}
\begin{proof}
\begin{enumerate}
  \item Zeigen $a_n$ ist beschränkt und monoton wachsend\\
    Monotonie: klar, $a_n \geq a_{n+1}$\\
    Beschränkt: Es gilt, $a_n \leq 3$
    \begin{align*}
      a_n& = 1+1+\frac{1}{2!}+\frac{1}{3!}+\cdots + \frac{1}{n!}\\
      & \leq 1+ 1+ \left(\frac{1}{2}\right)^1
      +\left(\frac{1}{2}\right)^2 +\cdots + \left( \frac{1}{2} \right)^{n-1}\\
      & = 1+ \frac{1-\left(\frac{1}{2}\right)^n}{1-\frac{1}{2}} \leq
      1+\frac{1}{\frac{1}{2}} = 3\\
      &\Rightarrow \lim a_n = \lim_{n \rightarrow \infty}
      \left(\sum_{k=0}^n \frac{1}{k!}\right) \text{ existiert}
  \end{align*}
  \item \begin{gather*}\left(1+\frac{1}{n}\right)^n = \sum_{k=0}^n \binom{n}{k}\frac{1}{n}^k
    1^{n-k} = \sum_{k=0}^n \binom{n}{k} \frac{1}{n^k}\end{gather*}
    \begin{align*}
    \binom{n}{k} \frac{1}{n^k} & = & \frac{n(n-1)\ldots(n-k+1)}{k!}\frac{1}{n^k}\\
    & = & \frac{n}{n} \frac{n-1}{n} \cdots \frac{n-k+1}{n} \frac{1}{k!}\\
    & = & \left(1-\frac{1}{n}\right)\left(1-\frac{2}{n}\right) \cdots \left(1-
    \frac{k-1}{n}\right) \frac{1}{k!}
    \end{align*}
    $\Rightarrow \lim_n \binom{n}{k} \frac{1}{n^k}=\frac{1}{k!}$ Ferner:
    $\binom{n}{k} \frac{1}{n^k} < \binom{n+1}{k} \frac{1}{(n+1)^k}$\\
    Also gilt: \begin{gather*}\left(1+\frac{1}{n}\right)^n<\left(1+\frac{1}{n+1}\right)^{n+1}
    \leq \sum_{k=0}^{n+1} \frac{1}{k!} \leq 3\end{gather*}
    $\Rightarrow \lim \left(1+\frac{1}{n}\right)^n$ existiert. Fixieren $l<n$.
    Dann gilt:\\
    $\lim_{n \rightarrow \infty} \sum_{k=0}^l \binom{n}{k} \frac{1}{n^k}
    = \sum_{k=0}^l \lim_{n \rightarrow \infty} \binom{n}{k} \frac{1}{n^k} = 
    \sum_{k=0}^l \frac{1}{k!}$\\
    wegen $\sum_{k=0}^l \binom{n}{k} \frac{1}{n^k}
    \leq \sum_{k=0}^n \binom{n}{k} \frac{1}{n^k}=\left( 1+\frac{1}{n}\right)^n
    \leq \sum_{k=0}^n \frac{1}{k!}$\\
    $\overset{n \rightarrow \infty}{\Rightarrow}\sum_{k=0}^l \frac{1}{k!} \leq
    \lim_n \left(1+\frac{1}{n}\right)^n \leq \lim_n \sum_{k=0}^n \frac{1}{k!}$\\
    $\overset{l \rightarrow \infty}{\Rightarrow} \lim_{l \rightarrow \infty}
    \sum_{k=0}^l \frac{1}{k!} = \lim_{n \rightarrow \infty} \left(1+\frac{1}{n}
    \right)^n$
\end{enumerate}
\end{proof}

\begin{theorem}[Intervallschachtelung]
  \label{satz:Ischachtelung}
  Seien $I_n=[a_n,b_n]$ mit $n \in \N$ abgeschlossene Intervalle, so
  dass $I_{n+1} \subset I_n$ und $\lim_{n \rightarrow \infty}
  (b_n-a_n)=0$. Dann gilt: Es existiert genau ein Punkt $a \in \R$:
  \begin{gather*}\bigcap_{n=1}^{\infty} I_n = \{a\}\end{gather*}
\end{theorem}
\begin{proof}
  Für alle $n,m \in \N$ mit der Eigenschaft $a_n \leq b_m$ ist $a_n $
  monoton wachsend und $b_m$ monoton fallend. Dann gilt wegen $\lim
  (b_n-a_n)=0$, dass der Limes von $a_n$ kleiner bzw. gleich als der
  Limes von $b_m$ ist. Weiter folgt $\lim b_n = \lim
  (b_n-a_n+a_n)=\lim(b_n-a_n)+\lim a_n=\lim a_n=:a$ und
  \begin{gather*}\Rightarrow \forall n \in \N \colon a_n \leq a \leq b_n \Rightarrow a \in
  \bigcap I_n\end{gather*}
  Zu zeigen ist noch, dass $a$ einziger Punkt in
  $\bigcap_{n=1}^\infty$ ist. Sei $a,b \in \bigcap I_n$
\begin{align*}
  \Rightarrow a_n \leq a,b \leq b_n & \Rightarrow 0 \leq \abs{a-b} \leq
  \underbrace{b_n-a_n}_{0} & \Rightarrow a = b
\end{align*}
\end{proof}

\subsection{Häufungspunkte von Folgen in metrischen Räumen}

Der Begriff \emph{Häufungspunkt\index{Häufungspunkt}} einer Folge kann
als eine Verallgemeinerung des Begriffs Grenzwert verstanden werden.

\begin{definition}[Häufungspunkt einer Folge]
  Sei $(X,d)$ ein metrischer Raum und $(a_n) \subset X$ eine
  Folge. Ein Punkt $a \in X$ heißt
  \emph{Häufungspunkt\index{Häufungspunkt}} von $(a_n)
  \perdef \forall \varepsilon > 0 \forall m \in \N
  \exists n>m\colon d(a,a_n) \leq \varepsilon$
\end{definition}

\textbf{geometrische Interpretation} In jeder $\varepsilon$-Kugel
$B_\varepsilon (a)$ liegen unendlich viele Glieder der Folge
$(a_n)$. Ausserhalb können ebenfalls unendlich viele liegen.

\begin{theorem}
\label{satz:hp}
\begin{enumerate}
\item $a\in X$ ist genau dann Häufungspunkt von $(a_n) \subset X$,
  wenn eine Teilfolge $(a_{n_k})\subset (a_n)$ mit der Eigenschaft
  $\lim a_{n_k}=a$ existiert.
\item Jede konvergente Folge besitzt genau einen Häufungspunkt und
  zwar den Grenzwert.
\end{enumerate}
\end{theorem}

\textbf{Beweis}:
\begin{enumerate}
  \item
    \begin{itemize}
      \item[$\Rightarrow$] $\varepsilon_k\coloneqq\frac{1}{k}, k \in \N$\\
        $\left.
	\begin{array}{lll}
	  \varepsilon_1=1\ m=1 \exists n_1>1\colon d(a,a_{n_1}) & \leq & 1\\
	  \varepsilon_2=\frac{1}{2}\ m = n_1 \exists n_2 >n_1\colon
	  d(a,a_{n_2}) & \leq & \frac{1}{2}\\
	  \quad \vdots \qquad \vdots \qquad \vdots & & \vdots\\
	  \varepsilon_k=\frac{1}{k}\ m=n_{k-1} \exists n_k > n_{k-1}\colon
	  d(a,a_{n-k}) & \leq & \frac{1}{k}
	\end{array}
	\right\} \Rightarrow$\\
	$\Rightarrow (a_{n_k})\subset (a_n)\colon\lim a_{n_k}=a$
      \item[$\Leftarrow$] Sei $\varepsilon > 0$ und $k \in \N \Rightarrow \exists n_k>k\colon d(a,a_{n_k})\leq \varepsilon$
    \end{itemize}
    \qed
  \item Sei $\lim a_n =a \overset{(1)}{\Rightarrow} a$ ist Häufungspunkt von $(a_n)$\\
    Eindeutigkeit des Häufungspunktes: Sei $b$ ebenfalls Häufungspunkt von $(a_n)$
    \begin{gather*}\overset{(1)}{\Rightarrow} \exists \text{ Teilfolge } (a_{n_k})\subset (a_n)\colon\lim_{k\rightarrow \infty}a_{n_k}=b\end{gather*}
    Da jede Teilfolge einer konvergenten Folge den gleichen Grenzwert hat, gilt $b=a$. \qed
\end{enumerate}

\textbf{Beispiel} $X=\R \quad d=\abs{\cdot} \quad a_n=(-1)^n$ besitzt die Häufungspunkte -1 und +1. Denn $a_{2n}=(-1)^{2n}
=1\rightarrow 1$ und $a_{2n+1}=(-1)^{2n+1}=-1\rightarrow -1$. Aber $(a_n)$ ist nicht konvergent.

\subsection[Häufungspunkte von reellen Zahlenfolgen\texorpdfstring{\\}{} und der Satz von Bolzano/Weierstrass]{Häufungspunkte von reellen Zahlenfolgen und der Satz von Bolzano/Weierstrass}
\begin{lemma}
\label{lemma:bw}
Jede reelle Zahlenfolge $(a_n) \subset \R$ enthält eine monotone Teilfolge.
\end{lemma}
\begin{proof}
  Sei $(a_n) \subset \R$. Setzen $M\coloneqq\{k \in \N \colon \forall n \in \N
  \colon a_{k+n}\leq a_k\}$
  \begin{enumerate}[1. F{a}ll]
  \item $M$ ist unendlich. $M=\{n_k\colon n_1<n_2<n_3<\ldots\}$
    \begin{align*}
      n_1 \in M & \Rightarrow \forall n \in M\colon a_{n_1}\geq a_{n_1+n} &
      \Rightarrow a_{n_1} \geq a_{n_2}\\
      n_2 \in M & \Rightarrow \forall n \in M\colon a_{n_2}\geq a_{n_2+n} &
      \Rightarrow a_{n_2} \geq a_{n_3}\\
      \vdots &\qquad \vdots & \Rightarrow \vdots\\
      a_{n_1} &\geq a_{n_2}\geq a_{n_3} &\geq \ldots
    \end{align*}
  \item $M$ ist endlich und $M \neq \emptyset$. Dann $\sup M = \max
    M$. Für $n_1>k \Rightarrow n_1 \notin M$, d.\,h.
    $\exists m_1 \in \N \colon a_{n_1+m_1}>a_{n_1}$. Setzen $n_2 \coloneqq n_1
    +m_1$. Dann $n_2>n_1 \wedge a_{n_2} > a_{n_1}$\\
    $n_2>n_1>k \Rightarrow n_2 \notin M$, d.\,h. $\exists m_2 \in \N \colon
    a_{n_2+m_2}$. Setzen $n_3\coloneqq n_2+m_2 \Rightarrow
    n_3>n_2 \wedge a_{n_3}>a_{n_2}$\\
    $a_{n_1}<a_{n_2}<a_{n_3}<\ldots$
  \item $M=\emptyset$, d.\,h. $\forall k \in \N \exists n \in \N \colon
    a_{k+n}>a_k$ siehe 2. Fall
\end{enumerate}
\end{proof}

\begin{theorem}[Satz von Bolzano/Weierstrass\index{Bolzano/Weierstrass!Satz von}]
\label{satz:bw}
Jede beschränkte Folge $(a_n)\subset \R$ besitzt einen
Häufungspunkt\index{Häufungspunkt}.
\end{theorem}
\begin{proof}
  Aus dem \autoref{lemma:bw} folgt: Es existiert eine Teilfolge
  $(a_{n_k})\subset (a_n)$. $(a_{n_k})$ ist monoton und
  beschränkt. Daraus folgt nach \autoref{satz:monotoneFolge}: $\lim
  a_{n_k}=a \in \R$ und \autoref{satz:hp} legt den Schluss nahe, dass
  $a$ Häufungspunkt ist.
\end{proof}

\textbf{Folgerung} Eine Zahlenfolge in $\R$ ist genau dann konvergent, wenn sie beschränkt ist und höchstens einen Häufungspunkt besitzt.

\paragraph{Limes superior\index{Limes superior} und Limes inferior\index{Limes inferior}}
\begin{definition}
Sei $(a_n) \subset \R$. Dann heißt $\lim_{n\rightarrow \infty} \sup a_n\coloneqq\lim(\sup\{a_k\colon k\geq n\})$\emph{Limes superior} und $\lim \inf a_n \coloneqq 
\lim (\inf\{a_k\colon k\geq n\})$ \emph{Limes inferior}.
\end{definition}

Schreibweise: $\overline{\lim}=\lim \sup \qquad \underline{\lim}=\lim \inf$

Beispiel: $a_n=(-1)^n \quad \sup \{(-1)^k\colon k\geq n\}=1 \Rightarrow \lim \sup (-1)^n=1$\\
$\inf\{(-1)^k\colon k\geq n\} \Rightarrow \lim \inf (-1)^n=-1$

\begin{remark}
Die Folge $b_n\coloneqq\sup \{a_k\colon k\geq n\}$ ist monoton fallend oder $+\infty$. Die Folge $c_n\coloneqq\inf\{a_k\colon k\geq n\}$ ist
monoton wachsend oder $-\infty$. Daher existieren $\lim\sup a_n=\lim b_n$ und $\lim \inf a_n=\lim c_n$ immer eigentlich
oder uneigentlich, d.\,h. es gilt $\lim \sup a_n \in \R$ oder $\lim \sup a_n=+\infty/-\infty$ und 
$\lim \inf a_n \in \R$ oder $\lim \inf a_n=+\infty/-\infty$.
\end{remark}

\begin{theorem}
Sei $(a_n) \subset \R$ beschränkt. Dann ist $\overline{\lim} a_n$ grösster
  Häufungspunkt von $(a_n)$ und $\underline{\lim} a_n$ kleinster Häufungspunkt
  von $(a_n)$.
\end{theorem}

\textbf{Beweis} Nach dem \autoref{satz:bw} (Satz von Bolzano/Weierstrass) besitzt $(a_n)$ einen Häufungspunkt.
\begin{gather*}\inf \{a_n\}\leq \overline{\lim}\ a_n \leq \sup \{a_n\}\end{gather*}
\begin{enumerate}[1. Schr{i}tt]
  \item Zu zeigen: $a=\overline{\lim}\ a_n$ ist Häufungspunkt von $(a_n)$\\
    Setzen $b_n\coloneqq\sup \{a_k\colon k\geq n\}$ ist monoton fallend und nach unten beschränkt. Daraus folgt nach
    \autoref{satz:monotoneFolge}: $a=\lim b_n=\inf \{b_n\}=\overline{\lim}\ a_n$\\
    Für $k \in \N \exists m_k \in \N \colon a\leq b_{m_k}<a+\frac{1}{k}\Rightarrow \exists n_k\geq m_k\colon b_{m_k}-\frac{1}{k}
    <a_{n_k}\leq b_{m_k}$\\
    $\Rightarrow a-\frac{1}{k}\leq b_{m_k}-\frac{1}{k}<a_{n_k}<a+\frac{1}{k}$\\
    $\Rightarrow a-\frac{1}{k}<a_{n_k}<a+\frac{1}{k}$\\
    $\Rightarrow \lim_{k\rightarrow \infty} a_{n_k}=a\stackrel{\text{\autoref{satz:hp}}}{\Longrightarrow} a$ ist Häufungspunkt 
    von $(a_n)$
  \item $a$ ist grösster Häufungspunkt von $(a_n)$. Sei $a'$ Häufungspunkt von $(a_n)\stackrel{\text{\autoref{satz:hp}}}
    {\Longrightarrow} \exists \text{Teilfolge } (a_{n_k})\colon\lim a_{n_k}=a'$\\
    $b_{n_k}=\sup \{a_l\colon l\geq n_k\} \geq a_{n_k}\Rightarrow a=\lim b_{n_k}\geq \lim a_{n_k}=a'$
\end{enumerate}
\qed

\subsection{Cauchyfolgen}
\begin{definition}
Sei $(X,d)$ ein metrischer Raum. Eine Folge $(a_n) \subset X$ heißt \emph{Cauchy\-fol\-ge}\index{Cauchyfolge} $\perdef$
\begin{gather*}\forall \varepsilon > 0 \exists n_{\varepsilon}\in \N \forall n,m \geq
  n_{\varepsilon}\colon d(a_n,a_m)\leq \varepsilon\end{gather*}
\end{definition}

\begin{theorem}
\label{satz:cf}
Sei $(X,d)$ ein metrischer Raum und $(a_n)\subset X$ eine konvergente Folge.
  Dann ist $(a_n)$ eine Cauchyfolge.\\
\textbf{Beweis} Sei $a=\lim a_n$ und $\varepsilon>0$. Dann existiert
  $n_{\varepsilon}\in \N \forall n\geq n_{\varepsilon}
\colon d(a,a_n)\leq \frac{\varepsilon}{2}$ . Für $n,m\geq n_{\varepsilon}\colon d(a_n,a_m)\leq d(a_n,a)+d(a,a_m)=\frac{\varepsilon}{2}
+\frac{\varepsilon}{2}=\varepsilon \Rightarrow a_n$ ist eine Cauchyfolge.\qed
\end{theorem}

\begin{remark}
In einem beliebigen metrischen Raum ist \emph{nicht} jede Cauchyfolge konvergent.\\
\textbf{Beispiel}: $(\Q,\abs{\cdot })$ ist ein metrischer Raum. $a_{n+1}=\frac{1}{2}(a_n+\frac{2}{a_n})\quad a_0\coloneqq1$\\
$(a_n)\subset \Q, \lim a_n =\sqrt{2}\notin \Q$
\end{remark}

\begin{theorem}[Cauchysches Konvergenzkriterium in $\R$\index{Konvergenzkriterium!Cauchysches}]
\label{satz:CKonv}
 Eine Folge $(a_n)\subset \R$ 
ist genau dann konvergent, wenn sie eine Cauchyfolge ist.
\end{theorem}
\textbf{Beweis}
\begin{itemize}
  \item["`$\Rightarrow$"'] siehe \autoref{satz:cf}
  \item["`$\Leftarrow$"'] Sei $(a_n)\subset \R$ eine
    Cauchyfolge. $(a_n)$ ist beschränkt für $\varepsilon=1$
    \begin{align*}
      & \exists n_1\in \N \forall n,m >n_1 \colon&\abs{a_n-a_m}\leq\varepsilon =1\\  
      &\Rightarrow \abs{a_n}=\abs{a_n-a_m+a_m}\leq \abs{a_n-a_m}+\abs{a_m}\leq 1+\abs{a_m}
      & \text{ für } n,m\geq n_1
    \end{align*}
    Für $M=\max\{\abs{a_1},\abs{a_2},\ldots, \abs{a_m}, 1+\abs{a_m}\}$ gilt $\abs{a_n}\leq
    M \forall n \in \N$. Nach dem Satz von Bolzano/Weierstrass
    (\autoref{satz:bw}) gilt: $\exists$ Teilfolge $(a_{n_k})\subset
    (a_n)\colon a_{n_k}$ ist konvergent mit $a\coloneqq\lim_{k\rightarrow \infty}
    a_{n_k}$.\\
    Sei $\varepsilon>0$. Dann existiert $k_{\varepsilon}, n_{\varepsilon} \in \N \colon\abs{a_{n_k}-a}\leq \frac{\varepsilon}{2}$
    für $k\geq k_{\varepsilon}$\\
    $\abs{a_n-a_m}\leq \frac{\varepsilon}{2}$ für $n,m \geq n_{\varepsilon}$. Wähle $n_{k_0}\geq \{\max n_{k_{\varepsilon}},
    n_{\varepsilon}\}$. Dann gilt für $n\geq n_{k_0}\colon\abs{a_n-a}=\abs{a_n-a_{n_{k_0}}+a_{n_{k_0}}-a}\leq 
    \abs{a_n-a_{n_{k_0}}}+\abs{a_{n_{k_0}}-a}\leq \frac{\varepsilon}{2}+\frac{\varepsilon}{2}=\varepsilon \Rightarrow (a_n)$
    ist konvergent.
\end{itemize}
\qed

\begin{remark}
Um die Konvergenz einer Folge in $\R$ nachzuweisen, genügt es, zu zeigen, dass die Folge Cauchyfolge ist. Dabei braucht 
man den Grenzwert nicht zu kennen.
\end{remark}

\subsection{Vollständigkeit und kompakte metrische Räume}

\begin{theorem}
In $\R$ sind folgende Aussagen äquivalent:
\begin{enumerate}[(1)]
  \item \textbf{Vollständigkeitsaxiom\index{Vollständigkeitsaxiom}}: Jede nichtleere nach oben beschränkte Menge besitzt
    ein Supremum\index{Supremum}.
  \item \textbf{Satz über monotone Folgen\index{monotone Folgen!Satz über}}: Nach \autoref{satz:monotoneFolge} Jede 
    nach oben beschränkte mo\-no\-ton wachsende Folge besitzt einen Grenzwert.
  \item \textbf{Satz von Bolzano/Weierstrass\index{Bolzano/Weierstrass!Satz von}}: Jede beschränkte Folge hat eine 
    konvergente Teil\-fol\-ge.
  \item Jede Cauchyfolge hat einen Grenzwert.
  \item Intervallschachtelungsprinzip (\autoref{satz:Ischachtelung})
\end{enumerate}
\end{theorem}
\textbf{Beweis}
\begin{itemize}
  \item[(1)$\Rightarrow$(2)] $\lim (a_n)=\sup \{a_n\}$ nach \autoref{satz:monotoneFolge}
  \item[(2)$\Rightarrow$(3)] siehe Beweis zu \autoref{satz:bw}
  \item[(3)$\Rightarrow$(4)] siehe Beweis zu \autoref{satz:CKonv}
  \item[(4)$\Rightarrow$(5)] zu zeigen: Sei $I_n=[a_n,b_n]$ eine Intervallschachtelung $\Rightarrow \bigcap I_n=\{s\}$\\
    $\forall n,m \in \N$ gilt:$\left.
    \begin{array}{lll}
      (a_n) \text{ monoton fallend }\\
      (b_n) \text{ monoton wachsend }
    \end{array}
    \right\} \Rightarrow b_n-a_n\rightarrow 0$\\
    $n\geq m =\abs{a_n-a_m}=a_n-a_m\leq b_m-a_m$\\
    Sei $\varepsilon>0$. Dann $\exists m_{\varepsilon} \in \N\ m\geq m_{\varepsilon}\colon b_m-a_m\leq \varepsilon$\\
    $\Rightarrow \forall n,m \colon n\geq m \geq m_{\varepsilon}\Rightarrow \abs{a_n-a_m}\leq \varepsilon$, d.\,h. $(a_n)$ ist
    Cauchyfolge.\\
    $\Rightarrow \lim a_n = s \in \R$\\
    Ferner $\lim b_n =\lim ((b_n-a_n)+a_n)=\lim (b_n-a_n)+\lim a_n = 0+s=s$. Ausserdem $\forall n \in \N \colon a_n\leq s\leq 
    b_n \Rightarrow s \in \bigcap_{n=1}^{\infty}I_n$\\
    Eindeutigkeit von $s$ wie im Beweis von \autoref{satz:Ischachtelung}
  \item[(5)$\Rightarrow$(1)] zu zeigen: Sei $\emptyset \neq M \subset \R$ nach oben beschränkt. $\Rightarrow \sup M 
    \subset \R$\\
    Sei $b \in \R$ obere Schranke und $a \in M$
    \begin{enumerate}[1. F{a}ll]
      \item $a$ ist obere Schranke von $M \Rightarrow a = \sup M$
      \item $a$ ist keine obere Schranke von $M$. Wir setzen $a_1\coloneqq a,
      b_1\coloneqq b$ und bilden das Mittel $\frac{a_1+b_1}{2}$
      \begin{enumerate}[{2}.1. F{a}ll]
        \item $\frac{a_1+b_1}{2}$ ist obere Schranke von $M$, so setzen wir
	$a_2\coloneqq a_1, b_2\coloneqq\frac{a_1+b_1}{2}$
	\item $\frac{a_1+b_1}{2}$ ist keine obere Schranke $\Rightarrow M \cap [\frac{a_1+b_1}{2},b_1]\neq \emptyset$
	  Wählen $a_2 \in M \cap [\frac{a_1+b_1}{2},b_1]$ und $b_2\coloneqq b_1$. In beiden Fällen gilt, dass $M\cap [a_2,b_2]
	  \neq \emptyset$ und $b_2-a_2\leq b_1-\frac{a_1+b_1}{2}=\frac{a_1-b_1}{2}$. Führen wir diese Prozedur fort, so
	  erhalten wir Intervalle $[a_n,b_n]$ mit $a_n \in M$ und $b_n$ obere Schranke von $M$.\\
	  $b_n-a_n\leq \frac{a_{n-1}+b_{n-1}}{2}\leq \cdots \leq (\frac{1}{2})^{n-1}(b_1-a_1)\Rightarrow I_n=[a_n,b_n]$
	  ist Intervallschachtelung, da $I_1\supset I_2\supset I_3\supset \ldots$ und $\lim (b_n-a_n)=0$\\
	  $\Rightarrow \bigcap I_n =\{s\}, \lim a_n=\lim b_n=s$ zu zeigen ist: $s=\sup M$
	  \begin{itemize}
	    \item[$\alpha$] $s$ ist obere Schranke von $M$. Sei $x \in M \Rightarrow \forall n \in \N \colon x \leq b_n
	      \Rightarrow x \leq \lim b_n =s$
	    \item[$\beta$] $s$ ist kleinste obere Schranke von $M$. Sei $\varepsilon >0\Rightarrow \exists I_{n_{\varepsilon}}=
	      [a_{n_{\varepsilon}},b_{n_{\varepsilon}}]$\\
	      $s-\varepsilon <a_{n_{\varepsilon}}\leq s$. Da $M\cap I_{n_{\varepsilon}}\neq \emptyset$ folgt $x_{\varepsilon}
	      \in M \cap I_{n_{\varepsilon}}\colon s-\varepsilon<a_{n_{\varepsilon}}\leq s\Rightarrow s$ ist kleinste obere
	      Schranke.
	  \end{itemize}
      \end{enumerate}
    \end{enumerate}
\end{itemize}
\qed

Die Aussagen (3) und (4) haben grosse Bedeutung in der Mathematik und dienen zur Einführung der Begriffe
\emph{Kompaktheit\index{Kompaktheit}} und \emph{Vollständigkeit\index{Vollständigkeit} von metrischen Räumen}.

\begin{definition}
\label{def:vollst}
Sei $(X,d)$ ein metrischer Raum
\begin{enumerate}[(1)]
  \item $X$ heißt \emph{vollständiger metrischer Raum\index{Raum!vollständiger metrischer}} $\perdef$ jede Cauchyfolge 
    in $X$ hat einen Grenz\-wert in $X$.
  \item $X$ heißt \emph{kompakter metrischer Raum\index{Raum!kompakter metrischer}} $\perdef$ Jede Folge aus $X$ 
    enthält eine konvergente Teilfolge mit Grenzwert in $X$.
\end{enumerate}
\textbf{Beispiel} $d=\abs{\cdot }$
\begin{enumerate}[(1)]
  \item $[a,b]$ ist ein vollständiger metrischer Raum und ein kompakter metrischer Raum.
  \item $\R$ ist ein vollständiger metrischer Raum, allerdings kein kompakter.
  \item $[a,b]\in \Q$ ist keines von beiden
\end{enumerate}
\end{definition}

\section{Reihen}

\begin{definition}
\label{def:reihe}
Sei $(a_n) \subset \R$ eine reelle Zahlenfolge. Die Folge
\begin{gather*}s_n\coloneqq\sum_{k=1}^n a_k \qquad a_k \in \N\end{gather*} der
Partialsummen\index{Partialsumme} heißt
\emph{Reihe\index{Reihe}}\footnote{Schreibweise: $\sum_{n=1}^\infty
  (a_n), (\sum_{k=1}^n a_k)_{n\in \N}, \sum_{k=1}^\infty a_k$}.
Konvergiert $(s_n)$, so heißt $\sum_{k=1}^\infty a_k\coloneqq\lim s_n$
\emph{Summe\index{Reihe!Summe}} oder \emph{Wert\index{Summe!Wert}} der
Reihe.
\end{definition}


\subsection{Rechenregeln für konvergente Reihen}
\begin{theorem}
\label{satz:RechenregelReihe}
\begin{enumerate}[(1)]
  \item $\sum a_n$ ist konvergent $\Rightarrow \sum ca_n$ konvergiert $c\in \R =c\sum a_n$
  \item $\sum a_n, \sum b_n$ sind konvergent $\Rightarrow \sum(a_n+b_n)$ konvergent
  \item $\sum_{n=1}^\infty a_n$ konvergent $\Rightarrow \sum_{k+1}^\infty (\sum_{j=k}^{n_k+1} a_j)$ konvergent $1=n_1<n_2<\ldots$
\end{enumerate}
\end{theorem}
\textbf{Beweis}
\begin{enumerate}[(1)]
  \item $s_n=\sum_{k=1}^n a_k, \lim s_n=\sum_{k=1}^\infty a_k$\\
    $\sum_{k=1}^\infty ca_k =\lim(cs_n)=c\lim s_n =c\sum_{k=1}^\infty a_k$
  \item $s_n=\sum_{k=1}^n a_k, t_n=\sum_{k=1}^n b_k, s_n+t_n=\sum_{k=1}^n (a_n+ b_k)$\\
    $\sum_1^\infty (a_k+b_k)=\lim (s_n+t_n)=\lim s_n +\lim t_n=\sum_1^\infty a_k +\sum_1^\infty b_k$
  \item $s_n=\sum_{k=1}^n a_k, s_{\stackrel{n-1}{l+1}}=\sum_{k=1}^l(\sum_{j=n_k}^{n_{k+1}-1} a_j), 1=n_1<n_2<\ldots$\\
    $\lim s_n$ existiert $\Rightarrow \lim_{l\rightarrow \infty}
    s_{\stackrel{n-1}{l+1}}$ (Jede Teilfolge hat gleichen Grenzwert.)
\end{enumerate}
\textbf{Beispiele}:
\begin{description}
  \item[geometrische Reihe\index{Reihe!geometrische}] $a_n=q^n \quad n=0,1,2,\ldots \quad \sum_{n=0}^\infty q^n=1+q^1+q^2\cdots$
    kon\-ver\-giert für $\abs{q}<1$ und divergiert für $\abs{q}\geq 1$\\
    Beweis: $s_n =1+q+\cdots +q^n=\frac{1-q^{n-1}}{1-q}, q\neq 1$\\
    Für $\abs{q}<1 \quad \lim s_n=\frac{1}{1-q}$\\
    Für $\abs{q}>1$ ist $s_n$ divergent.\\
    Für $q=-1 \quad s_n=\begin{cases}1 \quad n=2k\\0 \quad n=2k+1\end{cases}$ divergent.\\
    Für $q=1 \quad s_n=n+1$ divergent.
  \item[harmonische Reihe\index{Reihe!harmonische}] $\sum_{n=1}^\infty \frac{1}{n}$ divergent
  \item[alternierende harmonische Reihe\index{Reihe!alternierende harmonische}]  $\sum_{n=1}^\infty (-1)^n\frac{1}{n}$ konvergent
\end{description}

\subsection{Einige Konvergenzkriterien für Reihen}

\begin{theorem}[Notwendiges Kriterium für
  Konvergenz\index{Konvergenzkriterium!notwendiges}]
\label{satz:konvkrit}
$\sum a_n$ ist konvergent, wenn  $\lim a_n=0$ ist.
%lim neu eingefuegt, da sonst kein Sinn
\end{theorem}
\begin{proof}
  $s_n=\sum_{k=1}^n a_k, s_{n+1}-s_n=a_{n+1} \Rightarrow
  0=s-s=\lim s_{n+1}-\lim s_n=\lim a_{n+1}$
\end{proof}

\begin{remark}
  Die Umkehrung von \autoref{satz:konvkrit} gilt im allgemeinen
  nicht. Ein Beispiel ist die harmonische Reihe.
\end{remark}

\begin{theorem}[Cauchykriterium\index{Cauchykriterium}]
\label{satz:CKrit}
 $\sum a_n$ konvergent $\perdef$
\begin{gather*}\forall \varepsilon >0 \exists n_{\varepsilon}\in \N \forall n>m>n_{\varepsilon}\colon\abs{\sum_{k=m}^n a_k}
\leq \varepsilon\end{gather*}
\end{theorem}
\textbf{Beweis}: $s_n-s_m=\sum_{k=m+1}^n a_k\quad \sum a_k$ konvergent
$\stackrel{\text{\hyperref[def:reihe]{Def.\,\ref*{def:reihe}}}}{\Leftrightarrow}
(s_n)$ konvergent $\stackrel{\text{\autoref{satz:CKonv}}}{\Leftrightarrow}(s_n)$ ist Cauchyfolge.

\begin{definition}
\textbf{Absolute Konvergenz\index{Konvergenz!absolute}} Eine Reihe $\sum a_k$ heißt \emph{absolut konvergent\index{absolut konvergent}}
$\perdef \sum \abs{a_k}$ konvergiert.
\end{definition}

\textbf{Korollar}: $\sum a_n$ sei absolut konvergent. Dann ist auch $\sum a_k$ konvergent.
Zum Beweis nutzt man das Cauchykriterium: Sei $\varepsilon >0$. Dann existiert $n\in \N \colon \abs{\sum_{k=m+1}^n a_k}\leq 
\sum_{k=m+1}^n \abs{a_k}\leq \varepsilon$ für $n>m>n_{\varepsilon}$\qed\\
\textbf{Bemerkung}: Es gibt konvergente Reihen, die nicht absolut konvergent sind. Bsp.: al\-ter\-nie\-rende harmonische
Reihe

\begin{theorem}
\label{satz:wkonvkrit}
\textbf{weitere Konvergenzkriterien}
\begin{enumerate}[(1)]
  \item \textbf{Monotoniekriterium\index{Monotoniekrit.}} Sei $a_n\geq 0$. Dann $\sum a_n$ konvergent $\Leftrightarrow
    (s_n)$ beschränkt.
  \item \textbf{Vergleichskriterium\index{Vergleichskrit.}}:
  \begin{enumerate}[({2}.1)]
    \item \textbf{Majorantenkriterium\index{Majorantenkrit.}} Sei $\abs{a_n}\leq c_n, n\geq n_0$. Dann $\sum c_n$ konvergent
      $\Rightarrow \sum a_n$ absolut konvergent
    \item \textbf{Minorantenkriterium\index{Minorantenkrit.}} Sei $a_n\geq d_n\geq 0$ für $n\geq n_0$. Dann $\sum d_n$
      divergent $\Rightarrow \sum a_n$ divergent
  \end{enumerate}
  \item \textbf{Teleskopsummenkriterium\index{Teleskopsummenkrit.} / Verdichtungskriterium\index{Verdichtungskrit.}} 
    Seien $a_1\geq a_2\geq \ldots \geq a_n\geq 0$. Dann $\sum a_n$ konvergent $\Leftrightarrow \sum 2^n a_{2^n}$ konvergent
  \item \textbf{Wurzelkriterium\index{Wurzelkrit.}} Sei $\alpha \coloneqq\overline{\lim}\sqrt[n]{\abs{a_n}}$. Dann ist $\sum a_n$
    konvergent für $\alpha <1$ und divergent für $\alpha >1$. Für $\alpha=1$ existieren sowohl konvergente als auch
    divergente Reihen.
  \item \textbf{Quotientenkriterium\index{Quotientenkrit.}} Seien $\underline{\beta}\coloneqq\underline{\lim}\abs{\frac{a_{n+1}}{a_n}},
    \overline{\beta}\coloneqq\overline{\lim}\abs{\frac{a_{n+1}}{a_n}}$. Dann folgt für $\overline{\beta}<1$, dass $\sum a_n$
    konvergent ist und für $\underline{\beta}>1$, dass $\sum a_n$ divergent ist.
\end{enumerate}
\end{theorem}
\textbf{Beweis}
\begin{enumerate}[(1)]
  \item $a\geq 0 \Rightarrow s_{n+1}=s_n+a_{n+1} \geq s_n, (s_n)$ nach oben beschränkt und monoton wachsend $\Rightarrow (s_n)$
    konvergent
  \item
    \begin{enumerate}[1)]
      \item $\abs{\sum_{k=m+1}^n a_k}\leq \sum_{k=m+1}^n \abs{a_k}\leq \sum_{k=m+1}^n c_k <\varepsilon$ für $n>m\geq n_{\varepsilon}
        \stackrel{\text{Cauchykrit.}}{\Longrightarrow} \sum \abs{a_k}$ absolut konvergent
      \item Wäre $\sum a_n$ konvergent, folgt darus, dass auch $\sum d_n$ konvergent ist
    \end{enumerate}
  \item $s_n<a_1+a_2+\cdots +a_n, t_k\coloneqq a_1+2a_2+2^2a_{2^2}+\cdots +2^ka_{2^k}$\\
    Für $n\leq 2^k$ gilt $s_n\leq t_k$.\\
    Denn $s_n\leq a_1+(a_2+a_3)+\cdots +(a_{2^k}+a_{2^k+1}+\cdots +a_{2^{k+1}-1})\leq
    a_1+2a_2+\cdots +2^ka_{2^k}=t_k$. Für $n\geq 2^k$ gilt $s_n\geq \frac{1}{2}t_k$.\\
    Denn $s_n\geq a_1 + a_2+(a_3+a_4)+\cdots +(a_{2^{k-1}+1}+\cdots +a_{2^k})\geq \frac{a_1}{2}+a_2+2a_4+\cdots +2^{k-1}
    a_{2^k}=\frac{1}{2}(a_1+2a_2+2^2a_{2^2}+\cdots +2^ka_{2^k})=\frac{1}{2}t_k$. Somit gilt nach (1) $(s_n)$ ist
    konvergent, genau dann wenn $(t_k)$ konvergent ist.
  \item
    \begin{enumerate}[1. F{a}ll]
      \item Sei $\alpha >1, \alpha=\overline{\lim}\sqrt[n]{\abs{a_n}}>1$. Dann existiert eine Teilfolge $(a_{n_k}) \subset (a_n)\colon
        \lim \sqrt[n_k]{\abs{a_{n_k}}}=\alpha$. Wähle $\varepsilon_0>0\colon\alpha >1+\varepsilon_0$. Dann existiert ein $k_0 \in \N \colon
	\abs{\sqrt[n_k]{\abs{a_{n_k}}} -\alpha }<\varepsilon_0$ für
        $k\geq k_0$. Somit ist $-\varepsilon_0 <\sqrt[n_k]{\abs{a_{n_k}}}< 
	\varepsilon_0 \Rightarrow 1<\alpha-\varepsilon_0<\sqrt[n_k]{\abs{a_{n_k}}}\Rightarrow 1<\abs{a_{n_k}}$ für $k\geq k_0$
	Daraus folgt, dass $a_{n_k}$ nicht gegen 0 streben. Daher strebt auch $a_n$ nicht gegen 0. Nach \autoref{satz:konvkrit}
	folgt, dass auch $\sum a_n$ divergiert.
      \item Sei $\alpha =\overline{\lim}\sqrt[n]{\abs{a_n}}<1$. Wähle $\beta \colon\alpha<\beta <1, b_n\coloneqq\sup\{\sqrt[k]{\abs{a_k}}\colon k\geq n\}$
        Für $b_n$ gilt $\lim b_n=\alpha$. Wähle
      $\varepsilon_0\colon\alpha+\varepsilon_0<\beta$. Dann existiert ein $n_0
      \in \N\,\forall n\geq n_0\colon\alpha
      -b_n|<\varepsilon_0$\todo{Was macht das Pipe hier?}. Somit ist $-\varepsilon_0<\alpha -b_n<\varepsilon_0$ für $n\geq n_0
	\Rightarrow b_n<\alpha +\varepsilon_0$ für $n\geq n_0$. Insobesondere gilt für $n=n_0\colon b_{n_0}<\alpha +\varepsilon_0<
	\beta$, d.\,h. $\sqrt[k]{\abs{a_k}}\leq b_{n_0}<\beta \quad \forall k\geq n_0 \Rightarrow \abs{a_k}<\beta^k, k\geq n_0
	\stackrel{\beta <1}{\Rightarrow} \sum \beta^k$ ist konvergent $\stackrel{(2)}{\Rightarrow} \sum \abs{a_n}$ konvergent.
	Diese Summe ist sogar absolut konvergent.
    \end{enumerate}
  \item $\overline{\beta}\coloneqq\overline{\lim}\abs{\frac{a_{n+1}}{a_n}}<1 \Rightarrow \sum a_n$ konvergent\\
    $\underline{\beta}\coloneqq\underline{\lim}\abs{\frac{a_{n+1}}{a_n}}>1 \Rightarrow \sum a_n$ divergent\\
    $\underline{\lim}_n\abs{\frac{a_{n+1}}{a_n}}\leq \underline{\lim}_n \sqrt[n]{\abs{a_n}}\leq \overline{\lim}_n \sqrt[n]{\abs{a_n}}
    \leq \overline{\lim}_n \abs{\frac{a_{n+1}}{a_n}}$\\
    $b_1\coloneqq\sup \{\abs{a_k}\colon k\geq 1\}\geq \abs{a_1}$\\
    $b_n\coloneqq\sup \{\abs{\frac{a_{k+1}}{a_k}}\colon k\geq n\}\geq \frac{a_n}{a_{n-1}}|, n\geq 2$\\
    $\overline{\lim}\abs{\frac{a_{n+1}}{a_n}}=\lim b_n$. Dann:\\
    $\sqrt[n]{\abs{a_n}}=\sqrt[n]{\abs{a_1}\cdot \frac{\abs{a_2}}{\abs{a_1}}\cdot \frac{\abs{a_3}}{\abs{a_2}}\cdot \ldots \cdot 
    \frac{\abs{a_{n-1}}}{\abs{a_{n-2}}}\cdot \frac{\abs{a_n}}{\abs{a_{n-1}}}} \leq \sqrt[n]{b_1b_2\ldots b_n}\leq 
    \frac{b_1+b_2+\cdots +b_n}{n}$\\
    $\Rightarrow \overline{\lim} \sqrt[n]{\abs{a_n}}\leq \overline{\lim}
    \frac{b_1+\cdots +b_n}{n}=\lim \frac{b_1+\cdots +b_n}{n}=\lim b_n=\overline{\lim} \abs{\frac{a_{n+1}}{a_n}}$\\
    Der Beweis für $\underline{\lim}\abs{\frac{a_{n+1}}{a_n}}\leq \underline{\lim} \sqrt[n]{\abs{a_n}}$ geht analog.
\end{enumerate}
\qed

\textbf{Beispiele}: Sei $0\leq \alpha <\infty$ und $\sum_{n=1}^\infty \frac{1}{n^\alpha}$ eine Reihe. Diese ist
konvergent für $\alpha>1$ und divergent für $0\leq \alpha \leq 1$. Nach dem Quotientenkriterium gilt:\\
$a_n=\frac{1}{n^\alpha}, \abs{\frac{a_{n+1}}{a_n}}=\frac{a_{n+1}}{a_n}=\frac{1}{(n+1)^\alpha}\cdot \frac{n^\alpha}{1}=
(\frac{n}{n+1})^\alpha=(1-\frac{1}{n+1})^\alpha$\\
$\lim \frac{a_{n+1}}{a_n}=\lim_n (1-\frac{1}{n+1})^\alpha=1^\alpha=1$\\
Daraus folgt, dass nach dem Quotientenkriterium keine Entscheidung zu treffen ist, ob diese Reihe konvergiert oder nicht.\\
Nach dem Teleskopsummenkriterium gilt:\\
$a_1\geq a_2\geq \cdots \geq a_n\geq \cdots \geq 0, \lim a_n=\lim_{n\rightarrow \infty}\frac{1}{n^\alpha}=0$ für $0<
\alpha<\infty$. Die Summe $\sum a_n$ konvergiert genau dann, wenn die Summe $\sum 2^na_{2^n}$ konvergiert.\\
$a_{2^n}=\frac{1}{(2^n)^\alpha}=\frac{1}{2^{n\alpha}}=(\frac{1}{2^\alpha})^n$\\
$\sum 2^na_{2^n}=\sum2^n(2^{-\alpha})^n=\sum (2^{1-\alpha})^n\Rightarrow \sum 2^na_{2^n}$ ist konvergent für $\alpha>1$
und divergent für $\alpha \leq 1$.

$\sum_{n=1}^\infty \frac{n!}{n^n}$ ist konvergent.\\
Beweis nach dem Wurzelkriterium: $a_n=\frac{n!}{n^n} \quad \sqrt[n]{\abs{a_n}}=\sqrt[n]{a_n}=\sqrt[n]{\frac{n!}{n^n}}=
\frac{1}{n}\sqrt[n]{n!}$ Dies ist kompliziert zu berechnen. Daher ein Versuch mit dem Quotientenkriterium:\\
$\abs{\frac{a_{n+1}}{a_n}}=\frac{a_{n+1}}{a_n}=\frac{(n+1)!}{(n+1)^{n+1}}\cdot \frac{n^n}{n!}=\frac{n!(n+1)n^n}{(n+1)^n(n+1)n!}
=\frac{n^n}{(n+1)^n}=\frac{1}{(1+\frac{1}{n})^n}\Rightarrow \lim \abs{\frac{a_{n+1}}{a_n}}=\lim \frac{1}{(1+\frac{1}{n})^n}=
\frac{1}{e}<1\Rightarrow$  Summe ist konvergent.

\subsubsection{Alternierende Reihen}
\begin{definition}
Die Reihe $\sum_{n=0}^\infty (-1)^na_n$ heißt genau dann \emph{alternierende Reihe\index{Reihe!alternierende}}, wenn
entweder $a_n\geq 0$ für $n \in \N$ oder $a_n\leq 0$ für $n \in \N$.
\end{definition}

\begin{theorem}
\label{satz:LeibKrit}
\textbf{Leibnitzsches Kriterium\index{Leibnitzsches Kriterium}} Sei $a_0\geq a_1\geq a_2\geq \cdots \geq a_n\geq \cdots
\geq 0$ und $\lim a_n=0$. Dann ist $\sum_{n=0}^\infty (-1)^na_n$ konvergent.
\end{theorem}
\textbf{Beweis}: $s_n=\sum_{k=0}^n (-1)^ka_k=a_0-a_1+a_2+\cdots +(-1)^na_n$ Wegen der Monotone gilt:\\
$\left.
\begin{array}{rcl}
  s_{2n+2}-s_{2n}=-a_{2n+1}+a_{2n+2} & \leq & 0\\
  s_{2n+3}-s_{2n+1}=a_{2n+2}-a_{2n+3} & \geq & 0
\end{array}
\right\} \Rightarrow
\begin{array}{rcl}
  s_0\geq s_2\geq s_2\geq & \ldots & \geq s_{2n}\geq \ldots\\
  s_1\leq s_3\leq s_5\leq & \ldots & \leq s_{2n+1}\leq \ldots
\end{array}$ und $s_{2n+1}-s_n=-a_{2n+1}\leq 0$\\
$\Rightarrow s_{2n+1}\leq 2_{2n}$\\
$\Rightarrow
\begin{array}{rcl}
  s_{2n} &\geq & s_1\\
  s_{2n+1}&\leq & s_0
\end{array}$
für alle $n=0,1,2,\ldots \Bigg\}\stackrel{\text{\autoref{satz:monotoneFolge}}}{\Longrightarrow}
\begin{array}{rcl}
  \lim s_{2n} & = & s\\
  \lim s_{2n+1} & = & s'
\end{array}$\\
$s_{2n+1}=s_n-a_{2n+1}\stackrel{n\rightarrow\infty}{\Longrightarrow} s'=s-0\Rightarrow s'=s$\\
noch zu zeigen: $\lim s_n=s$\\
Sei $\varepsilon>0$. Dann existiert ein $n_0, n_1 \in \N \colon
\begin{array}{rcl}
  \abs{s_{2n}-s} & \leq & \varepsilon \text{ für } n\geq n_0\\
  \abs{s_{2n+1}-s} &< & \varepsilon \text{ für } n\geq n_1
\end{array}$\\
Für $N\coloneqq\max\{2n_0,2n_1+1\}$ gilt: $\abs{s_n-s}<\varepsilon$ für $n\geq N$, d.\,h. $\lim s_n=s$
\qed

\textbf{Beispiel} 
\begin{enumerate}
  \item $\sum_{n=1}^\infty (-1)^{n-1}\frac{1}{n}$ konvergiert. $a_n=\frac{1}{n}, a_1\geq a_2\geq \ldots \geq 
    a_n\geq \ldots \geq0, \lim a_n=0$\\
    $\stackrel{\text{\autoref{satz:LeibKrit}}}{\Longrightarrow} \sum (-1)^{n-1}\frac{1}{n}$ ist konvergent.
  \item $\sum_{n=1}^\infty \frac{(n+1)^{n-1}}{(-n)^n}=\sum \frac{1}{(-1)^n}\cdot \frac{(n+1)^{n-1}}{n^n}=\sum (-1)^n
    \frac{(n+1)^{n-1}}{n^n}$\\
    $a_n=\frac{(n+1)^{n-1}}{n^n}=(\frac{n+1}{n})^n\cdot \frac{1}{n+1}=(1+\frac{1}{n})^n\cdot \frac{1}{n+1}\rightarrow e
    \cdot 0=0$\\
    zu zeigen ist noch die Monotonie: $a_n=\frac{(n+1)^{n-1}}{n^n}\geq \frac{(n+2)^n}{(n+1)^{n+1}}=a_{n+1}$\\
    $(n+1)^{2n}=((n+1)^2)^n=(n^2+2n+1)^n\geq (n(n+2))^n=(n^2+2n)^n \Rightarrow$ monoton fallend\\
    $\Rightarrow \sum \frac{(n+1)^{n-1}}{(-n)^n}$ ist konvergent.
\end{enumerate}

\subsubsection{Umordnung und Produkt von Reihen}
\begin{definition}
Sei $\pi \colon\N\rightarrow \N$ bijektiv. Dann heißt
\begin{gather*}\sum_{k=1}^\infty a_{\pi(k)}\end{gather*}
eine \emph{Umordnung\index{Umordnung}} der Reihe $\sum_{k=1}^\infty a_k$.
\end{definition}

\begin{theorem}
\label{satz:umordnung}
Seien $c_n\geq 0$ und $\sum_{n=1}^\infty c_n$ konvergent. Dann gilt $\forall \pi \colon\N\rightarrow \N$ bijektiv
$\Rightarrow \sum_{k=1}^\infty c_{\pi(k)}$ konvergent und es gilt $\sum_{k=1}^\infty c_k=\sum_{k=1}^\infty c_{\pi(k)}$
\end{theorem}
\textbf{Beweis}: Sei $n \in \N, M\coloneqq\max\{\pi(1),\ldots ,\pi(n)\}$\\
Dann ist $n\leq M$ und es gilt $\sum_{k=1}^n c_{\pi(k)}\leq \sum_{k=1}^M c_k\leq \sum_{k=1}^\infty c_k<\infty 
\stackrel{c_k\geq 0}{\Rightarrow} \sum_{k=1}^\infty c_{\pi(k)}\leq \sum_{k=1}^\infty c_k$\\
Obige Aussage auf $\sum_1^\infty c_k=\sum_1^\infty c_{\pi^{-1}(\pi(k))}\leq \sum_1^\infty c_{\pi(k)} \Rightarrow
\sum_1^\infty c_k=\sum_1^\infty c_{\pi(k)}$\qed

\begin{theorem}
\label{satz:absUmordnung}
$\sum a_n$ ist absolut konvergent $\Leftrightarrow \forall \pi \colon\N \rightarrow \N$ bijektiv\\
$\sum_1^\infty a_{\pi(k)}$ konvergent.
\end{theorem}
Ferner gilt: $\sum_{k=1}^\infty a_{\pi(k)}=\sum_{k=1}^\infty a_k \qquad \forall \pi$\\
\textbf{Beweis}:
\begin{itemize}
  \item["`$\Rightarrow$"'] Sei $\sum a_n$ absolut konvergent.
    $\begin{array}{rcl}
      0\leq a_n^+\coloneqq\max\{a_n,0\} & = & \frac{\abs{a_n}+a_n}{2}\leq \abs{a_n}\\
      0\leq a_n^-\coloneqq\min\{a_n,0\} & = & \frac{\abs{a_n}-a_n}{2}\leq \abs{a_n}
    \end{array}$\\
    $\stackrel{\text{Maj.-krit.}}{\Rightarrow} \sum a_n^+, \sum a_n^-$ konvergent\\
    $\stackrel{\text{\autoref{satz:umordnung}}}{\Rightarrow} \sum_1^\infty \sum_1^\infty a_{\pi(k)}^+=\sum_1^\infty a_k^+,
    \sum_1^\infty a_{\pi(k)}^-=\sum_1^\infty a_k^-$\\
    $\Rightarrow \sum_1^\infty a_{\pi(k)}=\sum_1^\infty (a_{\pi(k)}^+-a_{\pi(k)}^-)=\sum_1^\infty a_{\pi(k)}^+-
    \sum_1^\infty a_{\pi(k)}^- =\sum_1^\infty a_k^+ -\sum_1^\infty a_k^-
  =\sum_1^\infty (a_k^+ -a_k^-)=\sum_1^\infty a_k$
  \item["`$\Leftarrow$"'] Sei $\sum \abs{a_n}$ divergent. Sei o.\,B.\,d.\,A. $\sum a_n$ konvergent (sonst $\pi=id$)\\
    Feststellung: $a_k=a_k^+-a_k^- \quad \abs{a_k}=a_k^++a_k^-$\\
    $\left.\begin{array}{rcl}
      \sum \abs{a_n} \text{ divergent}\\
      \sum a_n \text{ konvergent}
    \end{array}\right\}\Rightarrow \sum a_k^+=\infty, \sum a_k^-=\infty$\\
    Sei $(a_{\varphi_+(k)})$ Teilfolge aller $a_k>0$ ($a_k\leq 0$ streichen) und $(a_{\varphi_-(k)})$ Teilfolge aller
    $a_k\leq 0$ ($a_k>0$ streichen)\\
    $s_n^\pm\coloneqq\sum_{k=1}^n a_k^\pm, t_n^\pm\coloneqq\sum_{k=1}^n
  a_{\varphi_\pm(k)}$\\
    $s_n^+\leq t_n^+$ (da $t_n^+$ nur positiv, bei $s_n^+$ kann auch die 0 enthalten sein)\\
    $s_n^-=-t_n^- \Rightarrow \lim_{n\rightarrow \infty}=\sum_1^\infty a_{\varphi_+(k)}=\infty, \lim_{n\rightarrow \infty}
    t_n^-=\sum_1^\infty a_{\varphi_-(k)}=-\infty$ %weitere Beweisfolge mit einbauen
\end{itemize}

\begin{definition}
\begin{enumerate}[(1)]
  \item Eine konvergente Reihe heißt genau dann \emph{unbedingt kon\-ver\-gent\index{konvergent!unbedingt}
    \index{unbedingt konvergent}}, wenn alle Umordnungen konvergent sind.
  \item Eine konvergente Reihe heißt \emph{bedingt konvergent\index{konvergent!bedingt}\index{bedingt konvergent}}, wenn
    sie nicht unbedingt kon\-ver\-gent ist.
\end{enumerate}
\end{definition}

\autoref{satz:absUmordnung} besagt, dass unbedingt konvergente Reihen vorhanden sind, wenn diese absolut konvergieren.

\begin{theorem}
\textbf{Riemannsche Umordnungssatz\index{Umordnungssatz!Riemannsche}\index{Riemannsche Umordnungssatz}} Sei $\sum_1^\infty
a_k$ bedingt konvergent. Dann 
\begin{gather*}\forall S \in \R \exists \pi \colon\N\rightarrow\N \text{ Bijektion }\colon\sum_1^\infty a_{\pi(k)}=S\end{gather*}
\end{theorem}
\textbf{Beweis}: siehe Heuser S.\,197--199

\paragraph{Produkte von Reihen}

$\sum_{n=0}^\infty a_n, \sum_{n=0}^\infty b_n$ seien Reihen in $\R$
\begin{gather*}\left(\sum_{i=0}^M a_i\right)\left( \sum_{j=0}^N\right) =\sum_{i=0}^M \sum_{j=0}^N a_ib_j\end{gather*}
Ordnet man alle $a_jb_k$ (Reihenfolge der Glieder spielt keine Rolle) zu einer Folge $(p_n)_{n=0}^\infty$ an, so wird
die Reihe $\sum_0^\infty p_n$ als \emph{Produktreihe\index{Produktreihe}} der Reihen $\sum a_n \sum b_n$ bezeichnet.

\begin{theorem}
\label{satz:abskonvReihe}
Seien $\sum_{n=0}^\infty a_n, \sum_{b=0}^\infty b_n$ absolut konvergent. Dann ist auch $\sum_{n=0}^\infty p_n$ absolut
konvergent und es gilt
\begin{gather*}\sum_{n=0}^\infty p_n=\left(\sum_{n=0}^\infty a_n\right)\left(\sum_{n=0}^\infty b_n\right)\end{gather*}
\end{theorem}
\textbf{Beweis}:
\begin{enumerate}[1. Schr{i}tt]
  \item Zu zeigen ist, dass $\sum \abs{p_n}$ konvergent ist. Nach dem Monotoniekriterium reicht es zu zeigen, dass
    $\exists K \geq 0 \forall n \in \N \cup \{0\}\colon\sum_{k=0}^\infty \abs{p_k}\leq K$.\\
    Sei $n \in \N \Rightarrow \exists m \in \N \colon \sum_{k=0}^n \abs{p_k}\leq (\sum_{k=0}^m \abs{a_k})(\sum_{k=0}^m \abs{b_k})$\\
    $\leq
    (\sum_0^\infty \abs{a_k})(\sum_0^\infty \abs{b_k})=:K$
  \item Beweis der Summenformel
    %Matrixformel einfuegen
    $q_0+q_1+\cdots +q_{(n+1)^2-1}=(\sum_{k=0}^n a_k)(\sum_{k=0}^n b_k)\stackrel{n\rightarrow \infty}{\rightarrow}
    (\sum_{k=0}^\infty a_k)(\sum_{k=0}^\infty b_k)$\\
    $\sum_{k=0}^\infty q_k=(\sum_{k=0}^\infty a_k)(\sum_{k=0}^\infty b_k)$\\
    Da $\sum q_n$ eine Umordnung von $\sum p_n$ ist, folgt nach \autoref{satz:absUmordnung} und dem ersten Schritt, dass
    $\sum p_n=\sum q_n = (\sum a_n)(\sum b_n)$
\end{enumerate}
\qed

\begin{definition}
\textbf{Cauchy-Produkt} %%pstricks einfuegen
Die Produktreihe $\sum c_n$ heißt \emph{Cauchyprodukt\index{Cauchyprodukt}} der Reihen $\sum a_n, \sum b_n$.
\end{definition}

\begin{theorem}
Seien $\sum a_n, \sum b_n$ absolut konvergent. Dann ist das Cauchyprodukt $\sum c_n$ absolut konvergent und es gilt:
\begin{gather*}\sum_{n=0}^\infty c_n = \sum_{n=0}^\infty \left(\underbrace{\sum_{k=0}^n a_k b_{n-k}}_{=:d_n}\right) = \left(\sum a_n\right)\left(\sum b_n\right)\end{gather*}
\end{theorem}
\textbf{Beweis}: $\sum c_n=(\sum a_n)(\sum b_n)$ ist nach \autoref{satz:abskonvReihe} absolut konvergent. Da $\sum d_n$ eine
spezielle Klammerung von $\sum c_n$ ist, gilt $\sum_{n=0}^\infty c_n=\sum_{n=0}^\infty d_n$ nach
\autoref{satz:RechenregelReihe} Punkt 3.\qed

\paragraph{Bemerkungen zum Cauchyprodukt} für $n\in \N\cup \{0\}$ sei
$a_n\coloneqq b_n\coloneqq\frac{(-1)^n}{\sqrt{n+1}}$ und 
$d_n=\sum_{k=0}^n a_kb_{n-k}$. Die Reihen $\sum a_n, \sum b_n$ konvergieren nach dem Leibnitzkriterium. Ihr 
Cau\-chy\-pro\-dukt konvergiert nicht, denn 
\begin{align*}
  d_n &= \sum_{k=0}^n a_k b_{n-k}\\
  &= \sum_{k=0}^n \frac{(-1)^k}{\sqrt{k+1}}\cdot \frac{(-1)^{n-k}}{\sqrt{n-k+1}}\\
  &= (-1)^n \sum_{k=0}^n \frac{1}{\sqrt{(k+1)(n-k+1)}}\\
  \\
  \abs{d_n} &= \sum_{k=0}^n \frac{1}{\sqrt{(k+1)(n-k+1)}}\\
  &\geq \sum_{k=0}^n \frac{\frac{1}{(k+1)(n-k+1)}}{2}\\
  &= \sum_{k=0}^n \frac{2}{n+2}\\
  &= \frac{2n+2}{n+2}\\
  &\geq 1
\end{align*}
$\Rightarrow \abs{d_n}$ konvergiert nicht gegen $0\Rightarrow d_n \not\rightarrow 0\Rightarrow \sum d_n$ ist divergent. Daraus
folgt, dass auch $\sum c_n$ divergent ist.

Ein Beispiel für das Cauchyprodukt ist die \emph{Exponentialreihe\index{Exponentialreihe}}:
\begin{gather*}e^x \coloneqq \exp(x)\coloneqq\sum_{n=0}^\infty \frac{x^n}{n!}=1+x+\frac{x^2}{2}+\frac{x^3}{3!}+\cdots +\frac{x^n}{n!}\end{gather*}
Dann gilt $\exp(x+y)=\exp(x)\cdot \exp(y)$.\\
\textbf{Beweis}: $\sum_0^\infty \frac{x^n}{n!}$ ist nach dem Quotientenkriterium absolut konvergent für alle $x\in \R$
\begin{align*}
  \exp(x)\cdot \exp(y) & = & \left(\sum_{k=0}^\infty \frac{x^k}{k!}\right)\left(\sum_{j=0}^\infty \frac{x^j}{j!}\right)\\
  & = & \sum_{n=0}^\infty \left(\sum_{k=0}^n a_k b_{n-k}\right)\\
  & = & \sum_{n=0}^\infty \left(\sum_{k=0}^n \frac{x^k}{k!}\cdot \frac{y^{n-k}}{(n-k)!}\right)\\
  & = & \sum_{n=0}^\infty \frac{1}{n!} \left(\sum_{k=0}^n \underbrace{\frac{n!}{k!(n-k)!}}_{=\binom{n}{k}} x^k y^{n-k}\right)\\
  & = & \sum_{n=0}^\infty \frac{1}{n!}(x+y)^n\\
  & = & \exp(x+y)
\end{align*}
\qed

\textbf{Korollar:}
\begin{enumerate}[(1)]
  \item $\forall x \in \R \colon \exp(x)>0$\\
    $\forall x\geq 0\colon \exp(x)\geq 1>0$\\
    $\forall x<0\colon(-x)>0\Rightarrow \exp(-x)>0\Rightarrow \exp(x)>0$
  \item $\forall x\in \R \colon \exp(-x)=\frac{1}{\exp(x)}$\\
    Nach der Funktionalgleichung ist $\exp(x)\exp(-x)=\exp(x-x)=\exp(0)=1$.
  \item $\forall x \in \Z \colon \exp(n)=e^n$\\
    $n\in \N \cup \{0\}$\\
    $n=0\colon \exp(0)=1=e^0$\\
    $n\Rightarrow n+1\colon \exp(n+1)=\exp(n)\cdot \exp(1)=e^n\cdot e=e^{n+1}$\\
    $n\in \Z , n<0, (-n)\in \N, e^{-n}=\exp(-n)=\frac{1}{\exp(n)}\Rightarrow \exp(n)=e^n$
\end{enumerate}
\qed

\chapter{Funktionen und Stetigkeit}
Seien $(X,d), (Y,\tilde{d})$ metrische Räume und $D\subset X, f\colon D\rightarrow Y$ eine Funktion.

\section{Grenzwerte und Stetigkeit}
\begin{definition}
Sei $a\in X$ mit folgenden Eigenschaften: $\exists (a_n)\subset D\colon a_n\rightarrow a$. Die Funktion $f\colon D\rightarrow Y$
hat in $a$ den Grenzwert 
\begin{gather*}c\perdef \forall x_n \subset D\colon\lim_{n\rightarrow \infty} x_n=a\Rightarrow \lim_{n\rightarrow \infty} f(x_n)=c\end{gather*}
Dann heißt $c$ \emph{Grenzwert\index{Grenzwert!Funktion} an der Stelle $a$}.
\end{definition}
Schreibweise: $\lim_{x\rightarrow a} f(x)=c, 
\lim_{\stackrel{x\rightarrow a}{x \in D}} f(x)=c$\\
Beispiel:
\begin{enumerate}[(1)]
  \item Seien $X=Y=\R$ und der Abstand definiert durch $d(x,y)=\abs{x-y}$. Wie ermittelt man $\lim_{x\rightarrow 1} f(x)$
    mit $f\colon D=\R \backslash \{1\}\rightarrow \R, f(x)=\frac{x^2-1}{x-1}$? $a=1\notin D, a_n=1+\frac{1}{n} \in \R\backslash
    \{1\}$.\\
    Sei $(x_n)\subset D \subset \R \backslash \{1\}$ mit $x_n\rightarrow 1$.\\
    $f(x)=\frac{x_n^2 -1}{x_n-1}=x_n+1 \stackrel{n\rightarrow \infty}{\rightarrow} 1+1=2 \Rightarrow \lim_{x \rightarrow 1}
    f(x)=2$\\
    $a\neq 1, x_n\rightarrow a, f(x_n)=x_n+1 \stackrel{n \rightarrow \infty}{\rightarrow} a+1$
  \item $X=Y=\R \quad f\colon D=\R\backslash \{0\}\rightarrow \R \quad f(x)=\frac{\exp(x)-1}{x}$\\
    Es gilt $\lim_{x\rightarrow 0} \frac{\exp(x)-1}{x}=1$\\
    Beweis: 
    \begin{align*}
      \exp(x)-1-x &= \frac{x^2}{2!}+\frac{x^3}{3!}+\frac{x^4}{4!}+\cdots\\
      \abs{\exp(x)-1-x} &\leq \frac{\abs{x}^2}{2!}
      +\frac{\abs{x}^3}{3!} +\frac{\abs{x}^4}{4!}+\cdots\\
      &= \abs{x}^2\left(\frac{1}{2!} +\frac{\abs{x}}{3!}
        +\frac{\abs{x}^2}{4!} +\cdots\right)\\
      &\leq \abs{x}^2\left(\underbrace{\frac{1}{2!} +\frac{1}{3!}
          +\frac{1}{4!} +\cdots}_{=e-2}\right) \text{für } \abs{x}\leq 1\\
      &= (e-2)\abs{x}^2\\
      \abs{\frac{\exp(x)-1}{x}-1} &\leq (e-2)\abs{x} \text{für } x\neq
        0, \abs{x}\leq 1
    \end{align*}
    Sei $x_n\stackrel{x_n\neq 0}{\rightarrow} 0 \Rightarrow 0\leq \abs{\frac{\exp(x_n)-1}{x_n}-1}\leq (e-2)x_n
    \stackrel{n\rightarrow \infty}{\rightarrow} 0 \Rightarrow \frac{\exp(x_n)-1}{x_n}\rightarrow 1$
    \begin{gather*}\lim \frac{\exp(x)-1}{x}=1\end{gather*}
  \item $X=Y=\R \quad f(x)=\begin{cases}1 & x \geq 0\\-1 & x<0\end{cases}$\\
    Vermutung: $f(x)\not\rightarrow c \perdef \exists (x_n) \subset D\colon x_n\rightarrow a \wedge f(x_n)\not\rightarrow c$\\
    $x_n=(-1)^n\frac{1}{n}\rightarrow 0 \wedge f(x_n)=\begin{cases}1 & n \text{ gerade}\\-1 & n \text{ ungerade}\end{cases}
    \Rightarrow \lim f(x_n)$ existiert nicht.
\end{enumerate}

\begin{definition}
Sei $f\colon D\rightarrow Y$ und $a \in D$. $f$ heißt genau dann stetig in $a$, wenn $\lim_{x\rightarrow a} 
f(x)=f(a)$. $f$ heißt genau dann stetig in $D$, wenn $f$ in jedem Punkt $a$ aus $D$ stetig ist.
\end{definition}
Beispiel: Die konstante Funktion $f(x)=b$ und die identische Funktion sind stetige Funktionen.\\
$f(x)=\begin{cases}\frac{x^2-1}{x-1} & x \neq 1\\1 & x=1\end{cases} f\colon\R\rightarrow \R$\\
$lim_{x\rightarrow 1}f(x)=2\neq 1=f(1)$ Dies heißt, dass $f$ nicht stetig in 1 ist.

\begin{theorem}
Rechenregeln:
\begin{enumerate}[(1)]
  \item Sei $(X,d)$ und $D \subset X$. Dann gilt:\\
    sind $f,g\colon D\rightarrow\R$ stetig in $a \in D$, so sind $f+g, f\cdot g, \lambda f (\lambda \in \R)$
    stetig in $a$. Ist $g(a)\neq 0$, so ist auch $\frac{f}{g}\colon D'\rightarrow \R (D'=\{x\in D\colon g(x)\neq 0\})$
    stetig in $a$.\\
    \textbf{Beweis}: Siehe hierzu \autoref{satz:wkonvkrit}. z.\,B. Sei $(x_n)$ eine Folge mit $x_n\rightarrow a
    \stackrel{f,g \text{ stetig}}{\Longrightarrow} f(x_n)\rightarrow f(a), g(x_n)\rightarrow g(a)$\\
    $\Rightarrow (f+g)(x_n)=f(x_n)+g(x_n)\rightarrow f(a)+g(a)=(f+g)(a)$\\
    Daraus folgt, dass $f+g$ stetig in $a$ sind.
  \item Seien $X,Y,Z$ metrische Räume mit $D\subset X, E\subset Y, f\colon D\rightarrow Y, g\colon E\rightarrow Z,
    f(D)\subset E$. Ist $f$ in $a\in D$ und $g$ in $f(a)$ stetig, so ist $g\circ f$ in $a$ stetig.\\
    \textbf{Beweis}:$x_n\rightarrow a \stackrel{f \text{ stetig}}{\Longrightarrow} f(x_n)\rightarrow f(a)
    \stackrel{g \text{ stetig}}{\Longrightarrow} (g \circ f)(x_n)=g(f(x_n))\rightarrow g(f(a))=(g\circ f)
    (a)$
\end{enumerate}
\qed
\end{theorem}

\section{\texorpdfstring{$\varepsilon$-$\delta$}{epsisol-delta}-Stetigkeit}
\begin{theorem}
\label{satz:e-d-stetig}
Sei $D\subset X, f\colon D\rightarrow Y$. $f$ ist genau dann im Punkt $a\in D$ stetig, wenn:
\begin{gather*}\forall \varepsilon >0 \exists \delta_{\varepsilon}(a)>0 \forall x \in D\colon d(x,a)<\delta_{\varepsilon}
(a)\Rightarrow  \tilde{d}(f(x),f(a))<\varepsilon\end{gather*}
In Worten: $f(x)$ weicht beliebig wenig von $f(a)$ ab, falls nur $x$ hinreichend nahe bei $a$ liegt oder 
zu jeder $\varepsilon$-Kugel $\stackrel{\circ}{B_{\varepsilon}}(f(a))$ existiert eine $\delta_{\varepsilon}$
-Kugel relativ zu $D$ mit $f(\stackrel{\circ}{B_{\varepsilon}}\cap D)\subset \stackrel{\circ}{B_{\varepsilon}}
(f(a))$.
\begin{gather*}\forall \varepsilon >0 \exists \delta_{\varepsilon}>0\colon f(\stackrel{\circ}{B_{\delta_{\varepsilon}}}(a)
\cap D) \subset \stackrel{\circ}{B_{\varepsilon}}(f(a))\end{gather*}
\end{theorem}
\textbf{Beweis}
\begin{itemize}
  \item["`$\Rightarrow$"'] Voraussetzung: $\forall (x_n)\subset D\colon x_n\rightarrow a \Rightarrow f(x_n)
    \rightarrow f(a)$\\
    zu zeigen: $\forall \varepsilon >0 \exists \delta_{\varepsilon} >0 \forall x\ in D\colon d(x,a)<
    \delta_{\varepsilon}\Rightarrow \tilde{d}(f(x),f(a))<\varepsilon$\\
    Der Beweis wird indirekt geführt. Annahme: $\exists \varepsilon >0 \forall \delta >0 \exists
    x \in D\colon d(x,a)<\delta \wedge \tilde{d} (f(x),f(a))\geq \varepsilon$\\
    Insbesondere gilt: $\forall n \in \N \exists x_n \in D\colon d(x_n,a)<\frac{1}{n} \wedge \tilde{d}(f(x_n),
    f(n))\geq \varepsilon \stackrel{n\rightarrow \infty}{\Longrightarrow} x_n \rightarrow a \wedge 
    f(x_n)\not\rightarrow f(a)$
   \lightning
  \item["`$\Leftarrow$"'] zu zeigen: $\forall (x_n) \subset D$ mit $x_n\rightarrow a$ gilt $f(x_n)
    \rightarrow f(a)$\\
    Sei $(x_n)\subset D$ mit $x_n\rightarrow a$ und $\varepsilon >0$. Nach Voraussetzung existiert ein
    $\delta >0$, so dass $\tilde{d}(f(x),f(a))<\varepsilon \forall x \in D$ mit $d(x,a)<\delta$. Da
    $x_n\rightarrow a$ gibt es ein $n_0\in \N$, so dass $d(x_n,a)<\delta \forall n\geq n_0
    \Rightarrow \tilde{d}(f(x_n),f(a))<\varepsilon$ für alle $n\geq n_0$.
\end{itemize}
\qed

Beispiel: $f\colon\Q\rightarrow\R , f(x)\coloneqq\begin{cases}0 & x<\sqrt{2}\\1 & x>\sqrt{2}\end{cases}$\\
$f(x)$ ist stetig auf $\Q$.\\
Beweis: Sei $a\in \Q$. Zeige $\lim_{x\rightarrow a} f(x)=f(a)$
\begin{enumerate}[1. F{a}ll]
\item Sei $a>\sqrt{2}$ und $(x_n)\subset \Q$, so dass $x_n\rightarrow a$.\\
  Setze $\varepsilon \coloneqq a-\sqrt{2}>0$. Für $\varepsilon$ gibt es ein
  $n_0\in \N$, so dass $\abs{x_n-a} <\varepsilon$ für alle $n\geq
  n_0$. Ferner gilt $x_n>\sqrt{2}$ für $n\geq n_0$, denn $-\varepsilon
  <x_n-a<\varepsilon$ für $n\geq n_0 \Rightarrow
  \underbrace{a-\varepsilon}_{\sqrt{2}} <x_n
  \Rightarrow f(x_n)=1 \forall n\geq n_0$\\
  $\lim_{n\rightarrow \infty} f(x)=1=f(a)$
\item Sei $a<\sqrt{2}$: analog
\end{enumerate}

\section{Grenzwerte und Häufungspunkte von Mengen}
\begin{definition}
  Sei $X$ ein metrischer Raum und $D\subset X$. Ein Punkt $a\in X$
  heißt genau dann Häufungspunkt von $D$, wenn:
  \begin{gather*}\forall \varepsilon >0\colon
  \left(\stackrel{o}{B_{\varepsilon}}(a)\backslash \{a\} \right)\cap D
  \neq \emptyset\end{gather*}
\end{definition}
\emph{Achtung}: Die Häufungspunkte einer Folge $(x_n)$ stimmen
i.\,a. \emph{nicht} mit dem Häufungspunkt der entsprechenden Menge
$\{x_n\colon n\in\N\}$ überein. Zum Beispiel hat die konstante Folge $(a)_n$
hat den Häufungspunkt $a$. $a$ selbst hat keinen Häufungspunkt.

\begin{theorem}
  Sei $f\colon D\rightarrow Y, D\subset Y$ und $a\in X$ ein Häufungspunkt
  von $D$. Dann gilt:
  \begin{gather*}\lim_{x\rightarrow a} f(x)=c\Leftrightarrow \forall\varepsilon >0
  \exists \delta >0\colon\forall x\in D\colon d(x,a) <\delta \Rightarrow
  \tilde{d}(f(x),c)<\varepsilon\end{gather*}
\end{theorem}
\begin{proof}
  Der Beweis wird analog zu \autoref{satz:e-d-stetig} geführt.
\end{proof}

\begin{remark}
\begin{description}
\item[Negation des Häufungspunktes] $a\in X$ ist genau dann kein
  Häufungspunkt von $D$, wenn es eine $\varepsilon$-Kugel um $a$ gibt,
  die kein Element aus $D$ enthält, ausser eventuell $a$ selbst.
  \begin{gather*}\exists \varepsilon >0\colon(B_{\varepsilon}(a)\backslash \{a\})\cap D=\emptyset\end{gather*}
\item[isolierter Punkt] $a\in D$ heißt \emph{isolierter
    Punkt\index{Punkt!isolierter}}
  \begin{gather*}\perdef \exists \varepsilon>0\colon(B_{\varepsilon}(a)\backslash
  \{a\})\cap D=\emptyset\end{gather*}
\item[Korollar] Sei $D\subset X, f\colon D\rightarrow Y$. Dann gilt
  \begin{enumerate}[i]
  \item $f$ ist in jedem isolierten Punkt von $D$ stetig.
  \item $f$ ist genau dann in einem Häufungspunkt von $D$ stetig, wenn
    $\lim_{x\rightarrow a}f(x)=f(a)$, d.\,h. bei der Untersuchung einer
    Funktion auf Stetigkeit genügt es, nur die Häufungspunkte zu
    betrachten.
  \end{enumerate}
\end{description}
\end{remark}

\section{Stetigkeit, offene und abgeschlossene Mengen}
\begin{definition}
Sei $X$ ein metrischer Raum.
\begin{enumerate}[(1)]
\item $O\subset X$ heißt genau dann \emph{offen\index{Menge!offene}},
  wenn es zu jedem Element in $O$ eine $\varepsilon$-Kugel um dieses
  Element gibt, die ebenfalls ganz in $O$ liegt.
  \begin{gather*}\forall x\in O\colon\stackrel{\circ}{B_{\varepsilon}}(x)\subset O\end{gather*}
\item $A\subset X$ heißt genau dann
  \emph{abgeschlossen\index{Menge!abgeschlossene}}, wenn
  $X\backslash A$ offen ist.
\end{enumerate}
\end{definition}
Beispiele:
\begin{enumerate}[(i)]
  \item $\emptyset, X$ sind offen und abgeschlossen
    \begin{itemize}
      \item $X$ offen: klar!
      \item $\emptyset$ offen: Sei $\emptyset$ nicht offen, dann gilt
        $\exists x_0\in \emptyset$ \lightning $\forall \varepsilon>0\colon
        \stackrel{o}{B_{\varepsilon}}(x_0)\cap (X\backslash
        \emptyset)\neq \emptyset$\lightning 
      \item $X$ ist abgeschlossen, da $X\backslash X=\emptyset$. Die leere Menge ist offen.
      \item $\emptyset$ ist abgeschlossen, da $X\backslash \emptyset=X$. $X$ ist offen.
    \end{itemize}
  \item $r\geq 0\quad \stackrel{o}{B_r}(a)$ ist offen und $B_r(a)$ ist abgeschlossen.
\end{enumerate}

\begin{theorem}
\label{satz:abgTeilmenge}
Eine Teilmenge $A\subseteq X$ ist genau dann abgeschlossen, wenn $\forall (x_n) \subset A\colon(x_n)$
konvergent $\Rightarrow \lim x_n \in A$.\\
\textbf{Beweis}
\begin{itemize}
  \item["`$\Rightarrow$"'] Der Beweis erfolgt durch Kontraposition: Sei $A$ abgeschlossen\\
    Annahme: $\exists (x_n)\subset A\colon(x_n) \text{ konvergent} \Rightarrow \lim x_n \notin A$\\
    $a\coloneqq\lim x_n$\\
    $\Rightarrow a \in X\backslash A$ offen, da $A$ nach Voraussetzung abgeschlossen.\\
    $\Rightarrow \exists \varepsilon >0 \stackrel{o}{B_{\varepsilon}}(a)\subset X\backslash A$\\
    Da $x_n$ gegen $a$ strebt, existiert ein $n_0\in \N$, so dass $d(x_n,a)<\varepsilon$ für $n\geq n_0$\\
    $\Rightarrow x_n \in \stackrel{o}{B_{\varepsilon}}(a)$\textnormal{\lightning}
  \item["`$\Leftarrow$"'] Sei $\forall (x_n)\subset A\colon x_n \text{ konvergent} \Rightarrow \lim x_n \in A$\\
    Annahme: $A$ ist offen. Dann ist zu zeigen:
    \begin{align*}
      A \text{ abgeschlossen} & \Leftrightarrow & X\backslash A \text{ offen}\\
      & \Leftrightarrow & \forall x \in X\backslash A \exists \varepsilon >0\colon\stackrel{o}{B_{\varepsilon}}
      (x)\subseteq X\backslash A\\
      & \Leftrightarrow & \forall x \in X\backslash A \exists \varepsilon >0\colon\stackrel{o}{B_{\varepsilon}}
      (x)\cap A = \emptyset
    \end{align*}
    $\Rightarrow \exists x_0 \in X\backslash A \forall \varepsilon >0\colon\stackrel{o}{B_{\varepsilon}}(x_0)
    \cap A \neq \emptyset$\\
    Insbesondere existiert ein $x_n \in A \colon d(x_n,x_0)<\frac{1}{n}$\\
    $\stackrel{Voraussetzung}{\Longrightarrow}x_0=\lim x_n \in A$\textnormal{\lightning}
\end{itemize}
\qed
\end{theorem}

\textbf{Korollar} Sei $A'$ die Menge der Häufungspunkte von $A$. Dann ist $A$ genau dann abgeschlossen, wenn
$A'$ eine Teilmenge von $A$ ist.\\
\textbf{Beweis}
\begin{itemize}
  \item["`$\Rightarrow$"'] Sei $a\in A'$. Dann existiert $x_n \subset A, x_n\neq a, x_n\rightarrow a
    \Rightarrow a \in A$
  \item["`$\Leftarrow$"'] Annahme: $A$ ist nicht abgeschlossen.\\
    $\Rightarrow \exists (x_n) \subset A, (x_n)$ ist konvergent, aber $\lim x_n\in A$\\
    $\Rightarrow a$ ist Häufungspunkt von $A$\\
    $\Rightarrow A'\not\subset A$\lightning
\end{itemize}
\qed

\begin{theorem}
\label{satz:fkt-aquiv}
Seien $X,Y$ metrische Räume und $f\colon D\rightarrow Y$. Dann sind folgende Aussagen äquivalent:
\begin{enumerate}[(1)]
  \item $f$ ist stetig auf $X$.
  \item $\forall O \subset Y$ offen $\colon f^{-1}(O)$ offen
  \item $\forall A \subset Y$ abgeschlossen $\colon f^{-1}(A)$ abgeschlossen
\end{enumerate}
\end{theorem}
\textbf{Beweis}
\begin{itemize}
  \item[$(1)\Rightarrow (2)$] Sei $O\subset Y$ offen, $x\in f^{-1}(O)\Leftrightarrow f(x)\in O$\\
    $\stackrel{O \text{ offen}}{\Longrightarrow} \exists \varepsilon >0\colon\stackrel{o}{B_{\varepsilon}}
    (f(x))\subset O$\\
    $\stackrel{f \text{ stetig}}{\Longrightarrow} \exists \delta >0\colon f(\stackrel{o}{B_{\delta}}(x))\subset
    \stackrel{o}{B_{\varepsilon}}(f(x))\subset O$\\
    $\Longrightarrow \stackrel{o}{B_{\delta}}(x)\subset f^{-1}(O)$
  \item[$(2)\Rightarrow (1)$] Sei $x\in X, \varepsilon
    >0\stackrel{(2)}{\Rightarrow} f^{-1}(\stackrel{o}
    {B_{\varepsilon}}(f(x)))$ offen\\
    $\Rightarrow \exists \delta >0\colon\stackrel{o}{B_{\delta}}(x)\subset
    f^{-1}(\stackrel{o}
    {B_{\varepsilon}}(f(x)))$\\
    $\Rightarrow f(\stackrel{o}{B_{\delta}}(x))\subset
    \stackrel{o}{B_{\varepsilon}} (f(x)) \Rightarrow f$ stetig
  \item[$(2)\Leftrightarrow (3)$] $f^{-1}(Y\backslash M)=f^{-1}(Y)\backslash f^{-1}(M)=x\backslash f^{-1}(M)$
  \item[$(2)\Rightarrow (3)$] Sei $A$ abgeschlossen. $O=Y\backslash A$ offen $\Leftrightarrow A=Y
    \backslash O$\\
    $f^{-1}(A)=f^{-1}(Y)\backslash f^{-1}(O)=X\backslash \underbrace{f^{-1}(O)}_{offen} \Rightarrow$
    abgeschlossen
  \item[$(3)\Rightarrow (2)$] Sei $O$ offen. Dann ist $A=Y\backslash O$ abgeschlossen. $\Rightarrow f^{-1}
    (A)=X\backslash \underbrace{f^{-1}(O)}_{offen} \Rightarrow$ abgeschlossen.
\end{itemize}
\qed

\section{Stetigkeit und kompakte Mengen}
\begin{definition}
Sei $X$ ein metrischer Raum. Eine Menge $K\subset X$ heißt genau dann \emph{kompakt\index{Menge!kompakte}},
wenn jede Folge aus $K$ eine konvergente Teilfolge in $K$ enthält.
\begin{gather*}\forall (x_n) \subset K \exists (x_{n_k})\subset (x_n)\colon\lim_{K\rightarrow \infty} x_{n_k}\in K\end{gather*}
\end{definition}

\begin{theorem}
\label{satz:beschr-abg}
\begin{enumerate}[(1)]
  \item Sei $K\subset X$ kompakt. Dann ist $K$ beschränkt und abgeschlossen.\\
    \textbf{Beweis}\textit{Beschränktheit} Annahme: $K$ ist nicht beschränkt.\\
    $\Rightarrow \exists a \in K \forall n \in \N \exists x_n \in K\colon d(x_n,a)\geq n$\\
    $\Rightarrow$ Es existiert keine konvergente Teilfolge $(x_{n_k})$ aus $(x_n)$\textnormal{\lightning}\\
    \textit{Abgeschlossenheit} Sei $(x_n)\subset K \colon x_n \rightarrow a\in X$ zu zeigen: $a\in K$\\
    $\stackrel{\text{kompakt}}{\Rightarrow} \exists \text{ Teilfolge} (x_{n_k})\subset X \colon\lim (x_{n_k})\in K$\\
    $\Rightarrow \lim x_n=\lim x_{n_k}=a\in K$
  \item In $\R$ gilt: $K\subset \R$ ist genau dann kompakt, wenn $K$ beschränkt und abgeschlossen ist.\\
    \textbf{Beweis} $K\subset \R$ abgeschlossen und beschränkt. Dann ist zu zeigen, dass $K$ kompakt ist.\\
    Sei $(x_n)\subset K \Rightarrow (x_n)$ beschränkt $\stackrel{\text{\autoref{satz:bw}}}{\Rightarrow}
    \exists \text{ TF} (x_{n_k})\subset (x_n)\colon \lim x_{n_k}\in\R\stackrel{\text{abg.}}{\Rightarrow}
    \lim (x_{n_k})\in K$
\end{enumerate}
\qed
\end{theorem}

Beispiele:
\begin{enumerate}[(i)]
  \item $[a,b]$ ist kompakt, da beschränkt und abgeschlossen.
  \item Endliche Mengen sind kompakt.
  \item $\lsofint{0,1}$ ist nicht kompakt.
\end{enumerate}

\subsubsection{Gleichmässige Stetigkeit}
\begin{definition}
Sei $D\subset X, f\colon D\rightarrow Y$. $f$ heißt genau dann 
\highl{gleichmässig stetig}, wenn:
\begin{gather*}\forall \varepsilon >0 \exists \delta_{\varepsilon}>0 \forall x,y \in D\colon d(x,y)<\delta_{\varepsilon}
\Rightarrow \tilde{d} (f(x),f(y))<\varepsilon\end{gather*}
\end{definition}
Bemerkung: $f$ ist stetig auf $D \perdef \forall x\in D \forall \varepsilon >0 \exists \delta_{\varepsilon}
(x)>0 \forall y\in D\colon d(x,y)<\delta_{\varepsilon}(x)\Rightarrow \tilde{d}(f(x),f(y))<\varepsilon$\\
Offenbar gilt: $f$ ist gleichmässig stetig auf $D\Rightarrow f$ stetig auf $D$. Die Umkehrung gilt im allgemeinen
nicht.\\
Beispiel: $D=\lsofint{0,1}\subset \R =X=Y, f(x)=\frac{1}{x}$\\
Es gilt, dass $f$ in $\lsofint{0,1}$ stetig, aber nicht gleichmässig stetig ist.\\
\textbf{Negation von gleichmässiger Stetigkeit} $f\colon D\rightarrow Y$ ist auf $D$ nicht gleichmässig stetig:
\begin{gather*}\exists \varepsilon >0 \forall \delta_{\varepsilon}>0 \exists x_{\delta},y_{\delta}\in D\colon
\abs{x_{\delta}-y_{\delta}}<\delta \wedge \abs{f(x_{\delta})-f(y_{\delta})}\geq \varepsilon\end{gather*}
In unserem Fall sei $\varepsilon=1$. Für $\delta>0$ wählen wir $x_{\delta}=\frac{\min\{1,\delta\}}{1+\delta},
y_{\delta}=\min\{1,\delta\}\in \lsofint{0,1}$\\
Dann:
\begin{align*}
  \abs{x_{\delta}-y_{\delta}} &= y_{\delta}-x_{\delta}\\
  &= \min\{1,\delta\}(1-\frac{1}{1+\delta})\\
  &= \min\{1,\delta\}\frac{\delta}{\delta+1}<\delta
\intertext{und}
  \abs{f(x_{\delta})-f(y_{\delta})} &= \abs{\frac{1}{x_{\delta}}
    -\frac{1}{y_{\delta}}}\\
  &= \frac{1}{x_{\delta}}-\frac{1}{y_{\delta}}\\
  &= \frac{1+\delta}{\min\{1,\delta\}}-\frac{1}{\min\{1,\delta\}}\\
  &= \frac{\delta}{\min\{1,\delta\}}\geq \frac{\delta}{\delta}=1\\
  &\Rightarrow f(x)=\frac{1}{x} \text{ nicht gleichmässig stetig auf } \lsofint{0,1}
\end{align*}

\begin{theorem}
\label{satz:gleichm-stetig}
Sei $K\subset X$ kompakt und $f\colon K\rightarrow Y$ stetig. Dann gilt
\begin{enumerate}[(1)]
  \item $f$ ist gleichmässig stetig auf $K$.\\
    \textbf{Beweis} Annahme: $f$ ist stetig, aber nicht gleichmässig stetig auf $K$\\
    $\exists \varepsilon_0>0 \forall \delta >0 \exists x_{\delta},y_{\delta}\in K\colon d(x_{\delta},
    y_{\delta})<\delta\wedge\tilde{d}(f(x_{\delta}),f(y_{\delta}))\geq \varepsilon_0$\\
    Insbesondere existiert für $\delta_n=\frac{1}{n}$ ein $x_n,y_n$ aus $K$ mit \\
    $d(x_n,y_n)<\frac{1}{n}
    \wedge \tilde{d}(f(x_n),f(y_n))\geq \varepsilon_0$\\
    Wegen der Kompaktheit existiert eine Teilfolge $(x_{n_k})\subset (x_n)\colon x_{n_k}\rightarrow a\in K
    \Rightarrow (y_{n_k})\rightarrow a\in K$ gilt wegen $d(y_{n_k},a)\leq d(y_{n_k},x_{n_k})+d(x_{n_k},a)
    \stackrel{K\rightarrow\infty}{\rightarrow}0$\\
    Stetigkeit: $f(x_{n_k})\rightarrow f(a), f(y_{n_k})\rightarrow f(a)$\textnormal{\lightning}
  \item $f(K)$  ist kompakt.
    Sei $(y_n)\subset f(K)$. Dann existiert $x_n \in K\colon f(x_n)=y_{n_k}$\\
    $\stackrel{\text{kompakt}}{\Rightarrow} \exists \text{ Teilfolge } (x_{n_k})\subset (x_n)\colon x_{n_k}\rightarrow
    a \in K$\\
    $\stackrel{\text{stetig}}{\Rightarrow} y_{n_k}=f(x_{n_k})\rightarrow f(a) \in f(K)$\\
    $\Rightarrow f(K)$ ist kompakt
\end{enumerate}
\qed
\end{theorem}

\begin{theorem}
\label{satz:max-fkt}
Sei $K\subset X$ kompakt und $f\colon K\rightarrow\R$ stetig. Dann gilt:
\begin{gather*}\exists p \in K\colon f(p)=\sup_{X\in K}f(x)\end{gather*}
$f$ nimmt auf $K$ ihr Maximum an.
\begin{gather*}\exists q \in K\colon f(q)=\inf_{X\in K}f(x)\end{gather*}
$f$ nimmt auf $K$ ihr Minimum an.\\
\textbf{Beweis}: Für Maximum: Nach \autoref{satz:beschr-abg} und \autoref{satz:gleichm-stetig} wissen wir: Die Tatsache, dass
$f$ stetig ist, impliziert, dass $f(K)$ beschränkt ist.
\begin{align*}
  M\coloneqq\sup_{x\in K} f(x)\in\R & \Rightarrow \forall n \in \N\,\exists x_n\in K\colon f(x_n)\leq M\leq f(x_n)+\frac{1}{n}\\
  & \stackrel{K\text{~kompakt}}{\Rightarrow} \exists \text{Teilfolge} (x_{n_k})\subset (x_n)\colon x_{n_k}\rightarrow p\in K\\
  & \stackrel{f\text{~stetig}}{\Rightarrow} f(p)=\lim_{K\rightarrow \infty} f(x_{n+k})=M
\end{align*}
\qed
\end{theorem}

Bemerkung: \autoref{satz:max-fkt} ist im allgemeinen falsch, falls $K$ nicht kompakt ist. Ein Beispiel hierfür ist
die Funktion $f(x)=\frac{1}{x}$. Diese hat auf dem Intervall $\bsofint{0,\infty}$ weder ein Maximum noch ein Minimum.

\subsubsection{Ein Satz über inverse Funktionen}
\begin{theorem}
\label{satz:invFunkt}
Sei $X$ ein kompakter metrischer Raum, die Abbildung $f\colon X\rightarrow Y$ stetig und injektiv. Dann gilt:
\begin{gather*}f^{-1}\colon f(X)\rightarrow X\text{ist stetig}\end{gather*}
\textbf{Beweis} $Y_0 \coloneqq f(X)$ ist nach \autoref{satz:gleichm-stetig} kompakt. Nach \autoref{satz:fkt-aquiv} genügt es,
zu zeigen, dass die Urbilder von abgeschlossenen Mengen wieder abgeschlossen sind.\\
$A\subset X$ abgeschlossen $\Rightarrow (f^{-1})^{-1}(A)=f(A)$ abgeschlossen\\
Sei $(y_n)\subset f(A), y_0\rightarrow b\in Y=f(X)$. Es ist zu zeigen, dass $b\in f(A)$.\\
$x_n=f^{-1}(y_n)\in A\subset X\stackrel{X\text{~kompakt}}{\Rightarrow} \exists \text{Teilfolge}(x_{n_k})\subset (x_n)
\colon x_{n_k}\rightarrow a\in X\stackrel{A\text{~abg.}}{\Rightarrow} a\in A\stackrel{f\text{~stetig}} b=\lim y_n=
\lim_{n\rightarrow\infty}f(x_n)=\lim_{k\rightarrow\infty}f(x_{n_k})=f(a)\in f(A)$
\qed
\end{theorem}

\section{Zwischenwert- und Fixpunktsatz}
\subsubsection{Zwischenwertsätze reeller Funktionen}
Eine Funktion $f\colon D\rightarrow\R , D\subset \R$ nennt man \emph{reelle Funktion\index{Funktion!reelle}}.
\begin{theorem}
\label{satz:zws}
Sei $f\colon[a,b]\rightarrow \R$ stetig mit $f(a)<0$ und $f(b)>0$ (bzw. umgekehrt). Dann existiert ein
\begin{gather*}p\in[a,b]\colon f(p)=0\end{gather*}
\textbf{Beweis}: Zur Beweisführung wird die Intervall-Halbierungsmethode heran gezogen:
Sei $f(a)<0$ und $f(b)>0$. Wir definieren induktiv $[a_n,b_n]\subset [a,b], n\in \N$
\begin{enumerate}[(i)]
  \item $[a_n,b_n]\subset [a_{n-1},b_{n-1}], n\geq 1, [a_0,b_0]\coloneqq[a,b]$
  \item $b_n-a_n=2^{-n}(b-a)$
  \item $f(a_n)\leq 0, f(b_n)\geq 0$
\end{enumerate}
Induktionsanfang: $[a_0,b_0]=[a,b]$\\
Induktionsschritt: $n\rightarrow n+1$\\
Sei $[a_n,b_n]$ bereits definiert und $m\coloneqq\frac{a_n+b_n}{2}$. Dann sind folgende zwei Fälle möglich:
\begin{enumerate}[1. F{a}ll]
  \item $f(m)\geq 0$ Dann ist $[a_{n+1},b_{n+1}]\coloneqq[a_n,m]\subset [a_n,b_n]$
    \begin{enumerate}[(i)]
      \item $b_{n+1}-a_{n+1}=m-a_n=\frac{a_n+b_n}{2}-a_n=\frac{1}{2}(b_n-a_n)=\frac{1}{2}2^{-n}(b-a)=2^{-(n+1)}(b-a)$
      \item $f(a_{n+1})=f(a_n)\geq 0, f(b_{n+1})=f(m)\geq 0$
    \end{enumerate}
  \item $f(m)<0$ Dann ist $[a_{n+1},b_{n+1}]\coloneqq[m,b_{n+1}]\subset [a_n,b_n]$
    \begin{enumerate}[(i)]
      \item $b_{n+1}-a_{n+1}=b_n-m=b_n-\frac{a_n+b_n}{2}=\frac{1}{2}(b_n-a_n)=\frac{1}{2}2^{-n}(b-a)=2^{-(n+1)}(b-a)$
      \item $f(a_{n+1})=f(m)\leq 0, f(b_{n+1})\geq 0$
    \end{enumerate}
    $\left.\begin{array}{rcl}
      (a_n) \text{mon. wachsend u. beschr.}\\
      (b_n) \text{mon. fallend u. beschr.}\\
      b_n-a_n=2^{-n}(b-a)
    \end{array}\right\}\Rightarrow \lim a_n=\lim b_n=p$
\end{enumerate}
Die Stetigkeit von $f$ und die vorige Fallunterscheidung liefern:\\
$\left.\begin{array}{rcl}
  f(p)=\lim f(a_n)\leq 0\\
  f(p)=\lim f(b_n)\geq 0
\end{array}\right\}\Rightarrow f(p)=0$
\qed
\end{theorem}

\begin{Folg}
\textbf{2. Zwischenwertsatz} Sei $f\colon[a,b]\rightarrow\R$ und $c\in \R$ liegt zwischen $f(a)$ und $f(b)$. Dann existiert
$p\in[a,b]\colon f(p)=c$.\\
\textbf{Beweis} Sei $f(a)<c<f(b)$. Wir definieren eine Funktion
  $g\colon[a,b]\rightarrow \R$ durch $g(x)\coloneqq f(x)-c$. Die
Funktion $g$ ist stetig mit $g(a)=f(a)-c<0, g(b)=f(b)-c>0$. Dann folgt nach \autoref{satz:zws} $\exists p\in[a,b]
\colon g(p)=f(p)-c=0\Rightarrow f(p)=c$
\qed
\end{Folg}

\begin{Folg}
Sei $f\colon[a,b]\rightarrow\R$ stetig mit $f([a,b])\subset [a,b]$. Dann existiert $p\in [a,b]\colon f(p)$. $p$ heißt
\emph{Fixpunkt\index{Fixpunkt}}.
\end{Folg}

Bemerkung: Der Zwischenwertsatz gilt nicht, wenn rationale Zahlen betrachtet werden. Beispielsweise gibt es für
die Funktion $f(x)\coloneqq x^2-2$ keinen Fixpunkt im Intervall $[0,2]$, wenn das $x$ aus den rationalen Zahlen stammt.

\subsection{Ein Satz über reelle inverse Funktionen}
\begin{definition}
Sei $f\colon D\rightarrow\R, D\subset \R$ eine reelle Funktion. Sie heißt genau dann \emph{monoton wachsend} auf $D$, wenn
\begin{gather*}\forall x_1,x_2\in D\colon x_1<x_2\Rightarrow f(x_1)\leq f(x_2)\end{gather*}
Sie heißt genau dann \emph{streng monoton wachsend} auf $D$, wenn
\begin{gather*}\forall x_1,x_2\in D\colon x_1<x_2\Rightarrow f(x_1)<f(x_2)\end{gather*}
Sie heißt genau dann \emph{monoton fallend} auf $D$, wenn
\begin{gather*}\forall x_1,x_2\in D\colon x_1<x_2\Rightarrow f(x_1)\geq f(x_2)\end{gather*}
Sie heißt genau dann \emph{streng monoton fallend} auf $D$, wenn
\begin{gather*}\forall x_1,x_2\in D\colon x_1<x_2\Rightarrow f(x_1)>f(x_2)\end{gather*}
\end{definition}

\begin{theorem}
  \label{satz:reellInvFkt}
Sei $f\colon[a,b]\rightarrow\R$ eine stetige, streng monoton wachsende (fallende) Funktion und $A=f(a), B=f(b)$. Dann ist
$f\colon[a,b]\rightarrow [A,B] ([B,A])$ bijektiv und $f^{-1}\colon[A,B]([B,A])\rightarrow [a,b]$ ist stetig und streng 
monoton wachsend (fallend).
\textbf{Beweis} Sei $f\colon[a,b]\rightarrow\R$ stetig und streng monoton wachsend. Diese Funktion ist injektiv, denn
$x_1<x_2\Rightarrow f(x_1)<f(x_2)$.\\
$f\colon[a,b]\rightarrow[A,B]$ ist surjektiv, denn wenn $A<c<B$ dann folgt nach dem zweiten Zwischenwertsatz $\exists
p\in [a,b]\colon f(p)=c$. Daher ist $f$ bijektiv von $[a,b]\rightarrow [A,B]$.\\
$f^{-1}$ ist streng monoton wachsend. Es ist zu zeigen, dass $y_1,y_2\in [A,B]\colon y_1<y_2\rightarrow f^{-1}<f^{-1}$.\\
Annahme: $f^{-1}(y_1)\geq f^{-1}(y_2)\rightarrow y_1=f(f^{-1}(y_1))\geq f(f^{-1}(y_2))=y_2$\textnormal{\lightning}\\
$f^{-1}[A,B]\rightarrow [a,b]$ ist stetig. Nach \autoref{satz:invFunkt} ist auch $f$ auf der kompakten Menge 
$[a,b]$ stetig und bijektiv. Daher folgt, dass $^{-1}\colon f([A,B])=[A,B]\rightarrow [a,b]$ stetig.\qed
\end{theorem}

\subsection{Der Banachsche Fixpunktsatz in vollständigen metrischen Räumen}

Zur Erinnerung sollte sich nochmals \autoref{def:vollst} anschauen.\\
\textbf{Bemerkung} Eine abgeschlossene Teilmenge $A$ eines vollständigen metrischen Raumes $X$ ist in der Metrik
von $X$ ebenfalls ein vollständiger metrischer Raum.\\
Beweis: Sei $(x_n)\subset A$ eine Cauchyfolge. Dann ist $(x_n)\subset X$ eine Cauchyfolge. Da $X$ vollständig ist,
existiert ein $a\in X$ für das gilt $\lim x_n=a$. Aufgrund der Tatsache, dass $A$ abgeschlossen ist, gilt nach
\autoref{satz:abgTeilmenge}, dass $a\in A$ liegt. Daher folgt, dass $A$ abgeschlossen ist.

Beispiele: $X=\R, [a,b]$ ist ein vollständiger metrischer Raum.\\
$\rsofint{a,\infty}$ ist ein vollständiger metrischer Raum.\\
$\lsofint{\infty,a}$ ist ein vollständiger metrischer Raum.\\
$\bsofint{a,\infty}$ ist \emph{kein} vollständiger metrischer Raum.

\begin{theorem}[Banachscher
  Fixpunktsatz\index{Fixpunktsatz!Banachscher}]
  Dieser Satz wird auch \emph{Prinzip der kontrahierenden Abbildung} genannt.\\
Sei $(X,d)$ ein vollständiger metrischer Raum und $f\colon X\rightarrow X$ eine \emph{kontrahierende Abbildung
\index{Abbildung!kontrahierende}}, d.\,h.
\begin{gather*}\exists 0\leq\alpha <1 \forall x,y\in X\colon d(f(x),f(y))\leq \alpha d(x,y)\end{gather*}
Dann gilt:
\begin{enumerate}[(1)]
  \item $\exists!! a\in X\colon f(a)=a$\\
    $a$ heißt \emph{Fixpunkt\index{Fixpunkt}} von $f$.
  \item Sei $x_0\in X, x_{n+1}=f(f_x), n=0,1,2,\ldots \Rightarrow \lim x_n=a$\\
    Fehlerabschätzung: $d(a,x_n)\leq\frac{\alpha^n}{1-\alpha}d(x_0,x_1)$
\end{enumerate}
\textbf{Beweis} Sei $x_0\in X$ beliebig und $x_{n+1}=f(f_x), n=0,1,2,\ldots$
\begin{enumerate}[1. Schr{i}tt]
  \item $(x_n)$ ist eine Cauchyfolge. Dann gilt:
    \begin{align*}
      d(x_{n+1},x_n)&=d(f(x_n),f(x_{n-1}))\\
      & \leq \alpha d(x_n,x_{n-1})\\
      & \leq \alpha^2 d(x_{n-1},x_{n-2})\\
      & \leq \ldots \leq \alpha^n d(x_1,x_0)
    \end{align*}
    Nach der Dreiecksungleichung gilt 
    \begin{align*}
    n>m\colon d(x_n,x_m) & \leq d(x_n,x_{x-1})+d(x_{n-1},x_{n-2})+\cdots +d(x_{m+1},x_m)\\
    & \leq (\alpha^{n-1}+\alpha^{n-2}+\cdots +\alpha^n)d(x_1,x_0)\\
    & = \alpha^m(\alpha^{n-m-1}+\alpha^{n-m-2}+\cdots +1)d(x_1,x_0)\\
    & = \alpha^m\left(\frac{1-\alpha^{n-m}}{1-\alpha}\right)d(x_1,x_0)\\
    & \leq \frac{\alpha^m}{1-\alpha}d(x_1,x_0)
    \end{align*}
    Also hat man $d(x_n,x_m)\leq \frac{\alpha^m}{1-\alpha}d(x_1,x_0)$ für $n>m$. Aus der Tatsache, dass $\alpha$
    zwischen 0 und 1 liegt, folgt $\forall \varepsilon >0 \exists n_{\varepsilon}\in \N \forall n,m\geq
    n_{\varepsilon} \colon d(x_n,x_m)\leq \varepsilon$. Daher folgt weiter, dass $(x_n)$ eine Cauchyfolge ist. Weiterhin
    ist bekannt, dass $X$ vollständig ist. Dies bedingt, dass ein $a\in X$ existiert, für das $\lim x_n=a$ ist. Wegen
    der Dreiecksungleichung $\abs{d(a,x_m)-d(x_m,x_n)}\leq d(a,x_n)$ ergibt sich für $n\rightarrow \infty$, dass
    $d(a,x_n)\rightarrow 0\Rightarrow d(a,x_m)=\lim_{n\rightarrow\infty} d(x_n,x_m)\leq \frac{\alpha^m}{1-\alpha}
    d(x_1,x_0)$. Diese Formel impliziert die Fehlerabschätzung.
  \item $a$ ist Fixpunkt von $f$: $a=\lim_{n\rightarrow\infty}x_{n+1}=\lim_{n\rightarrow\infty} f(x_n)$. Da $f$ stetig
  ist, kann man das wie folgt umformen: $=f(\lim_{n\rightarrow\infty} x_n)=f(a)$
\end{enumerate}
\qed
\end{theorem}

\paragraph{Eindeutigkeit von Fixpunkten}
Annahme: $\exists a,b\in X\colon f(a)=a,f(b)=b$. Dann:
\begin{align*}
  d(a,b)=d(f(a),f(b)) & \leq \alpha d(a,b)\\
  \Rightarrow \underbrace{(1-\alpha)}_{>0}d(a,b)& \Rightarrow d(a,b)\leq 0\\
  & \Rightarrow d(a,b)=0\\
  & \Rightarrow a=b
\end{align*}
\qed

\textbf{Beispiel}: Berechnung von $\sqrt{a}$, Abbildung: $f(x)=\frac{1}{2}(x+\frac{a}{x}),
x=\rsofint{\sqrt{a},\infty}, d=\abs{\cdot }$
\begin{enumerate}
  \item $f(\rsofint{\sqrt{a},\infty})\subset \rsofint{\sqrt{a},\infty}$
  \item $f$ ist kontrahierend: $\abs{f(x)-f(y)}\leq \frac{1}{2}\abs{x-y}\ \alpha=\frac{1}{2}$
  \item $f(p)=\sqrt{p}, p=\sqrt{a}$ ist ein Fixpunkt.
\end{enumerate}
Rechenbeispiel: $a=2, f(x)=\frac{1}{2}(x+\frac{2}{x}), \rsofint{\sqrt{2},\infty}$
\begin{align*}
  x_0 & = 2\\
  x_1 & = f(x_0)=f(2)=\nicefrac{3}{2}\\
  x_2 & = f(x_1)= f(\nicefrac{3}{2})= \nicefrac{1}{2} (\nicefrac{3}{2}
  +\nicefrac{4}{3})=\nicefrac{17}{12}=1,41\overline{6}\\
  x_3 & = f(x_2)= f(\nicefrac{17}{12})= \nicefrac{1}{2}
  (\nicefrac{17}{12} +\nicefrac{24}{17})= \nicefrac{579}{408}=
  1,41415\overline{6}\\
  x_4 & = 1,4142135623746\ldots
\end{align*}

\section{Elementare Funktionen}
\paragraph{Bemerkungen über Grenzwerte und Stetigkeit von reellen Funktionen}

Sei $D\subset \R , f\colon D\rightarrow \R$ eine reelle Funktion, $a\in\R$ ist Häufungspunkt von $D$. Man schreibt:
\begin{enumerate}[(1)]
  \item $\lim_{x\rightarrow a+0}f(x)=c\perdef \forall (x_n)\subset D\ x_n>a,x_n\rightarrow a\Rightarrow f(x_n)=c$ $f$ hat in $c$
    den \emph{rechtsseitigen Grenzwert\index{Grenzwert!rechtsseitig}}.
  \item $\lim_{x\rightarrow a-0}f(x)=c\perdef \forall (x_n)\subset D\ x_n<a,x_n\rightarrow a\Rightarrow f(x_n)=c$ $f$ hat in $c$
    den \emph{linksseitigen Grenzwert\index{Grenzwert!linksseitig}}.
  \item $\lim_{x\rightarrow a+0}f(x)=f(a)\perdef \forall \varepsilon >0\ \exists \delta >0 \forall x \in D\colon 0\leq x-a<\delta
    \Rightarrow \abs{f(x)-f(a)}<\varepsilon$ $f$ ist \emph{linksseitig stetig\index{Stetigkeit!linksseitig}}.
  \item $\lim_{x\rightarrow a-0}f(x)=f(a)\perdef \forall \varepsilon >0\ \exists \delta >0 \forall x \in D\colon 0\leq a-x<\delta
    \Rightarrow \abs{f(x)-f(a)}<\varepsilon$ $f$ ist \emph{rechtsseitig stetig\index{Stetigkeit!rechtsseitig}}.
  \item $\lim_{x\rightarrow\infty} f(x)=c\perdef \forall (x_n)\subset D (x_n \rightarrow \infty \Rightarrow f(x_n)\rightarrow c)$
  \item $\lim_{x\rightarrow a} f(x)=\infty\perdef \forall (x_n)\subset D\\\{a\} (x_n \rightarrow a \Rightarrow f(x_n)\rightarrow \infty)$
\end{enumerate}

\subsection{Polynome und rationale Funktionen}

Eine Funktion $P\colon\R\rightarrow \R$ mit $P(x)=a_0x^k+a_1x^{k-1}+\cdots + a_{k-1}x+a_k (a_0\neq 0, k=0,1,2,\ldots)$ heißt
\emph{Polynom\index{Polynom}} $k$-ten Grades.

Eine Funktion $R(x)=\frac{P(x)}{Q(x)}$ mit $P,Q$ Polynomen heißt \emph{rationale Funktion\index{Funktion!rationale}}.

Es gilt: $P\colon\R\rightarrow\R$ stetig, $R\colon D\rightarrow\R, D=\{x\in \R\colon Q(x)\neq0\}$
\textbf{Beweis}: siehe \autoref{satz:e-d-stetig}. Ferner gilt:
\begin{gather*}\lim_{x\rightarrow\infty}P(x)=\begin{cases}\infty, a_0>0, k\geq 1\\-\infty, a_0<0, k\geq 1\end{cases}\end{gather*}
\begin{gather*}\lim_{x\rightarrow\infty}P(x)=\begin{cases}\infty, a_0>0, k \text{ gerade}\\-\infty, a_0<0, k \text{ gerade}\\-\infty, a_0>0,
k \text{ ungerade}\\\infty, a_0<0, k \text{ ungerade}\end{cases}\end{gather*}
\begin{gather*}P(x)=x^k(a_0+\frac{a_1}{x}+\cdots + \frac{a_k}{x^k}), x \neq 0\end{gather*}

\subsection{Exponential-, Logarithmus- und Potenzfunktionen}

\begin{gather*}\exp(x)\coloneqq\sum_{k=0}^\infty \frac{x^k}{k!}=1+x+\frac{x^2}{2}+\frac{x^3}{3!}+\frac{x^4}{4!}+\cdots\end{gather*}
ist absolut konvergent für alle $x\in \R$. Somit definiert $\exp\colon\R\rightarrow\R$ eine Funktion auf $\R$. Sie heißt
\emph{Exponentialfunktion\index{Exponentialfunktion}}.

\begin{theorem}
  \label{satz:expEigenschaft}
Für $\exp\colon\R\rightarrow\R$ gelten folgende Eigenschaften:
\begin{enumerate}[i]
  \item $\exp(0)=1, \exp(1)=e, \exp(x+y)=\exp(x)\cdot \exp(y), x,y \in \R$\\
    zum Beweis siehe Beispiele und Korollar aus dem vorigen Kapitel
  \item $\exp(x)>0, x\in \R$\\
    zum Beweis siehe Beispiele und Korollar aus dem vorigen Kapitel
  \item $\exp(-x)=(\exp(x))^{-1}$\\
    zum Beweis siehe Beispiele und Korollar aus dem vorigen Kapitel
  \item $e^n=\exp(n), n\in \Z$\\
    zum Beweis siehe Beispiele und Korollar aus dem vorigen Kapitel
  \item Abschätzung des Rest:\\
    $\exp(x)=\sum_{k=0}^N \frac{x^k}{k!}+r_{N+1}(x)$, wobei $\abs{r_{N+1}(x)}\leq 2\frac{\abs{x}^{N+1}}{(N+1)!}$ für $\abs{x}\leq 1+\frac{N}{2}$\\
    \textbf{Beweis}:
    \begin{align*}
      \abs{r_{N+1}(x)} &= \abs{\sum_{k=N+1}^\infty \frac{x^k}{k!}}\\
      &\leq \sum_{k=N+1}^\infty \frac{\abs{x}^k}{k!}=\frac{\abs{x}^{N+1}}{(N+1)!}+\frac{\abs{x}^{N+2}}{(N+2)!}+\frac{\abs{x}^{N+3}}{(N+3)!}+\cdots\\
      &= \frac{\abs{x}^{N+1}}{(N+1)!}\left( 1+\frac{\abs{x}}{N+2}\right.\\
      & \left. +\frac{\abs{x}^2}{(N+2)(N+3)}+\frac{\abs{x}^3}{(N+2)(N+3)(N+4)}+\cdots\right)\\
      &\leq \frac{\abs{x}^{N+1}}{(N+1)!}\left( 1+\frac{\abs{x}}{N+2}+\frac{\abs{x}^2}{(N+2)^2}+\frac{\abs{x}^3}{(N+2)^3}+\cdots \right)\\
      &\leq \frac{\abs{x}^{N+1}}{(N+1)!}\left( 1+\frac{1}{2}\left(\frac{1}{2}\right)^2+\cdots + \left(\frac{1}{2}\right)^k\right)
        \text{ für } \frac{\abs{x}}{N+2}\leq \frac{1}{2}\\
      &= \frac{\abs{x}^{N+1}}{(N+1)!}\cdot \frac{1}{1-\frac{1}{2}}\\
      &= 2\frac{\abs{x}^{N+1}}{(N+1)!} \text{ für } \abs{x}\leq 1+\frac{N}{2}
    \end{align*}
\end{enumerate}
\end{theorem}

\begin{theorem}
\begin{enumerate}[i]
  \item Die Exponentialfunktion $\exp\colon \R\rightarrow\R$ ist stetig, streng monoton wach\-send und bildet $\R$ bijektiv auf
    $\bsofint{0,\infty}$ ab.
  \item Die Umkehrfunktion $ln\colon\bsofint{0,\infty}\rightarrow\R$ ist stetig, monoton wachsend und heißt der \emph{natürliche
    Logarithmus\index{Logarithmus!natürlicher}}. Es gilt die Funktionalgleichung $ln(xy)=ln(x)+ln(y)$.
\end{enumerate}
\end{theorem}

\textbf{Beweis}
\begin{enumerate}[zu i]
  \item \textbf{Stetigkeit von $\exp$} $\exp$ ist in $x=0$ stetig:\\
    $\abs{\exp(x)-\exp(0)}=\abs{\exp(x)-1}\leq 2\frac{\abs{x}}{1!}=2x$ für $\abs{x}\leq 1 (N=0)$\\
    $\Rightarrow \lim_{x\rightarrow 0}\exp(x)=\exp(0)=1\Rightarrow$ Stetigkeit in $x=0$\\
    Stetigkeit in $x_0\in \R$ beliebig\\
    $\lim_{x\rightarrow x_0} \exp(x)=\lim_{x\rightarrow x_0} (\exp(x-x_0)\cdot \exp(x_0))$\\
    $\Rightarrow \lim_{x\rightarrow x_0\rightarrow 0} \exp(x-x_0)\cdot \lim_{x\rightarrow x_0} \exp(x_0)=\exp(0)\cdot \exp(x_0)
    =\exp(x_0)$\\
    \textbf{streng monoton wachsend}\\
    $x_0<x_1 \Rightarrow \exp(x_1)=\exp(x_1-x_0)\cdot \exp(x_0)>\exp(x_0)\Rightarrow$ streng monoton wachsend\\
    \textbf{$\exp\colon\R\rightarrow \bsofint{0,\infty}$ bijektiv}\\
    Die Exponentialfunktion ist bijektiv, da sie streng monoton wachsend ist. Ferner gilt: $0<\exp(x)<\infty$ für $x\in\R$
    (\autoref{satz:expEigenschaft})
  \item $ln\coloneqq(\exp)^{-1}; \bsofint{0,\infty}$ ist stetig und streng monoton wachsend auf jedem kompakten Intervall $[a,b]\subset \bsofint{0,
    \infty}$ (nach \autoref{satz:reellInvFkt})
    und damit auch auf $\bsofint{0,\infty}$\\
    $x_0<x_1 \Rightarrow f(x_0)<f(x_1)$\\
    Funktionalgleichung:\\
    $\exp(ln (x)+ln(y))=\exp(ln(x))\cdot \exp(ln(y))=x\cdot y$
\end{enumerate}

\subsection{Exponentialfunktion zur Basis \texorpdfstring{$a$}{a}}

\begin{definition}
\textbf{Exponentialfunktion zur Basis $a$} Sei $a>0, a\neq 1$. Dann heißt $\exp_a \colon\R\rightarrow\R$ definiert durch $\exp_a (x)\coloneqq
exp(x\ ln (a))$ \emph{Exponentialfunktion\index{Exponentialfunktion}} zur Basis $a$.
\end{definition}

\begin{theorem}
\label{satz:expa}
Die Funktion $\exp_a \colon\R\rightarrow\R$ ist stetig und es gilt:
\begin{enumerate}[i]
  \item $\exp_a(x+y)=\exp_a(x)\cdot \exp_a(y), x,y \in \R$
  \item $\exp_a(n)=a^n, n\in \Z$
  \item $\exp_a (\frac{p}{q})=\sqrt[q]{a^p}=:a^{\frac{p}{q}}, p\in \Z , q\in \N$
\end{enumerate}
\end{theorem}
\textbf{Beweis}: Stetigkeit: da $x \mapsto x \cdot \underbrace{ln (a)}_{Konstante}$\\
$f(x)=x\cdot ln(a)\quad g(x)=\exp(x)\quad \exp_a(x)=g(f(x))$ Die Komposition von stetigen Funktionen ist wieder stetig.
\begin{enumerate}[i)]
  \item \begin{align*}
    \exp(x+y) & = & \exp((x+y)ln (a))\\
    & = & \exp(x \cdot ln (a))\cdot \exp(y\cdot ln(a))\\
    & = & \exp_a(x)\cdot \exp_a(y)
  \end{align*}
  \item $n\in \N\colon \exp_a (n)=\exp(n\cdot ln(a))=\exp(ln(a^n))=a^n$\\
    $-n\in \N\colon \exp_a(n)=\frac{1}{\exp(-n)}=\frac{1}{a^{-n}}=a^n$
  \item $p\in \Z, q\in \N$\\
    $a^p=\exp_a(p)=\exp_a(q\frac{p}{q})=\left(\exp_a(\frac{p}{q})\right)^q\Rightarrow \exp_a(\frac{p}{q})=\sqrt[q]{a^p}=a^{\frac{p}{q}}$
\end{enumerate}

Bemerkung: \autoref{satz:expa} rechtfertigt die Bezeichnung $a^x\coloneqq \exp_a(x)$. Für $a=e$ hat man $e^x=\exp_e(x)=\exp(x)$, 
da $ln(e)=1$. Die Funktionalgleichung aus \autoref{satz:expa} i) hat jetzt die Form $a^{x+y}=a^x\cdot a^y, x,y\in \R$

\begin{theorem}
Für $a,b>0$ und $x,y\in \R$ gilt:
\begin{enumerate}[i)]
  \item $(a^x)^y=a^{xy}$\\
    Wegen $a^x=\exp(x \cdot ln(a))$ gilt $ln (a^x)=x \cdot ln (a)$. Damit $(a^x)^y=\exp(y\cdot ln(a^x))=\exp(xy\cdot ln(a))
    =a^{xy}$
  \item $a^x\cdot b^x=(ab)^x$\\
    $a^xb^x=\exp(x\cdot ln(a))\cdot \exp(x\cdot ln(b))=\exp(x(ln(a)+ln(b)))=\exp(x(ln(ab)))=(ab)^x$
  \item $(\frac{1}{a})^x=\frac{1}{a^x}=a^{-x}$\\
    $(\frac{1}{a})^x=(a^{-1})^x=a^{-x}$
\end{enumerate}
\end{theorem}

Es gilt $\exp_a \colon\R\rightarrow \bsofint{0,\infty}$ ist stetig und bijektiv für $a>0, a\neq 1$. Ferner: streng monoton wachsend
für $a>1$ und streng monoton fallend für $a<1$.
Die Umkehrfunktion $log_a\coloneqq(\exp_a)^{-1}$ heißt \emph{Logarithmus\index{Logarithmus}} zur Basis $a$. Es gilt $log_a\colon
\bsofint{0,\infty} \rightarrow \R$ ist stetig und streng monoton wachsend für $a>1$ und streng monoton fallend für $a<1$.\\
\textbf{Beweis}: $\log_ax=\frac{ln(x)}{ln(a)}$\\
$\exp_alog_a(x)=\exp(\frac{ln(x)}{ln(a)}\cdot ln (a))=\exp (ln (x))=x$

\subsection{Die Potenzfunktion}
\begin{definition}
Sei $\alpha>0$. Dann heißt $f_{\alpha}(x)=x^{\alpha}$ für $x\geq 0$ \emph{Potenzfunktion\index{Potenzfunktion}}
mit Exponent\index{Exponent} $\alpha$.
\end{definition}

Es gilt: $f_{\alpha}\rsofint{0,\infty}\rightarrow \rsofint{0,\infty}$ ist stetig, bijektiv und streng monoton
wachsend.\\
Beweis: $x^{\alpha}=\exp(\alpha \ln x)=e^{\alpha \ln x}$
\qed

\section{Konvergenz in \texorpdfstring{$\C$}{C}}
\subsection{Der vollständige metrische Raum der komplexen Zahlen}

$\C$ sei der Körper der komplexen Zahlen.
\begin{gather*}z=x+iy \qquad i=\sqrt{-1} \qquad i^2=-1 \qquad x,y \in \R\end{gather*}
\begin{gather*}x=\Re z \qquad \text{Realteil\index{Realteil} von } z\end{gather*}
\begin{gather*}y=\Im z \qquad \text{Imaginärteil\index{Imaginärteil} von } z\end{gather*}
\begin{align*}
  z_1 & = x_1+iy_1\\
  z_2 & = x_2+iy_2\\
  z_1+z_2 & \coloneqq (x_1+x_2)+i(y_1+y_2)\\
  z_1z_2 & \coloneqq (x_1x_2-y_1y_2)+i(x_1y_2+x_2y_1)\\
  z_1=x_1+iy_1=z_2=x_2+iy_2 & \Leftrightarrow x_1=x_2, y_1=y_2, \Re z_1=\Re z_2, \Im z_1=\Im z_2
\end{align*}

\begin{description}
  \item[konjugiert komplexe Zahl\index{Zahl!konjugiert komplexe}] $\overline{z}=x-iy$\\
    $z=\overline{z} \Leftrightarrow z \in \R$\\
    $\Re z=\frac{1}{2}(z+\overline{z}), \Im z=\frac{1}{2i}(z-\overline{z})$
  \item[Rechenregeln] $\overline{\overline{z}}=z, \overline{z_1+z_2}=\overline{z_1}+\overline{z_2},
    \overline{z_1z_2}=\overline{z_1}\cdot\overline{z_2}$
  \item[Betrag einer komplexen Zahl] $\abs{z}=\sqrt{z\overline{z}}=\sqrt{x^2+y^2}$\\
    $\abs{\Re z} \leq \abs{z}, \abs{\Im z}\leq \abs{z}$
    \begin{enumerate}[(1)]
      \item $\abs{z}\geq 0, \abs{z}=0\Leftrightarrow z=0$\\
        Der Nachweis hierzu ist trivial zu führen.
      \item $\abs{z_1z_2}=\abs{z_1}\abs{z_2}$\\
        Beweis: $\abs{z_1z_2}^2=(z_1z_2)(\overline{z_1z_2})=(z_1z_2)(\overline{z_1}\cdot\overline{z_2})
	=(z_1\overline{z_1})(z_2\overline{z_2})=\abs{z_1}^2\abs{z_2}^2$
      \item $\abs{z_1+z_2}\leq \abs{z_1}+\abs{z_2}$\\
        Beweis: $\abs{z_1+z_2}^2=(z_1+z_2)(\overline{z_1+z_2})=z_1\overline{z_1}+z_1\overline{z_2}+
	z_2\overline{z_1}+z_2\overline{z_2}=\abs{z_1}^2+(z_1\overline{z_2}+z_2\overline{z_1})+\abs{z_2}^2
	=\abs{z_1}^2+2\Re (z_1\overline{z_2})+\abs{z_2}^2\leq \abs{z_1}^2+2\abs{z_1\underbrace{\overline{z_2}}_{=\abs{z_2}}}
        +\abs{z_2}^2=(\abs{z_1}^2+\abs{z_2}^2)^2$
      \item $d(z_1,z_2)=\abs{z_1-z_2}$\\
        Hierdurch wird eine Metrik auf $\C$ erklärt.
    \end{enumerate}
\end{description}

\begin{theorem}
\begin{enumerate}[(1)]
  \item $\lim z_n=z\Leftrightarrow \lim\Re z_n =\Re z \wedge \lim \Im z_n=\Im z$\\
    Beweis: Dies folgt aus $\max\{\abs{\Re z},\abs{\Im z}\}\leq \abs{z}\leq 2\max\{\abs{\Re z},\abs{\Im z}\}$
  \item $\lim z_n=z\Leftrightarrow \lim \overline{z_n}=\overline{z_n}$\\
    Beweis: $\abs{z_n-z}=\abs{\overline{z_n-z}}=\abs{\overline{z_n}-\overline{z}}$
  \item $(\C,\abs{\cdot })$ ist ein vollständiger metrischer Raum.\\
    Beweis: Dies folgt aus dem Punkt (1) und der Tatsache, dass $\R$ vollständig ist
\end{enumerate}
\qed
\end{theorem}

\subsubsection{Reihen in $\C$}
\begin{gather*}(z_n)\subset \C\quad s_n\coloneqq\sum_{k=0}^n z_k \quad \text{n-te Partialsumme\index{Partialsumme}}\end{gather*}
\begin{gather*}\sum_{k=0}^{\infty} z_k\coloneqq(s_n) \quad \text{Reihe\index{Reihe}}\end{gather*}
Für den Wert der Reihe gilt:
\begin{gather*}\sum_{k=0}^{\infty} z_k\coloneqq\lim s_n \quad \text{falls }(s_n) \text{ konvergiert}\end{gather*}
Weiterhin gilt:
\begin{gather*}\overline{\sum_{k=0}^{\infty} z_k}=\sum_{k=0}^\infty \overline{z_k}\end{gather*}
Beweis: $\overline{\lim s_n}=\overline{\lim\sum_{k=0}^\infty z_k}=\lim \overline{\sum_{k=0}^\infty
z_k}=\lim \sum_{k=0}^\infty \overline{z_k}=\lim \overline{s_n}$\\
In $\C$ existiert \emph{keine} Kleiner-Gleich-Beziehung. Für Reihen gelten im wesentlichen die
gleichen Aussagen wie für Reihen in $\R$.

\subsubsection{Die Exponentialfunktion in $\C$}

$\sum_{k=0}^\infty \frac{z^k}{k!}$ ist für jedes $z\in\C$ absolut konvergent, d.\,h. $\sum \frac{\abs{z^k}}{k!}
<\infty$.
\begin{definition}
\begin{gather*}e^z\coloneqq\exp(z)=\sum_{k=0}^\infty \frac{z^k}{k!}\quad z\in\C\quad\exp\colon\C\rightarrow\C\end{gather*}
\end{definition}

Eigenschaften:
\begin{enumerate}[(i)]
  \item Funktionalgleichung: $e^{z_1+z_2}=e^{z_1}e^{z_2}\quad z_1,z_2\in\R$\\
    Beweis: Die Multiplikation von Reihen ist ähnlich wie im Reellen (siehe voriges Kapitel).
  \item $\overline{e^z}=e^{\overline{z}}$\\
    Beweis: $\overline{\sum_{k=0}^\infty \frac{z^k}{k!}}=\sum_{k=0}^\infty (\overline{\frac{z^k}{k!}})=
    \sum_{k=0}^\infty \frac{\overline{z^k}}{k!}$
  \item $\abs{e^z}=e^{\Re (z)}>0$\\
    Beweis: $e^z=e^{\Re (z)+i\Im (z)}=e^{\Re (z)}+e^{i\Im (x)}\Rightarrow \abs{e^z}=\abs{e^{\Re (z)}}\abs{e^{i\Im (x)}}
    =e^{\Re (z)}\cdot \abs{e^{i\Im (x)}}$\\
    zu zeigen: $\abs{e^{i\Im (z)}}=1$\\
    $\abs{e^{i\Im (z)}}^2=e^{i\Im (z)}\cdot \overline{e^{i\Im (z)}}=e^{i\Im (z)}e^{-i\Im (z)}=1$
  \item $\abs{e^z-\sum_{k=0}^N \frac{z^k}{k!}}\leq 2\frac{\abs{z}^{N+1}}{(N+1)!}\quad \abs{z}\leq 1+\frac{N}{2}$
    Der Beweis wird wie im Reellen geführt.
  \item $\exp\colon\C\rightarrow\C$ stetig
    Der Beweis wird wie im Reellen geführt.
  \item $\lim_{z\rightarrow 0}\frac{e^z-1}{z}=1$
    Beweis: $\abs{e^z-(1+z)}\leq \abs{z^2}$ für $\abs{z}\leq \frac{3}{2}$\\
    $\Rightarrow \abs{\frac{e^z-1}{z}-1}\leq \abs{z}^2$\\
    $\Rightarrow \lim_{z\rightarrow 0}\frac{{e^z}-1}{z}=1$
\end{enumerate}

\subsection{Trigonometrische Funktionen}
\begin{definition}
Sei $x\in\R$. Dann gilt
\begin{align*}
\cos x & \coloneqq \Re (e^{ix})\\
\sin x & \coloneqq \Im (e^{ix})
\end{align*}
$\cos$ heißt \emph{Kosinus\index{Kosinus}} und $\sin$ heißt \emph{Sinus\index{Sinus}}.
\end{definition}

Also ist $\abs{e^{ix}}^s=1=\cos^2 x+\sin^2 x$. Insbesondere folgt, dass $\abs{\cos x}, \abs{\sin x}\leq 1$.
%Zeichnung zum sin und cos einfuegen

\begin{theorem}
Seien $x,y\in\R$:
\begin{enumerate}[(i)]
  \item \begin{align*}
    \cos x & = \frac{1}{2}(e^{ix}+e^{-ix}) =  &\sum_{k=0}^\infty (-1)^k \frac{x^{2k}}{(2k)!}\\
    \sin x & = \frac{1}{2i}(e^{ix}-e^{-ix}) =  &\sum_{k=1}^\infty (-1)^{k-1}\frac{x^{2k-1}}{(2k-1)!}
  \end{align*}
  \item \begin{alignat*}{2}
    \cos (-x) & = \cos x & \qquad \cos 0 = 1\\
    \sin (-x) & = -\sin x & \qquad \sin 0 =0
  \end{alignat*}
  \item Additionstheoreme:
  \begin{align*}
    \cos (x\pm y) & = \cos x \cos y \mp \sin x \sin y\\
    \sin (x\pm y) & = \sin x \cos y \pm \cos x \sin y\\
    \sin x - \sin y & = 2\cos (\frac{x+y}{2})\sin (\frac{x-y}{2})\\
    \cos x - \cos y & = -2\sin (\frac{x+y}{2})\sin(\frac{x-y}{2})
  \end{align*}
  \item $\lim_{x\rightarrow 0} \frac{\sin x}{x}=1$
  \item $\left.\begin{array}{rcl}
    \cos \colon\R\rightarrow\R\\
    \sin \colon \R\rightarrow\R\end{array}\right\}$ stetig
  \item Der Kosinus hat eine kleinste positive Nullstelle $a$ mit $1<a<2$. Man setzt $\pi\coloneqq2a\Rightarrow
    \sin \frac{\pi}{2}=1$
    %Beweis aus Hefter einfuegen
  \item Kosinus und Sinus sind $2\pi$-periodisch:
    \begin{alignat*}{2}
      \cos (x+2\pi) & = \cos x & \qquad \cos (x+\frac{\pi}{2}) & = -\sin x\\
      \sin (x+2\pi) & = \sin x & \qquad \sin (x+\frac{\pi}{2}) & = \cos x
    \end{alignat*}
  \item $\sin \colon [-\frac{\pi}{2},\frac{\pi}{2}]$ ist streng monoton wachsend.\\
    $\cos \colon [0,\pi]$ ist streng monoton fallend
\end{enumerate}
\end{theorem}

\chapter{Differentiation reeller Funktionen}
\section{Definition, Rechenregeln und Beispiele}

\begin{definition}
Sei $D\subseteq \R, f\colon D\rightarrow\R$ eine reelle Funktion und $a\in D$ ein Häuf\-ungs\-punkt von $D$. $f$
heißt genau dann differenzierbar in $a$, wenn gilt:
\begin{gather*}\exists c \in\R \exists r\colon D\backslash\{a\}\rightarrow\R \text{ mit } \lim_{x\rightarrow a}
\frac{r(x)}{x-a}=0\end{gather*}
\begin{gather*}\forall x \in D\colon f(x)=f(a)+c(x-a)+r(x)\end{gather*}
\end{definition}

$c$ ist eindeutig bestimmt, denn:\\
Seien $c_1,c_2 \in \R\colon \forall x \in D\colon f(x)=f(a)+c_1(x-a)+r_1(x)$ und $f(x)=f(a)+c_2(x-a)+r_2(x)$ und
$\lim_{x\rightarrow a}\frac{r_1(x)}{x-a}=\lim_{x\rightarrow a}\frac{r_2(x)}{x-a}=0$\\
$\Rightarrow c_1(x-a)+r_1(x)=c_2(x-a)+r_2(x)$\\
$\Rightarrow c_1=c_2+\frac{r_2(x)}{x-a}-\frac{r_1(x)}{x-a}$\\
$\Rightarrow c_1=c_2$
Schreibweise: $f'(a)=c, \frac{df}{dx}(a)=c$

$c$ heißt \emph{Ableitung\index{Ableitung}} von $f$ an der Stelle $a$. $f$ heißt genau dann
\emph{differenzierbar} in $D$, wenn $f$ in jedem Punkt $a\in D$ diffenzierbar ist.

\begin{remark}
Die Differenzierbarkeit einer Funktion $f$ in $a\in D$ ist gleich\-be\-deu\-tend mit der Approximierbarkeit
durch eine affin-lineare Funktion, d.\,h. ein Polynom\index{Polynom} ersten Grades:
\begin{gather*}L(x)=f(a)+c(x-a)\end{gather*}
Der Graph von $L$ ist die Tangente an dem Graphen von $f$ in $(a,f(a))$.
\end{remark}

\begin{theorem}
$f$ ist genau dann in $a\in D$ differenzierbar, wenn $\lim_{x\rightarrow a} \frac{f(x)-f(a)}{x-a}$
existiert.\\
\textbf{Beweis}:
\begin{itemize}
  \item["`$\Rightarrow$"'] Sei $f$ in $a\in D$ differenzierbar. Dann ist $f(x)=f(a)+c(x-a)+r(x)$ mit
    $\lim_{x\rightarrow a}\frac{r(x)}{x-a}=0$\\
    $\Rightarrow \frac{f(x)-f(a)}{x-a}=c+\frac{r(x)}{x-a}$\\
    $\Rightarrow \lim_{x\rightarrow a} \frac{f(x)-f(a)}{x-a}=c$
  \item["`$\Leftarrow$"'] Sei $\lim_{x\rightarrow a}
  \frac{f(x)-f(a)}{x-a}\coloneqq c$\\
    $r(x)\coloneqq f(x)-f(a)-c(x-a)$\\
    Dann ist $f(x)=f(a)+c(x-a)+r(x)$ und $\frac{r(x)}{x-a}=
    \frac{f(x)-f(a)}{x-a}-c\stackrel{x\rightarrow a}{\rightarrow}c-c=0$
\end{itemize}
\qed
\end{theorem}

\paragraph{Geometrische Interpretation}
Der Differenzenquotient\index{Differenzenquotient}
$\frac{f(x)-f(a)}{x-a}$ ist die Steigung der Sekante
\index{Sekante} von $f$ durch die Punkte $(x,f(x))$ und
$(a,f(a))$. Beim Grenzübergang $x\rightarrow a$ geht die Sekante in
die Tangente\index{Tangente} vom Graphen $f$ im Punkt $(a,f(a))$
über. $f'(a)$ ist also die Steigung der Tangente in $(a,f(a))$.

Beispiele:
\begin{enumerate}[(1)]
\item $f\colon\R\rightarrow\R, f(x)=c$ konstante Funktion\\
  Es gilt: $f'(a)=0$\\
  Beweis: $f'(a)=lim_{x\rightarrow
    a}\frac{f(x)-f(a)}{x-a}=\lim_{x\rightarrow a}\frac{c-c}{x-a}=0$
\item $f\colon\R\rightarrow\R, f(x)=cx, f'(a)=c$\\
  Beweis: $f'(a)=lim_{x\rightarrow
    a}\frac{f(x)-f(a)}{x-a}=\lim_{x\rightarrow a}\frac{cx-ca}{x-a}
  =\lim_{x\rightarrow a}\frac{c(x-a)}{x-a}=c$
\item $f\colon\R\rightarrow\R, f(x)=e^x, f'(a)=e^x$ Exponentialfunktion\\
  Beweis: $f'(a)=lim_{x\rightarrow
    a}\frac{f(x)-f(a)}{x-a}=\lim_{x\rightarrow a}\frac{e^x-e^a}{x-a}=
  \lim_{x\rightarrow a}e^a\frac{e^{x-a}-1}{x-a}=$\\
  $\lim_{x\rightarrow a}\underbrace{e^a}_{\text{konstant}}
  \underbrace{\lim_{x\rightarrow
      a}\frac{e^{x-a}-1}{x-a}}_{=1}=e^a\cdot 1$
 \end{enumerate}

\textbf{Korollar} Ist $f\colon D\rightarrow\R$ in $a\in D$ differenzierbar, so ist $f$ in $a$ stetig.\\
Beweis: $f(x)=f(a)+f'(a)(x-a)+r(x), \lim_{x\rightarrow a}\frac{r(x)}{x-a}=0$\\
$\frac{r(x)}{x-a}\rightarrow 0 \Rightarrow \lim_{x\rightarrow a}r(x)=0$\\
Denn es gilt: $\lim r(x)=\lim (x-a)\frac{r(x)}{x-a}=\lim (x-a)\lim\frac{r(x)}{x-a}=0\cdot 0=0$\\
Somit folgt: $\lim_{x\rightarrow a}f(x)=\lim(f(a)+f'(a)(x-a)+r(x))=\lim f(a)+\lim f'(a)(x-a)+\lim r(x)
=f(a)+0+0=f(a)$

\begin{theorem}
\begin{enumerate}[(1)]
  \item Seien $f,g\colon D\rightarrow \R$ in $x\in D$ differenzierbar und $\lambda\in\R$. Dann sind die 
    Funktionen $f+g, \lambda f, f\circ g\colon D\rightarrow\R$ in $x\in D$ differenzierbar und es gilt:
    \begin{itemize}
      \item $(f+g)'(x)=f'(x)+g'(x)$
      \item $(\lambda f)'(x)=\lambda f'(x)$
      \item $(f\cdot g)'(x)=f'(x)g(x)+f(x)g'(x)$
    \end{itemize}
    Ist $g(\xi)\neq 0$ für alle $\xi\in D$, so ist $\frac{f}{g}\colon D\rightarrow\R$ in $x\in D$ differenzierbar 
    und es gilt:
    \begin{itemize}
      \item $(\frac{f}{g})'=\frac{f'(x)g(x)-f(x)g'(x)}{(g(x))^2}$
    \end{itemize}
  \item \textbf{Kettenregel} Seien $f\colon D\rightarrow\R, g\colon E\rightarrow\R$ Funktionen mit $f(D)\subset E$ und
    $f$ sei in $x\in D$ und $g$ in $y=f(x)$ differenzierbar. Dann ist $g\circ f\colon D\rightarrow\R$ in $x$
    differenzierbar und es gilt:
    \begin{itemize}
      \item $(g\circ f)'(x)=g'(f(x))\cdot f'(x)$
    \end{itemize}
  \item \textbf{Ableitung der Umkehrfunktion} Sei $D\subset \R$ ein abgeleitetes Intervall und 
    $f\colon D\rightarrow\R$ eine stetige, streng monotone Funktion und $f^{-1}\colon\tilde{D}=f(D)\rightarrow\R$
    die Umkehrfunktion. Ist weiterhin $f$ in $x\in D$ differenzierbar und $f'(x)\neq 0$, so ist
    $f^{-1}$ in $y=f(x)$ differenzierbar. Es gilt
    \begin{itemize}
      \item $(f^{-1})'(x)=\frac{1}{f'(x)}=\frac{1}{f'(f^{-1}(y))}$
    \end{itemize}
\end{enumerate}
\end{theorem}

Beispiele:
\begin{enumerate}[(1)]
  \item $f(x)=\ln x\quad f'(x)=\frac{1}{x}$\\
    Beweis: $f(x)=\ln x=g^{-1}(x)\ g(x)=e^x\ (g^{-1'}(x))=
    \frac{1}{(g(x))'(g^{-1}(x))}=\frac{1}{e^{\ln x}}=\frac{1}{x}$
  \item $f(x)=h(x)^{g(x)}\ h>0$ differenzierbar und $g$ differenzierbar\\
    $f'(x)=h(x)^{g(x)}(\frac{h'(x)g(x)}{h(x)}+g'(x)\ln h(x))$\\
    Beweis: $(h(x)^{g(x)})'=(e^{g(x)\ln h(x)})'=e^{g(x)\ln h(x)}
    (g(x)\ln h(x))'$\\
    $=h(x)^{g(x)}(g'(x)\ln h(x)+g(x)\frac{h'(x)}{h(x)})$
  \item $f(x) = x^\alpha \quad f'(x) = \alpha x^{\alpha-1}$\\
    Beweis: $h(x)=x\quad g(x)=\alpha\quad f'(x)=(x^\alpha)'=x^\alpha
    (0x+\frac{\alpha 1}{x})=\alpha x^{\alpha-1}$
  \item $f(x) = a^x \quad f'(x) = a^x \ln a$\\
    Beweis: $h(x)=a\quad g(x)=x\quad f'(x)=(a^x)'=a^x(1\ln a+0)=a^x\ln a$
  \item $f(x) = x^x \quad f'(x) = x^x(1+\ln x)$\\
    Beweis: $h(x)=x\quad g(x)=x\quad f'(x)=(x^x)'=x^x(\ln x+1)$
  \item $(\cos x)'=-\sin x\quad (\sin x)'=\cos x$\\
    Beweis: $(e^z)'=e^z, z\in\C\quad (e^z)'=\lim_{h\rightarrow 0}
    \frac{e^{z+h}-e^z}{h}=e^z$\\
    $x\in\R\colon e^{ix}=\cos x+i\sin x$
    \begin{align*}
      (\cos x+i\sin x) & = & (\cos x)'+i(\sin x)'=(e^{ix})'=ie^{ix}\\
      & = & (\cos x+i\sin x)i=i\cos x-\sin x\\
      & \Rightarrow & (\cos x)'=-\sin x, (\sin x)'=\cos x
    \end{align*}
\end{enumerate}

\section{Ableitung höherer Ordnung}
\begin{definition}
  \begin{enumerate}[(1)]
    \item $f\colon D\rightarrow\R$ sei differenzierbar in $D$.\\
      Falls $f'\colon D\rightarrow\R$ in $x\in D$ differenzierbar ist, so
      heißt $\frac{d^2 f}{dx^2}(x)=f''(x)\coloneqq(f')'(x)$ die zweite 
      Ableitung von $f$ an der Stelle $x$.
    \item Allgemein durch Induktion: $f\colon D\rightarrow\R$ heißt $k$-mal
      differenzierbar in $x\in D\perdef \exists \varepsilon>0
      \colon f\colon D\cap \bsofint{x-\varepsilon,x+\varepsilon}\rightarrow\R$ ist $(k-1)$-mal
      in $D\cap\bsofint{x-\varepsilon,x+\varepsilon}$ differenzierbar und die
      $(k-1)$-te Ableitung von $f$ in $x$ differenzierbar ist.
  \end{enumerate}
\end{definition}

\paragraph{Leibnitzsche Produktformel}
$f,g\colon D\rightarrow\R$ sind $n$-mal differenzierbar. Dann $(f\circ g)^{(n)}
=\sum_{k=0}^n \binom{n}{k}f^{(k)}(x)g^{(n-k)}(x)$ mit $f^{(0)}\coloneqq f$

\section{Lokale Extrema, Mittelwertsatz, Konvexität}
\begin{definition}
  Eine Funktion $f\colon\bsofint{a,b}\rightarrow\R$ hat in $x\in \bsofint{a,b}$ genau dann
  ein \emph{lokales (relatives) Maximum/Minimum\index{Maximum!lokales}
  \index{Maximum!relatives}\index{Minimum!lokales}\index{Minimum!relatives}},
  wenn
  \begin{gather*}\exists \varepsilon>0\,\forall\xi\in \bsofint{a,b}\colon\abs{x-\xi}<\varepsilon
  \Rightarrow f(\xi)\leq f(x) \text{ bzw. } f(\xi)\geq f(x)\end{gather*}
  Trifft das $f(\xi)=f(x)$ nur für $\xi=x$ zu, so sagt man in $x$ liegt
  ein isoliertes lokales Maximum/Minimum vor.
\end{definition}

\begin{theorem}
  \label{satz:lokExtremum}
  $f\colon\bsofint{a,b}\rightarrow\R$ besitze in $x\in \bsofint{a,b}$ ein lokales Extremum
  und sei in $x$ differenzierbar. Dann gilt $f'(x)=0$.\\
  \textbf{Beweis}: $f$ habe in $x$ ein lokales Maximum. Dann gilt:
  \begin{gather*}\exists\varepsilon>0\colon D=\bsofint{x-\varepsilon,x+\varepsilon}\subset\bsofint{a,b}
  \forall\xi\in D\colon f(\xi)\leq f(x)\end{gather*}
  Somit
  \begin{align*}
    f'_+(x) & \coloneqq & \lim_{\xi\searrow x}\frac{f(\xi)-f(x)}{\xi-x}\leq 0 \text{ da } f(\xi)\leq f(x)\\
    f'_-(x) & \coloneqq & \lim_{\xi\nearrow x}\frac{f(\xi)-f(x)}{\xi-x}\geq 0 \text{ da } f(\xi)\geq f(x)
  \end{align*}
  Da $f$ in $x$ differenzierbar folgt, dass $f'_+(x)-f'_-(x)=0$
  \qed
\end{theorem}

Bemerkungen:
\begin{enumerate}[(1)]
  \item $f'(x)=0$ ist eine notwendige, aber keine hinreichende 
    Bedingung für ein lokales Extremum. Ein Beispiel ist die Funktion
    $f(x)=x^3$. Die Ableitung ist $f'(x)=3x^2$ und es gilt $f'(0)=0$.
    $f$ hat in 0 aber kein lokales Extremum.
  \item Hinreichende Bedingung für lokales Extremum: $f'(x)=0\wedge f''(x)\neq 0$
  \item Jede in einem kompakten Intervall $[a,b]$ stetige Funktion nimmt
    in dem Intervall ihr absolutes Maximum $f(p)=\max_{x\in[a,b]}f(x)$
    und ihr absolutes Minimum $f(q)=\min_{x\in[a,b]}f(x)$.\\
    Liegt ein Extremum jedoch am Rand, d.\,h. in $a$ oder $b$ vor, so ist
    dort $f'(x)=0$ nicht notwendig.
\end{enumerate}

\subsection{Satz von Rolle und Mittelwertsatz}
\begin{theorem}
  \begin{enumerate}[(1)]
    \item Satz von Rolle\index{Rolle!Satz von}: Sei $f\colon[a,b]\rightarrow\R$ stetig und sei $f\colon
      \bsofint{a,b}\rightarrow\R$ differenzierbar in $\bsofint{a,b}$ und $f(a)=f(b)$.
      Dann existiert $\xi\in \bsofint{a,b}\colon f'(\xi)=0$\\
      \textbf{Beweis}:\begin{enumerate}[1. F{a}ll]
	\item Falls $f$ konstant ist, ist der Beweis trivial.
	\item Falls $f$ nicht konstant ist, existiert ein $x_0\in
	  \bsofint{a,b}\colon f(x_0)>f(a)$. Dann wird das absolute Maximum/Minimum von
	  $f\colon[a,b]\rightarrow\R$ in einem Punkt $\xi\in\bsofint{a,b}$
	  angenommen. Nach \autoref{satz:lokExtremum} gilt $f'(\xi)=0$.
      \end{enumerate}
    \item Mittelwertsatz\index{Mittelwertsatz}: Sei $f\colon[a,b]\rightarrow\R$ stetig und sei $f\colon
      \bsofint{a,b}\rightarrow\R$ differenzierbar in $\bsofint{a,b}$ und $f(a)=f(b)$. Dann
      existiert $\xi\in\bsofint{a,b}\colon\frac{f(b)-f(a)}{b-a}=f'(\xi)$\\
      \textbf{Beweis}: Aus dem Punkt 3 folgt der Punkt 2 mit $g(x)=x$.
    \item 2. Mittelwertsatz: Seien $f,g\colon[a,b]\rightarrow\R$ stetig und 
      in $\bsofint{a,b}$ differenzierbar und sei $g'(\xi)\neq 0$ in $\bsofint{a,b}$. 
      Dann existiert $\xi\in\bsofint{a,b}\colon\frac{f(b)-f(a)}{g(b)-g(a)}=
      \frac{f'(\xi)}{g'(\xi)}$.\\
      \textbf{Beweis}: Wegen $g'\neq 0$ in $\bsofint{a,b}$ folgt nach dem 
      ersten Punkt $g(b)\neq g(a)$. Betrachten $\varphi(x)\coloneqq f(x)-f(x)-
      \frac{f(b)-f(a)}{g(b)-g(a)}(g(x)-g(a))$. Die Funktion $\varphi\colon
      [a,b]\rightarrow\R$ ist stetig und in $\bsofint{a,b}$ differenzierbar und
      es gilt $\varphi (a)=\varphi(b)=0\Rightarrow \exists\xi\in\bsofint{a,b}\colon
      0=\varphi'(\xi)=f'(\xi)-\frac{f(b)-f(a)}{g(b)-g(a)}g'(\xi)
      \Rightarrow \frac{f(b)-f(a)}{g(b)-g(a)}=\frac{f'(\xi)}{g'(\xi)}$
  \end{enumerate}
  \qed
\end{theorem}

Folgerung:
\begin{enumerate}[(1)]
  \item Sei $f\colon[a,b]\rightarrow\R$ stetig und $f'=0$ in $\bsofint{a,b}
    \Rightarrow f(x)=c$ konstant auf $[a,b]$\\
    Beweis: Sei $x\in\lsofint{a,b}$ beliebig. Wir betrachten das Intervall $[a,x]$
    Nach dem Mittelwertsatz existiert ein $\xi\in\bsofint{a,x}\subset\bsofint{a,b}\colon
    \frac{f(x)-f(a)}{x-a}=f'(\xi)=0\Rightarrow f(x)=f(a) \forall x\in
    \lsofint{a,b}\Rightarrow f(x)=f(a)\,\forall x\in[a,b]$ wegen der Stetigkeit.
  \item Sei $f\colon\R\rightarrow\R$ differenzierbar und genüge der
    Differentialgleichung $f'=f$ auf $\R$ mit $f(0)=1$. Dann ist
    $f(x)=e^x$.\\
    Beweis: $F(x)=f(x)e^{-x}$ Dann ist $F'(x)=f'(x)e^{-x}-f(x)e^{-x}=
    \underbrace{(f'(x)-f(x))e^{-x}}_{=0}$\\
    $\Rightarrow F(x)=c=f(x)e^{-x}$\\
    $f(x)=ce^x\quad f(0)=1\Rightarrow c=1$. Also ist $f(x)=e^x$
\end{enumerate}

\subsection{Berechnung von Grenzwert, Regel von L'Hospital}
\begin{tabular}{c|l|l}
  & \textsc{Grenzübergänge} & \textsc{Differenzierbarkeitsintervalle}\\
  \hline
  (1) & $x\searrow a$ & $a<x<a+h$\\
  (2) & $x\nearrow a$ & $a-h<x<a$\\
  (3) & $x\rightarrow a$ & $0<\abs{x-a}<h$\\
  (4) & $x\rightarrow\infty$ & $ x>R$\\
  (5) & $x\rightarrow -\infty$ & $x<-R\,R>0$
\end{tabular}

Unter diesen Voraussetzungen gilt die \emph{Regel von L'Hospital\index{L'Hospital!Regel von}}:\\
Seien $\lim f(x)=\lim g(x)=0$ und existiert $\lim \frac{f'(x)}{g'(x)}$
eigentlich oder uneigentlich, so gilt $\frac{\lim f(x)}{\lim g(x)}=\lim
\frac{f'(x)}{g'(x)}$.

Beispiel: \begin{gather*}\lim_{x\rightarrow 0} \frac{e^x-1}{x}=\lim_{x\rightarrow 0}
\frac{(e^x-1)'}{x'}
=\lim_{x\rightarrow 0} \frac{e^x}{1}=\frac{e^0}{1}=1\end{gather*}
\begin{gather*}\lim_{x\rightarrow 0} \frac{e^x-1-x}{x^2}=\lim_{x\rightarrow 0}
\frac{(e^x-1-x)'}{(x^2)'}=\lim_{x\rightarrow 0}\frac{e^x-1}{2x}=
\lim_{x\rightarrow 0}\frac{e^x}{2x}=\frac{1}{2}\end{gather*}

\subsection{Monotonie differenzierbarer Funktionen}
\begin{theorem}
  \label{satz:monoton}
  Sei $f\colon[a,b]\rightarrow\R$ stetig und in $\bsofint{a,b}$ differenzierbar. Dann
  gilt:
  \begin{enumerate}
    \item $\forall x \in \bsofint{a,b}\colon f'(x)\geq \Rightarrow f$ auf $[a,b]$
      monoton wachsend
    \item $\forall x \in \bsofint{a,b}\colon f'(x)> \Rightarrow f$ auf $[a,b]$ 
      streng monoton wachsend
    \item $\forall x \in \bsofint{a,b}\colon f'(x)\leq \Rightarrow f$ auf $[a,b]$
      monoton fallend
    \item $\forall x \in \bsofint{a,b}\colon f'(x)< \Rightarrow f$ auf $[a,b]$
      streng monoton fallend
  \end{enumerate}
  \textbf{Beweis} (für den zweiten Fall): Sei $f'(x)>0$ für alle $x\in
  \bsofint{a,b}$. Man nehme an, dass $f$ nicht streng monoton wachsend ist. Dann
  existiert $x_1,x_2\in\bsofint{a,b}\colon x_1<x_2\wedge f(x_1)\geq f(x_2)$. Nach dem
  Mittelwertsatz folgt: $\exists \xi\in\bsofint{a,b}\colon\frac{f(x_2)-f(x_1)}{x_2-x_1}
  =f'(\xi)\leq 0$\textnormal{\lightning}
  \qed
\end{theorem}

\subsection{Hinreichende Bedingungen für lokale Extrema}
\begin{theorem}
  \label{satz:lokExtrema}
  Sei $f\colon\bsofint{a,b}\rightarrow\R$ differenzierbar. In $x \in \bsofint{a,b}$ sei $f$
  zweimal differenzierbar und es gelte, $f'(x)=0$ und $f''(x)\neq 0$.
  Dann besitzt $f$ in $x$ ein isoliertes lokales Extremum.\\
  \textbf{Beweis}: Sei $f''(x)>0$. Wegen $f''(x)=\lim_{\xi\rightarrow x}
  \frac{f'(\xi)-f'(x)}{\xi-x}>0\Rightarrow\exists\xi>0\colon
  \frac{f'(\xi)-f'(x)}{\xi-x}>0 \forall\xi\colon0<\abs{\xi-x}<\varepsilon$.
  Da $f'(x)=0$ ist, folgt $\frac{f'(\xi)}{\xi}>0\Rightarrow
  \left.
  \begin{array}{rcl}
    f'(\xi)<0 & \text{für } x-\xi<\xi<x\\
    f'(\xi)>0 & \text{für } x<\xi<x+\xi
  \end{array}\right\}$ Nach \autoref{satz:monoton} besitzt $f$ in $x$
  ein isoliertes lokales Minimum. Die Beweisführung erfolgt analog für
  das Maximum.
  \qed
\end{theorem}

\subsection{Konvexität}
\begin{definition}
  \begin{enumerate}[(1)]
    \item Sei $D\subset\R$ ein (endliches oder unendliches) Intervall.
      Eine Funktion $f\colon D\rightarrow\R$ heißt genau dann \emph{konvex\index{Funktion!konvexe}\index{konvex}}, wenn:
      \begin{gather*}\forall x_0,x_1\in D\,\forall 0<\Theta<1\colon f( (1-\Theta)x_0+\Theta x_1)\leq(1-\Theta)f(x_0)+\Theta f(x_1)\end{gather*}
    \item $f$ heißt genau dann
      \emph{konkav\index{Funktion!konkave}\index{konkav}}, wenn $(-f)$
      konvex ist.
  \end{enumerate}
\end{definition}
  
\paragraph{Geometrische Interpretation}
Seien $x_0,x_1\in D, x_0<x_1, x=(1-\Theta)x_0+\Theta x_1\Rightarrow
\Theta=\frac{x-x_0}{x_1-x_0}, 1-\Theta=\frac{x_1-x}{x_1-x_0}, 0<\Theta<1$\\
$f(x)=f( (1-\Theta)x_0+\Theta x_1)\leq (1-\Theta)f(x_0)+\Theta f(x_1)
=\frac{x_1-x}{x_1-x_0}f(x_0)+\frac{x-x_0}{x_1-x_0}f(x_1)$\\
$y_0\coloneqq f(x_0), y_1\coloneqq f(x_1), y=\frac{x_1-x}{x_1-x_0}y_0+\frac{x-x_0}{x_1-x_0}y_1
\Leftrightarrow$
\begin{gather*}\frac{y-y_0}{y_1-y_0}=\frac{x-x_0}{x_1-x_0}\end{gather*}
Eine lineare Funktion $f(x)=ax+b$ ist sowohl konvex als auch konkav.

\begin{theorem}
  \begin{enumerate}[(i)]
    \item \textit{Konvexität und Stetigkeit}\\
      Sei $D\subset\R$ ein offenes Intervall und $f\colon D\rightarrow\R$
      konvex. Dann ist $f$ stetig auf $D$.
      \textbf{Beweis}: Sei$p\in D$. Dann existiert $x_0,x_1\in D\colon
      x_0<p<x_1, [x_0,x_1]\subset D$. Mann kann zeigen, dass für
      $x\in[x_0,x_1]$ die folgende Abschätzung gilt:\\
      $\abs{f(x)-f(p)}\leq L\abs{x-p}$, wobei $L=
      \frac{2\max\{\abs{f(x_0)},\abs{f(x_1)}\}}{\min\{\abs{x_0-p},\abs{x_1-p}\}}
      \Rightarrow\lim_{x\rightarrow p} f(x)=f(p)\Rightarrow f$ in $p$
      stetig.
    \item \textit{Konvexität und Differenzierbarkeit}\\
      Sei $D\subset\R$ ein offenes Intervall und $f\colon D\rightarrow\R$
      zweimal differenzierbar. Dann gilt, dass $f$ genau dann auf $D$
      konvex ist, wenn $\forall x\in D\colon f''(x)\geq 0$\\
      \textbf{Beweis}: \begin{itemize}
	\item["`$\Rightarrow$"'] Sei $f\colon D\rightarrow\R$ konvex. Man
	  trifft die Annahme, dass $f''(x)<0$ \emph{nicht} gilt und
	  setzt $\varphi(x)\coloneqq f(x)-f'(x_0)(x-x_0)$ für $x_0\in D$. Dann
	  hat man $\varphi\colon D\rightarrow\R$ ist zweimal differenzierbar
	  mit $\varphi'(x_0)=0$ und $\varphi''(x_0)=f''(x)<0$. Nach
	  \autoref{satz:lokExtrema} hat $\varphi$ in $x_0$ ein
	  isoliertes lokales Maximum. Somit existiert ein $h>0\colon
	  [x_0-h,x_0+h]\subset D$ und $\varphi(x_0-h)<\varphi(x_0),
	  \varphi(x_0+h)<\varphi(x_0)$. Damit folgt:
	  \begin{align*}
	    f(x_0)&=& \varphi(x_0)\\
	    &>& \frac{1}{2}(\varphi(x_0-h)+\varphi(x_0+h))\\
	    &=& \frac{1}{2}(f(x_0-h)-f'(x_0)(-h)+f(x_0+h)-f'(x_0)(h))\\
	    &=& \frac{1}{2}(f(x_0-h)+f(x_0+h))
	  \end{align*}
	  Man setzt $x_1=x_0-h, x_2=x_0+h, \Theta=\frac{1}{2}$. Dann ist
	  $x_0=\frac{1}{2}(x_0-h)+\frac{1}{2}(x_0+h)=(1-\Theta)x_1+
	  \Theta x_2$ und $f(x_0)=f( (1-\Theta)x_1+\Theta x_2)>(1-\Theta)
	  f(x_1)+\Theta f(x_2)$\textnormal{\lightning}
	\item["`$\Leftarrow$"'] Sei $f''\geq 0$ auf $D$. Dann ist $f'$
	  monoton wachsend. Seien $x_1,x_2\in D, 0<\Theta<1$ und 
	  $x=(1-\Theta)x_2+\Theta x_1$.\\
	  O.\,B.\,d.\,A. sei $x_1<x_2$. Dann folgt nach dem Mittelwertsatz:
	  $\exists\xi_1\in\bsofint{x_1,x}, \xi_2\in\bsofint{x,x_2}\colon
	  \frac{f(x)-f(x_1)}{x-x_1}=f'(\xi_1)\leq f'(\xi_2)=
	  \frac{f(x_2)-f(x)}{x_2-x}$. Mit $x-x_1=(1-\Theta)(x_2-x_1)$
	  und $x_2-x=\Theta(x_2-x_1)$ folgt $\frac{f(x)-f(x_1)}{1-\Theta}
	  \leq\frac{f(x_2)-f(x)}{\Theta}$ oder $\Theta(f(x)-f(x_1))\leq
	  (1-\Theta)(f(x_2)-f(x))$. Somit ist $f(x)\leq \Theta f(x_1)+
	  (1-\Theta)f(x_2)\Rightarrow f$ ist konvex.
      \end{itemize}
  \end{enumerate}
  \qed
\end{theorem}

\subsection{Wendepunkt}
\begin{definition}
  Eine Funktion $f\colon\bsofint{a,b}\rightarrow\R$ hat in $x_0\in\bsofint{a,b}$ genau dann
  einen \emph{Wendepunkt\index{Wendepunkt}}, wenn ein $\varepsilon>0$
  mit der Eigenschaft existiert, dass $f$ auf $\lsofint{x_0-\varepsilon,x_0}$
  konkav und $f$ auf $\rsofint{x_0,x+\varepsilon}$ konvex ist oder dies auf
  $(-f)$ zutrifft.
\end{definition}

Bemerkung:
\begin{itemize}
  \item Nach der obigen Definition hat eine lineare Funktion
    $f(x)=cx+d$  in jedem Punkt einen Wendepunkt.
  \item Ist $f$ auf $\lsofint{x_0-\varepsilon,x_0}$ streng konkav und auf
    $\rsofint{x_0,x_0+\varepsilon}$ streng konvex, so liegt ein isolierter
    Wendepunkt vor.
\end{itemize}

\subsection{Hinreichende Bedingungen für (isolierte) Wendepunkte}
\begin{theorem}
  \begin{enumerate}[(i)]
    \item Sei $f\colon\bsofint{a,b}\rightarrow\R$ in $x_0\in\bsofint{a,b}$ differenzierbar.
      $f$ besitzt in $x_0$ einen Wendepunkt, falls ein $\varepsilon>0$
      existiert und für $0<\abs{h}<\varepsilon$ stets
      \begin{enumerate}[(1)]
	\item Übergang von konkav in konvex:
	  \begin{gather*}\frac{f(x_0+h)-f(x_0)}{h}>f'(x_0)\end{gather*}
	\item Übergang von konvex in konkav:
	  \begin{gather*}\frac{f(x_0+h)-f(x_0)}{h}<f'(x_0)\end{gather*}
      \end{enumerate}
      gilt.\\
      \textbf{Beweis}: $\frac{f(x_0+h)-f(x_0)}{h}>0f'(x_0)$ für $0<\abs{h}
      <\varepsilon\Leftrightarrow$
      \begin{align*}
	f(x_0+h) & < & f(x_0)+f'(x_0)h \text{ für } h<0\\
	f(x_0+h) & < & f(x_0)+f'(x_0)h \text{ für } h>0
      \end{align*}
      $h\coloneqq x-x_0$\\
      Tangente in $(x_0,f(x_0))$: $y=f(x_0)+f'(x_0)(x-x_0)$
    \item Sei $f\colon\bsofint{a,b}\rightarrow\R$ differenzierbar. Dann besitzt $f$
      in $x_0\in\bsofint{a,b}$ einen Wendepunkt, wenn $f'\colon\bsofint{a,b}\rightarrow\R$
      in $x_0$ ein isoliertes lokales Extremum hat.\\
      \textbf{Beweis}: Habe $f'$ in $x_0$ ein isoliertes lokales Maximum,
      d.\,h. es existiert ein $\varepsilon>0\colon f'(\xi)<f'(x_0)$ für $0<
      \abs{\xi-x_0}<\varepsilon$. Sei $\abs{h}<\varepsilon$, dann folgt nach dem
      Mittelwertsatz: $\exists\xi_0\in \bsofint{x_0,x_0+h}$ für $h>0$ bzw.
      $\xi_0\in \bsofint{x_0+h,x_0}$ für $h<0$ mit $\frac{f(x_0+h)-f(x_0)}{h}
      =f'(\xi_0)<f'(x_0)$. Nach (i)(2) folgt: Übergang von konvex in
      konkav. Analog kann man dies für das isolierte lokale Minimum
      zeigen.
    \item Sei $f\colon\bsofint{a,b}\rightarrow\R$ in $\bsofint{a,b}$ zweimal differenzierbar.
      \begin{enumerate}[(1)]
	\item Ist $f''(x)>0$ für $x<x_0$ und $f''(x)<0$ für $x>x_0$, so
	  hat $f$ in $x_0$ einen Wendepunkt (Übergang konkav nach konvex).
	\item Ist $f''(x)<0$ für $x<x_0$ und $f''(x)>0$ für $x>x_0$, so
	  hat $f$ in  $x_0$ einen Wendepunkt (Übergang konvex nach konkav).
	\item Sei $f\colon\bsofint{a,b}\rightarrow\R$ dreimal differenzierbar. Ist
	  $f''(x_0)=0$ und $f'''(x_0)\neq 0$, so hat $f$ in $x_0$
	  einen Wendepunkt.
	  \begin{itemize}
	    \item $f''(x_0)=0, f'''(x_0)<0$ Dann hat $f'$ in $x_0$ ein
	      isoliertes lokales Maximum (Übergang konvex nach konkav).
	    \item $f''(x_0)=0, f'''(x_0)>0$ Dann hat $f'$ in $x_0$ ein
	      isoliertes lokales Minimum (Übergang konkav nach konvex)
	  \end{itemize}
      \end{enumerate}
  \end{enumerate}
  \qed
\end{theorem}

\subsection{Kurvendiskussionen von reellen Funktionen}
Mögliches Vorgehen beim Studium einer Funktion $f\colon D\rightarrow\R$:
\begin{itemize}
  \item Bestimmen der Definitionsbereiche und der Symmetrieeigenschaften
  \item Bestimmung der Nullstellen von $f, f', f''$
  \item Untersuchung des Monotonie- und Konvexitätsverhaltens
  \item Bestimmung lokaler Extremalstellen
  \item Wendepunkte
  \item Unstetigkeitsstellen
\end{itemize}

\section{Taylorreihen und Satz von Taylor}
Problem: Approximation von Funktionen in der Nähe eines Punktes durch
möglichst einfache Funktionen (Polynome).

\begin{lemma}
  Sei $p(x)=\sum_{k=0}^n a_kx^k$ ein Polynom $n$-ten Grades. Dann gilt:
  \begin{gather*}p(x)=\sum_{k=0}^n \frac{p^{(k)}(x_0)}{k!} (x-x_0)^k\end{gather*}
  \textbf{Beweis}:
  \begin{enumerate}[1. F{a}ll]
    \item Sei $x_0=0$
      \begin{align*}
	p'(x)&=& a_1+2a_2x+\cdots+na_nx^{n-1}\\
	p''(x)&=& 2a_2+\cdots+n(n-1)a_nx^{n-2}\\
	\vdots\\
	p^{(k)}(x)&=& k!a_k+\cdots+n(n-1)(n-k+1)a_nx^{n-k}\\
	p^{(k)}(0)&=& k!a_k \quad\text{für } 0\leq k\leq n\\
	p^{(k)}(0)&=& 0 \quad\text{für } k\geq n+1\\
	&\Rightarrow & p(x)=\sum_{k-0}^n \frac{p^{(k)}(0)}{k!}x^k
      \end{align*}
    \item Sei $x_0$ beliebig. Setzen: $q(y)\coloneqq p(y+x_0)$. Es gilt $q^{(k)}
      (y)=p^{(k)}(y+x_0), q^{(k)}(y)=p^{(k)}(x_0)$.\\
      $p(y+x_0)=q(y)=\sum_{k=0}^n \frac{p^{(k)}(0)}{k!}y^k=\sum_{k=0}^n
      \frac{p^{(k)}(x_0)}{k!}y^k$\\
      $y\coloneqq x-x_0, p(x)=\sum_{k=0}^n \frac{p^{(k)}(0)}{k!}(x-x_0)^k$
  \end{enumerate}
  \qed
\end{lemma}

Sei $f$ eine $n$-mal stetig differenzierbare Funktion in $x_0$. Man
verwendet 
\begin{gather*}\sum_{k=0}^n \frac{f^{(k)}(x_0)}{k!}(x-x_0)^k\end{gather*}
zur Approximation von $f$ in der "`Nähe"' von $x_0$.

\begin{definition}
  \begin{enumerate}[(1)]
    \item Sei $I\subset\R$ ein Intervall und $f\colon I\rightarrow\R$ in $x_0
      \in I$ eine $n$-mal differenzierbare Funktion. Dann heißt:
      \begin{gather*}T_n(f;x_0)\colon\R\rightarrow\R\end{gather*}
      definiert durch
      \begin{gather*}T_n(f;x_0)\coloneqq\sum_{k=0}^n \frac{f^{(k)}(x_0)}{k!}(x-x_0)^k\end{gather*}
      $n$-tes \emph{Taylorpolynom\index{Taylorpolynom}} von $f$ im
      Punkt $x_0$.
    \item Taylorreihe von $f$ in $x$ mit Entwicklungspunkt $x_0$\\
      Sei $f\colon I\rightarrow\R$ beliebig oft differenzierbar in $x\in I$.
      Dann heißt
      \begin{gather*}T(f;x_0)(x)\coloneqq\sum_{k=0}^\infty \frac{f^{(k)}(x_0)}{k!}(x-x_0)^k\end{gather*}
      \emph{Taylorreihe\index{Taylorreihe}} von $f$ in $x$ mit
      Entwicklungspunkt $x_0$.
    \item Gilt für eine unendlich oft differenzierbare Funktion 
      $f\colon I\rightarrow\R$ in $x_0\in I\colon f(x)=\sum_{k=0}^\infty
      \frac{f^{(k)}(x_0)}{k!}(x-x_0)^k$, so sagt man, $f$ ist in $I$
      taylorentwickelbar mit dem Entwicklungspunkt $x_0$.
  \end{enumerate}
\end{definition}

Beispiele:
\begin{enumerate}[(1)]
  \item $f(x)=e^x, f\colon\R\rightarrow\R, x_0\in\R$
    \begin{align*}
      f^{(k)}(x_0)&=& e^{x_0}\\
      f(x)&=& e^x=e^{x_0}e^{x-x_0}\\
      &=& e^{x_0}\sum_{k=0}^\infty \frac{(x-x_0)^k}{k!}\\
      &=& \sum_{k=0}^\infty \frac{e^{x_0}}{k!}(x-x_0)^k\\
      &=& \sum_{k=0}^\infty \frac{f^{(k)}(x_0)}{k!}(x-x_0)^k
    \end{align*}
    Also $f(x)=e^x$ ist für $x_0\in\R$ taylorentwickelbar.
  \item $f(x)=\begin{cases}
      e^{-\frac{1}{x^2}} & x\neq 0\\
      0 & x=0
    \end{cases}, f\colon\R\rightarrow\R$\\
    Es gilt $f^{(k)}(0)=0$ mit $k=0,1,2,\dots$. Somit ist $T(f;x_0=0)=
    \sum_{k=0}^\infty \frac{f^{(k)}(0)}{k!}x^k=0, x\in\R$. Aber $f(x)
    \neq 0$ für $x\neq 0$. Damit ist $f$ in $x_0=0$ \emph{nicht}
    taylorentwickelbar.
\end{enumerate}

$R_n(f;x_0)=f-T_n(f;x_0)$ Restglied kürzer $R_n\coloneqq R_n(f;x_0)$\\
$f\colon I\rightarrow\R$ in $x_0$ genau dann taylorentwickelbar, wenn
$\lim_{n\rightarrow\infty} R_n(x)=0$

\begin{theorem}
  \textbf{Taylorscher Satz}
  \begin{gather*}I\colon\begin{cases}
    [x_0,x] & x>x_0\\
    [x.x_0] & x<x_0
  \end{cases}\qquad f\colon I\rightarrow\R\end{gather*}
  $f$ sei $n$-mal stetig auf $I$ differenzierbar und $n+1$-mal
  differenzierbar in $I\backslash\{x,x_0\}$ und $p\in\N$. Dann
  \begin{gather*}\forall x\in I\,\exists 0<\Theta<1\colon R_n(x)=\frac{f^{(n+1)}(x_0+\Theta(x-x_0))}{n!p}
  (1-\Theta)^{n+1-p}(x-x_0)^{n+1}\end{gather*}
  (\emph{Restglied von Schlömilch\index{Restglied von Schlömilch}}) und
  \begin{gather*}f(x)=\sum_{k=0}^n \frac{f^{(k)}(x_0)}{k!}(x-x_0)+R_n(x)\end{gather*}
  (\emph{Taylorsche Formel\index{Formel!Taylorsche}})\\
  \textbf{Beweis}:
  \begin{gather*}F(t)\coloneqq f(x)-\sum_{k=0}^n \frac{f^{(k)}(t)}{k!}(x-t)^k\qquad G(t)\coloneqq(x-t)^p\end{gather*}
  Dann ist $F(x_0)-\underbrace{F(x)}_{=0}=R_n(x), G(x_0)-\underbrace{G(x)}_{=0}
  =(x-x_0)^p, F'(t)=-\sum_{k=0}^n \frac{f^{(k+1)}t}{k!}(x-t)^k +
  \sum_{k=1}^n \frac{f^{(k)}t}{k!}k(x-t)^{k-1}=-\frac{f^{(n+1)}(t)}{n!}
  (x-t)^n, G'(t)=p(x-t)^{p-1}$\\
  Nach dem zweiten Zwischenwertsatz folgt:
  \begin{align*}
    \exists 0<\Theta<1\colon \frac{F(x_0)-F(x)}{G(x_0)-G(x)} &=
    \frac{F'(x_0+\Theta(x-x_0))}{G'(x_0+\Theta(x-x_0))}\\
    \Rightarrow\frac{R_n(x)}{(x-x_0)^p} &=
    \frac{f^{(n+1)}(x_0+\Theta(x-x_0))\cdot(x-(x_0+\Theta(x-x_0)))^n}{n!p(x-(x_0+\Theta(x-x_0)))^{p-1}}\\
    &= \frac{f^{(n+1)}(x+\Theta(x-x_0))}{n!p}(1-\Theta)^{n+1-p}(x-x_0)^{n+1-p}\\
    \Rightarrow R_n(x)&=  \frac{f^{(n+1)}(x+\Theta(x-x_0))}{n!p}(1-\Theta)^{n+1-p}(x-x_0)^{n+1}
  \end{align*}
  \qed
\end{theorem}

\paragraph{Spezialfälle des Restglieds}
\begin{description}
  \item[Lagrange] $p=n+1\Rightarrow R_n(x)=\frac{f^{(n+1)}(x_0+\Theta(x-x_0))}{(n+1)!}(x-x_0)^{n+1}$
  \item[Cauchy] $p=1\Rightarrow R_n(x)=\frac{f^{(n+1)}(x+\Theta(x-x_0))}{n!}(1-\Theta)^n(x-x_0)^{n+1}$
\end{description}

Beispiel: Gegeben sei die Funktion $f(x)=\ln(1+x)$ mit dem
Entwicklungspunkt $x_0=0$. Es gilt
\begin{gather}
  \label{eq:y2}
  \ln(1+x)=\sum_{k=1}^n \frac{(-1)^{k-1}}{k}x^k+R_n(x)
\end{gather}
wobei
\begin{enumerate}
  \item $R_n(x)=(-1)^n\Theta_1\frac{x^{n+1}}{n+1}, 0<\Theta_1<1, 0\leq x\leq 1$
  \item $R_n(x)=(-1)^n\Theta_2\frac{x^{n+1}}{1+x}, 0<\Theta_2<1, -1<x<0$
\end{enumerate}
($\Theta_1, \Theta_2$ hängen von $n$ und $x$ ab.)
Die Taylorreihe
\begin{gather*}\ln(1+x)=\sum_{k=1}^\infty \frac{(-1)^{k-1}}{k}x^k\qquad -1<x\leq 1\end{gather*}
ist für $-1<x<1$ absolut konvergent und für $\abs{x}>1$ divergent.\\
Folgerung: Für $1\leq y<\infty$ gilt: 
\begin{gather*}
  \ln y=2\sum_{k=1}^n \frac{1}{2k-1}\left(\frac{y-1}{y+1}\right)^{2k-1}
  +\widetilde{R_n}(y)
\end{gather*}
\begin{gather*}\widetilde{R_n}(y)=\left(\frac{\Theta_1}{2n+1}+\frac{\Theta_2}{2}(y+1)\right)
\left(\frac{y-1}{y+1}\right)^{2n+1}\qquad 0<\Theta_1,\Theta_2<1\end{gather*}
Für $0<y\leq 1$ nutzt man $\ln y=-\ln(\frac{1}{y})$. Insbesondere
\begin{gather*}\sum_{k=1}^\infty \frac{(-1)^{k-1}}{k}=\ln 2=\sum_{k=1}^n
\frac{(-1)^{k-1}}{k}+R_n(1)\end{gather*}
$\abs{R_n(1)}=\abs{(-1)^n}\abs{\Theta_1}\frac{1}{n+1}\leq\frac{1}{n+1}
\xrightarrow{n\rightarrow\infty}0$\\
Genauigkeit auf sechs Stellen erhält man mit Sicherheit für $n\geq 10^6$
(schlechte Konvergenz), da  $\abs{R_n(1)}\leq \frac{1}{n+1}\leq \frac{1}{n}\leq 10^{-6}
\Rightarrow n\geq 10^6$.

Setzt man $y=2$ in \autoref{eq:y2} ein, erhält man $\ln 2=2\sum_{k=1}^n 
\frac{1}{2k-1}\left( \frac{1}{3} \right)^{2k-1}+\widetilde{R_n}(2)$:
\begin{gather*}\abs{\widetilde{R_n}(2)}=\abs{\frac{\Theta_1}{2n+1}+\frac{3}{2}\Theta_2}
\left( \frac{3}{2} \right)^{2n+1}\leq\left( \frac{1}{2n+1}+\frac{3}{2} \right)
\left( \frac{1}{3} \right)^{2n+1}\end{gather*}
\begin{align*}
  n=6 & & \abs{\widetilde{R_6}(2)}\leq \left( \frac{1}{13}+\frac{3}{2} \right)
  \left( \frac{1}{3} \right)^{13}<10^{-6}\\
  n=10 & & \abs{\widetilde{R_{10}}(2)}\leq \left( \frac{1}{21}+\frac{3}{2} \right)
  \left( \frac{1}{3} \right)^{21}<1,5\cdot 10^{-10}
\end{align*}

$f(x)=\ln(1+x)$\\
Es gilt: $\ln(1+x)=\sum_{k=1}^n (-1)^{k-1}\frac{x^k}{k}+R_n(x)$, wobei
\begin{enumerate}
  \item $R_n(x)=(-1)^n \Theta_1\frac{x^n+1}{n+1}$ mit $0<\Theta_1<1$ für 
    $0\leq x\leq 1$
  \item $R_n(x)=(-1)^n\Theta_2\frac{x^{n+1}}{x+1}$ mit $0<\Theta_2<1$ für
    $-1<x\leq 0$
\end{enumerate}
Dabei ist  $\Theta_1,\Theta_2$ abhängig von $x,n$.\\
Beweis:
\begin{align*}
  f(x)&=\ln(1+x)  f'(x)&=\frac{1}{1+x}\\
  f''(x)&=-\frac{1}{(1+x)^2}  f'''(x)&=\frac{2}{(1+x)^3}\\
  &\Longrightarrow &f^{(n)}(x)=(n-1)!(-1)^{n-1}\frac{1}{(1+x)^n}
\end{align*}

Einsetzen in Taylorformel:
\begin{align*}
  \ln(1+x)&=& f(x)=\sum_{k=0}^n \frac{f^{(k)}(0)}{k!}+R_n\\
  &=& \sum_{k=1}^n (k-1)!(-1)^{k-1}\frac{1}{k!}x^k+R_n(x)\\
  &=& \sum_{k=1}^n (-1)^{k-1}\frac{x^k}{k!}+R_n(x)
\end{align*}

Restglied:
\begin{enumerate}[1. F{a}ll]
  \item $0\leq x\leq 1$: Restglied von Lagrange:\\
    $R_n(x)=\frac{f^{(n+1)}(\Theta x)}{(n+1)!}x^{n+1}=(-1)^n
    \underbrace{\frac{1}{(1+\Theta x)^{n+1}}}_{=:\Theta_1}
    \frac{x^{n+1}}{n+1}$ mit $0<\Theta\leq 1$. Es gilt $0<\Theta_1<1$,
    denn $1+\Theta x\geq 1$. Daher folgt, $\frac{1}{1+\Theta x}\leq 1$.
    Somit ist $R_n(x)=(-1)^n\Theta_1\frac{x^{n+1}}{n+1}$ für alle
    $0\leq x\leq 1$ und es folgt $\abs{R_n(x)}\leq\frac{\abs{x}^{n+1}}{n+1}
    \xrightarrow{n\rightarrow\infty} 0\Rightarrow\lim_{n\rightarrow\infty}
    R_n(x)=0$ für $0\leq x \leq 1$.
  \item $-1<x\leq 0$: Cauchysches Restglied:\\
    \begin{align*}
      R_n(x)&=& \frac{f^{(n+1)}(\Theta x)}{n!}(1-\Theta)^nx^n+1\text{ für }
      0<\Theta <1\\
      &=& (-1)^n\frac{1}{(1+\Theta x)^{n+1}}(1-\Theta)^nx^{n+1}\\
      &=& (-1)^n\underbrace{\left( \frac{1-\Theta}{1+\Theta x} \right)^n
      \frac{1+x}{1+\Theta x}}_{=:\Theta_2}\frac{x^{n+1}}{1+x}
    \end{align*}
    Es gilt $0<\Theta<1$, da $0<1-\Theta<1+\Theta x$ und $0<1+x<1+\Theta x$.
    Somit ist:
    \begin{align*}
      R_n(x)&=& (-1)^n\Theta_2\frac{x^{n+1}}{1+x}\\
      &\Rightarrow & \abs{R_n(x)}\leq\frac{\abs{x}^{n+1}}{1+x}\xrightarrow{n\rightarrow\infty} 0\\
      &\Rightarrow & \lim_{n\rightarrow\infty} R_n(x)=0\text{ für }
      -1<x\leq 0
    \end{align*}
\end{enumerate}
Beide Fälle liefern die Konvergenz der Taylorreihe.
\qed

Folgerung: Für $1\leq y<\infty$ gilt:
\begin{align*}
  \ln y &=& 2\sum_{k=1}^n \frac{1}{(2k-1)}\left( \frac{y-1}{y+1} \right)^{2k-1}
  +\widetilde{R_n}(y)\\
  \widetilde{R_n}(y) &=& \left( \frac{\Theta_1}{2n+1}+\frac{\Theta_2}{2}(y+1) \right)
  \left( \frac{y-1}{y+1} \right)^{2n+1}\quad 0<\Theta_1,\Theta_2<1
\end{align*}
Beweis: Sei $1\leq y <\infty$ und $x\coloneqq\frac{y-1}{y+1}$. Es gilt $0\leq x<1$
und $y=\frac{1+x}{1-x}$:
\begin{align*}
  \ln(1+x) &=& \sum_{k=1}^{2n}\frac{(-1)^{k-1}}{k}x^k+R_{2n}(x)\\
  \ln(1-x) &=& \sum_{k=1}^{2n}\frac{(-1)^{k-1}}{k}(-x)^k+R_{2n}(-x)\\
  \ln\left( \frac{1+x}{1-x} \right) &=& \ln(1+x)-\ln(1-x)\\
  &=& \sum_{k=1}^{2n}\frac{(-1)^{k-1}}{k}x^k+R_{2n}(x)-
  \sum_{k=1}^{2n}\frac{(-1)^{k-1}}{k}(-x)^k+R_{2n}(-x)\\
  &=& \sum_{k=1}^{2n}\frac{(-1)^{k-1}-(-1)}{k}x^k+
  \underbrace{(R_{2n}(x)-R_{2n}(-x))}_{=:\widetilde{R_n}(x)}\\
  &=& 2\sum_{k=1}^n\frac{x^{2k-1}}{2k-1}+\widetilde{R_n}(x)\\
  R_{2n}(x)&=& (-1)^{2n}\Theta_1\frac{x^{2n+1}}{2n+1}\\
  R_{2n}(-x)&=& (-1)^{2n}\Theta_2\frac{(-x)^{2n+1}}{1-x}\\
  \widetilde{R_n}(x)&=& \left( \frac{\Theta_1}{2n+1}+\frac{\Theta_2}{1-x} \right)
  x^{2n+1}
\end{align*}
Damit ist:
\begin{gather*}\boxed{\ln(y)=2\sum_{k=1}^n\frac{1}{2k-1}\left( \frac{y-1}{y+1} \right)^{2k-1}
+\widetilde{R_n}(y)}\end{gather*}
mit
\begin{gather*}\boxed{\widetilde{R_n}=\left( \frac{\Theta_1}{2n+1}+\frac{\Theta_2}{2}
(y+1)\right)\left( \frac{y-1}{y+1} \right)^{2n+1}}\end{gather*}
\qed

\chapter{Integration}
\section{Das Riemannsche Integral}
Die Integralrechnung umfasst die klassische Problemstellung, 
dass man eine Fläche unterhalb einer Kurve berechnen möchte:

\begin{pspicture}(-1,-1)(5,4)
   \psaxes{->}(0,0)(-1,-1)(5,4)
   \psplot[linewidth=2pt]{0.8}{4.2}{x 0.85 mul 2 sub dup mul 1.5 add}
   \pscustom[linewidth=0.5pt,fillstyle=solid,fillcolor=lightgray]{%
     \psplot[linewidth=2pt]{1}{4}{x 0.85 mul 2 sub dup mul 1.5 add}
     \psline(4,0)(1,0)(1,2.8225)%
   }
\end{pspicture} 

Zur Untersuchung dieses Problems braucht man diverse Variablen:
\begin{description}
  \item[Zerlegung\index{Zerlegung}] $\ZZ\coloneqq\{I_1,\cdots,I_n\}$\\
    $I_i\coloneqq[x_{i-1},x_i]$ mit $a=x_0<x_1<\cdots<x_n=b$
  \item[Verfeinerung\index{Verfeinerung}] $\ZZ'\perdef\forall
    I'\in\ZZ'\,\exists I\in\ZZ\colon I'\subset I$\\
    Schreibweise: $\ZZ\prec\ZZ'$
  \item[Länge des Intervalls] $I=[c,d]\colon l(I)\coloneqq d-c$
  \item[Durchmesser der Zerlegung] $d(\ZZ)\coloneqq\max\{l(I)\colon
    I\in\ZZ\}$
  \item[Überlagerung von zwei Zerlegungen] $\ZZ\coloneqq\{I=I'\cap I''\colon
    I'\in\ZZ_1, I''\in\ZZ_2, l(I)>0\}$\\
    $\ZZ$ ist wieder eine Zerlegung und $\ZZ_1,\ZZ_2\prec\ZZ$\\
    Schreibweise: $\ZZ=\ZZ_1\vee\ZZ_2$
  \item[Menge der beschränkten Funktionen] $B[a,b]\coloneqq\{f\colon
    [a,b]\rightarrow\R\colon f\text{ beschränkt}\}$
  \item[Infimum/Supremum\index{Infimum!Integration}\index{Supremum!Integration}]
    Sei $M\subset[a,b]$\\
    \begin{gather*}\underline{f}(M)\coloneqq\inf\{f(x)\colon x\in M\}\end{gather*}
    \begin{gather*}\overline{f}(M)\coloneqq\sup\{f(x)\colon x\in M\}\end{gather*}
  \item[Flächeninhalt]
    \emph{Untersumme\index{Untersumme}}:
    \begin{gather*}\underline{S}(f;\ZZ)=\sum_{I\in\ZZ}\underline{f}(I)l(I)\end{gather*}
    \emph{Obersumme\index{Obersumme}}:
    \begin{gather*}\overline{S}(f;\ZZ)=\sum_{I\in\ZZ}\overline{f}(I)l(I)\end{gather*}
    Es gilt:
    \begin{gather*}\underline{S}(f;\ZZ)\leq\overline{S}(f;\ZZ)\end{gather*}
\end{description}

\begin{lemma}
  \label{lemma:int}
  Sei $f\in B[a,b]$ und $\ZZ\prec \ZZ'$. Dann gilt
  \begin{enumerate}[(i)]
    \item $\underline{S}(f;\ZZ')\geq \underline{S}(f;\ZZ)$
      bzw. $\underline{S}(f;\ZZ) \leq \underline{S}(f; \ZZ')$\\
      \textit{Beweis}: Annahme: $\ZZ'$ enthält genau einen Punkt $x'$ mehr
      als $\ZZ$ mit $x_{i-1}<x'<x_i$. Es gilt:
      \begin{gather*}\underline{f}([x_{i-1},x']),\underline{f}([x',x])\geq \underline{f}
      ([x_{i-1},x_i])\end{gather*}
      Also ist $\underline{f}([x_{i-1},x_i])l([x_{i-1},x_i])\leq 
      \underline{f}([x_{i-1},x'])l([x_{i-1},x'])+\underline{f}([x',x_i])
      l([x',x_i])$ und somit
      \begin{gather*}\underline{S}(f;\ZZ)\leq \underline{S}(f;\ZZ')\end{gather*}
      Falls $\ZZ'$ mehr als einen Punkt ($p>1$) hat, wendet man den Schluss
      $p$-mal an.
    \item $\overline{S}(f;\ZZ')\leq \overline{S}(f;\ZZ)$\\
      \textit{Beweis}: Der Beweis erfolgt analog zu oben.
    \item $\overline{S}(f;\ZZ')-\underline{S}(f;\ZZ')\leq \overline{S}(f;\ZZ)
      -\overline{S}(f;\ZZ)$\\
      \textit{Beweis}: Der Schluss folgt aus den obigen Aussagen.
    \item $\forall \ZZ_1,\ZZ_2 \underline{S}(f;\ZZ_1)\leq \overline{S}
      (f;\ZZ_2)$\\
      \textit{Beweis}: Sei $\ZZ=\ZZ_1\prec \ZZ_2$. Dann ist $\underline{S}
      (f;\ZZ_1)\leq \underline{S}(f;\ZZ)\leq \overline{S}(f;\ZZ)\leq
      \overline{S}(f;\ZZ_2)$
  \end{enumerate}
\end{lemma}

\begin{definition}
  Sei $f$ eine beschränkte Funktion auf $[a,b]$. Dann heissen die Größen
  \begin{gather*}\int_{\underline{a}}^b fdx \coloneqq \sup_\ZZ \underline{S}(f;\ZZ)\end{gather*}
  und
  \begin{gather*}\int_a^{\overline{b}} fdx \coloneqq \inf_\ZZ \overline{S}(f;\ZZ)\end{gather*}
  wobei $\ZZ$ die Menge aller Zerlegungen von $[a,b]$ durchläuft, unteres
  und oberes \emph{Darbouxsches Integral\index{Integral!Darbouxsches}}.
\end{definition}

\begin{remark}
  Nach \autoref{lemma:int} Punkt (iv) gilt immer
  $\int_{\underline{a}}^b fdx\leq \int_a^{\overline{b}}fdx$. Es gibt
  beschränkte Funktionen für die $\int_{\underline{a}}^b fdx<
  \int_a^{\overline{b}}fdx$.
\end{remark}

\begin{beispiel}
$f(x)\coloneqq
\begin{cases}
  1 & x\in [0,1], x \text{ irrational}\\
  0 & x\in [0,1], x \text{ rational}
\end{cases} \in B[0,1]$

Sei $\ZZ$ eine beliebige Zerlegung von $[0,1]$ und $I\in \ZZ$ ein Intervall.
Dann gilt $\underline{f}(I)=0, \overline{f}(I)=1$.
\begin{align*}
  \underline{S}(f;\ZZ)&= \sum_{I\in\ZZ} \underline{f}(I)l(I)=0&
  \overline{S}(f;\ZZ)&= \sum_{I\in\ZZ} \overline{f}(I)l(I)=l([0,1])=1\\
  &\Rightarrow \int_{\underline{a}}^b fdx =0 < 1= \int_a^{\overline{b}} fdx
\end{align*}
\end{beispiel}

\begin{definition}
  Eine Funktion $f\in B[a,b]$ heißt genau dann Riemann-integrierbar
  (R-integrierbar), wenn gilt:
  \begin{gather*}\int_{\underline{a}}^b fdx = \int_a^{\overline{b}} fdx\end{gather*}
  $\int_a^b$ heißt \emph{Riemannsches Integral\index{Integral!Riemannsches}}.
\end{definition}

\begin{theorem}
  \textbf{Riemannsches Integrabilitätskriterium}\\
  $f\in B[a,b]$ ist R-integrierbar $\perdef$
  \begin{gather*}\forall \varepsilon>0\,\exists \ZZ \colon \overline{S}(f;\ZZ)-
  \underline{S}(f;\ZZ)\leq \varepsilon\end{gather*}
  \textbf{Beweis}:
  \begin{itemize}
    \item["`$\Rightarrow$"'] Sei $f\in B[a,b]$ R-integrierbar. Dann folgt
      $\int_a^b fdx=\int_{\underline{a}}^b fdx = \int_a^{\overline{b}} fdx$,
      d.\,h.
      \begin{align}
        &\Rightarrow& \forall\varepsilon>0\,\exists\ZZ_1,\ZZ_2\colon\int_a^b fdx
        -\underline{S}(f;\ZZ_1)<\frac{\varepsilon}{2}\\
        & & \qquad \overline{S}(f;\ZZ_2)-\int_a^b fdx < \frac{\varepsilon}{2}
      \end{align}
      Für $\ZZ=\ZZ_1\prec\ZZ_2$ gilt: $\overline{S}(f;\ZZ)-\underline{S}(f;\ZZ)
      \leq \overline{S}(f;\ZZ_2)-\underline{S}(f;\ZZ_2) = 
      \overline{S}(f;\ZZ_2)+\int_a^b fdx-\int_a^b fdx-\underline{S}(f;\ZZ_2)
      <\frac{\varepsilon}{2}+\frac{\varepsilon}{2}=\varepsilon$
    \item["`$\Leftrightarrow$"'] Sei $\varepsilon>0$. Dann gilt: $0\leq
      \int_a^{\overline{b}} fdx - \int_{\underline{a}}^b fdx\leq
      \overline{S}(f;\ZZ)-\underline{S}(f;\ZZ)<\varepsilon$\\
      Daher folgt für alle positiven $\varepsilon$: $0\leq
      \int_a^{\overline{b}} fdx - \int_{\underline{a}}^b fdx\leq \varepsilon
      \Rightarrow \overline{\int}=\underline{\int}$. Womit klar ist, dass $f$ 
      R-integrierbar ist.
  \end{itemize}
  \qed
\end{theorem}

\subsection{Definition des Riemannsches Integrals über ZWS}

Auswahlfunktion: Sei $\ZZ$ eine Zerlegung von $[a,b]$.
\begin{gather*}\xi\colon\ZZ\rightarrow[a,b] \text{ mit } \xi(I)=\xi\in I\in\ZZ\end{gather*}
heißt \emph{Auswahlfunktion\index{Auswahlfunktion}}. Sie ordnet jedem
Intervall $I$ ein Element $\xi(I)$ des Intervalls zu.

Zwischensumme:
\begin{gather*}S(f;\ZZ;\xi)\coloneqq\sum_{I\in\ZZ} f(\xi(I)) l(I)\end{gather*}
heißt \emph{Zwischensumme\index{Zwischensumme}} von $f$ mit der Zerlegung
$\ZZ$ und der Auswahlfunktion $\xi\colon\ZZ\rightarrow[a,b]$.

Wegen $\underline{f}\leq f(\xi(I))\leq\overline{f}(I)$ gilt $\underline{S}
(f;\ZZ)\leq S(f;\ZZ;\xi)\leq\overline{S}(f;\ZZ)$.

\begin{lemma}
  Sei $f\in B[a,b]$ und $\ZZ\prec\ZZ'$. Dann gilt für alle Auswahlfunktionen
  $\xi\colon\ZZ\rightarrow[a,b]$ und $\xi'\colon\ZZ'\rightarrow
  [a,b]\colon \abs{S(f;\ZZ;\xi)
  -S(f;\ZZ';\xi')}\leq\max_{I\in\ZZ} (\overline{f}(I)-\underline{f}(I))
  \underbrace{l([a,b])}_{=b-a}$
\end{lemma}

\begin{theorem}
  Sei $f\in B[a,b]$. Dann ist $f$ genau dann R-integrierbar, wenn gilt:
  \begin{gather*}\exists A\in\R \forall\varepsilon>0 \exists\delta_\varepsilon>0
  \forall\ZZ(d(\ZZ)<\delta_\varepsilon) \forall \xi(\xi\colon\ZZ\rightarrow
  [a,b])\colon\abs{S(f;\ZZ;\xi)-A}\leq \varepsilon\end{gather*}
\end{theorem}

\begin{theorem}
  Sei $f\in B[a,b]$. Dann ist $f$ genau dann R-integrierbar, wenn
  \begin{gather*}\forall (\ZZ_n)\,\forall (\xi_n)\,(d(\xi_n)\rightarrow 0)\colon
  \lim_{n\rightarrow\infty} S(f;\ZZ_n;\xi_n)\end{gather*}
  existiert und es gilt $\lim_{n\rightarrow\infty} S(f;\ZZ_n;\xi_n)=\int_a^b
  fdx$.
\end{theorem}

\subsection{Beispiele von R-integrierbaren Funktionen}

\begin{theorem}
  \begin{enumerate}[(i)]
    \item Jede \emph{monotone} Funktion $f\in B[a,b]$ ist R-integrierbar.\\
      \textit{Beweis}: O.\,B.\,d.\,A. sei $f(b)\neq f(a)$ und $f$ monoton wachsend.
      $\ZZ=\{I_1,\dots,I_n\}, I_k=[x_{k-1},x_k], x_0=a,x_n=b$\\
      Es ist
      \begin{align*}
        \overline{S}(f;\ZZ)-\underline{S}(f;\ZZ)&= \sum_{I\in\ZZ} \overline{f}
        (I)l(I)-\underline{f}(I)l(I)
        &= \sum_{i=1}^n (f(x_i)-f(x_{i-1}))l(I_i)\\
        &\leq \left( \sum_{i=1}^n (f(x_i)-f(x_{i-1})) \right)d(\ZZ)
        &= (f(b)-f(a))(d(\ZZ))
      \end{align*}
      Für $\varepsilon>0$ wählt man $\ZZ$ derart, dass $d(\ZZ)\leq
      \frac{\varepsilon}{f(b)-f(a)}$. Dann gilt, $\overline{S}(f;\ZZ)-
      \underline{S}(f;\ZZ)\leq f(b)-f(a)d(\ZZ)\leq \varepsilon\Rightarrow f$
      ist R-integrierbar.
    \item Jede \emph{stetige} Funktion $f\in B[a,b]$ ist R-integrierbar.\\
      \textit{Beweis}: $f$ sei auf $[a,b]$ stetig. Dann ist $f$ auch beschränkt
      und gleichmässig stetig und es gilt:
      $\forall\varepsilon>0\,\exists\delta_\varepsilon>0\,\forall x_1,x_2\in
      [a,b]\colon \abs{x_1-x_2}\leq\delta_\varepsilon\Rightarrow\abs{f(x_1)-f(x_2)}\leq
      \frac{\varepsilon}{b-a}$. Man wählt $\ZZ$ mit $d(\ZZ)\leq
      \delta_\varepsilon$. Dann gilt $\overline{f}(I)-\underline{f}(I)\leq
      \frac{\varepsilon}{b-a}$ für $I \in\ZZ$. Somit ist
      \begin{align*}
        \overline{S}(f;\ZZ)-\underline{S}(f;\ZZ)&=& \sum_{I\in\ZZ}
        (\overline{f}(I)-\underline{f}(I))l(I)\\
        &\leq& \sum_{I\in\ZZ} \frac{\varepsilon}{b-a} l(I)=\left( \sum_{I\in\ZZ}
        \right)\frac{\varepsilon}{b-a}\\
        &=& b-a\frac{\varepsilon}{b-a}=\varepsilon
      \end{align*}
  \end{enumerate}
  \qed
\end{theorem}

\begin{theorem}
  Ändert man eine R-integrierbare Funktion $f\in B[a,b]$ an endlich vielen
  Stellen ab, so ist die neu entstandene Funktion $\tilde{f}$ ebenfalls
  R-integrierbar und es gilt
  \begin{gather*}\int_a^b fdx = \int_a^b \tilde{f}dx\end{gather*}
\end{theorem}

Ein Beispiel zur numerischen Auswertung eines R-Integrals über ZWS ist die
Funktion $f(x)=x^\alpha$.

\subsection{Eigenschaften des R-Integrals}
\begin{gather*}\RR[a,b]\coloneqq\{f\in B[a,b] | f \text{ ist R-integrierbar}\}\end{gather*}

\begin{theorem}
  \begin{enumerate}
    \item $f\in\RR[a,b]$. Dann gilt $\underline{f}([a,b])(b-a)\leq\int_a^b
      fdx\leq \overline{f}([a,b])(b-a)$.
    \item $f\in\RR[a,b], c\in\R\Rightarrow cf\in\RR[a,b]$\\
      $\int_a^b cfdx=c\int_a^b fdx$
    \item Additivität: $f_1,f_2\in\RR[a,b]\Rightarrow f_1+f_2\in\RR[a,b]$\\
      $\int_a^b (f_1+f_2)dx=\int_a^b f_1dx + \int_a^b f_2dx$
    \item $f_1,f_2\in\RR[a,b], f_1\leq f_2\Rightarrow \int_a^b f_1dx\leq 
      \int_a^b f_2dx$
    \item Sei $a<c<b$ und $f_i[a,b]\rightarrow\R$. Dann gilt $f\in\RR[a,b]
      \Leftrightarrow f_{[a,c]}\in\RR[a,c]\wedge f_{[c,b]}\in\RR[c,b]
      \int_a^b fdx=\int_a^c fdx + \int_c^b fdx$
    \item Sei $f\in\RR[a,b], m\leq f\leq M, \varphi\colon[m,M]\rightarrow\R$ stetig.
      Dann gilt $h=\varphi\circ f\in\RR[a,b]$
    \item $f,g\in\RR[a,b]\Rightarrow f\circ g \in\RR[a,b]$
    \item $f\in\RR[a,b]\Rightarrow \abs{f}\in\RR[a,b], \abs{\int_a^b fdx}\leq\int_a^b
      \abs{f}dx$
  \end{enumerate}
  %Beweis noch einfügen
\end{theorem}

\section{Integration und Differentiation}

\begin{definition}
  Sei $f\in\RR[a,b]$ und $x_0\in[a,b]$. Dann heißt
  \begin{gather*}F\colon[a,b]\rightarrow\R\text{ definiert durch }
  F(x)\coloneqq\int_{x_0}^x fdx\,x\in[a,b]\end{gather*}
  \emph{unbestimmtes Integral\index{Integral!unbestimmtes}}.
\end{definition}

\clearpage
\begin{thebibliography}{99}

 \bibitem{barner} \textsc{Barner}, \textsc{Flohr}. Analysis, Band I
  % @book{BOOK,
  %   author={Martin Barner and Friedrich Flohr},
  %   title={Analysis: Analysis, 2 Bde. Kt, Bd.1: Bd I (Gruyter - de Gruyter Lehrb{\"u}cher)},
  %   year={2000},
  %   price={EUR 28,95},
  %   publisher={Gruyter},
  %   isbn={3110167786}
  %  }
\end{thebibliography}

\printindex
\end{document}
