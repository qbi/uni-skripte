% Einige zusätzliche Informationen für rubber
%  rubber erkennt nicht, dass die Datei weg kann, daher sagen wir es ihm
% rubber: clean $base.thm
%  rubber soll nach Änderungen an der Datei nochmal bauen
% rubber: watch $base.thm
% rubber: makeidx.tool      xindy
% rubber: makeidx.language  german-din
%
% scrreprt trifft am Besten die Bedürfnisse eines Skripts, das ganze wird
% zweiseitig (twoside), d.h. es wird zwischen linker und rechter Seite
% unterschieden, und wir verwenden zwischen den Absätzen einen Abstand
% von einer halben Zeile (halfparskip) und dafür keinen Absatzeinzug,
% wobei die letzte Zeile eines Absatzes zu min. 1/4 leer ist.

\RequirePackage[l2tabu,orthodox]{nag}  % nag überprüft den Text auf veraltete
                   % Befehle oder solche, die man nicht in LaTeX verwenden
                   % soll -- l2tabu-Checker in LaTeX

\RequirePackage[ngerman=ngerman-x-latest]{hyphsubst} % einbinden der neuen
                   % Trennmuster, diese korrigieren einige Fehler der alten
                   % und bieten mehr Trennstellen

\documentclass[ngerman,titlepage,twoside, parskip=half*]{scrreprt}

\usepackage[ngerman]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[intlimits,leqno]{amsmath}
\usepackage[all,warning]{onlyamsmath}  % warnt bei Verwendung von nicht
                                       % amsmath-Umgebungen z.\,B. $$...$$
\usepackage{amssymb}     % wird für \R, \C,... gebraucht
\usepackage{fixmath}     % ISO-konforme griech. Buchstaben
\usepackage[euro]{isonums} % definiert Komma als Dezimaltrennzeichen
\usepackage{wasysym}
\usepackage{fancyhdr}
\usepackage{enumerate}
\usepackage{index}
\usepackage{tikz}
\usepackage{nicefrac}
\usepackage{svn}         % Zum Auswerten und ordentlichen Darstellen der
                         % SVN-Schlüsselwörter (s. vor \begin{document})
\usepackage[draft=false,colorlinks,urlcolor=blue,breaklinks]{hyperref}
\usepackage{paralist}
\usepackage{ellipsis}
\usepackage[amsmath,thmmarks,hyperref]{ntheorem} % für die Theorem-Umgebungen
                                                 % (satz, defini, bemerk)
\usepackage{todonotes}   % definiert den Befehl \todo{} um sich leicht
                         % Markierungen für offene Aufgaben zu setzen; wird
                         % auch für \help (s.u.) verwendet
\usepackage{mathtools}   % Zur Definition von \abs und \norm
\usepackage[text]{esdiff}

\usetikzlibrary{calc,shapes.geometric}

\newcommand*{\N}{\mathbb{N}}
\newcommand*{\Z}{\mathbb{Z}}
\newcommand*{\Q}{\mathbb{Q}}
\newcommand*{\R}{\mathbb{R}}
\newcommand*{\C}{\mathbb{C}}
\newcommand*{\ZZ}{\mathfrak{Z}}
\newcommand*{\RR}{\mathcal{R}}
\newcommand*{\perdef}{:\Leftrightarrow}

% Befehl für die Darstellung der Gliederungsüberschriften im Index
\newcommand*{\lettergroup}[1]{\minisec{#1}}

% nach dem Theoremkopf wird ein Zeilenumbruch eingefügt, die Schrift des
% Körpers ist normal und der Kopf wird fett gesetzt
\theoremstyle{break}
\theoremnumbering{arabic}
\theorembodyfont{\normalfont}
\theoremheaderfont{\normalfont\bfseries}

% Das Ende von Umgebungen, für die kein Beweis erbracht wurde, soll mit einer
% leeren Box gekennzeichnet werden. Wenn jedoch ein Beweis erbracht wurde,
% soll kein Zeichen ausgegeben werden (die ausgefüllte Box vom proof wird
% verwendet); man beachte die spezielle Definition von \theoremheaderfont für
% die Umgebung proof
% \newboolean{hasproof}
% \theoremheaderfont{\global\hasprooffalse\normalfont\bfseries}
% \theoremsymbol{\ifthenelse{\boolean{hasproof}}{}{\ensuremath{_\Box}}}

% Die folgenden Umgebungen werden einzeln nummeriert und am Ende jedes
% Kapitels zurückgesetzt
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Satz}[section]
\newtheorem{definition}{Definition}[chapter]
\newtheorem{Folg}{Folgerung}[chapter]

% Die folgenden Theoremumgebungen bekommen keine Nummer
\theoremstyle{nonumberbreak}
%\newtheorem{fakt}{Fakt}
\newtheorem{remark}{Bemerkung}
\newtheorem{beispiel}{Beispiel}

% \theoremheaderfont{\global\hasprooftrue\scshape}
\theoremheaderfont{\scshape}
\theorembodyfont{\normalfont}
% Das Zeichen am Ende eines Beweises
\theoremsymbol{\ensuremath{_\blacksquare}}
% \theoremsymbol{q.\,e.\,d.}
\newtheorem{proof}{Beweis:}

% Hier die Definition, wie \autoref die Umgebungen nennen soll, die mit
% \newtheorem definiert wurden
\newcommand*{\lemmaautorefname}{Lemma}
\renewcommand*{\theoremautorefname}{Satz}
\newcommand*{\definitionautorefname}{Definition}
\newcommand*{\Folgautorefname}{Folgerung}
% Zwischen Unter- und Unterunterabschnitten sollte nicht unterschieden
% werden.
\renewcommand*{\subsectionautorefname}{Abschnitt}
\renewcommand*{\subsubsectionautorefname}{Abschnitt}

% Um wichtige Begriffe im Text überall gleich vorzuheben (gleiches
% Markup), sollte dieser Befehl verwendet werden. Das Argument wird
% automatisch als Indexeintrag verwendet. Dieser kann aber auch als
% optionales Argument selbst bestimmt werden.
\newcommand*{\highl}[2][]{\textbf{\boldmath{#2}}%
  \ifthenelse{\equal{#1}{}}{\index{#2}}{\index{#1}}%
}

% Wenn irgendwo Unklarheiten zum Inhalt im Skript auftreten, können sie
% einfach mit \help{Ich verstehe das nicht} hervorgehoben werden. Dies
% macht es leichter sie alle zu finden und auch ganz einfach
% auszublenden, indem man den Befehl einfach leer definiert
\newcommand*{\help}[1]{\todo[color=green!40]{#1}}

% Um sicherzustellen, dass jeder Betrag/jede Norm links und rechts die
% Striche bekommt, sind diese Befehle da. Damit kann man nicht die
% rechten Striche vergessen und es wird etwas übersichtlicher. Aus
% mathtools.pdf, z. B. \abs[\big]{\abs{a}-\abs{b}} \leq \abs{a+b}
\DeclarePairedDelimiter{\abs}{\lvert}{\rvert}
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}

% In der Vorlesung werden offene Intervallenden durch umgekehrte Klammern
% dargestellt. In TeX hat wohnt aber dem Klammerzeichen bereits eine Bedeutung
% inne, sprich es gehört zu einer der Klassen öffnenede Klammer oder
% schließende Klammer. Dementsprechend werden die Abstände um das Zeichen
% herum gewählt. Damit man nicht immer die Zeichenklasse von Hand ändern muss,
% sollen diese Befehle verwendet werden.
\newcommand*{\lsofint}[1]{\mathopen{]}#1]}   % linksseitig offenes Intervall
\newcommand*{\rsofint}[1]{[#1\mathclose{[}}  % rechtsseitig offenes Intervall
\newcommand*{\bsofint}[1]{\mathopen{]}#1\mathclose{[}} % beidseitig off. Int.

\DeclareMathOperator{\graph}{graph}
\DeclareMathOperator{\id}{id}

\makeindex

\SVN $LastChangedRevision$
\SVN $LastChangedDate$

\begin{document}
\title{Analysis 1}
\author{Prof.\,Dr.\,Bernd Carl}
\date{Wintersemester 2003/04}

\maketitle

\clearpage
\chapter*{Vorwort}

{\itshape
  Dieses Dokument wurde als Skript für die auf der Titelseite genannte
  Vorlesung erstellt und wird jetzt im Rahmen des Projekts "`Vorlesungsskripte
  der Fakultät für Mathematik und Informatik"' weiter betreut. Das Dokument
  wurde nach bestem Wissen und Gewissen angefertigt. Dennoch garantiert weder
  der auf der Titelseite genannte Dozent, die Personen, die an dem Dokument
  mitgewirkt haben, noch die Mitglieder des Projekts für dessen
  Fehlerfreiheit. Für etwaige Fehler und dessen Folgen wird von keiner der
  genannten Personen eine Haftung übernommen. Es steht jeder Person frei,
  dieses Dokument zu lesen, zu verändern oder auf anderen Medien verfügbar zu
  machen, solange ein Verweis auf die Internetadresse des Projekts
  \url{http://uni-skripte.lug-jena.de/} enthalten ist.

  Diese Ausgabe trägt die Versionsnummer~\SVNLastChangedRevision{} und ist vom
  \SVNDate{}. Eine neue Ausgabe könnte auf der Webseite des Projekts
  verfügbar sein.

  Jeder ist dazu aufgerufen, Verbesserungen, Erweiterungen und
  Fehlerkorrekturen für das Skript einzureichen bzw. zu melden oder diese
  selbst einzupflegen -- einfach eine E-Mail an die Mailingliste
  \texttt{<uni-skripte@lug-jena.de>} senden. Weitere Informationen sind
  unter der oben genannten Internetadresse verfügbar.

  Hiermit möchten wir allen Personen, die an diesem Skript mitgewirkt haben,
  vielmals danken:
  \begin{itemize}
   \item Jens Kubieziel \texttt{<jens@kubieziel.de>} (2003/04)
   \item Stilianos Louca \texttt{<stelllaras@gmail.com>} (2007)
   \item Jörg Sommer \texttt{<joerg@alea.gnuu.de>} (2007)
  \end{itemize}
}

\tableofcontents{}

\chapter{Elemente der Logik und Mengenlehre}

Im folgenden werden einige der Grundlagen der Logik und Mengenlehre
vorgestellt. Eine tiefergehende Einführung zu der Thematik ist in den
Vorlesungsunterlagen für Lineare Algebra und analytische Geometrie zu finden.

Wenn du gerade mit deinem Studium beginnst, solltest du dir diese Grundlagen
genau anschauen. Denn das ist die Basis für das weitere Matematikstudium. In
der Regel werden in den Veranstaltungen sehr viele Aussagen bewiesen. Diese
Aussagen sind durch Verbindungen miteinander verknüpft. Bei der Verknüpfung
muss immer sicher gestellt sein, dass die Wahrheitswerte erhalten bleiben.
Diese Beziehungen erlernt man durch das Studium der Logik.

\section{Aussagen}

Das grundlegende Element in der Mengenlehre ist eine
\highl{Aussage}. Dies ist ein Satz, der wahr oder falsch sein kann. In
der Regel bezeichnet man eine Aussage mit $p$ oder den folgenden
Buchstaben im Alphabet und weist einer wahren Aussage den Buchstaben
$w$ wie wahr oder einer falschen Aussage den Buchstaben $f$ wie falsch
zu. In Formeln heißt das $p\equiv w$ oder $p\equiv f$. Wenn wir nun
zwei Aussagen $p$ und $q$ betrachten, lassen sich durch Verbindung
dieser neue Aussagen gewinnen:\index{Aussageverbindung}

\begin{description}
\item[\highl{Negation}] Als Negation wird die Verneinung einer Aussage
  bezeichnet. Wir bezeichnen die Negation der Aussage $p$ mit $\overline{p}$.
  Manchmal wird $\overline{p}$ auch mit $\neg p$ bezeichnet. Formal:
  $\overline{p}\equiv w\colon p\equiv f$ und  $\overline{\overline{p}}=p$
\item[\highl{Konjunktion}] Konjunktion heißt, dass die Aussagen $p$ \emph{und}
  $q$ wahr sein müssen. Formal:
  $q\wedge q\coloneqq w$ genau dann, wenn $p\equiv w$ und $q\equiv w$.
\item[\highl{Disjunktion}] Disjunktion heißt, dass die Aussagen $p$
  \emph{oder} $q$ bzw. beide wahr sind. Formal:
  $p\vee q\equiv f\coloneqq p\equiv f$ und $q\equiv f$
\item[\highl{Implikation}] Die Implikation ist einer der am häufigsten
  benutzten logischen Mittel im weiteren Verlauf des Studiums. Sie bezeichnet
  die Schlussfolgerung, dass aus der Aussage $p$ die Aussage $q$ folgt.
  Insbesondere ist anfangs verwirrend, dass aus einer falschen Aussage eine
  wahre folgen kann. Nur aus einer wahren Aussage kann keine falsche folgen.
  Formal: $(p\Rightarrow q)\equiv f$ genau dann, wenn $p\equiv w$ und $q\equiv
  f$. Daraus können wir folgern: $(\overline{p\Rightarrow q})\equiv p\wedge
  \overline{q}$ und  $(p\Rightarrow q) \equiv \overline{p\wedge
    \overline{q}}=\overline{q}\vee q$
\item[\highl{Äquivalenz}] Die Äquivalenz ist eine stärkere Verknüpfung als die
  Implikation. Die Aussage $p$ gilt genau dann, wenn $q$ gilt. Formal:
  $(p\Leftrightarrow q)\equiv w \perdef p$ und $q$ haben den gleichen
  Wahrheitswert.
\end{description}

\section{Grundbegriffe der Prädikatenlogik (Quantorenlogik)}

Unter einer \highl{Aussageform} $p(x,y,\ldots)$ versteht
man einen Satz, in dem eine oder mehrere Variablen $x,y,\dotsc$
auftreten. Wenn man für die Variablen Objekte einer festliegenden
Gesamtheit einsetzt, erhält man immer eine Aussage.

\subsection{Quantifizierung von Aussageformen}
Durch folgende sprachliche Gebilde wird die Aussageform
quantifiziert:
\begin{itemize}
\item $\forall x$: für alle (wird manchmal auch mit $\bigwedge$ bezeichnet)
\item $\exists x$: es gibt (mindestens) ein (wird manchmal auch mit $\bigvee$
  bezeichnet)
\end{itemize}

\subsection{Bausteine der Prädikatenlogik (Quantorenlogik)}
Diese Bausteine erlauben es uns, Aussagen zu formalisieren und dann auf
Gültigkeit zu prüfen. Die einzelnen Aussagen werden so zu größeren Einheiten
verbunden.
\begin{itemize}
\item $\forall x (p(x)\Rightarrow q(x))$ bedeutet, für jedes $x$ mit der
  Eigenschaft $p(x)$ folgt die Eigenschaft $q(x)$.
\item $\exists x (p(x)\wedge q(x))$ bedeutet, es gibt ein $x$ mit der
  Eigenschaft $p(x)$ \emph{und} der Eigenschaft $q(x)$.
\end{itemize}

\subsection{Negation quantorenlogischer Aussagen}
Es ist sehr oft sinnvoll, die Negation der obigen Aussagen zu betrachten.
Unten finden sich die aussagenlogischen Äquivalente der Bausteine der
Prädikatenlogik.
\begin{align*}
  \overline{\forall x (p(x)\Rightarrow q(x))} &\equiv \exists x (p(x)\wedge
\overline{q(x)}) &
  \overline{\exists x (p(x) \wedge q(x))}&\equiv \forall x
(p(x)\Rightarrow \overline{q(x)})   
\end{align*}

\section{Abbildungen (Funktionen)}

\begin{definition}[Teilmenge, Abbildung]
  Seien $X$ und $Y$ zwei nichtleere Mengen. Eine \highl{Teilmenge}
  $f\subseteq X\times Y\coloneqq \{(x,y)\colon x\in X \wedge y\in Y\}$ mit der
  Eigenschaft
  \begin{gather*}
    \forall x \in X\,\forall y_1\in Y\,\forall y_2\in Y (((x,y_1)\in
    f\wedge (x,y_2)\in f)\Rightarrow y_1=y_2)
  \end{gather*}
  heißt \highl{Abbildung} oder \highl{Funktion} von $X$ in $Y$.
\end{definition}

Wir schreiben hierfür: $f\colon X\rightarrow Y, x\mapsto f(x)$.

In Worten: Unter einer Abbildung (Funktion) $f$ von $X$ in $Y$
versteht man eine Vorschrift, die jedem $x\in X$ \emph{genau ein} $y
\in Y$ zuordnet und nennen es \highl{Bild} oder
\highl{Wert} der Abbildung $f$ an der Stelle $x$. Die Menge
$X$ heißt \highl{Urbildmenge} oder \highl{Definitionsbereich} und
$f(X)\coloneqq\{y\in Y\colon\exists x\in X\colon y=f(x)\}$ ist der
\highl[Bildbereich]{Bild-} oder \highl{Wertebereich}. Der \highl{Graph} von
$f$ ist die Menge $\graph(f)\coloneqq\{(x,f(x))\colon x\in X\}$.

Sei nun $A\subseteq X$. Dann ist $f(A)\coloneqq\{f(x)\colon x\in A\}$ das
\highl{Bild} von $A$ unter der Abbildung $f$. Für $B\subseteq Y$ ist
$f^{-1}(B)\coloneqq\{x\in X\colon f(x)\in B\}$ das \highl{Urbild} von $B$
unter der Abbildung $f$. Es gilt: $f(\emptyset)= f^{-1}(\emptyset)=\emptyset$.

\begin{definition}[injektiv,surjektiv]
  Eine Abbildung $f\colon X\rightarrow Y$ heißt genau dann
  \highl{surjektiv\index{Abbildung!surjektive}}, wenn $f(X)=Y$ gilt. Eine
  Abbildung $f\colon X\rightarrow Y$ heißt genau dann
  \highl{injektiv\index{Abbildung!injektive}} oder
  \highl{eineindeutig\index{Abbildung!eineindeutige}}, wenn gilt: $\forall
  x_{1}\in X\,\forall x_{2}\in X\colon f(x_{1})=f(x_{2})\Rightarrow
  x_{1}=x_{2}$.

  Schließlich heißt eine Abbildung
  \highl{bijektiv\index{Abbildung!bijektive}}, wenn sie injektiv und surjektiv
  ist bzw. eine eineindeutige Abbildung von $X$ auf $Y$ ist.
\end{definition}

\begin{theorem}
  Sei $f\colon X\rightarrow Y$ eine Abbildung. Dann gelten die folgenden
  Beziehungen:
  \begin{align*}
    \forall A,B\subseteq X \colon& f(A\cup B)= f(A)\cup f(B)\\
    & f(A\cap B)= f(A)\cap f(B)\\
    \forall A,B\subseteq Y \colon& f^{-1}(A\cup B)= f^{-1}(A)\cup f^{-1}(B)\\
    & f^{-1}(A\cap B)= f^{-1}(A)\cap f^{-1}(B)
  \end{align*}
  \begin{proof}
    Der Beweis der Aussage verbleibt zur Übung.
  \end{proof}
\end{theorem}

\subsection{Komposition (Hintereinanderausführung, Verkettung)}
\begin{definition}
  Seien $X,Y,Z$ nichtleere Mengen und $f\colon X\rightarrow Y,
  g\colon Y\rightarrow Z$ zwei Abbildungen. Dann heißt die Abbildung $g\circ
  f\colon X\rightarrow Z$, wobei $(g\circ f)(x)\coloneqq g(f(x))$ mit $x\in X$
  \highl{Komposition} oder \highl{Hintereinanderausführung} der
  Abbildung $f$ und $g$.
\end{definition}

\subsection{Inverse Abbildungen}
\begin{definition}
  Seien $X,Y$ zwei nichtleere Mengen und $f\colon X\rightarrow Y$
  bijektiv. Dann heißt $f^{-1}\colon Y\rightarrow X, f(x)\mapsto x$
  \highl[Abbildung!inverse]{inverse Abbildung} oder
  \highl{Umkehrabbildung}.
\end{definition}

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}
    \path (0,0) node(a) [shape=ellipse,minimum height=3cm,minimum width=2.3cm,draw] {}
          (5,0) node(b) [shape=ellipse,minimum height=2.6cm,minimum
          width=1.8cm,draw] {};
    \node (X) [above of=a] {$X$};
    \node (Y) [above of=b] {$Y$};
    \fill (.31,.31) circle (1pt) node [anchor=west] {$x$};
    \fill (5.2,.4) circle (1pt) node [anchor=east] {$f(x)$};
    \draw [->] (.31,.4) to [out=90,in=90] node
    [anchor=north] {$f$} (5.2,.5);
    \draw [->] (5.2,.3) to [out=270,in=270]  node
    [anchor=north] {$f^{-1}$} (.31,.2);
  \end{tikzpicture}
  \caption{Funktion $f$ mit Umkehrabbildung}
  \label{fig:umkehrabb}
\end{figure}

Es gilt, $f\circ f^{-1}=\id_{Y}$ und $f^{-1}\circ f=\id_{X}$. Dabei ist $\id$
die identische Abbildung.

\chapter{Zahlen}

Zahlen sind abstrakte mathematische Objekte. Sie werden zum Zählen, Ordnen und
anderen verwendet. Es gibt verschiedene Möglichkeiten, die Zahlen zu
konstruieren. Die Konstruktionen werden eventuell in weiteren Vorlesungen
vorgestellt.

In dem Kapitel werden wir meist Eigenschaften der reellen Zahlen
studieren. Dabei sind insbesondere Beziehungen zwischen Zahlen, die
Konstruktion von Intervallen und die Betragsfunktion von
Interesse. Einen weiteren Teil der Betrachtungen bilden die Teilmengen
reeller Zahlen sowie das Prinzip der vollständigen Induktion.

\section{Reelle Zahlen}
Für die Mathematik und insbesondere für die Analysis sind die reellen Zahlen
der wichtigste Zahlenbereich. Ohne diese wäre die Analysis in der weiterhin
vorgestellten Form kaum denkbar. Bildlich gesprochen ist das der erste
Zahlenbegriff, der keine Lücken aufweist. Hierdurch wird insbesondere
eine sinnvolle Definition des Grenzwerts möglich.

Neben den reellen Zahlen gibt es noch die natürlichen Zahlen $\N$, die
ganzen Zahlen $\Z$ sowie die rationalen Zahlen $\Q$. Unten sind
beispielhaft die Zahlenmengen aufgeführt.
\begin{align*}
\N &\coloneqq \{1,2,3,\ldots\} &
\Z &\coloneqq \{\ldots ,-2,-1,0,1,2,\ldots\} &
\Q &\coloneqq \left\{\frac{a}{b}\colon a,b\in \Z, b \neq 0\right\}
\end{align*}

Damit kommen wir zum ersten Satz:
\begin{theorem}
  \label{the:2-11}
  Es existiert keine rationale Zahl $x\in \Q$ mit der Eigenschaft
  $x^2=2$ oder $\sqrt{2}\notin \Q$.
\end{theorem}

\begin{lemma}
  Sei $m$ eine natürliche Zahl, so dass $m^2$ eine gerade Zahl
  ist. Dann ist $m$ auch eine gerade Zahl.
  \begin{gather*}
    \forall m \in \N (m^2 \text{ gerade}\Rightarrow m \text{
      gerade})
  \end{gather*}
  \begin{proof}
    Nehmen wir an, $m$ sei ungerade. Dann gibt es für ein $k \in\N$
    die folgende
    Darstellung: $m=2k+1$. Also folgt: $m^{2}= (2k+1)^{2} = 4k^{2}+ 4k+1=
    2(2k^{2}+2k)+1$. Wenn nun $2k^{2}+2k=n$ setzen, haben wir $2n+1$. Also ist
    $m^{2}$ wieder eine ungerade Zahl. Wir haben durch einfache Umformungen
    einen Widerspruch erzeugt. Also gilt die Annahme im Lemma. Damit
    kann auch der \autoref{the:2-11} bewiesen werden.
  \end{proof}
\end{lemma}

\begin{proof}[zu \autoref{the:2-11}]
  Zum Beweis der Aussage nehmen wir an, dass es ein $x\in\Q$ mit $x^{2}=2$
  gibt. Das heißt, für $a,b\in\Z$ und $b\neq0$ gibt es die Darstellung
  $x=\frac{a}{b}$. Ferner nehmen wir an, dass sich der Bruch $\frac{a}{b}$
  nicht weiter kürzen lässt. Also sind $a$ und $b$ teilerfremd. Einsetzen
  ergibt: $x^{2}= (\frac{a}{b})^{2}= \frac{a^{2}}{b^{2}}=2$ und durch die
  Multiplikation von $b^{2}$ haben wir: $a^{2}= 2b^{2}$. Durch das vorige
  Lemma wissen wir, dass $a$ eine gerade Zahl ist. Also hat $a$ die
  Darstellung $a=2c$ für eine ganze Zahl $c$. Somit erhalten wir, $a^{2}=
  (2c)^{2}= 4c^{2}= 2b^{2}$. Jetzt können wir beide Seiten um $2$ kürzen und
  erhalten im Ergebnis, dass auch $b$ eine gerade Zahl ist. Das heißt, beide
  Zahlen $a$ und $b$ sind gerade und könnten daher zu Anfang doch gekürzt
  werden. Das steht im Widerspruch zu unserer Annahme. Daher kann $x\notin\Q$
  sein.
\end{proof}

\subsection{Körperaxiome}

Eine ausführliche Diskussion zu Körpern und deren Eigenschaften wird
in der linearen Algebra durchgeführt. Unten sind nur einige wichtige
Ergebnisse für den Zahlkörper $\R$ aufgelistet. In dem Körper sind zwei
Abbildungen, Addition und Multiplikation, definiert:
\begin{align*}
  +&\colon\R\times\R&\rightarrow\R& (a,b)&\rightarrow a+b\\
  \cdot&\colon\R\times\R&\rightarrow\R& (a,b)&\rightarrow a\cdot b
\end{align*}
Dabei gelten bezüglich der Addition folgende Eigenschaften:
\begin{description}
 \item[Kommutativgesetz] $a+b=b+a$
 \item[Assoziativgesetz] $(a+b)+c=a+(b+c)$
 \item[Existenz und Eindeutigkeit des neutralen Elements] Es existiert genau
  eine Zahl $0$, so dass für alle $a\in\R$ gilt: $a+0=a$.
 \item[Eindeutigkeit der Lösbarkeit der Gleichung] Zu allen $a\in\R$ gibt es
  genau ein $x\in \R$ mit $a+x=0$.
\end{description}
bezüglich der Multiplikation gelten folgende Eigenschaften:
\begin{description}
\item[Kommutativgesetz] $a \cdot b = b \cdot a$
\item[Assoziativgesetz] $(a \cdot b) \cdot c = a \cdot (b\cdot c)$
\item[Existenz und Eindeutigkeit des neutralen Elements] Es gibt eine
  von $0$ verschiedene Zahl $1$, so dass für alle reellen Zahlen $a$
  gilt: $a \cdot 1 = a$
\item[Eindeutigkeit der Lösbarkeit der Gleichung] Zu jeder reellen
  Zahl $a$ gibt es genau eine reelle Zahl $x$ mit der Eigenschaft $a
  \cdot x = 1$ oder $x = a^{-1}$.
\item[Distributivgesetz] $a \cdot (b+c) = a \cdot b + a \cdot c$
\end{description}

\subsection{Anordnungsaxiome}

In $\R$ gibt es eine "`Kleinerbeziehung"' $<$ mit folgenden
Eigenschaften:
\begin{itemize}
\item Entweder gilt $a=b$ oder $a<b$ oder $b<a$.
\item \highl{Transitivgesetz}: $a<b \wedge b<c \Rightarrow a<c$
\item \highl{Monotoniegesetz} der Addition: $a<b \Rightarrow a+c<b+c$
\item Monotoniegesetz der Multiplikation: $a<b \wedge 0<c \Rightarrow
  a \cdot c < b \cdot c$\\
  Gilt $0<a$, so heißt $a$ \highl{positiv}. Gilt $a<0$, so heißt $a$
  \highl{negativ}.
\end{itemize}

\begin{description}
\item[Größerbeziehung] $a>b\perdef b<a$
\item[Kleinergleichbeziehung] $a \leq b \perdef a<b \vee
  a=b$
\item[Größergleichbeziehung] $a \geq b \perdef a>b \vee a=b$
\end{description}

\subsubsection{Intervalle}

Als Intervall wird eine zusammenhängende Teilmenge einer geordneten Menge
bezeichnet. Unten stehen die verschiedenen Arten von Intervallen:
\begin{itemize}
\item $[a,b] \coloneqq \{x \in \R \colon a \leq x \leq b\}$
  \highl[Intervall!abgeschlossenes]{abgeschlossenes Intervall}
\item $[a,a] \coloneqq \{a\}$
\item $\rsofint{a,b} \coloneqq \{x \in \R \colon a \leq x < b\}$
  \highl[Intervall!halboffenes]{halboffenes Intervall} (wird manchmal auch mit
  $[a,b)$ bezeichnet)
\item $\lsofint{a,b} \coloneqq \{x \in \R \colon a < x \leq b\}= (a,b]$
\item $\bsofint{a,b} \coloneqq \{x \in \R \colon a<x<b\}= (a,b)$ \highl[Intervall!offenes]{offenes
  Intervall}
\item $b-a$ Länge des Intervalls\index{Intervall!Länge}
\item $\rsofint{a,\infty} \coloneqq \{x \in \R \colon x \geq a\}$
\item $\lsofint{\infty,a} \coloneqq \{x \in \R \colon x \leq a\}$
\end{itemize}

\subsubsection{Absoluter Betrag}

Der Betrag einer reellen Zahl stellt den Abstand zur Null dar. Für $a \in \R$
gilt:
\begin{gather*}\abs{a} \coloneqq
\begin{cases}
  a &  a \geq 0 \\
  -a & a<0
\end{cases}\end{gather*}

Man nennt $\abs{a}$ den \highl[Betrag!absoluter]{absoluten Betrag} oder einfach
\highl{Betrag} von $a$. Der Betrag ist immer größer oder gleich Null
und entspricht dem Maximum von $a$ und $-a$.

\paragraph{Eigenschaften des Betrages}

\begin{enumerate}
\item $\abs{a} =0 \Leftrightarrow a=0$. Dies ergibt sich sofort aus
  der obigen Definition.
\item \highl{Homogenität}: $\abs{ab} = \abs{a}\abs{b}$. Dazu machen wir klar,
  dass die Beziehung $\abs{a} = \abs{-a}$ gilt. Denn $\abs{a}=
  \max\{a,-a\}=\max\{-a,-(-a)\}=\abs{-a}$.
  \begin{enumerate}[1.\,F{a}ll]
  \item Seien $a$ und $b$ eine reelle Zahlen, die beide größer oder
    gleich Null sind. Dann gilt: $\abs{ab}=ab=\abs{a}\abs{b}$.
  \item Sei nun $a<0$ und $b \geq 0$. Dann gilt, $\abs{ab} =-(ab)
    =(-a)b=\abs{a}\abs{b}$.
  \item Sei $a$ eine beliebige reelle Zahl und $b <0$. Es gilt,
    $\abs{ab}= \abs{-(ab)}=\abs{a(-b)}$. Jetzt ist $-b$ eine positive
    Zahl und wir können die Erkenntnis aus dem ersten Fall von oben
    anwenden: $\abs{a}\abs{-b}= \abs{a}\abs{b}$.
  \end{enumerate}
\item Die \highl{Dreiecksungleichung} besagt:
  \begin{gather*}
    \abs{a+b} \leq \abs{a} + \abs{b}
  \end{gather*}
  Für den Beweis dieser Aussage sind wieder einige Vorarbeiten zu
  leisten. Eine beliebige reelle Zahl $a$ ist immer kleiner oder
  gleich dem Maximum der Zahlen $a$ und $-a$. Die Kleinerrelation gilt
  für den Fall $a<0$. Weiterhin ist auch $-a\leq\max\{a,-a\}$. Für $a,b\in\R$
  gilt dann: $a+b\leq\max\{a,-a\}+\max\{b,-b\}=\abs{a}+\abs{b}$ und
  $-a-b= (-a)+(-b)\leq\max\{a,-a\}+\max\{b\}= \abs{a}+ \abs{b}$.
  Nun folgt aus beiden Aussagen, $\abs{a+b}= \max\{a+b, -a-b=-(a+b)\}
  \leq\max\{\abs{a}+\abs{b}, \abs{a}+\abs{b}\}= \abs{a}+\abs{b}$.
  \begin{enumerate}
  \item[$3'$] $\abs{\abs{a}-\abs{b}} \leq \abs{a-b}, \abs{\abs{a}-\abs{b}} \leq \abs{a+b}$\\
    Vorbereitend halten wir fest: $\abs{a}= \abs{a+0}= \abs{a+b-b}\leq
    \abs{a-b}+ \abs{b}= \abs{a+ (-b)}+ \abs{b}= \abs{a}+ \abs{b}+ \abs{b}$.
    Insgesamt ergibt sich die Aussage, $\abs{a}\leq \abs{a}+ \abs{b}+
    \abs{b}\Rightarrow \abs{a}- \abs{b} \leq\abs{a}+ \abs{b}$. Nun können wir
    die Aussage beweisen: $\abs{\abs{a}- \abs{b}}= \max\{\abs{a}- \abs{b},
    -(\abs{a}- \abs{b})\}\leq \max\{\abs{a}+ \abs{b}, \abs{a}+ \abs{b}\}=
    \abs{a+b}$.
  \end{enumerate}
\end{enumerate}

\subsection{Vollständigkeitsaxiom}
\begin{definition}[nach oben beschränkt]
  Eine Menge $M \subset \R$ heißt genau dann \highl[beschränkt!nach oben]{nach oben
    beschränkt}, wenn es eine reelle Zahl $S \in \R$ gibt, dass  $x \leq S$
  für alle $x \in M$ gilt:
  \begin{gather*}
    M\subset\R\perdef\,\exists S\in\R\,\forall x \in M\colon x\leq S
  \end{gather*}
\end{definition}

\begin{definition}[Obere Schranke]
  In dem Fall heißt $S$ \highl[Schranke!obere]{obere Schranke} von $M$.
\end{definition}

\begin{definition}[Supremum]
  Weiterhin heißt $S \in \R$ genau dann \highl{Supremum}\footnote{Bezeichnung:
  $S=\sup M$} oder \highl[Schranke!kleinste obere]{kleinste obere Schranke}
  von $M$, wenn gilt:
  \begin{enumerate}
    \item $S$ ist eine obere Schranke von $M$.
    \item Für jede obere Schranke $S'$ von $M$ gilt, $S \leq S'$
  \end{enumerate}
\end{definition}

Es existiert genau eine obere Schranke für $M$. Denn sind $S_1, S_2$
kleinste obere Schranken von $M$, dann gilt sowohl $S_1 \leq S_2$ wie
auch $S_2 \leq S_1$. Daraus folgt nun aber $S_1= S_2$.

\begin{theorem}[\highl{Vollständigkeitsaxiom}] Jede
  nichtleere, nach oben beschränkte Menge reeller Zahlen besitzt ein
  Supremum. $\forall M(M \subset \R \text{ n.\,o.\,b. } M \neq \emptyset
  \Rightarrow \sup M \in \R)$
\end{theorem}

\begin{remark}[Maximum]
  Über die Zugehörigkeit von $S=\sup M$ zur Menge $M$ wird nichts
  ausgesagt. Gilt $S \in M$, so schreibt man auch $\max M$ und $S$
  heißt \highl{Maximum} von $M$ oder formal  $S=\max M
  \Leftrightarrow S \in M \wedge \forall x \in M\colon x \leq S$.
\end{remark}

\begin{beispiel}
  Für die Menge $M\coloneqq\{x \in \R\colon x < 1\}$ ist $\sup M=1$. Ändert
  man $M\coloneqq\{x \in \R \colon x \leq 1\}$, so gilt $\sup M=1$ und  $\max
  M=1$.
\end{beispiel}

\begin{remark}
  Die Aussage, "`$S$ ist Supremum von $M \subset \R$"', kann auch durch
  folgende Äquivalenz charakterisiert werden:
  \begin{enumerate}
  \item $\forall x \in M \colon x \leq S$
  \item $\forall \varepsilon > 0 \exists x \in M\colon S - \varepsilon <
    x$
  \end{enumerate}
  \begin{proof}
    \begin{itemize}
    \item[$1\Rightarrow2$]  Sei $S=\sup M \Rightarrow \forall x \in M \colon x
      \leq S$. Wegen $S-\varepsilon < S$ ($S$ ist kleinste obere Schranke)
      existiert ein $x \in M$ mit $S - \varepsilon < x$.
    \item[$2\Leftarrow1$] Sei $S'$ obere Schranke von $M$. Wir müssen zeigen:
      $S \leq S'$. Nehmen wir das Gegenteil $S'<S$ an. Dann gibt es
      ein $\varepsilon > 0$ mit $S'+\varepsilon < S$. Wegen der
      Eigenschaften der Kleinerrelation gilt auch $S'<S-\varepsilon$
      und aus der zweiten Eigenschaft der obigen Bemerkung gibt es ein
      $x\in M$ mit $S- \varepsilon<x$. Insgesamt ergibt sich also
      $S'<S-\varepsilon<x$. Wir haben also gezeigt, dass $x$ echt
      größer als $S'$ ist. Dies steht in Widerspruch zu unserer
      Annahme. Also ist $S'$ ist keine obere Schranke von $M$.
\end{itemize}
  \end{proof}
\end{remark}

\subsubsection{Untere Schranke und Infimum}
Eine Menge $M \subset \R$ heißt genau dann \highl[beschränkt!nach
unten]{nach unten beschränkt}, wenn für alle $x\in M$ ein $s\in\R$
existiert, dass gilt: $x \geq s$. Das $s$ heißt genau dann
\highl{Infimum}\footnote{Schreibweise: $s=\inf M$}, wenn gilt:
\begin{enumerate}
\item Die Zahl $s$ ist untere Schranke.
\item Die Zahl $s$ ist größte untere Schranke.
\end{enumerate}

\begin{theorem}
  Jede nichtleere nach unten beschränkte Menge besitzt ein Infimum.
\end{theorem}

\section{Teilmengen von reellen Zahlen}
\subsection{Natürliche Zahlen und Prinzip der vollständigen Induktion}
Das unten vorgestellte Prinzip der vollständigen Induktion gehört zum
grundlegenden Handwerkszeug der Mathematiker. Die Idee dahinter ist
vergleichbar mit einer unendlich großen Leiter. Wenn man wissen will, ob man
jede Stufe erklimmen kann, wäre der naheliegende Versuch, einfach
loszuklettern. Da die Leiter kein Ende hat, kann man also nie sicher sein, ob
da nicht doch kaputte Stufen enthalten sind. Also wendet man das Prinzip der
vollständigen Induktion an. Zunächst probiert man, ob man die Leiter überhaupt
besteigen kann (Induktionsanfang). Danach zeigt man, dass man von jeder Stufe
auf die nächste steigen kann (Induktionsbeweis). Da beliebige Stufen getestet
werden, kann man sicher sein, jede Stufe zu erklimmen.

\begin{definition}[Induktive Menge]
  Eine Menge $I \subseteq \R$ heißt \highl{induktiv}$\perdef$
  \begin{enumerate}
  \item $1 \in I$
  \item $\forall x (x \in I \Rightarrow x+1 \in I)$
  \end{enumerate}
\end{definition}

\begin{beispiel}
  Sei $J\coloneqq\{I\colon I \subset \R, I \text{ ist induktiv}\}$ die
  Menge aller induktiven Mengen aus $\R$.
\end{beispiel}

\begin{definition}[Natürliche Zahlen]
  Die natürlichen Zahlen $\N$ sind der Durchschnitt über das oben definierte
  Mengensystem $J$:
  \begin{gather*}
    \N \coloneqq \bigcap J \coloneqq \bigcap_{I \in J} I = \{x \in \R \colon
  \forall I \in J x \in J\}
  \end{gather*}
\end{definition}

\begin{theorem}
  $\N$ ist die kleinste induktive Teilmenge von $\R$.
\begin{proof}
Wenn $A \in J \colon \bigcap_{I \in J} I \subset A$, genügt es zu zeigen,
dass $\N$  induktiv ist.
\begin{enumerate}
\item $\forall I \in J \colon 1 \in I \Rightarrow 1 \in \N = \bigcap_{I \in
    J} I$
\item Für $x \in \N = \bigcap_{I \in J} \Rightarrow \forall I \in J \colon x
  \in I \stackrel{I \text{ induktiv}}{\Longrightarrow} x+1 \in I\Rightarrow I
  \in J \colon x+1 \in I \Rightarrow x+1 \in \N = \bigcap_{I \in J} I$.
\end{enumerate}
\end{proof}
\end{theorem}

\begin{definition}
  Die zu $\N$ gehörenden Elemente heißen \highl[Zahlen!natürliche]{natürliche
    Zahlen}.
\end{definition}

\begin{theorem}
  \begin{enumerate}
  \item $\forall n \in \N \colon n \geq 1$
  \item $\forall n,m \in \N \colon n+m \in \N$ und  $n \cdot m \in \N$
  \item $\forall n > 1 \Rightarrow n-1 \in \N$
  \item $\forall n \in \N \forall x \in \R \colon n<x<n+1 \Rightarrow x
    \notin \N$
  \item Jede nichtleere Teilmenge $A \subset \N$ enthält eine kleinste
    natürliche Zahl.
  \end{enumerate}
\begin{proof}
  Die Beweise dazu finden sich in \cite{barner}.
\end{proof}
\end{theorem}

\begin{theorem}[Satz von Archimedes]
 $\N$ ist nicht beschränkt.
\begin{proof}
  Da wir wissen, dass $\R$ nicht beschränkt ist, genügt es zu zeigen,
  dass es für jedes $a\geq 0$ aus $\R$ ein $n$ aus $\N$ mit der
  Eigenschaft $n\geq a$ gibt:
  \begin{gather*}
    \forall a \in \R\text{ mit } a  \geq 0 \exists n \in \N\colon n \geq a
  \end{gather*}
  Zum Beweis nehmen wir das Gegenteil an und müssen nach den Gesetzen
  der Logik auf einen Widerspruch stossen:
  \begin{gather*}
    \exists a \in \R \text{ mit } a \geq 0\forall n \in \N\colon n < a
  \end{gather*}
  Damit folgt, dass $\N$ beschränkt und nach dem Vollständigkeitsaxiom
  muss es ein $b=\sup\N \in \R$ geben. Sei nun $\varepsilon =
  \nicefrac{1}{2}$. Dann existiert ein $n_0 \in \N$ mit
  $b-\varepsilon<n_0$. Damit folgt nun,
  $b<(b-\varepsilon)+1<n_0+1$. Natürlich muss $n_0+1$ in den
  natürlichen Zahlen liegen, da diese ja induktiv sind. \lightning
\end{proof}
\end{theorem}

\subsubsection{Das Prinzip der vollständigen Induktion}

\begin{theorem}
  Sei $A \subseteq \N$ mit folgenden Eigenschaften:
  \begin{enumerate}
  \item $1 \in A$
  \item Für alle $n \in \N$ liegt $n+1$ wieder in $A$. Dann gilt
    $A=\N$.
  \end{enumerate}
\begin{proof}
  Die Menge $A \subseteq \N$ ist induktiv. Da  $\N$ die kleinste induktive Menge
  ist, gilt  $A=\N$.
\end{proof}
\end{theorem}

\begin{remark}
  Das Prinzip der vollständigen Induktion kann o.\,B.\,d.\,A. für Mengen der
  Form $\{n \in \Z\colon n \geq m\}$ mit dem Induktionsanfang $m \in
  \Z$ formuliert werden.
\end{remark}

\begin{definition}[Folge]
  Sei $A$ eine Menge. Eine Abbildung $a\colon\N \rightarrow A$ heißt
  \highl{Folge}\footnote{Schreibweise: $(a_k)_{k \in \N},
    (a_k), (a_1,a_2,a_3, \ldots)$}.
\end{definition}

Eine Folge der Form $(a_n)\colon\N \rightarrow \R$ wird als
\highl[Zahlenfolge!reelle]{reelle Zahlenfolge} bezeichnet. Folgen werden
üblicherweise als Summe oder Produkt formuliert:
\begin{align*}
  \sum_{k=m}^{n} a_k & \coloneqq a_m+a_{m+1}+\dotsb + a_n &
  \prod_{k=m}^{n} a_k & \coloneqq a_m \cdot a_{m+1} \cdot \ldots \cdot a_n
\end{align*}

\subsubsection{Ganzzahlige Potenzen}
Sei $a \in \R$ und  $n \in \N$. Dann können wir die ganzzahligen Potenzen
definieren: $a^1\coloneqq a$ und  $a^{n+1}\coloneqq a^na$. Weiterhin haben wir
für $a\neq0$ die Potenz $a^{0}=1$.

Für die Potenzen gelten folgende Rechenregeln:
\begin{align*}
a^n a^m &=a^{n+m} & (a^n)^m &=a^{nm} & a^n b^n &=(ab)^n
\end{align*}

\subsubsection{Allgemeines Distributivgesetz}
\begin{align*}
  \left( \sum_{k=1}^m a_k\right) \left( \sum_{l=1}^n b_l\right) &=
     (a_{1}+a_{2}+\dotsb+ a_{n})(b_{1}+b_{2}+\dotsb+ b_{n})\\
  &= (a_{1}b_{1}+a_{1}b_{2}+\dotsb+ a_{1}b_{n})+ (a_{2}b_{1}+
     a_{2}b_{2}+\dotsb+ a_{2}b_{n})+\dotsb+(a_{n}b_{1}+ a_{n}b_{2}+\dotsb+
     a_{n}b_{n})\\
  &=\sum_{k=1}^n \sum_{l=1}^n a_k b_l
\end{align*}

\begin{beispiel}
Summenformel für die \highl[Reihe!geometrische]{geometrische Reihe}\\
  Sei $1 \neq q \in \R$ und  $n \in \N$. Dann ist die geometrische Reihe wie
  folgt definiert:
  \begin{gather*}
    \sum_{k=0}^n q^k=\frac{1-q^{n+1}}{1-q}
  \end{gather*}
  
Eine wichtige Formel ist die \highl[Ungleichung!Bernoullische]{Bernoullische
  Ungleichung}. Für alle  $x \geq -1$ und alle $n \in \N$
  \begin{gather*}
    (1+x)^n \geq 1+n+x
  \end{gather*}
  
Weiterhin haben wir die aus der Schule bekannte
  \highl[Formel!Binomische]{Binomische Formel} für alle  $a,b \in \R$ und alle
  $n \in \N$.
  \begin{gather*}
    (a+b)^n= \sum_{k=0}^n \binom{n}{k} a^k b^{n-k}
  \end{gather*}
\end{beispiel}

\subsection{Endliche und unendliche Teilmengen von \texorpdfstring{$\R$}{R}}
\begin{definition}[Endliche, unendliche Menge]
  Sei $A$ eine nichtleere Teilmenge von $\R$. Formal schreiben wir hierfür:
  $\emptyset \neq A \subset \R$. Dann heißt diese Menge:
  \begin{enumerate}
  \item endlich $\perdef \exists n \in \N \exists
    \varphi \colon \{1, \ldots , n\} \rightarrow A$ bijektiv
  \item unendlich $\perdef A$ ist nicht endlich
  \end{enumerate}
\end{definition}

\begin{definition}[abzählbar, überabzählbar]
  \begin{enumerate}
  \item Eine Teilmenge $\emptyset \neq A \subset \R$ heißt abzählbar
    $\perdef \exists \varphi \colon \N \rightarrow A$ surjektiv. Also mit
    $\varphi (\N)=A$.
  \item $\emptyset \neq A \subset \R$ heißt überabzählbar $\perdef A$ ist
    nicht abzählbar.
  \end{enumerate}
\end{definition}

\begin{beispiel}
  Sei $A=\{1,\ldots ,a_n\}$. Wir definieren die Abbildung $\varphi \colon \N
  \rightarrow A, \varphi (k) =
    \begin{cases}
      a_k &  1 \leq k \leq n\\
      a_n &  k=n+1,\ldots
    \end{cases}$.
\end{beispiel}

\begin{theorem}
  Die Vereinigung abzählbar vieler abzählbarer Mengen $A_n$ mit $n \in \N$
  ist wieder abzählbar, d.\,h.
  \begin{gather*}
    \bigcup_{n \in \N} A_n \coloneqq \{x \colon \exists n \in \N \colon x \in A\}
  \end{gather*}
\begin{proof}
  \begin{gather*}
    A_n \coloneqq\{a_{nm}\colon m\in \N\} \qquad \varphi_n(m)\coloneqq a_{nm} \qquad
    \varphi_n\colon\N \rightarrow A_n
  \end{gather*}
\end{proof}
\end{theorem}

\begin{theorem}
  $\R$ ist überabzählbar.
\begin{proof}
  Sei $f\colon\N \rightarrow \R, f(n) = b_n,a_{n1}a_{n2}a_{n3}\ldots$ mit
  $b_n \in \Z$ und  $a_{nk} \in \{0,\ldots ,9\}$.
\begin{gather*}\begin{array}{ccc}
  f(1) & = & b_{1},a_{11}a_{12}a_{13}\ldots\\
  f(2) & = & b_{2},a_{21}a_{22}a_{23}\ldots\\
  f(3) & = & b_{3},a_{31}a_{32}a_{33}\ldots\\
  \vdots & = & \vdots \\
  f(n) & = & b_{n},a_{n1}a_{n2}a_{n3}\ldots
\end{array}\end{gather*}
\begin{gather*}c_n =
\begin{cases}
  1 & \text{falls } a_{nn} \neq 1\\
  2 & \text{falls } a_{nn} = 1
\end{cases}\end{gather*}
Dann ist $c=0,c_{1}c_{2}c_{3}\ldots \in \R$ mit $\forall n \in \N\colon
f(n) \neq c$. Das
$c$ und $f(n)$ unterscheiden sich mindestens in der $n$-ten Stelle
nach dem Komma. Also gilt:
\begin{gather*}
  \forall f\colon \N \rightarrow \R \colon f(\N) \subset \R
\end{gather*}
\end{proof}
\end{theorem}

\chapter{Konvergenz}
\label{cha:konvergenz}
Im Zentrum dieses Kapitels stehen Betrachtungen zur Konvergenz von Folgen. Das
heißt, unter welchen Bedingungen streben Folgen gegen einen Grenzwert und wie
lässt sich der Grenzwert überhaupt sinnvoll definieren.

\section{Metrische Räume}

\begin{definition}[Metrik, Abstand]
  Sei $X$ eine nichtleere Menge oder formal $X\neq\emptyset$. Eine Abbildung
  $d\colon X \times X \rightarrow \rsofint{0,\infty}$ heißt \highl{Metrik} oder
  \highl{Abstand} auf $X$, wenn folgende drei Eigenschaften erfüllt sind:
  \begin{enumerate}[(M1)]
  \item $d(x,y)= 0 \Leftrightarrow x=y$ (\highl{Definitheit})
  \item $\forall x,y \in X \colon d(x,y)=d(y,x)$ (\highl{Symmetrie})
  \item $\forall x,y,z \in X \colon d(x,y) \leq d(x,z)+d(z,y)$
    (\highl{Dreiecksungleichung})
  \end{enumerate}
  Das Paar $(X,d)$  heißt \highl[Raum!metrischer]{metrischer Raum}.
\end{definition}

\begin{beispiel}
\begin{enumerate}
\item Sei $(\R,d)$ der metrische Raum der reellen Zahlen mit der
  Betragsmetrik: $d(x,y) \coloneqq \abs{x-y}$. Die drei Eigenschaften lassen sich
  einfach nachweisen.
  \begin{enumerate}[(M1)]
  \item $d(x,y)=\abs{x-y}=0 \Leftrightarrow x=y$
  \item $d(x,y)=\abs{x-y}=\abs{-(x-y)}=\abs{y-x}=d(y,x)$
  \item $d(x,y)=\abs{x-y}=\abs{(x-z)+(z-y)}\leq
    \abs{x-z}+\abs{z-y}=d(x,z)+d(z,y)$
  \end{enumerate}
\item Die reellen Zahlen in der $n$"~ten Dimension bilden mit dem euklidischen
  Abstand einen metrischen Raum $(\R^n,d)$. Dabei ist $\R^n=\R \times \cdots
  \times \R \coloneqq \{x=(\xi_{1}, \ldots ,\xi_{n})\colon\xi_{i} \in \R\},
  x=(\xi_{1},\xi_{2},\ldots ,\xi_{n})$ und $y=(\eta_{1},\eta_{2},\ldots
  ,\eta_{n}) \in \R^n$. Der \highl[Abstand!euklidischer]{euklidische Abstand}
  ist wie folgt definiert:
  \begin{gather*}d(x,y)=\sqrt{\left( \sum_{i=1}^n \abs{\xi_{i}-\eta_{i}}^2 \right)}\end{gather*}
  Nachweis der Eigenschaften:
  \begin{enumerate}[(M1)]
  \item $d(x,y)=0 \Leftrightarrow \xi_{1}=\eta_{1},\xi_{2}=\eta_{2}, \ldots
    ,\xi_{n}=\eta_{n} \Leftrightarrow x=y$
  \item Man sieht sofort, dass gilt $d(x,y)=d(y,x)$. Denn jeder Summand
    besteht aus der Betragsfunktion. Hier hatten wir bereits gezeigt, dass die
    Eigenschaft (M2) gilt.
  \item Zum Nachweis der Dreiecksungleichung verwenden wir folgende
    Ungleichung:
    \begin{gather*}\sqrt{\sum_{i=1}^n \abs{a_i + b_i}^2} \leq \sqrt{\sum_{i=1}^n
    \abs{a_i}^2} + \sqrt{\sum_{i=1}^n \abs{b_i}^2}\end{gather*}
    Sei $x= (\xi_1 ,\ldots , \xi_n), y= (\eta_1 ,\ldots ,\eta_n)$ und $z=
    (\zeta_1 ,\ldots ,\zeta_n)$. Wir setzen $a_i \coloneqq \xi_i -\zeta_i,
    b_i\coloneqq\zeta_i -\eta_i$. Damit ist $a_i +b_i= \xi_i -\eta_i$ und
    weiter ergibt sich:
    \begin{align*}
      d(x,y) & = \sqrt{\sum_{i=1}^n \abs{\xi_i -\eta_i}^2} =
	 \sqrt{\sum_{i=1}^n \abs{a_i +b_i}^2}\\
      &\leq \sqrt{\sum_{i=1}^n \abs{a_i}^2} + \sqrt{\sum_{i=1}^n \abs{b_i}^2}
	 = \sqrt{\sum_{i=1}^n \abs{\xi_i -\zeta_i}^2} + \sqrt{\sum_{i=1}^n
	 \abs{\zeta_i -\eta_i}^2}\\
      & = d(x,z)+d(y,z)
    \end{align*}

    Die folgenden Ungleichungen sind für die weiteren Beweise und für das
    allgemeine Verständnis der Analysis sehr wichtig. Sie werden uns im
    Verlauf dieser Vorlesung sowie auch in weiteren Vorlesungen immer wieder
    begegnen.
    \begin{description}
    \item[Cauchy-Schwartzsche Ungleichung]\footnote{\textsc{Augustin Louis
      Cauchy} (* 1789-08-21, \textdagger{} 1857-05-23), französischer Mathematiker}
      \footnote{\textsc{Laurent Schwartz} (* 1915-03-05, \textdagger{} 2002-07-04),
	französischer Mathematiker und Träger der \textsc{Fields}"~Medaille}
      Für alle $n\in\N$ und alle $a_1 ,\ldots ,a_n \in \R$ sowie
      $b_{1},\dotsc, ,b_n \in \R$ gilt:
      \begin{gather*}
	\abs[\bigg]{\sum_{i=1}^n a_i b_i} \leq \sqrt{\sum_{i=1}^n a_i^2}
	   \sqrt{\sum_{i=1}^n a_i^2}
      \end{gather*}
      \begin{proof}
	Sei $xy \leq\nicefrac{x^2}{2}+\nicefrac{y^2}{2}$ für alle $x,y \geq
	0$. Dann folgt, $2xy\leq x^{2}+y^{2}\Rightarrow0 \leq = x^2-2xy+y^2=
	(x-y)^{2}$. Seien o.\,B.\,d.\,A. $A\coloneqq\sqrt{\sum_{i=1}^n
	\abs{a_i}^2}>0$ und $B\coloneqq\sqrt{\sum_{i=1}^n \abs{b_i}^2}>0$. Wir
	setzen $x_i \coloneqq \nicefrac{\abs{a_i}}{A}$ und  $y_i
	\coloneqq\frac{\abs{b_i}}{B}$.  Dann ist:
      \begin{align*}
        \frac{1}{AB}\abs[\bigg]{\sum_{i=1}^n a_i b_i} &\leq
	   \frac{1}{AB}\sum_{i=1}^n \abs{a_i}\abs{b_i} = \sum_{i=1}^n
	   \frac{\abs{a_i}}{A} \frac{\abs{b_i}}{B} = \sum_{i=1}^n x_i y_i
	   \leq \sum_{i=1}^n \left(\frac{x_i^2}{2}+\frac{y_i^2}{2}\right)\\
	&= \frac{1}{2}\left(\sum_{i=1}^n x_i^2 + \sum_{i=1}^n y_i^2\right) =
	   \frac{1}{2} \left( \sum_{i=1}^n \frac{\abs{a_i}^2}{A^2} +
	   \sum_{i=1}^n \frac{\abs{b_i}^2}{B^2}\right)\\
        & = \frac{1}{2} \left( \frac{1}{A^2} \sum_{i=1}^n \abs{a_i}^2 +
	   \frac{1}{B^2} \sum_{i=1}^n \abs{b_i}^2\right) = \frac{1}{2} \left(
	   \frac{A^2}{A^2} + \frac{B^2}{B^2} \right)  = 1
      \end{align*}
	Wir haben also $\frac{1}{AB}\abs{\sum_{i=1}^{n} a_{i}
	b_{i}\leq1}\Rightarrow \abs{\sum_{i=1}^{n}a_{i} b_{i}}\leq AB=
	\sqrt{\sum\abs{a_{i}}} \sqrt{\sum\abs{b_{i}}}$.
      \end{proof}
    \item[Minkowskische Ungleichung]\footnote{\textsc{Hermann Minkowski} (* 1864-06-22, \textdagger
      1909-01-12), deutscher Mathematiker und Physiker}
      \begin{gather*}\sqrt{\sum_{i=1}^n \abs{a_i + b_i}^2} \leq \sqrt{\sum_{i=1}^n
      \abs{a_i}^2} + \sqrt{\sum_{i=1}^n \abs{b_i}^2}\end{gather*}
      \begin{proof}
	Sei o.\,B.\,d.\,A. $\sum_{i=1}^n \abs{a_i +b_i}^2 > 0$.
      \begin{align*}
        \sum_{i=1}^n \abs{a_i +b_i}^2 & = \sum_{i=1}^n \abs{a_i +b_i} \abs{a_i
	   +b_i} \leq \sum_{i=1}^n (\abs{a_i}+ \abs{b_i}) \abs{a_i +b_i}\\
        & = \sum_{i=1}^n \abs{a_i} \abs{a_i +b_i} + \sum_{i=1}^n \abs{b_i}
	   \abs{a_i +b_i}\\
        & \leq \sqrt{\sum_{i=1}^n \abs{a_i}^2} \sqrt{\sum_{i=1}^n \abs{a_i
	   +b_i}^2} + \sqrt{\sum_{i=1}^n \abs{b_i}^2} \sqrt{\sum_{i=1}^n
	   \abs{a_i +b_i}^2}\\
	& \Rightarrow \sqrt{\sum_{i=1}^n \abs{a_i +b_i}^2} \leq
	   \sqrt{\sum_{i=1}^n \abs{a_i}^2} + \sqrt{\sum_{i=1}^n \abs{b_i}^2}
      \end{align*}
      \end{proof}
    \end{description}
  \end{enumerate}
\item Maximummetrik: $d(x,y)\coloneqq \max_{1 \leq i \leq n}
  \abs{\xi_{i}-\eta_{i}}$
\item Summenmetrik: $d(x,y) \coloneqq \sum_{i=1}^n \abs{\xi_{i}-\eta_{i}}$
\end{enumerate}
  Der Nachweis der Metrikseigenschaften der letzten beiden bleibt dem Leser
  als Übung überlassen.
\end{beispiel}

\subsubsection{Geometrische Interpretation der Metrik im $(\R^2,d)$}

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}
    \draw[->] (0,0) -- (2,0);
    \draw[->] (0,0) -- (0,2);
    \draw (.2,.6) -- (1.7,1.3);
    \draw[fill,black] (.2,.6) circle (1pt) node[below] {$x$};
    \draw[fill,black] (1.7,1.3) circle (1pt) node[below] {$y$};
  \end{tikzpicture}
  \caption{Interpretation des Abstands}
  \label{fig:inter-abstand}
\end{figure}

Seien $x=(\xi_1 ,\xi_2), y=(\eta_1 ,\eta_2)$ zwei Punkte im $\R^{2}$. Dann ist
$d(x,y)$ die Länge der Strecke zwischen beiden Punkten. Man kann sich die
Punkte als diagonal gegenüberliegende Eckpunkte eines Vierecks vorstellen.
Wenn dieses die Kantenlängen $a$ und $b$ hat, ergibt sich für die Länge nach
dem Satz des Pythagoras: $a^{2}+b^{2}= (d(x,y))^{2}\Rightarrow d(x,y) =
\sqrt{a^{2}+ b^{2}}$.

Die Aussage der Dreiecksungleichung ergibt sich aus der
\autoref{fig:dreiecksungl}. Sie besagt, dass sich der Abstand zwischen den
Punkten $x$ und $y$ verlängert oder bestenfalls gleich bleibt, wenn man die
Strecke von $x$ nach $y$ mit einem "`Umweg"' vermisst: $d(x,y) \leq
d(x,z)+d(z,y)$.

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}
    \coordinate [label=left:{$x$}] (x) at (0+0.5*rand,0+0.5*rand);
    \coordinate [label=right:{$y$}] (y) at (2.5+0.5*rand,0+0.5*rand);
    \coordinate [label=above:{$z$}] (z) at (1.25+0.5*rand,1.3+0.5*rand);
    \draw[black] (x) -- node[anchor=north] {$d(x,y)$} (y) --
    node[anchor=west] {$d (y,z)$} (z) -- node[anchor=east] {$d (x,z)$}(x);
  \end{tikzpicture}
  \caption{Dreiecksungleichung}
  \label{fig:dreiecksungl}
\end{figure}

\begin{definition}[Kugel]
  Sei $(X,d)$ ein metrischer Raum mit $a \in X$ und $r \geq 0$. Dann
  ist
  \begin{gather*}
    B_r(a) \coloneqq \{x \in X \colon d(a,x) \leq r\}
  \end{gather*}
  eine \highl[Kugel!abgeschlossene]{abgeschlossene Kugel} mit Mittelpunkt $a$
  und Radius $r$ sowie 
  \begin{gather*}
    \mathring{B_{r}}(a) \coloneqq \{x \in X \colon d(a,x) < r\}
  \end{gather*}
  eine \highl[Kugel!offene]{offene Kugel} mit Mittelpunkt $a$ und
  Radius $r$.
\end{definition}
Im metrischen Raum der reellen Zahlen $\R^{2}$ versehen mit dem euklidischen
Abstand lässt sich die abgeschlossene Kugel wie folgt interpretieren: Sei
$(a_1,a_2) \in \R^2$. Der Abstand ist definiert als
$d(a,x)=\sqrt{\abs{a_1-x_1}^2+ \abs{a_2-x_2}^2}$. Die abgeschlossene Kugel
besteht dann aus $B_r(a)=\{x \in \R^2 \colon
d(a,x)=\sqrt{\abs{a_1-x_1}^2+ \abs{a_2-x_2}^2} \leq r\}$. Somit ist hier die
Kugel auch im geometrischen Sinne eine Kugel. Sobald andere Metriken
vorliegen, ändert sich auch das Aussehen der Kugel. Diese muss dann keine
Kugel im bekannten Sinne mehr sein.

\section{Folgen}
\begin{definition}
  Sei $X$ eine Menge. Eine Abbildung $a\colon\N \rightarrow X$ heißt
  \highl{Folge}\footnote{Schreibweise: $(a_n)_{n  \in \N}, (a_n),
  (a_n)_{n=1}^\infty,  (a(n))_{n \in \N}, (a_1,a_2,\ldots)$; Verallgemeinert
  kann man auch schreiben: $(a_n)_{n \geq n_0}$ für $n_0 \in \Z$}.
\end{definition}

\begin{beispiel}[reelle Zahlenfolgen]
\begin{align*}
  a_n & = a & \text{\highl[Folge!konstante]{konstante Zahlenfolge}}\\
  a_n & = \nicefrac{1}{n} & \text{\highl{Nullfolge}}\\
  a_n & = (-1)^n & \text{\highl[Folge!alternierende]{alternierende
     Zahlenfolge}}\\
  a_n & = q^n & q \in \R
\end{align*}
\end{beispiel}


\subsection{Konvergente Folgen}
\begin{definition}[Konvergenz]
  Sei $(X,d)$ ein metrischer Raum. Eine Folge $(a_n) \subset X$ heißt
  genau dann \highl[Folge!konvergente]{konvergent\index{Konvergenz}}, wenn es
  ein $a \in X$ gibt, dass für alle $\varepsilon > 0$ ein $n_{\varepsilon} \in
  \N$ mit der Eigenschaft $d(a,a_n)\leq \varepsilon$ für alle $n \geq
  n_{\varepsilon}$ existiert oder formal:
  \begin{gather*}\exists a \in X\ \forall \varepsilon > 0\ \exists n_{\varepsilon}
  \in \N\ \forall n \geq n_{\varepsilon}\colon d(a,a_n)\leq \varepsilon\end{gather*}
\end{definition}
Man sagt $(a_n)$ konvertiert gegen $a$. Das Gegenteil von konvergenten
Folgen sind \highl[Folge!divergente]{divergente Folgen}.

Die Konvergenz lässt sich geometrisch so interpretieren, dass in jeder
$\varepsilon$-Kugel $B_{\varepsilon}(a)$ unendlich viele Glieder der Folge
$(a_n)$ liegen und ausserhalb $B_{\varepsilon}(a)$ höchstens endlich viele
Glieder der Folge $(a_n)$ sind.

\begin{theorem}[Grenzwert einer Folge]
  Sei $(a_n) \subset X$ konvergent gegen $a$. Dann ist $a$ eindeutig
  bestimmt und heißt \highl{Grenzwert}\footnote{Schreibweise:
  $\lim_{n\rightarrow \infty} a_n =a, a_n \rightarrow a, (a_n) \rightarrow
  a$} oder \highl{Limes} von $(a_n)$.
  \begin{proof}
    Es ist zu zeigen, wenn $(a_n)$ gegen $b$ und $c$ konvergiert, so ist
    $b=c$. Sei dazu $\varepsilon > 0$. Dann existieren $n_{\varepsilon}^{(1)},
    n_{\varepsilon}^{(2)} \in \N$ mit $d(b,a_n) \leq
    \nicefrac{\varepsilon}{2}$ für $n \geq n_{\varepsilon}^{(1)}$ und
    $d(c,a_n) \leq \frac{\varepsilon}{2}$ für $n \geq n_{\varepsilon}^{(2)}$.
    Wir setzen $n_{\varepsilon} \coloneqq\max\{n_{\varepsilon}^{(1)},
    n_{\varepsilon}^{(2)}\}$. Dann ist $d(b,a_n) \leq\frac{\varepsilon}{2}$
    und $d(c,a_n) \leq\frac{\varepsilon}{2}$ für $n\geq n_{\varepsilon}$. Nach
    der Dreiecksungleichung haben wir $d(b,c) \leq d(b,a_n)+d(a_n,c)
    \leq\nicefrac{\varepsilon}{2} +\nicefrac{\varepsilon}{2}=\varepsilon$ für
    $n\geq n_{\varepsilon}$. Also gilt:
    \begin{gather*}\underbrace{\forall \varepsilon > 0 \colon d(b,c) \leq \varepsilon}_{p}
    \Rightarrow \underbrace{d(b,c)=0}_{q} \Rightarrow a=c\end{gather*}
    wegen der Beziehung $\overline{p \Rightarrow q} \equiv p \wedge
    \overline{q}$ gilt:
    \begin{gather*}\forall \varepsilon >0\colon d(b,c) \leq \varepsilon \wedge d(b,c)>0\end{gather*}
    Wir setzen $\varepsilon \coloneqq \frac{1}{2} d(b,c) >0$. Dann ist
    \begin{gather*}d(b,c) \leq \frac{1}{2} d(b,c) \Rightarrow 1 \leq \frac{1}{2}
    \text{\lightning}\end{gather*}
\end{proof}
\end{theorem}


\subsection{Teilfolgen}

\begin{definition}[monoton wachsend/""fallend]
  Sei $X$ eine nichtleere Menge und $(a_{n})\subset X$ eine Folge. Diese heißt
  \begin{itemize}
   \item monoton wachsend, wenn gilt, $a_{n}\leq a_{n+1}$,
   \item streng monoton wachsend, wenn gilt, $a_{n}<a_{n+1}$,
   \item monoton fallend, wenn gilt, $a_{n}\geq a_{n+1}$,
   \item streng monoton fallend, wenn gilt, $a_{n}>a_{n+1}$
  \end{itemize}
\end{definition}

\begin{remark}
  Manchmal wird anstatt der strengen Varianten auch gesagt, monoton nicht
  steigend bzw. monoton nicht fallend.
\end{remark}

\begin{definition}[Teilfolge]
  Sei $X$ eine nichtleere Menge, $(a_n) \subset X$ eine Folge und $\varphi
  \colon \N \rightarrow \N$ streng monoton wachsend. Dann heißt die Folge
  $(a_{\varphi(k)})_{k \in \N}$ \highl{Teilfolge}\footnote{Schreibweise: $n_k
  \coloneqq \varphi(k), n_1 < n_2 < n_3, (a_{n_k})\subset (a_n)$} von $(a_n)$.
\end{definition}

\begin{theorem}
  Sei $(X,d)$ ein metrischer Raum. Eine Folge $(a_n)$ konvergiert genau dann
  gegen $a \in X$, wenn jede Teilfolge von $(a_n)$ gegen $a$ konvergiert.
  \begin{proof}
\begin{itemize}
\item["`$\Rightarrow$"'] Es ist zu zeigen, dass aus $a_n \rightarrow a$,
  folgt, dass $a_{n_k} \rightarrow a$. 
  Sei $\varepsilon > 0$. Dann existiert $n_{\varepsilon} \in \N$ mit
  $d(a,a_n)<\varepsilon$ für $n \geq n_{\varepsilon}$. Wähle ein
  $k_{\varepsilon} \in \N$ mit $n_{k_{\varepsilon}}\geq n_{\varepsilon}$.
  Für $k \geq k_{\varepsilon} \Rightarrow n_k \geq n_{k_{\varepsilon}}$ und
  aus $d(a,a_{n_k})<\varepsilon \Rightarrow a_{n_k} \rightarrow a$.
\item["`$\Leftarrow$"'] Es ist zu zeigen, dass für alle $(a_{n_k}) \subset
  (a_n)$ mit $a_{n_k} \rightarrow a$ ist. Insbesondere gilt dies für $(a_n)$
  selbst: $a_n \rightarrow a$.
\end{itemize}
\end{proof}
\end{theorem}

\begin{definition}[Beschränkte Folge]
  Sei $(X,d)$ ein metrischer Raum. Die Folge $(a_n) \subset X$ heißt
  genau dann \highl[Folge!beschränkte]{beschränkt}, wenn gilt:
  \begin{gather*}
    \exists a \in X\ \exists M \geq 0\ \forall n \in \R \colon d(a,a_n) \leq M
  \end{gather*}
\end{definition}

\begin{theorem}
  \label{satz:beschraenkt}
  Jede konvergente Folge in $(X,d)$ ist beschränkt.
  \begin{proof}
    Sei $a \in X$ der Grenzwert der Folge $(a_n)$. Für $\varepsilon = 1$ gibt
    es ein $n_{\varepsilon} \in \N$, so dass für alle  $n \geq \varepsilon$
    gilt: $d(a_n,a) \leq 1$. Für $M \coloneqq \max\{d(a,a_1),\ldots,
    d(a,a_{n_{\varepsilon}}), 1\}$ und für alle $n\in\N$ gilt $d(a,a_n) \leq
    M$.
\end{proof}
\end{theorem}

\subsection{Sätze über reelle Zahlenfolgen}

Im folgenden sei $X = \R$ und $d(x,y) = \abs{x-y}$  für $x,y \in\R$. Aus dem
vorigen Abschnitt folgt:
\begin{enumerate}
\item $a \in \R$ ist Grenzwert von $(a_n) \subset \R \Leftrightarrow
  \forall \varepsilon > 0\ \exists n_{\varepsilon} \in \N\ \forall
  n \geq n_{\varepsilon}\colon \abs{a_n-a} \leq \varepsilon$
\item Eine konvergente Folge $(a_n) \subset \R$ ist beschränkt,
  d.\,h. es existiert ein $M \geq 0$ mit $\abs{a_n}\leq M$ für alle $n\in\N$.
  Denn sei $a = \lim a_n$. Dann existiert $M_1 \geq 0$ mit $\abs{a-a_n} \leq
  M_1$ für alle $n\in\N$ und es folgt, $\abs{a_n}= \abs{(a_n-a)+a}\leq
  \abs{a_n-a}+ \abs{a}\leq M_1+\abs{a}$. Für $M\coloneqq M_1+ \abs{a}$ gilt
  $\abs{a_n}\leq M$ für alle $n\in\N$.
\end{enumerate}

\begin{remark}
  \begin{enumerate}
  \item Eine Folge $(a_n) \subset \R$ heißt \highl{Nullfolge} $\Leftrightarrow
    \lim a_n =0 \Leftrightarrow \lim \abs{a_n}=0$.
  \item $\lim a_n =a \Leftrightarrow \lim (a_n-a)=0$, d.\,h. $a_n -a$
    ist Nullfolge.
  \end{enumerate}
\end{remark}

\begin{beispiel}
  Die Folge $a_n=\nicefrac{1}{n}$ ist eine Nullfolge. Denn sei
  $\varepsilon > 0$ und wähle $n_{\varepsilon} \in \R$, so dass
  $\nicefrac{1}{n_{\varepsilon}} \leq \varepsilon$. Dann $n \geq
  n_{\varepsilon} \Rightarrow \abs{\nicefrac{1}{n}-0}=\nicefrac{1}{n}\leq
  \nicefrac{1}{n_{\varepsilon}} \leq \varepsilon$.
\end{beispiel}

\subsubsection{Rechenregeln für konvergente Folgen}
\begin{theorem}
  \label{satz:rechenregel}
  Seien $(a_n),(b_n) \subset \R$ konvergent, $a\coloneqq\lim a_n$ und
  $b\coloneqq\lim b_n$. Dann:
  \begin{enumerate}
  \item $\lim (a_n +b_n)=\lim a_n+\lim b_n=a+b$
  \item $\lim (a_nb_n)=\lim a_n \lim b_n =ab$
  \item $\lim \left(\frac{a_n}{b_n}\right)=\frac{\lim a_n}{\lim
      b_n}=\frac{a}{b} \text{ falls } b \neq 0 \quad b_n \neq 0$
  \item $\lim \abs{a_n}=\abs{\lim a_n} =\abs{a}$
  \item \highl{Vergleichssatz}:
    $\exists m \in \N \forall n \geq m\colon a_n
    \leq b_n \Rightarrow \lim a_n \leq \lim b_n \Rightarrow a \leq b$
  \item $\exists m \in \N  \forall n \geq m\colon a_n \leq c_n \leq b_n
    \wedge \lim a_n =\lim b_n \Rightarrow (c_n) \text{ konvergent und
    } \lim c_n = \lim a_n$
  \item $\lim \frac{a_1+\cdots +a_n}{n}=\lim a_n$
  \item $a_n>0 \Rightarrow \lim \sqrt[n]{a_1\ldots a_n}=\lim a_n$
  \item $a_n>0, \lim \frac{a_{n+1}}{a_n} \text{ existiert }
    \Rightarrow \sqrt[n]{a_n}=\frac{\lim a_{n+1}}{\lim a_n}$
  \end{enumerate}
\end{theorem}
\begin{proof}
\begin{enumerate}
\item Übung
\item zu zeigen: $\forall \varepsilon >0 \exists n_{\varepsilon}
  \in \N\forall n \geq n_{\varepsilon}\colon a_nb_n-ab=a_n(b_n-b)+(a_n-a)b$\\
  Nach \autoref{satz:beschraenkt} folgt, dass $(a_n)$ beschränkt ist,
  d.\,h. $\exists M \geq 0 \forall n \in \N\colon \abs{a_n} \leq M$. Sei
  $\varepsilon > 0$. Dann existiert $n_0,n_1 \in \N$, so dass $\abs{a-a_n}
  \leq \frac{\varepsilon}{2(\abs{b}+1)}$ für $n \geq n_1$ und $\abs{b-b_n}
  \leq \frac{\varepsilon}{2M}$ für $n \geq n_0$. Für $n \geq
  n_{\varepsilon} = \max \{n_0,n_1\}$ gilt
  \begin{align*}
    \left.
      \begin{array}{rcl}
        \abs{a_n-a} & \leq & \frac{\varepsilon}{2(\abs{b}+1)}\\
        \abs{b_n-b} & \leq & \frac{\varepsilon}{2M}
      \end{array}
    \right\}&
    \forall n \geq n_{\varepsilon}\\
    \abs{a_nb_n-ab} & \leq \abs{a_n}\abs{b_n-b}+\abs{a_n-a}\abs{b} &\leq M
    \frac{\varepsilon}{2M}+\frac{\varepsilon}{2(\abs{b}+1)}\abs{b}\\
    & \leq \frac{\varepsilon}{2}+\frac{\varepsilon}{2}=\varepsilon
  \end{align*}
\item Seien $b$ und $ b_n \neq 0$. Man zeigt zunächst: $\lim
  \nicefrac{1}{b_n}=\nicefrac{1}{\lim b}=\nicefrac{1}{b}$. Aus der
  Tatsache, dass $\exists n_0 \forall n \geq n_0 \colon \abs{b_n-b}\leq
  \nicefrac{\abs{b}}{2}$ für $b\neq 0$ folgt nach der Dreiecksungleichung,
  dass $\abs{b}-\abs{b_n} \leq \abs{b_n-b} \leq \nicefrac{\abs{b}}{2}$ für $n \geq
  n_0$. Daraus kann man nun für alle $n\geq n_0$ schließen, dass
  $\nicefrac{\abs{b}}{2} \leq \abs{b_n}$\\
  Sei $\varepsilon > 0$. Dann $\exists n_1 \in \N \colon \abs{b_n-b} \leq
  \frac{\varepsilon \abs{b}^2}{2}$ und für $n \geq \max \{n_0,n_1\}$
  gilt:
  \begin{gather*}
    \abs{\frac{1}{b_n}-\frac{1}{b}}
    =\frac{\abs{b_n-b}}{\abs{b_n} \abs{b}}\leq \frac{\varepsilon
    \nicefrac{\abs{b}^2}{2}}{\nicefrac{\abs{b}}{2}\abs{b}}=\varepsilon
  \end{gather*}
  Damit ist nach Regel~2 $\lim \frac{a_n}{b_n}=\frac{\lim a_n}{\lim b_n}$.
\item Sei $\varepsilon > 0$. Dann $\exists n_{\varepsilon} \in
  \N\colon\abs{a_n-a}< \varepsilon \forall n \geq n_{\varepsilon}$. Nach der
  Dreiecksungleichung folgt für alle $n\geq n_\varepsilon\colon
  \abs{\abs{a_n}-\abs{a}} \leq \abs{a_n-a} < \varepsilon \Rightarrow
  \lim \abs{a_n} =\abs{a}$.
\item Annahme: $\lim a_n > \lim b_n$. Dann ist $\varepsilon =
  \nicefrac{a-b}{2}$ und es existieren $n_0,n_1 \in \N$, so dass
  $\abs{a_n-a} < \varepsilon$ für $n \geq n_0$ und $\abs{b_n-b} < \varepsilon$
  für $n \geq n_1$. Wir definieren $n_{\varepsilon} \coloneqq \max
  \{n_0,n_1\}\colon\abs{a_n-a}<\varepsilon, \abs{b_n-b}<\varepsilon$. Insbesondere
  da $\varepsilon = \nicefrac{a-b}{2}$ ist, folgt für alle $n\geq n_0\colon
  a-\varepsilon = b + \nicefrac{a-b}{2}= \nicefrac{a+b}{2}<a_n$ und
  $b_n<b+\varepsilon=\nicefrac{a+b}{2}$
  $\Rightarrow b_n < a_n \quad \forall n \geq n_{\varepsilon}$\lightning\\
  \qed
\item Sei $\varepsilon > 0$. Dann $\exists n_0, n_1 \in \N$,
  $\abs{a_n-a}<\varepsilon$ und $\abs{b_n-a}<\varepsilon$. Sei
  $n_{\varepsilon}\coloneqq \max \{n_0,n_1\}$.
  \begin{align*}
    a-\varepsilon &\leq a_n \leq c_n \leq b_n \leq a+\varepsilon\\
    &\Rightarrow \abs{c_n-a} \leq \varepsilon & \forall n \geq n_{\varepsilon}\\
    &\Rightarrow \lim c_n = a
  \end{align*}
\end{enumerate}
\end{proof}

\begin{beispiel}
  Sei $q \in \R$ und $a_n \coloneqq q^n$.
  \begin{gather*}\lim q^n =
  \begin{cases}
    0 \qquad \abs{q} < 1\\
    1 \qquad q = 1\\
    divergent \qquad & \abs{q}>1 \vee q=-1
  \end{cases}\end{gather*}
\begin{proof}
  \begin{enumerate}[1.~F{a}ll]
  \item $q=0 \Rightarrow q^n=0 \Rightarrow \lim q^n=0$
  \item $0<\abs{q}<1$\\
    Man setzt:
    \begin{align*}
      h &\coloneqq \nicefrac{1}{\abs{q}}-1>0\Rightarrow \abs{q} =
      \frac{1}{1+h}\\
      0 &<\abs{q}^n = \frac{1}{(1+h)^n} \leq \frac{1}{1+nh} \leq
      \frac{1}{nh}
    \end{align*}
    Nach \autoref{satz:rechenregel} Punkt~6 folgt damit, $\lim \abs{q}^n=0
    \Rightarrow \lim q^n=0$.
  \item $q=1 \Rightarrow q^n =1 \Rightarrow \lim q^n=1$
  \item $q=-1$\\
    $a_n=q^n=(-1)^n$ ist divergent. Angenommen, es existiert ein $a
    \in \R \colon a_n \rightarrow a$. Für $\varepsilon=\nicefrac{1}{2}
    \Rightarrow \exists n_0 \in \N \forall n \geq n_0 \colon
    \abs{a_n-a}<\nicefrac{1}{2}$. Somit gilt:
    \begin{align*}
      a_{n+1}-a_n& = (-1)^{n+1}-(-1)^n = (-1)^n(-1)-(-1)^n =
      (-1)^n(-2)\\ \
      \abs{-2}=2 &= \abs{a_{n+1}-a_n} \leq \abs{a_{n+1}-a} + \abs{a-a_n} \leq
      \nicefrac{1}{2} +\nicefrac{1}{2}=1
    \end{align*}
    für $n \geq n_0$ \lightning
  \item $\abs{q}>1$\\
    Annahme: $q^n$ ist konvergent. Dann ist nach
    \autoref{satz:beschraenkt} $q^n$ beschränkt, d.\,h. $\exists M >
    0 \forall n \in \N \colon \abs{q^n} \leq M \Rightarrow M \geq
    \abs{q^n} = \abs{q}^n
    =\underbrace{(1+\abs{q}-1)^n}_{>0} \geq 1+n(\abs{q}-1) \geq n(\abs{q}-1)$\\
    $\Rightarrow n \leq \frac{M}{\abs{q}-1} \Rightarrow \N$ ist beschränkt
    \lightning
\end{enumerate}
\end{proof}
\end{beispiel}

\begin{remark}
  \emph{Bestimmte
    Divergenz\index{Divergenz!bestimmte}}\footnote{Schreibweise: $\lim
    a_n = +\infty \qquad a_n \rightarrow \infty$\\} (=uneigentliche
  Konvergenz\index{Konvergenz!uneigentliche}) gegen $+\infty$ bzw.
  $-\infty$: Eine Folge $(a_n) \subset \R$ heißt \emph{bestimmt
    divergent} gegen $+\infty\ (-\infty) \perdef \forall M
  \in \R  \exists n_M \in \N  \forall n \geq n_M \colon a_n \geq M (a_n
  \leq M)$
\end{remark}

\begin{beispiel}
\begin{align*}
  a_n& =n & \lim a_n &=\infty\\
  a_n &=-n  & \lim a_n &=-\infty\\
  a_n &=(-1)^n & \text{nicht bestimmt divergent}
\end{align*}
\end{beispiel}

\begin{remark}
  $\infty$ ist keine relle Zahl. Denn wäre $\infty$ eine reelle Zahl,
  so würde für die Folgen $a_n=a$ und $b_n=1$ gelten, dass $\lim
  (a_n+b_n) = \lim a_n + \lim b_n\Rightarrow\infty=\lim(n+1)=\lim n +
  \lim 1 = \infty +1 \Rightarrow 0=1$ \lightning.
\end{remark}

\subsubsection{Monotone Folgen}
\begin{definition}[monotone Folgen] Eine Zahlenfolge $(a_n) \subset \R$
  heißt \highl{monoton wachsend (fallend)}\index{monoton}
  \index{Folge!monotone} $\perdef \forall n,m \in \N\colon n<m \Rightarrow a_n
  \leq a_m (a_n \geq a_m)$.
\end{definition}

\begin{theorem}
  \label{satz:monotoneFolge}
  \begin{enumerate}
  \item Für eine monoton wachsende und nach oben beschränkte Folge
    $(a_n) \subset \R$ gilt: $\lim a_n = \sup \{a_n\}$
  \item Für eine monoton fallende und nach unten beschränkte Folge $(a_n)
    \subset \R$ gilt: $\lim a_n = \inf \{a_n\}$
  \end{enumerate}
\end{theorem}
\begin{proof}
\begin{enumerate}
\item Sei $a \coloneqq \sup \{a_n\} \in \R$. Dies existiert nach dem
  Vollständigkeitsaxiom. Sei $\varepsilon > 0$. Dann existiert ein
  $n_{\varepsilon} \in \N \colon a-\varepsilon < a_{n_{\varepsilon}}$. Für
  $n \geq n_{\varepsilon} \colon a-\varepsilon \leq a_{n_{\varepsilon}}
  \leq a_n \leq a+\varepsilon\Rightarrow \abs{a_n-a} \leq \varepsilon$ für
  $n \geq n_{\varepsilon} \Rightarrow \lim a_n= \sup \{a_n\}$
\item Der Beweis erfolgt analog zum ersten Fall.
\end{enumerate}
\end{proof}
%%Hier weiter das Skript anpassen.

\begin{beispiel}
\begin{align*}
  \lim_{n \rightarrow \infty} \sum_{k=0}^n \frac{1}{k!} &= e & a_n=
  1+1+\frac{1}{2!}+\frac{1}{3!}+\cdots + \frac{1}{n!}\\
  \lim_{n \rightarrow \infty} \left(1+\frac{1}{n}\right)^n &= \lim_{n \rightarrow
    \infty} \sum_{k=0}^n \frac{1}{k!}=e\approx2,7182818
\end{align*}
\end{beispiel}
\begin{proof}
\begin{enumerate}
  \item Zeigen $a_n$ ist beschränkt und monoton wachsend\\
    Monotonie: klar, $a_n \geq a_{n+1}$\\
    Beschränkt: Es gilt, $a_n \leq 3$
    \begin{align*}
      a_n& = 1+1+\frac{1}{2!}+\frac{1}{3!}+\cdots + \frac{1}{n!}\\
      & \leq 1+ 1+ \left(\frac{1}{2}\right)^1
      +\left(\frac{1}{2}\right)^2 +\cdots + \left( \frac{1}{2} \right)^{n-1}\\
      & = 1+ \frac{1-\left(\frac{1}{2}\right)^n}{1-\frac{1}{2}} \leq
      1+\frac{1}{\frac{1}{2}} = 3\\
      &\Rightarrow \lim a_n = \lim_{n \rightarrow \infty}
      \left(\sum_{k=0}^n \frac{1}{k!}\right) \text{ existiert}
  \end{align*}
  \item \begin{gather*}\left(1+\frac{1}{n}\right)^n = \sum_{k=0}^n \binom{n}{k}\frac{1}{n}^k
    1^{n-k} = \sum_{k=0}^n \binom{n}{k} \frac{1}{n^k}\end{gather*}
    \begin{align*}
    \binom{n}{k} \frac{1}{n^k} & = & \frac{n(n-1)\ldots(n-k+1)}{k!}\frac{1}{n^k}\\
    & = & \frac{n}{n} \frac{n-1}{n} \cdots \frac{n-k+1}{n} \frac{1}{k!}\\
    & = & \left(1-\frac{1}{n}\right)\left(1-\frac{2}{n}\right) \cdots \left(1-
    \frac{k-1}{n}\right) \frac{1}{k!}
    \end{align*}
    $\Rightarrow \lim_n \binom{n}{k} \frac{1}{n^k}=\frac{1}{k!}$ Ferner:
    $\binom{n}{k} \frac{1}{n^k} < \binom{n+1}{k} \frac{1}{(n+1)^k}$\\
    Also gilt: \begin{gather*}\left(1+\frac{1}{n}\right)^n<\left(1+\frac{1}{n+1}\right)^{n+1}
    \leq \sum_{k=0}^{n+1} \frac{1}{k!} \leq 3\end{gather*}
    $\Rightarrow \lim \left(1+\frac{1}{n}\right)^n$ existiert. Fixieren $l<n$.
    Dann gilt:\\
    $\lim_{n \rightarrow \infty} \sum_{k=0}^l \binom{n}{k} \frac{1}{n^k}
    = \sum_{k=0}^l \lim_{n \rightarrow \infty} \binom{n}{k} \frac{1}{n^k} = 
    \sum_{k=0}^l \frac{1}{k!}$\\
    wegen $\sum_{k=0}^l \binom{n}{k} \frac{1}{n^k}
    \leq \sum_{k=0}^n \binom{n}{k} \frac{1}{n^k}=\left( 1+\frac{1}{n}\right)^n
    \leq \sum_{k=0}^n \frac{1}{k!}$\\
    $\overset{n \rightarrow \infty}{\Rightarrow}\sum_{k=0}^l \frac{1}{k!} \leq
    \lim_n \left(1+\frac{1}{n}\right)^n \leq \lim_n \sum_{k=0}^n \frac{1}{k!}$\\
    $\overset{l \rightarrow \infty}{\Rightarrow} \lim_{l \rightarrow \infty}
    \sum_{k=0}^l \frac{1}{k!} = \lim_{n \rightarrow \infty} \left(1+\frac{1}{n}
    \right)^n$
\end{enumerate}
\end{proof}

\begin{theorem}[Intervallschachtelung]
  \label{satz:Ischachtelung}
  Seien $I_n=[a_n,b_n]$ mit $n \in \N$ abgeschlossene Intervalle, so
  dass $I_{n+1} \subset I_n$ und $\lim_{n \rightarrow \infty}
  (b_n-a_n)=0$. Dann gilt: Es existiert genau ein Punkt $a \in \R$:
  \begin{gather*}\bigcap_{n=1}^{\infty} I_n = \{a\}\end{gather*}
\end{theorem}
\begin{proof}
  Für alle $n,m \in \N$ mit der Eigenschaft $a_n \leq b_m$ ist $a_n $
  monoton wachsend und $b_m$ monoton fallend. Dann gilt wegen $\lim
  (b_n-a_n)=0$, dass der Limes von $a_n$ kleiner bzw. gleich als der
  Limes von $b_m$ ist. Weiter folgt $\lim b_n = \lim
  (b_n-a_n+a_n)=\lim(b_n-a_n)+\lim a_n=\lim a_n=:a$ und
  \begin{gather*}\Rightarrow \forall n \in \N \colon a_n \leq a \leq b_n \Rightarrow a \in
  \bigcap I_n\end{gather*}
  Zu zeigen ist noch, dass $a$ einziger Punkt in
  $\bigcap_{n=1}^\infty$ ist. Sei $a,b \in \bigcap I_n$
\begin{align*}
  \Rightarrow a_n \leq a,b \leq b_n & \Rightarrow 0 \leq \abs{a-b} \leq
  \underbrace{b_n-a_n}_{0} & \Rightarrow a = b
\end{align*}
\end{proof}

\subsection{Häufungspunkte von Folgen in metrischen Räumen}

Der Begriff \emph{Häufungspunkt\index{Häufungspunkt}} einer Folge kann
als eine Verallgemeinerung des Begriffs Grenzwert verstanden werden.

\begin{definition}[Häufungspunkt einer Folge]
  Sei $(X,d)$ ein metrischer Raum und $(a_n) \subset X$ eine
  Folge. Ein Punkt $a \in X$ heißt
  \highl{Häufungspunkt} von $(a_n)
  \perdef \forall \varepsilon > 0 \forall m \in \N
  \exists n>m\colon d(a,a_n) \leq \varepsilon$
\end{definition}

Geometrisch lässt sich das so interpretieren, dass in jeder $\varepsilon$-Kugel
$B_\varepsilon (a)$ unendlich viele Glieder der Folge
$(a_n)$ liegen.  Ausserhalb können ebenfalls unendlich viele liegen.

\begin{theorem}
\label{satz:hp}
\begin{enumerate}
\item $a\in X$ ist genau dann Häufungspunkt von $(a_n) \subset X$,
  wenn eine Teilfolge $(a_{n_k})\subset (a_n)$ mit der Eigenschaft
  $\lim a_{n_k}=a$ existiert.
\item Jede konvergente Folge besitzt genau einen Häufungspunkt und
  zwar den Grenzwert.
\end{enumerate}
  \begin{proof}
\begin{enumerate}
  \item
    \begin{itemize}
      \item[$\Rightarrow$] $\varepsilon_k\coloneqq\frac{1}{k}, k \in \N$\\
        $\left.
	\begin{array}{lll}
	  \varepsilon_1=1\ m=1 \exists n_1>1\colon d(a,a_{n_1}) & \leq & 1\\
	  \varepsilon_2=\frac{1}{2}\ m = n_1 \exists n_2 >n_1\colon
	  d(a,a_{n_2}) & \leq & \frac{1}{2}\\
	  \quad \vdots \qquad \vdots \qquad \vdots & & \vdots\\
	  \varepsilon_k=\frac{1}{k}\ m=n_{k-1} \exists n_k > n_{k-1}\colon
	  d(a,a_{n-k}) & \leq & \frac{1}{k}
	\end{array}
	\right\} \Rightarrow$\\
	$\Rightarrow (a_{n_k})\subset (a_n)\colon\lim a_{n_k}=a$
      \item[$\Leftarrow$] Sei $\varepsilon > 0$ und $k \in \N \Rightarrow \exists n_k>k\colon d(a,a_{n_k})\leq \varepsilon$
    \end{itemize}
  \item Sei $\lim a_n =a \overset{(1)}{\Rightarrow} a$ ist Häufungspunkt von $(a_n)$\\
    Eindeutigkeit des Häufungspunktes: Sei $b$ ebenfalls Häufungspunkt von $(a_n)$
    \begin{gather*}\overset{(1)}{\Rightarrow} \exists \text{ Teilfolge } (a_{n_k})\subset (a_n)\colon\lim_{k\rightarrow \infty}a_{n_k}=b\end{gather*}
    Da jede Teilfolge einer konvergenten Folge den gleichen Grenzwert hat, gilt $b=a$. \qed
\end{enumerate}    
  \end{proof}
\end{theorem}

\begin{beispiel}
  $X=\R \quad d=\abs{\cdot} \quad a_n=(-1)^n$ besitzt die Häufungspunkte -1
  und +1. Denn $a_{2n}=(-1)^{2n}=1\rightarrow 1$ und
  $a_{2n+1}=(-1)^{2n+1}=-1\rightarrow -1$. Aber $(a_n)$ ist 
  nicht konvergent. 
\end{beispiel}

\subsection[Häufungspunkte von reellen Zahlenfolgen und der Satz von Bolzano/Weierstrass]{Häufungspunkte von reellen Zahlenfolgen und der Satz von Bolzano/Weierstrass}
\begin{lemma}
\label{lemma:bw}
Jede reelle Zahlenfolge $(a_n) \subset \R$ enthält eine monotone Teilfolge.
\begin{proof}
  Sei $(a_n) \subset \R$. Setzen $M\coloneqq\{k \in \N \colon \forall n \in \N
  \colon a_{k+n}\leq a_k\}$
  \begin{enumerate}[1.\,F{a}ll]
  \item $M$ ist unendlich. $M=\{n_k\colon n_1<n_2<n_3<\ldots\}$
    \begin{align*}
      n_1 \in M & \Rightarrow \forall n \in M\colon a_{n_1}\geq a_{n_1+n} &
      \Rightarrow a_{n_1} \geq a_{n_2}\\
      n_2 \in M & \Rightarrow \forall n \in M\colon a_{n_2}\geq a_{n_2+n} &
      \Rightarrow a_{n_2} \geq a_{n_3}\\
      \vdots &\qquad \vdots & \Rightarrow \vdots\\
      a_{n_1} &\geq a_{n_2}\geq a_{n_3} &\geq \ldots
    \end{align*}
  \item $M$ ist endlich und $M \neq \emptyset$. Dann $\sup M = \max
    M$. Für $n_1>k \Rightarrow n_1 \notin M$, d.\,h.
    $\exists m_1 \in \N \colon a_{n_1+m_1}>a_{n_1}$. Setzen $n_2 \coloneqq n_1
    +m_1$. Dann $n_2>n_1 \wedge a_{n_2} > a_{n_1}$\\
    $n_2>n_1>k \Rightarrow n_2 \notin M$, d.\,h. $\exists m_2 \in \N \colon
    a_{n_2+m_2}$. Setzen $n_3\coloneqq n_2+m_2 \Rightarrow
    n_3>n_2 \wedge a_{n_3}>a_{n_2}$\\
    $a_{n_1}<a_{n_2}<a_{n_3}<\ldots$
  \item $M=\emptyset$, d.\,h. $\forall k \in \N \exists n \in \N \colon
    a_{k+n}>a_k$ siehe 2.\,Fall
\end{enumerate}
\end{proof}
\end{lemma}

\begin{theorem}[Satz von Bolzano/Weierstrass\index{Bolzano/Weierstrass!Satz von}]
\label{satz:bw}
Jede beschränkte Folge $(a_n)\subset \R$ besitzt einen
Häufungspunkt\index{Häufungspunkt}.
\begin{proof}
  Aus dem \autoref{lemma:bw} folgt: Es existiert eine Teilfolge
  $(a_{n_k})\subset (a_n)$. $(a_{n_k})$ ist monoton und
  beschränkt. Daraus folgt nach \autoref{satz:monotoneFolge}: $\lim
  a_{n_k}=a \in \R$ und \autoref{satz:hp} legt den Schluss nahe, dass
  $a$ Häufungspunkt ist.
\end{proof}
\end{theorem}

\begin{Folg}
  Eine Zahlenfolge in $\R$ ist genau dann konvergent, wenn sie beschränkt ist
  und höchstens einen Häufungspunkt besitzt.
\end{Folg}

\paragraph{Limes superior und Limes inferior}
\begin{definition}[Limes superior/""inferior]
Sei $(a_n) \subset \R$. Dann heißt $\lim_{n\rightarrow \infty} \sup
  a_n\coloneqq\lim(\sup\{a_k\colon k\geq n\})$ \highl{Limes superior} und
  $\liminf a_n \coloneqq \lim (\inf\{a_k\colon k\geq n\})$ \highl{Limes
  inferior}.
\end{definition}

Wir schreiben $\overline{\lim}=\limsup$ und $\underline{\lim}=\liminf$.

\begin{beispiel}
  $a_n=(-1)^n \quad \sup \{(-1)^k\colon k\geq n\}=1 \Rightarrow \limsup
  (-1)^n=1$\\
$\inf\{(-1)^k\colon k\geq n\} \Rightarrow \liminf (-1)^n=-1$
\end{beispiel}

\begin{remark}
Die Folge $b_n\coloneqq\sup \{a_k\colon k\geq n\}$ ist monoton fallend oder
  $+\infty$. Die Folge $c_n\coloneqq\inf\{a_k\colon k\geq n\}$ ist monoton
  wachsend oder $-\infty$. Daher existieren $\limsup a_n=\lim b_n$ und
  $\liminf a_n=\lim c_n$ immer eigentlich oder uneigentlich, d.\,h. es gilt
  $\limsup a_n \in \R$ oder $\limsup a_n=+\infty/-\infty$ und $\liminf a_n \in
  \R$ oder $\liminf a_n=+\infty/-\infty$.
\end{remark}

\begin{theorem}
Sei $(a_n) \subset \R$ beschränkt. Dann ist $\overline{\lim} a_n$ grösster
  Häufungspunkt von $(a_n)$ und $\underline{\lim} a_n$ kleinster Häufungspunkt
  von $(a_n)$.
  \begin{proof}
    Nach dem \autoref{satz:bw} (Satz von Bolzano/Weierstrass) besitzt $(a_n)$
    einen Häufungspunkt.
    \begin{gather*}
      \inf \{a_n\}\leq \overline{\lim}\ a_n \leq \sup \{a_n\}
    \end{gather*}
    \begin{enumerate}[1.\,Schr{i}tt]
     \item Zu zeigen: $a=\overline{\lim}\ a_n$ ist Häufungspunkt von $(a_n)$\\
      Setzen $b_n\coloneqq\sup \{a_k\colon k\geq n\}$ ist monoton fallend und nach unten beschränkt. Daraus folgt nach
    \autoref{satz:monotoneFolge}: $a=\lim b_n=\inf \{b_n\}=\overline{\lim}\ a_n$\\
    Für $k \in \N \exists m_k \in \N \colon a\leq b_{m_k}<a+\frac{1}{k}\Rightarrow \exists n_k\geq m_k\colon b_{m_k}-\frac{1}{k}
    <a_{n_k}\leq b_{m_k}$\\
    $\Rightarrow a-\frac{1}{k}\leq b_{m_k}-\frac{1}{k}<a_{n_k}<a+\frac{1}{k}$\\
    $\Rightarrow a-\frac{1}{k}<a_{n_k}<a+\frac{1}{k}$\\
    $\Rightarrow \lim_{k\rightarrow \infty} a_{n_k}=a\stackrel{\text{\autoref{satz:hp}}}{\Longrightarrow} a$ ist Häufungspunkt 
    von $(a_n)$
  \item $a$ ist grösster Häufungspunkt von $(a_n)$. Sei $a'$ Häufungspunkt von $(a_n)\stackrel{\text{\autoref{satz:hp}}}
    {\Longrightarrow} \exists \text{Teilfolge } (a_{n_k})\colon\lim a_{n_k}=a'$\\
    $b_{n_k}=\sup \{a_l\colon l\geq n_k\} \geq a_{n_k}\Rightarrow a=\lim b_{n_k}\geq \lim a_{n_k}=a'$
\end{enumerate}
  \end{proof}
\end{theorem}

\subsection{Cauchyfolgen}
\begin{definition}[Cauchyfolge]
Sei $(X,d)$ ein metrischer Raum. Eine Folge $(a_n) \subset X$ heißt genau dann
  \highl{Cauchyfolge}, wenn
  \begin{gather*}
    \forall \varepsilon > 0 \exists n_{\varepsilon}\in \N \forall n,m \geq
       n_{\varepsilon}\colon d(a_n,a_m)\leq \varepsilon
  \end{gather*}
\end{definition}

\begin{theorem}\label{satz:cf}
  Sei $(X,d)$ ein metrischer Raum und $(a_n)\subset X$ eine konvergente Folge.
  Dann ist $(a_n)$ eine Cauchyfolge.
  \begin{proof}
    Sei $a=\lim a_n$ und $\varepsilon>0$. Dann existiert ein
    $n_{\varepsilon}\in \N \forall n\geq n_{\varepsilon}\colon d(a,a_n)\leq
    \frac{\varepsilon}{2}$ . Für $n,m\geq n_{\varepsilon}\colon d(a_n,a_m)\leq
    d(a_n,a)+d(a,a_m)=\frac{\varepsilon}{2} +\frac{\varepsilon}{2}=\varepsilon
    \Rightarrow a_n$ ist eine Cauchyfolge.
  \end{proof}
\end{theorem}

\begin{remark}
  In einem beliebigen metrischen Raum ist \emph{nicht} jede Cauchyfolge
  konvergent. Zum Beispiel ist $(\Q,\abs{\cdot })$ ein metrischer Raum. Die
  Folge $a_{n+1}=\frac{1}{2}(a_n+\frac{2}{a_n})$ und $a_0\coloneqq1$ liegt in
  $\Q$. Aber der Grenzwert ist $\sqrt{2}\notin \Q$.
\end{remark}

\begin{theorem}[Cauchysches Konvergenzkriterium in $\R$\index{Konvergenzkriterium!Cauchysches}]
\label{satz:CKonv}
  Eine Folge $(a_n)\subset \R$ ist genau dann konvergent, wenn sie eine
  Cauchyfolge ist.
  \begin{proof}
    \begin{itemize}
     \item["`$\Rightarrow$"'] siehe \autoref{satz:cf}.
     \item["`$\Leftarrow$"'] Sei $(a_n)\subset \R$ eine Cauchyfolge. Dann ist
      $(a_n)$ beschränkt. Für $\varepsilon=1$
    \begin{align*}
      & \exists n_1\in \N \forall n,m >n_1 \colon&\abs{a_n-a_m}\leq\varepsilon =1\\  
      &\Rightarrow \abs{a_n}=\abs{a_n-a_m+a_m}\leq \abs{a_n-a_m}+\abs{a_m}\leq 1+\abs{a_m}
      & \text{ für } n,m\geq n_1
    \end{align*}
    Für $M=\max\{\abs{a_1},\abs{a_2},\ldots, \abs{a_m}, 1+\abs{a_m}\}$ gilt $\abs{a_n}\leq
    M \forall n \in \N$. Nach dem Satz von Bolzano/Weierstrass
    (\autoref{satz:bw}) gilt: $\exists$ Teilfolge $(a_{n_k})\subset
    (a_n)\colon a_{n_k}$ ist konvergent mit $a\coloneqq\lim_{k\rightarrow \infty}
    a_{n_k}$.\\
    Sei $\varepsilon>0$. Dann existiert $k_{\varepsilon}, n_{\varepsilon} \in \N \colon\abs{a_{n_k}-a}\leq \frac{\varepsilon}{2}$
    für $k\geq k_{\varepsilon}$\\
    $\abs{a_n-a_m}\leq \frac{\varepsilon}{2}$ für $n,m \geq n_{\varepsilon}$. Wähle $n_{k_0}\geq \{\max n_{k_{\varepsilon}},
    n_{\varepsilon}\}$. Dann gilt für $n\geq n_{k_0}\colon\abs{a_n-a}=\abs{a_n-a_{n_{k_0}}+a_{n_{k_0}}-a}\leq 
    \abs{a_n-a_{n_{k_0}}}+\abs{a_{n_{k_0}}-a}\leq \frac{\varepsilon}{2}+\frac{\varepsilon}{2}=\varepsilon \Rightarrow (a_n)$
    ist konvergent.
\end{itemize}
  \end{proof}
\end{theorem}

\begin{remark}
  Um die Konvergenz einer Folge in $\R$ nachzuweisen, genügt es, zu zeigen,
  dass die Folge Cauchyfolge ist. Dabei braucht man den Grenzwert nicht zu
  kennen.
\end{remark}

\subsection{Vollständige und kompakte metrische Räume}

\begin{theorem}
In $\R$ sind folgende Aussagen äquivalent:
\begin{enumerate}[(1)]
  \item \textbf{\highl{Vollständigkeitsaxiom}}: Jede nichtleere nach oben
  beschränkte Menge besitzt ein Supremum.
  \item \textbf{Satz über monotone Folgen\index{monotone Folgen!Satz über}}: Nach \autoref{satz:monotoneFolge} Jede 
    nach oben beschränkte mo\-no\-ton wachsende Folge besitzt einen Grenzwert.
  \item \textbf{Satz von Bolzano/Weierstrass\index{Bolzano/Weierstrass!Satz von}}: Jede beschränkte Folge hat eine 
    konvergente Teil\-fol\-ge.
  \item Jede Cauchyfolge hat einen Grenzwert.
  \item Intervallschachtelungsprinzip (\autoref{satz:Ischachtelung})
\end{enumerate}
  \begin{proof}
    \begin{itemize}
  \item[(1)$\Rightarrow$(2)] $\lim (a_n)=\sup \{a_n\}$ nach \autoref{satz:monotoneFolge}
  \item[(2)$\Rightarrow$(3)] siehe Beweis zu \autoref{satz:bw}
  \item[(3)$\Rightarrow$(4)] siehe Beweis zu \autoref{satz:CKonv}
  \item[(4)$\Rightarrow$(5)] zu zeigen: Sei $I_n=[a_n,b_n]$ eine Intervallschachtelung $\Rightarrow \bigcap I_n=\{s\}$\\
    $\forall n,m \in \N$ gilt:$\left.
    \begin{array}{lll}
      (a_n) \text{ monoton fallend }\\
      (b_n) \text{ monoton wachsend }
    \end{array}
    \right\} \Rightarrow b_n-a_n\rightarrow 0$\\
    $n\geq m =\abs{a_n-a_m}=a_n-a_m\leq b_m-a_m$\\
    Sei $\varepsilon>0$. Dann $\exists m_{\varepsilon} \in \N\ m\geq m_{\varepsilon}\colon b_m-a_m\leq \varepsilon$\\
    $\Rightarrow \forall n,m \colon n\geq m \geq m_{\varepsilon}\Rightarrow \abs{a_n-a_m}\leq \varepsilon$, d.\,h. $(a_n)$ ist
    Cauchyfolge.\\
    $\Rightarrow \lim a_n = s \in \R$\\
    Ferner $\lim b_n =\lim ((b_n-a_n)+a_n)=\lim (b_n-a_n)+\lim a_n = 0+s=s$. Ausserdem $\forall n \in \N \colon a_n\leq s\leq 
    b_n \Rightarrow s \in \bigcap_{n=1}^{\infty}I_n$\\
    Eindeutigkeit von $s$ wie im Beweis von \autoref{satz:Ischachtelung}
  \item[(5)$\Rightarrow$(1)] zu zeigen: Sei $\emptyset \neq M \subset \R$ nach oben beschränkt. $\Rightarrow \sup M 
    \subset \R$\\
    Sei $b \in \R$ obere Schranke und $a \in M$
    \begin{enumerate}[1.\,F{a}ll]
      \item $a$ ist obere Schranke von $M \Rightarrow a = \sup M$
      \item $a$ ist keine obere Schranke von $M$. Wir setzen $a_1\coloneqq a,
      b_1\coloneqq b$ und bilden das Mittel $\frac{a_1+b_1}{2}$
      \begin{enumerate}[{2}.1.\,F{a}ll]
        \item $\frac{a_1+b_1}{2}$ ist obere Schranke von $M$, so setzen wir
	$a_2\coloneqq a_1, b_2\coloneqq\frac{a_1+b_1}{2}$
	\item $\frac{a_1+b_1}{2}$ ist keine obere Schranke $\Rightarrow M \cap [\frac{a_1+b_1}{2},b_1]\neq \emptyset$
	  Wählen $a_2 \in M \cap [\frac{a_1+b_1}{2},b_1]$ und $b_2\coloneqq b_1$. In beiden Fällen gilt, dass $M\cap [a_2,b_2]
	  \neq \emptyset$ und $b_2-a_2\leq b_1-\frac{a_1+b_1}{2}=\frac{a_1-b_1}{2}$. Führen wir diese Prozedur fort, so
	  erhalten wir Intervalle $[a_n,b_n]$ mit $a_n \in M$ und $b_n$ obere Schranke von $M$.\\
	  $b_n-a_n\leq \frac{a_{n-1}+b_{n-1}}{2}\leq \cdots \leq (\frac{1}{2})^{n-1}(b_1-a_1)\Rightarrow I_n=[a_n,b_n]$
	  ist Intervallschachtelung, da $I_1\supset I_2\supset I_3\supset \ldots$ und $\lim (b_n-a_n)=0$\\
	  $\Rightarrow \bigcap I_n =\{s\}, \lim a_n=\lim b_n=s$ zu zeigen ist: $s=\sup M$
	  \begin{itemize}
	    \item[$\alpha$] $s$ ist obere Schranke von $M$. Sei $x \in M \Rightarrow \forall n \in \N \colon x \leq b_n
	      \Rightarrow x \leq \lim b_n =s$
	    \item[$\beta$] $s$ ist kleinste obere Schranke von $M$. Sei $\varepsilon >0\Rightarrow \exists I_{n_{\varepsilon}}=
	      [a_{n_{\varepsilon}},b_{n_{\varepsilon}}]$\\
	      $s-\varepsilon <a_{n_{\varepsilon}}\leq s$. Da $M\cap I_{n_{\varepsilon}}\neq \emptyset$ folgt $x_{\varepsilon}
	      \in M \cap I_{n_{\varepsilon}}\colon s-\varepsilon<a_{n_{\varepsilon}}\leq s\Rightarrow s$ ist kleinste obere
	      Schranke.
	  \end{itemize}
      \end{enumerate}
    \end{enumerate}
\end{itemize}
  \end{proof}
\end{theorem}

Die Aussagen (3) und (4) haben grosse Bedeutung in der Mathematik und dienen
zur Einführung der Begriffe \emph{Kompaktheit} und \emph{Vollständigkeit} von
metrischen Räumen. 

\begin{definition}[vollständig, kompakt]\label{def:vollst}
Sei $(X,d)$ ein metrischer Raum
\begin{enumerate}[(1)]
  \item $X$ heißt genau dann \highl[Raum!vollständiger
  metrischer]{vollständiger metrischer Raum}, wenn jede Cauchyfolge in $X$
  einen Grenzwert in $X$ hat.
  \item $X$ heißt genau dann \highl[Raum!kompakter metrischer]{kompakter
  metrischer Raum}, wenn jede Folge aus $X$ eine konvergente Teilfolge mit
  Grenzwert in $X$ enthält.
\end{enumerate}
\end{definition}

\begin{beispiel}
  Sei $d=\abs{\cdot }$. Dann gilt:
\begin{enumerate}[(1)]
  \item $[a,b]$ ist ein vollständiger und ein kompakter metrischer Raum.
  \item $\R$ ist ein vollständiger metrischer Raum, allerdings kein kompakter.
  \item $[a,b]\cap \Q$ ist keines von beiden.
\end{enumerate}
\end{beispiel}

\section{Reihen}

\begin{definition}[Reihe]\label{def:reihe}
  Sei $(a_n) \subset \R$ eine reelle Zahlenfolge. Die Folge
  \begin{gather*}
    s_n\coloneqq\sum_{k=1}^n a_k \qquad a_k \in \N
  \end{gather*}
  der \highl[Partialsumme]{Partialsummen} heißt
  \highl{Reihe}\footnote{Schreibweise: $\sum_{n=1}^\infty (a_n), (\sum_{k=1}^n
  a_k)_{n\in \N}, \sum_{k=1}^\infty a_k$}. Konvergiert $(s_n)$, so heißt
  $\sum_{k=1}^\infty a_k\coloneqq\lim s_n$ \highl[Reihe!Summe]{Summe} oder
  \highl[Summe!Wert]{Wert} der Reihe.
\end{definition}

\subsection{Rechenregeln für konvergente Reihen}
\begin{theorem}\label{satz:RechenregelReihe}
\begin{enumerate}[(1)]
  \item Wenn $\sum a_n$ konvergent ist, so konvergiert auch $\sum ca_n$ für
  $c\in \R$. Außerdem gilt $\sum_{k=1}^{\infty} c\cdot a_{k}
  =c\sum_{k=1}^{\infty} a_k$.
  \item Wenn $\sum a_n, \sum b_n$ konvergent sind, so auch $\sum(a_n+b_n)$. Es
  gilt, $\sum(a_{n}+n_{n})= \sum a_{n}+\sum b_{n}$.
  \item $\sum_{n=1}^\infty a_n$ konvergent $\Rightarrow \sum_{k=1}^\infty
  (\sum_{j=n_{k}}^{n_{k+1}-1} a_j)$ konvergent $1=n_1<n_2<\ldots$
\end{enumerate}
  \begin{proof}
    \begin{enumerate}[(1)]
  \item $s_n=\sum_{k=1}^n a_k, \lim s_n=\sum_{k=1}^\infty a_k$\\
    $\sum_{k=1}^\infty ca_k =\lim(cs_n)=c\lim s_n =c\sum_{k=1}^\infty a_k$
  \item $s_n=\sum_{k=1}^n a_k, t_n=\sum_{k=1}^n b_k, s_n+t_n=\sum_{k=1}^n (a_n+ b_k)$\\
    $\sum_1^\infty (a_k+b_k)=\lim (s_n+t_n)=\lim s_n +\lim t_n=\sum_1^\infty a_k +\sum_1^\infty b_k$
  \item $s_n=\sum_{k=1}^n a_k, s_{\stackrel{n-1}{l+1}}=\sum_{k=1}^l(\sum_{j=n_k}^{n_{k+1}-1} a_j), 1=n_1<n_2<\ldots$\\
    $\lim s_n$ existiert $\Rightarrow \lim_{l\rightarrow \infty}
    s_{\stackrel{n-1}{l+1}}$ (Jede Teilfolge hat gleichen Grenzwert.)
\end{enumerate}
  \end{proof}
\end{theorem}

\begin{beispiel}
  \begin{description}
  \item[geometrische Reihe\index{Reihe!geometrische}] $a_n=q^n \quad n=0,1,2,\ldots \quad \sum_{n=0}^\infty q^n=1+q^1+q^2\cdots$
    kon\-ver\-giert für $\abs{q}<1$ und divergiert für $\abs{q}\geq 1$
    \begin{proof}
      $s_n =1+q+\cdots +q^n=\frac{1-q^{n-1}}{1-q}, q\neq 1$\\
    Für $\abs{q}<1 \quad \lim s_n=\frac{1}{1-q}$\\
    Für $\abs{q}>1$ ist $s_n$ divergent.\\
    Für $q=-1 \quad s_n=\begin{cases}1 \quad n=2k\\0 \quad n=2k+1\end{cases}$ divergent.\\
    Für $q=1 \quad s_n=n+1$ divergent.
    \end{proof}
  \item[harmonische Reihe\index{Reihe!harmonische}] $\sum_{n=1}^\infty
    \frac{1}{n}$ divergent.
  \item[alternierende harmonische Reihe\index{Reihe!alternierende
    harmonische}]  $\sum_{n=1}^\infty (-1)^n\frac{1}{n}$ konvergent.
\end{description}
\end{beispiel}

\subsection{Einige Konvergenzkriterien für Reihen}

\begin{theorem}[Notwendiges Kriterium für
  Konvergenz\index{Konvergenzkriterium!notwendiges}]
\label{satz:konvkrit}
$\sum a_n$ ist konvergent, wenn  $\lim a_n=0$ ist.
%lim neu eingefuegt, da sonst kein Sinn
\end{theorem}
\begin{proof}
  $s_n=\sum_{k=1}^n a_k, s_{n+1}-s_n=a_{n+1} \Rightarrow
  0=s-s=\lim s_{n+1}-\lim s_n=\lim a_{n+1}$
\end{proof}

\begin{remark}
  Die Umkehrung von \autoref{satz:konvkrit} gilt im allgemeinen
  nicht. Ein Beispiel ist die harmonische Reihe.
\end{remark}

\begin{theorem}[Cauchykriterium\index{Cauchykriterium}]
\label{satz:CKrit}
 Die Summe $\sum a_n$ ist genau dann konvergent, wenn
  \begin{gather*}
    \forall \varepsilon >0 \exists n_{\varepsilon}\in \N \forall n>m>n_{\varepsilon}\colon\abs{\sum_{k=m}^n a_k}\leq \varepsilon
  \end{gather*}
  \begin{proof}
    Für die Partialsummen gilt: $s_n-s_m=\sum_{k=m+1}^n a_k$. Die Summe $\sum
    a_k$ ist nach \autoref{def:reihe} genau dann konvergent, wenn auch $(s_n)$
    konvergent ist. Dies ist nach \autoref{satz:CKonv} genau dann der Fall,
    wenn $(s_n)$ eine Cauchyfolge ist.
  \end{proof}
\end{theorem}

\begin{definition}[Absolute Konvergenz\index{Konvergenz!absolute}]
  Eine Reihe $\sum a_k$ heißt genau dann \highl{absolut konvergent}, wenn
  $\sum \abs{a_k}$ konvergiert.
\end{definition}

\begin{lemma}
  Sei $\sum a_n$ absolut konvergent. Dann ist auch $\sum a_k$ konvergent.
  \begin{proof}
    Zum Beweis nutzt man das Cauchykriterium: Sei $\varepsilon >0$. Dann
    existiert $n\in \N \colon \abs{\sum_{k=m+1}^n a_k}\leq \sum_{k=m+1}^n
    \abs{a_k}\leq \varepsilon$ für $n>m>n_{\varepsilon}$.
  \end{proof}
\end{lemma}

\begin{beispiel}
  Es gibt konvergente Reihen, die nicht absolut konvergent sind. Ein Beispiel
  ist die alternierende harmonische Reihe.
\end{beispiel}

\begin{theorem}[weitere Konvergenzkriterien]\label{satz:wkonvkrit}
\begin{enumerate}[(1)]
  \item \highl{Monotoniekriterium} Sei $a_n\geq 0$. Dann $\sum a_n$ konvergent
  $\Leftrightarrow (s_n)$ beschränkt.
  \item \highl{Vergleichskriterium}:
  \begin{enumerate}[({2}.1)]
    \item \highl{Majorantenkriterium} Sei $\abs{a_n}\leq c_n, n\geq n_0$. Dann $\sum c_n$ konvergent
      $\Rightarrow \sum a_n$ absolut konvergent.
    \item \highl{Minorantenkriterium} Sei $a_n\geq d_n\geq 0$ für $n\geq n_0$. Dann $\sum d_n$
      divergent $\Rightarrow \sum a_n$ divergent.
  \end{enumerate}
  \item \highl{Teleskopsummenkriterium} oder \highl{Verdichtungskriterium} 
    Seien $a_1\geq a_2\geq \ldots \geq a_n\geq 0$. Dann $\sum a_n$ konvergent $\Leftrightarrow \sum 2^n a_{2^n}$ konvergent
  \item \highl{Wurzelkriterium} Sei $\alpha \coloneqq\overline{\lim}\sqrt[n]{\abs{a_n}}$. Dann ist $\sum a_n$
    konvergent für $\alpha <1$ und divergent für $\alpha >1$. Für $\alpha=1$ existieren sowohl konvergente als auch
    divergente Reihen.
  \item \highl{Quotientenkriterium} Seien $\underline{\beta}\coloneqq\underline{\lim}\abs{\frac{a_{n+1}}{a_n}},
    \overline{\beta}\coloneqq\overline{\lim}\abs{\frac{a_{n+1}}{a_n}}$. Dann folgt für $\overline{\beta}<1$, dass $\sum a_n$
    konvergent ist und für $\underline{\beta}>1$, dass $\sum a_n$ divergent ist.
\end{enumerate}
  \begin{proof}
    \begin{enumerate}[(1)]
     \item $a\geq 0 \Rightarrow s_{n+1}=s_n+a_{n+1} \geq s_n, (s_n)$ nach oben
      beschränkt und monoton wachsend $\Rightarrow (s_n)$ konvergent.
     \item
      \begin{enumerate}[({2}.1)]
       \item $\abs{\sum_{k=m+1}^n a_k}\leq \sum_{k=m+1}^n \abs{a_k}\leq
	\sum_{k=m+1}^n c_k <\varepsilon$ für $n>m\geq n_{\varepsilon}
        \stackrel{\text{Cauchykrit.}}{\Longrightarrow} \sum \abs{a_k}$ absolut
	konvergent.
       \item Wäre $\sum a_n$ konvergent, folgt daraus, dass auch $\sum d_n$
	konvergent ist.
      \end{enumerate}
     \item Die Partialsumme ist $s_n = a_1+a_2+\dotsb +a_n,
     $ und wird definieren $t_k\coloneqq a_1+2a_2+2^2a_{2^2}+\dotsb+
      +2^ka_{2^k}$.  Für $n\leq 2^k$ gilt, $s_n\leq t_k$. Denn $s_n\leq
      a_1+(a_2+a_3)+\dotsb +(a_{2^k}+a_{2^k+1}+\dotsb +a_{2^{k+1}-1})\leq
      a_1+2a_2+\dotsb +2^ka_{2^k}=t_k$. Für $n\geq 2^k$ gilt $s_n\geq
      \frac{1}{2}t_k$. Denn $s_n\geq a_1 + a_2+(a_3+a_4)+\dotsb
      +(a_{2^{k-1}+1}+\dotsb +a_{2^k})\geq \frac{a_1}{2}+a_2+2a_4+\dotsb
      +2^{k-1} a_{2^k}=\frac{1}{2}(a_1+2a_2+2^2a_{2^2}+\dotsb +2^ka_{2^k})=
      \frac{1}{2} t_k$. Somit gilt nach (1), dass $(s_n)$ genau dann
      konvergent ist, wenn $(t_k)$ konvergent ist.
     \item
      \begin{enumerate}[1.\,F{a}ll]
      \item Sei $\alpha >1$ und $\alpha=\overline{\lim}\sqrt[n]{\abs{a_n}}>1$.
	Dann existiert eine Teilfolge $(a_{n_k}) \subset (a_n)\colon
        \lim \sqrt[\uproot{3}n_k]{\abs{a_{n_k}}}=\alpha$. Wähle
	$\varepsilon_0>0\colon\alpha >1+\varepsilon_0$. Dann existiert ein
	$k_0 \in \N \colon \abs{\sqrt[\uproot{3}n_k]{\abs{a_{n_k}}}
	-\alpha}<\varepsilon_0$ für $k\geq k_0$. Somit ist $-\varepsilon_0
	<\sqrt[\uproot{3}n_k]{\abs{a_{n_k}}}< \varepsilon_0 \Rightarrow
	1<\alpha-\varepsilon_0<\sqrt[\uproot{3}n_k]{\abs{a_{n_k}}}\Rightarrow
	1<\abs{a_{n_k}}$ für $k\geq k_0$.
	Daraus folgt, dass $a_{n_k}$ nicht gegen 0 streben. Daher strebt auch
	$a_n$ nicht gegen 0. Nach \autoref{satz:konvkrit}
	folgt, dass auch $\sum a_n$ divergiert.
      \item Sei $\alpha<1$ und $\alpha =\overline{\lim}\sqrt[n]{\abs{a_n}}<1$.
	Wähle $\beta$ mit $\alpha<\beta <1$ und
	$b_n\coloneqq\sup\{\sqrt[k]{\abs{a_k}}\colon k\geq n\}$.
        Für $b_n$ gilt $\lim b_n=\alpha$. Wähle
      $\varepsilon_0\colon\alpha+\varepsilon_0<\beta$. Dann existiert ein $n_0
      \in \N\,\forall n\geq n_0\colon\abs{\alpha -b_n}<\varepsilon_0$. Somit ist $-\varepsilon_0<\alpha -b_n<\varepsilon_0$ für $n\geq n_0
	\Rightarrow b_n<\alpha +\varepsilon_0$ für $n\geq n_0$. Insobesondere gilt für $n=n_0\colon b_{n_0}<\alpha +\varepsilon_0<
	\beta$, d.\,h. $\sqrt[k]{\abs{a_k}}\leq b_{n_0}<\beta \quad \forall k\geq n_0 \Rightarrow \abs{a_k}<\beta^k, k\geq n_0
	\stackrel{\beta <1}{\Rightarrow} \sum \beta^k$ ist konvergent $\stackrel{(2)}{\Rightarrow} \sum \abs{a_n}$ konvergent.
	Diese Summe ist sogar absolut konvergent.
    \end{enumerate}
  \item $\overline{\beta}\coloneqq\overline{\lim}\abs{\frac{a_{n+1}}{a_n}}<1 \Rightarrow \sum a_n$ konvergent\\
    $\underline{\beta}\coloneqq\underline{\lim}\abs{\frac{a_{n+1}}{a_n}}>1 \Rightarrow \sum a_n$ divergent\\
    $\underline{\lim}_n\abs{\frac{a_{n+1}}{a_n}}\leq \underline{\lim}_n \sqrt[n]{\abs{a_n}}\leq \overline{\lim}_n \sqrt[n]{\abs{a_n}}
    \leq \overline{\lim}_n \abs{\frac{a_{n+1}}{a_n}}$\\
    $b_1\coloneqq\sup \{\abs{a_k}\colon k\geq 1\}\geq \abs{a_1}$\\
    $b_n\coloneqq\sup \{\abs{\frac{a_{k+1}}{a_k}}\colon k\geq n\}\geq \frac{a_n}{a_{n-1}}|, n\geq 2$\\
    $\overline{\lim}\abs{\frac{a_{n+1}}{a_n}}=\lim b_n$. Dann:\\
    $\sqrt[n]{\abs{a_n}}=\sqrt[n]{\abs{a_1}\cdot \frac{\abs{a_2}}{\abs{a_1}}\cdot \frac{\abs{a_3}}{\abs{a_2}}\cdot \ldots \cdot 
    \frac{\abs{a_{n-1}}}{\abs{a_{n-2}}}\cdot \frac{\abs{a_n}}{\abs{a_{n-1}}}} \leq \sqrt[n]{b_1b_2\ldots b_n}\leq 
    \frac{b_1+b_2+\cdots +b_n}{n}$\\
    $\Rightarrow \overline{\lim} \sqrt[n]{\abs{a_n}}\leq \overline{\lim}
    \frac{b_1+\cdots +b_n}{n}=\lim \frac{b_1+\cdots +b_n}{n}=\lim b_n=\overline{\lim} \abs{\frac{a_{n+1}}{a_n}}$\\
    Der Beweis für $\underline{\lim}\abs{\frac{a_{n+1}}{a_n}}\leq \underline{\lim} \sqrt[n]{\abs{a_n}}$ geht analog.
\end{enumerate}
  \end{proof}
\end{theorem}

\begin{beispiel}
  Sei $0\leq \alpha <\infty$ und $\sum_{n=1}^\infty \frac{1}{n^\alpha}$ eine
  Reihe. Diese ist konvergent für $\alpha>1$ und divergent für $0\leq \alpha
  \leq 1$. Nach dem Quotientenkriterium gilt, $a_n= \frac{1}{n^\alpha},
  \abs{\frac{a_{n+1}}{a_n}}=\frac{a_{n+1}}{a_n}=\frac{1}{(n+1)^\alpha}\cdot
  \frac{n^\alpha}{1}= (\frac{n}{n+1})^\alpha=(1-\frac{1}{n+1})^\alpha$. Der
  Grenzwert ist$\lim \frac{a_{n+1}}{a_n}=\lim_{n\rightarrow\infty}
  (1-\frac{1}{n+1})^\alpha=1^\alpha=1$. Daraus folgt, dass nach dem
  Quotientenkriterium keine Entscheidung zu treffen ist, ob diese Reihe
  konvergiert oder nicht.
  
  Nach dem Teleskopsummenkriterium gilt, $a_1\geq a_2\geq \cdots \geq a_n\geq
  \cdots \geq 0, \lim a_n=\lim_{n\rightarrow \infty}\frac{1}{n^\alpha}=0$ für
  $0< \alpha<\infty$. Die Summe $\sum a_n$ konvergiert genau dann, wenn die
  Summe $\sum 2^na_{2^n}$ konvergiert. Umstellen ergibt
  $a_{2^n}=\frac{1}{(2^n)^\alpha}=\frac{1}{2^{n\alpha}}=(\frac{1}{2^\alpha})^n$.
  Somit ist $\sum 2^na_{2^n}=\sum2^n(2^{-\alpha})^n=\sum
  (2^{1-\alpha})^n\Rightarrow \sum 2^na_{2^n}$ ist konvergent für $\alpha>1$
  und divergent für $\alpha \leq 1$.

  Die Summe $\sum_{n=1}^\infty \frac{n!}{n^n}$ ist konvergent. Wir führen den
  Beweis nach dem Wurzelkriterium: $a_n=\frac{n!}{n^n}$ und
  $\sqrt[n]{\abs{a_n}}=\sqrt[n]{a_n}=\sqrt[n]{\frac{n!}{n^n}}=
  \frac{1}{n}\sqrt[n]{n!}$ Dies ist kompliziert zu berechnen. Daher ein
  Versuch mit dem Quotientenkriterium:
  $\abs{\frac{a_{n+1}}{a_n}}=\frac{a_{n+1}}{a_n}=\frac{(n+1)!}{(n+1)^{n+1}}\cdot
  \frac{n^n}{n!}=\frac{n!(n+1)n^n}{(n+1)^n(n+1)n!}
  =\frac{n^n}{(n+1)^n}=\frac{1}{(1+\frac{1}{n})^n}\Rightarrow \lim
  \abs{\frac{a_{n+1}}{a_n}}=\lim \frac{1}{(1+\frac{1}{n})^n}=
  \frac{1}{e}<1\Rightarrow$  Summe ist konvergent.
\end{beispiel}

\subsection{Alternierende Reihen}
\begin{definition}[Alternierende Reihe]
  Die Reihe $\sum_{n=0}^\infty (-1)^na_n$ heißt genau dann
  \highl[Reihe!alternierende]{alternierende Reihe}, wenn entweder $a_n\geq 0$
  für $n \in \N$ oder $a_n\leq 0$ für $n \in \N$.
\end{definition}

\begin{theorem}[Leibnitzsches Kriterium\index{Leibnitzsches Kriterium}]\label{satz:LeibKrit}
  Sei $a_0\geq a_1\geq a_2\geq\dotsb\geq a_n\geq \dotsb\geq 0$ und $\lim
  a_n=0$. Dann ist $\sum_{n=0}^\infty (-1)^na_n$ konvergent.
  \begin{proof}
    Die Partialsummen lassen sich aufschreiben als:
    \begin{gather*}
      s_n=\sum_{k=0}^n (-1)^ka_k=a_0-a_1+a_2+\dotsb +(-1)^na_n
    \end{gather*}
    Wegen der Monotone gilt, $s_{2n+2}- s_{2n}= -a_{2n+1}+a_{2n+2} \leq 0$ und
    $s_{2n+3} -s_{2n+1}= a_{2n+2}-a_{2n+3} \geq 0$. Somit folgt, $s_{0}\geq
    s_{2}\geq s_{4}\geq\dotsb\geq s_{2n}\geq\dotsb$ und $s_{1}\leq s_{3}\leq
    s_{5}\leq\dotsb\leq s_{2n+1}\leq\dotsb$. Weiter ist $s_{2n+1}- s_{2n}=
    -a_{2n+1}\leq0$ und damit $s_{2n+1}\leq s_{2n}$ für $n\geq0$.  Die Folge
    der $s_{2n}$ ist nach unten beschränkt durch $s_{1}$ und die Folge der
    $s_{2n+1}$ ist nach oben beschränkt durch $s_{0}$. Nach dem
    \autoref{satz:monotoneFolge} folgt, $\lim s_{2n} = s$ und $\lim s_{2n+1}
    =s'$. Für $s_{2n+1}= s_{2}-a_{2n+1}$ folgt im Grenzprozess mit
    $n\rightarrow\infty$, dass $s'=s-0$, also $s'=s$ ist.

    Nun ist noch zu zeigen, dass $\lim s_n=s$. Sei $\varepsilon>0$. Dann
    existiert ein $n_0, n_1 \in \N$ mit $\abs{s_{2n}-s} \leq \varepsilon$ für
    $n\geq n_0$ und $\abs{s_{2n+1}-s} < \varepsilon$ für  $n\geq n_1$. Wir
    setzen $N\coloneqq\max\{2n_0,2n_1+1\}$ und es gilt:
    $\abs{s_n-s}<\varepsilon$ für $n\geq N$, d.\,h. $\lim s_n=s$.
  \end{proof}
\end{theorem}

\begin{beispiel}
  \begin{enumerate}
  \item $\sum_{n=1}^\infty (-1)^{n-1}\frac{1}{n}$ konvergiert. $a_n=\frac{1}{n}, a_1\geq a_2\geq \ldots \geq 
    a_n\geq \ldots \geq0, \lim a_n=0$\\
    $\stackrel{\text{\autoref{satz:LeibKrit}}}{\Longrightarrow} \sum (-1)^{n-1}\frac{1}{n}$ ist konvergent.
  \item $\sum_{n=1}^\infty \frac{(n+1)^{n-1}}{(-n)^n}=\sum \frac{1}{(-1)^n}\cdot \frac{(n+1)^{n-1}}{n^n}=\sum (-1)^n
    \frac{(n+1)^{n-1}}{n^n}$\\
    $a_n=\frac{(n+1)^{n-1}}{n^n}=(\frac{n+1}{n})^n\cdot \frac{1}{n+1}=(1+\frac{1}{n})^n\cdot \frac{1}{n+1}\rightarrow e
    \cdot 0=0$\\
    zu zeigen ist noch die Monotonie: $a_n=\frac{(n+1)^{n-1}}{n^n}\geq \frac{(n+2)^n}{(n+1)^{n+1}}=a_{n+1}$\\
    $(n+1)^{2n}=((n+1)^2)^n=(n^2+2n+1)^n\geq (n(n+2))^n=(n^2+2n)^n \Rightarrow$ monoton fallend\\
    $\Rightarrow \sum \frac{(n+1)^{n-1}}{(-n)^n}$ ist konvergent.
\end{enumerate}
\end{beispiel}

\subsection{Umordnung und Produkt von Reihen}
\begin{definition}[Umordnung]
Sei $\pi \colon\N\rightarrow \N$ bijektiv. Dann heißt
\begin{gather*}
  \sum_{k=1}^\infty a_{\pi(k)}
\end{gather*}
eine \highl{Umordnung} der Reihe $\sum_{k=1}^\infty a_k$.
\end{definition}

\begin{theorem}\label{satz:umordnung}
  Seien $c_n\geq 0$ und $\sum_{n=1}^\infty c_n$ konvergent. Dann gilt $\forall
  \pi \colon\N\rightarrow \N$ bijektiv $\Rightarrow \sum_{k=1}^\infty
  c_{\pi(k)}$ konvergent und es gilt $\sum_{k=1}^\infty c_k=\sum_{k=1}^\infty
  c_{\pi(k)}$.
  \begin{proof}
    Sei $n \in \N, M\coloneqq\max\{\pi(1),\ldots ,\pi(n)\}$. Dann ist $n\leq
    M$ und es gilt $\sum_{k=1}^n c_{\pi(k)}\leq \sum_{k=1}^M c_k\leq
    \sum_{k=1}^\infty c_k<\infty \stackrel{c_k\geq 0}{\Rightarrow}
    \sum_{k=1}^\infty c_{\pi(k)}\leq \sum_{k=1}^\infty c_k$. Obige Aussage auf
    $\sum_1^\infty c_k=\sum_1^\infty c_{\pi^{-1}(\pi(k))}\leq \sum_1^\infty
    c_{\pi(k)} \Rightarrow \sum_1^\infty c_k=\sum_1^\infty c_{\pi(k)}$.
  \end{proof}
\end{theorem}

\begin{theorem}\label{satz:absUmordnung}
  Die Summe $\sum a_n$ ist genau dann absolut konvergent, wenn $\forall \pi
  \colon\N \rightarrow \N$ bijektiv $\sum_1^\infty a_{\pi(k)}$ konvergent ist.
  Ferner gilt $\sum_{k=1}^{\infty} a_{\pi(k)}= \sum_{k=1}^{\infty} a_{k}$ für
  alle $\pi$.
  \begin{proof}
    \begin{itemize}
     \item["`$\Rightarrow$"'] Sei $\sum a_n$ absolut konvergent.
      \begin{align*}
	0 &\leq a_n^+\coloneqq\max\{a_n,0\} = \frac{\abs{a_n}+a_n}{2}\leq
	   \abs{a_n}\\
        0 &\leq a_n^-\coloneqq\min\{a_n,0\} = \frac{\abs{a_n}-a_n}{2}\leq
	   \abs{a_n}
      \end{align*}
      Nach dem Majorantenkriterium sind $\sum a_n^+, \sum a_n^-$ konvergent.
      Weiterhin wissen wir wegen \autoref{satz:absUmordnung}, dass
      $\sum_1^\infty a_{\pi(k)}^+ =\sum_1^\infty a_k^+, \sum_1^\infty
      a_{\pi(k)}^- =\sum_1^\infty a_k^-$. Also folgt, $\sum_1^\infty
      a_{\pi(k)} =\sum_1^\infty (a_{\pi(k)}^+-a_{\pi(k)}^-) =\sum_1^\infty
      a_{\pi(k)}^+ - \sum_1^\infty a_{\pi(k)}^- =\sum_1^\infty a_k^+
      -\sum_1^\infty a_k^- =\sum_1^\infty (a_k^+ -a_k^-) =\sum_1^\infty a_k$.
  \item["`$\Leftarrow$"'] Sei $\sum \abs{a_n}$ divergent. Sei o.\,B.\,d.\,A.
      $\sum a_n$ konvergent (sonst ist $\pi$ die identische Abbildung). Es
      lässt sich folgende Feststellung treffen: $a_k =a_k^+ -a_k^-$ und
      $\abs{a_k}=a_k^+ +a_k^-$.
    $\left.\begin{array}{rcl}
      \sum \abs{a_n} \text{ divergent}\\
      \sum a_n \text{ konvergent}
    \end{array}\right\}\Rightarrow \sum a_k^+=\infty, \sum a_k^-=\infty$\\
    Sei $(a_{\varphi_+(k)})$ Teilfolge aller $a_k>0$ ($a_k\leq 0$ streichen) und $(a_{\varphi_-(k)})$ Teilfolge aller
    $a_k\leq 0$ ($a_k>0$ streichen)\\
    $s_n^\pm\coloneqq\sum_{k=1}^n a_k^\pm, t_n^\pm\coloneqq\sum_{k=1}^n
  a_{\varphi_\pm(k)}$\\
    $s_n^+\leq t_n^+$ (da $t_n^+$ nur positiv, bei $s_n^+$ kann auch die 0 enthalten sein)\\
    $s_n^-=-t_n^- \Rightarrow \lim_{n\rightarrow \infty}=\sum_1^\infty a_{\varphi_+(k)}=\infty, \lim_{n\rightarrow \infty}
    t_n^-=\sum_1^\infty a_{\varphi_-(k)}=-\infty$ \todo{weitere Beweisfolge
      mit einbauen}
\end{itemize}
  \end{proof}
\end{theorem}

\begin{definition}[Bedingte/""unbedingte Konvergenz]
\begin{enumerate}[(1)]
  \item Eine konvergente Reihe heißt genau dann \highl{unbedingt konvergent},
  wenn alle Umordnungen konvergent sind.
  \item Eine konvergente Reihe heißt \highl{bedingt konvergent}, wenn
    sie nicht unbedingt konvergent ist.
\end{enumerate}
\end{definition}

Das \autoref{satz:absUmordnung} besagt, dass unbedingt konvergente Reihen
vorhanden sind, wenn diese absolut konvergieren.

\begin{theorem}[Riemannscher Umordnungssatz\index{Umordnungssatz!Riemannscher}]
  Sei $\sum_1^\infty a_k$ bedingt konvergent. Dann
  \begin{gather*}
    \forall S \in \R \exists \pi \colon\N\rightarrow\N \text{ Bijektion }\colon\sum_1^\infty a_{\pi(k)}=S
  \end{gather*}
  \begin{proof}
    siehe Heuser S.\,197--199
  \end{proof}
\end{theorem}

\subsection{Produkte von Reihen}

Seien $\sum_{n=0}^\infty a_n$ und $\sum_{n=0}^\infty b_n$ Reihen in $\R$
\begin{gather*}
  \left(\sum_{i=0}^M a_i\right)\left( \sum_{j=0}^N\right) =\sum_{i=0}^M \sum_{j=0}^N a_ib_j
\end{gather*}
Ordnet man alle $a_j b_k$ (Reihenfolge der Glieder spielt keine Rolle) zu
einer Folge $(p_n)_{n=0}^\infty$ an, so wird die Reihe $\sum_0^\infty p_n$ als
\highl{Produktreihe} der Reihen $\sum a_n \sum b_n$ bezeichnet.

\begin{theorem}\label{satz:abskonvReihe}
  Seien $\sum_{n=0}^\infty a_n, \sum_{b=0}^\infty b_n$ absolut konvergent.
  Dann ist auch $\sum_{n=0}^\infty p_n$ absolut konvergent und es gilt
  \begin{gather*}
    \sum_{n=0}^\infty p_n=\left(\sum_{n=0}^\infty
       a_n\right)\left(\sum_{n=0}^\infty b_n\right)
  \end{gather*}
  \begin{proof}
    \begin{enumerate}[1.\,Schr{i}tt]
     \item Zu zeigen ist, dass $\sum \abs{p_n}$ konvergent ist. Nach dem
      Monotoniekriterium reicht es zu zeigen, dass $\exists K \geq 0 \forall n
      \in \N \cup \{0\}\colon \sum_{k=0}^n \abs{p_k}\leq K$.

      Sei $n \in \N \Rightarrow$. Dann existiert ein $m \in \N$ mit
      \begin{gather*}
	\sum_{k=0}^n \abs{p_k}
      \leq \left(\sum_{k=0}^m \abs{a_k}\right)\left(\sum_{k=0}^m
      \abs{b_k}\right) \leq \left(\sum_0^\infty
      \abs{a_k}\right)\left(\sum_0^\infty \abs{b_k}\right)=\colon K
      \end{gather*}
      
  \item Beweis der Summenformel:
    $q_0+q_1+\cdots +q_{(n+1)^2-1} =(\sum_{k=0}^n a_k)(\sum_{k=0}^n
      b_k)\xrightarrow{n\rightarrow \infty} (\sum_{k=0}^\infty
      a_k)(\sum_{k=0}^\infty b_k) =\sum_{k=0}^\infty q_k$. Da $\sum q_n$ eine
      Umordnung von $\sum p_n$ ist, folgt nach \autoref{satz:absUmordnung} und
      dem ersten Schritt, dass $\sum p_n=\sum q_n = (\sum a_n)(\sum b_n)$.
\end{enumerate}
  \end{proof}
\end{theorem}

\begin{definition}[Cauchy-Produkt]
  Die Produktreihe $\sum c_n$ heißt \emph{Cauchyprodukt\index{Cauchyprodukt}}
  der Reihen $\sum a_n, \sum b_n$.
  \begin{gather*}
    \begin{matrix}
      c_{0}& c_{1}& c_{3}&\\
      a_{0}b_{0}& a_{0}b_{1}& a_{0}b_{2}& \dotso\\
      c_{2}& c_{4}& c_{7}&\\
      a_{1}b_{0}& a_{1}b_{1}& a_{1}b_{2}& \dotso \\
      c_{5}& c_{8}& c_{12}& \\
      a_{2}b_{0}& a_{2}b_{1}& a_{2}b_{2}& \dotso \\
      \vdots& \vdots& \vdots
    \end{matrix}
  \end{gather*}
\end{definition}

\begin{theorem}
  Seien $\sum a_n, \sum b_n$ absolut konvergent. Dann ist das Cauchyprodukt
  $\sum c_n$ absolut konvergent und es gilt:
  \begin{gather*}
    \sum_{n=0}^\infty c_n = \sum_{n=0}^\infty \left(\underbrace{\sum_{k=0}^n
       a_k b_{n-k}}_{=\colon d_n}\right) = \left(\sum a_n\right)\left(\sum
       b_n\right)
  \end{gather*}
  \begin{proof}
    Die Summe $\sum c_n=(\sum a_n)(\sum b_n)$ ist nach
    \autoref{satz:abskonvReihe} absolut konvergent. Da $\sum d_n$ eine
    spezielle Klammerung von $\sum c_n$ ist, gilt $\sum_{n=0}^\infty c_n=
    \sum_{n=0}^\infty d_n$ nach \autoref{satz:RechenregelReihe} Punkt~3.
  \end{proof}
\end{theorem}

\begin{remark}[zum Cauchyprodukt]
  Sei $a_n\coloneqq b_n\coloneqq\frac{(-1)^n}{\sqrt{n+1}}$ und
  $d_n=\sum_{k=0}^n a_kb_{n-k}$ für $n\in \N\cup \{0\}$. Die Reihen $\sum a_n,
  \sum b_n$ konvergieren nach dem Leibnitzkriterium. Ihr Cauchyprodukt
  konvergiert nicht, denn
\begin{align*}
  d_n &= \sum_{k=0}^n a_k b_{n-k}= \sum_{k=0}^n \frac{(-1)^k}{\sqrt{k+1}}\cdot
     \frac{(-1)^{n-k}}{\sqrt{n-k+1}}\\
  &= (-1)^n \sum_{k=0}^n \frac{1}{\sqrt{(k+1)(n-k+1)}}\\
  \abs{d_n} &= \sum_{k=0}^n \frac{1}{\sqrt{(k+1)(n-k+1)}} \geq \sum_{k=0}^n
     \frac{\frac{1}{(k+1)(n-k+1)}}{2}\\
  &= \sum_{k=0}^n \frac{2}{n+2}= \frac{2n+2}{n+2}\geq 1
\end{align*}
$\Rightarrow \abs{d_n}$ konvergiert nicht gegen $0\Rightarrow d_n \not\rightarrow 0\Rightarrow \sum d_n$ ist divergent. Daraus
folgt, dass auch $\sum c_n$ divergent ist.
\end{remark}

\begin{beispiel}[Exponentialreihe]
  Ein Beispiel für das Cauchyprodukt ist die \highl{Exponentialreihe}:
  \begin{gather*}
    e^x \coloneqq \exp(x)\coloneqq\sum_{n=0}^\infty
       \frac{x^n}{n!}=1+x+\frac{x^2}{2}+\frac{x^3}{3!}+\cdots +\frac{x^n}{n!}
  \end{gather*}
  Dann gilt $\exp(x+y)=\exp(x)\cdot \exp(y)$.
  \begin{proof}
    $\sum_0^\infty \frac{x^n}{n!}$ ist nach dem Quotientenkriterium absolut
    konvergent für alle $x\in \R$.
    \begin{align*}
      \exp(x)\cdot \exp(y) &= \left(\sum_{k=0}^\infty
	 \frac{x^k}{k!}\right)\left(\sum_{j=0}^\infty \frac{x^j}{j!}\right) =
	 \sum_{n=0}^\infty \left(\sum_{k=0}^n a_k b_{n-k}\right)\\
      &= \sum_{n=0}^\infty \left(\sum_{k=0}^n \frac{x^k}{k!}\cdot
	 \frac{y^{n-k}}{(n-k)!}\right) = \sum_{n=0}^\infty \frac{1}{n!}
	 \left(\sum_{k=0}^n \underbrace{\frac{n!}{k!(n-k)!}}_{=\binom{n}{k}}
	 x^k y^{n-k}\right)\\
      &= \sum_{n=0}^\infty \frac{1}{n!}(x+y)^n = \exp(x+y)
\end{align*}
  \end{proof}
\end{beispiel}

\begin{lemma}
  \begin{enumerate}[(1)]
  \item $\forall x \in \R \colon \exp(x)>0$\\
    $\forall x\geq 0\colon \exp(x)\geq 1>0$\\
    $\forall x<0\colon(-x)>0\Rightarrow \exp(-x)>0\Rightarrow \exp(x)>0$
  \item $\forall x\in \R \colon \exp(-x)=\frac{1}{\exp(x)}$\\
    Nach der Funktionalgleichung ist $\exp(x)\exp(-x)=\exp(x-x)=\exp(0)=1$.
  \item $\forall x \in \Z \colon \exp(n)=e^n$\\
    $n\in \N \cup \{0\}$\\
    $n=0\colon \exp(0)=1=e^0$\\
    $n\Rightarrow n+1\colon \exp(n+1)=\exp(n)\cdot \exp(1)=e^n\cdot e=e^{n+1}$\\
    $n\in \Z , n<0, (-n)\in \N, e^{-n}=\exp(-n)=\frac{1}{\exp(n)}\Rightarrow \exp(n)=e^n$
\end{enumerate}
\end{lemma}

\chapter{Funktionen und Stetigkeit}
Im folgenden betrachten wir zwei metrische Räume  $(X,d)$ und $(Y,\tilde{d})$.
Dabei ist $D$ eine Teilmenge von $X$ und $f$ eine Funktion $f\colon
D\rightarrow Y$.

\section{Grenzwerte und Stetigkeit}
\begin{definition}[Grenzwert]
Sei $a\in X$ mit folgenden Eigenschaften: $\exists (a_n)\subset D\colon a_n\rightarrow a$. Die Funktion $f\colon D\rightarrow Y$
hat in $a$ den Grenzwert 
\begin{gather*}c\perdef \forall x_n \subset D\colon\lim_{n\rightarrow \infty} x_n=a\Rightarrow \lim_{n\rightarrow \infty} f(x_n)=c\end{gather*}
Dann heißt $c$ \highl{Grenzwert} an der Stelle $a$.
\end{definition}

\begin{remark}
  Schreibweise: $\lim_{x\rightarrow a} f(x)=c, \lim_{\stackrel{x\rightarrow
  a}{x \in D}} f(x)=c$
\end{remark}

\begin{beispiel}
  \begin{enumerate}[(1)]
  \item Seien $X=Y=\R$ und der Abstand definiert durch $d(x,y)=\abs{x-y}$. Wie
    ermittelt man $\lim_{x\rightarrow 1} f(x)$ für die Funktion $f\colon D=\R
    \backslash \{1\}\rightarrow \R, f(x)=\frac{x^2-1}{x-1}$? Es ist $a=1\notin
    D$. Wir definieren eine Folge $a_n=1+\frac{1}{n} \in \R\backslash
    \{1\}$, die gegen $a$ strebt.

    Sei $(x_n)\subset D \subset \R \backslash \{1\}$ mit $x_n\rightarrow 1$.
    Dann gilt, $f(x)=\frac{x_n^2 -1}{x_n-1}=x_n+1 \xrightarrow{n\rightarrow
    \infty} 1+1=2 \Rightarrow \lim_{x \rightarrow 1} f(x)=2$. Für
    $a\neq 1$ und $x_n\rightarrow a$ gilt $f(x_n)=x_n+1 \xrightarrow{n
    \rightarrow \infty} a+1$.
  \item Sei $X=Y=\R$ und $f\colon D=\R\backslash \{0\}\rightarrow \R$ mit
    $f(x)=\frac{\exp(x)-1}{x}$. Es gilt: $\lim_{x\rightarrow 0}
    \frac{\exp(x)-1}{x}=1$.
    \begin{proof}
      \begin{align*}
	\exp(x)-1-x &= \frac{x^2}{2!}+\frac{x^3}{3!}+\frac{x^4}{4!}+\dotsb\\
	\abs{\exp(x)-1-x} &\leq \frac{\abs{x}^2}{2!} +\frac{\abs{x}^3}{3!}
	   +\frac{\abs{x}^4}{4!}+\dotsb\\
	&= \abs{x}^2\left(\frac{1}{2!} +\frac{\abs{x}}{3!}
	   +\frac{\abs{x}^2}{4!} +\dotsb\right)\\
	&\leq \abs{x}^2\left(\underbrace{\frac{1}{2!} +\frac{1}{3!}
	   +\frac{1}{4!} +\dotsb}_{=e-2}\right) \text{für } \abs{x}\leq 1\\
	&= (e-2)\abs{x}^2\\
	\abs[\bigg]{\frac{\exp(x)-1}{x}-1} &\leq (e-2)\abs{x} \text{ für }
	   x\neq 0, \abs{x}\leq 1
    \end{align*}
    Sei $x_n\xrightarrow{x_n\neq 0} 0 \Rightarrow 0\leq
      \abs{\frac{\exp(x_n)-1}{x_n}-1}\leq (e-2)x_n \xrightarrow{n\rightarrow
      \infty} 0 \Rightarrow \frac{\exp(x_n)-1}{x_n}\rightarrow 1$
    \begin{gather*}\lim \frac{\exp(x)-1}{x}=1\end{gather*}
    \end{proof}
  \item Sei $X=Y=\R$ und $f(x)=\begin{cases}1 & x \geq 0\\-1 &
				 x<0\end{cases}$. Wir vermuten:
    $f(x)\not\rightarrow c \perdef \exists (x_n) \subset D\colon
    x_n\rightarrow a \wedge f(x_n)\not\rightarrow c$. Wir setzen
    $x_n=(-1)^n\frac{1}{n}\rightarrow 0 \wedge f(x_n)=\begin{cases}1 & n
							\text{ gerade}\\-1 & n
							\text{
							  ungerade}\end{cases}$.
    Somit existiert der $\lim f(x_n)$ nicht.
\end{enumerate}
\end{beispiel}

\begin{definition}[Stetigkeit]
Sei $f\colon D\rightarrow Y$ und $a \in D$. Die Funktion $f$ heißt genau dann
  \highl{stetig}\index{Stetigkeit} im Punkt $a$, wenn $\lim_{x\rightarrow a}
  f(x)=f(a)$. Die Funktion $f$ heißt genau dann
  \highl{stetig}\index{Funktion!Stetigkeit} in $D$, wenn $f$ in jedem Punkt
  $a$ aus $D$ stetig ist.
\end{definition}

\begin{beispiel}
  Die konstante Funktion $f(x)=b$ und die identische Funktion $\id\colon
  X\rightarrow X, \id(x)=x$ sind stetige Funktionen. Dies sind triviale
  Beispiele für Stetigkeit.

  Die Funktion
  \begin{gather*}
    f\colon\R\rightarrow \R\qquad f(x)=\begin{cases}\frac{x^2-1}{x-1} & x \neq
					 1\\1 & x=1\end{cases}
  \end{gather*}
  ist im Punkt $x=1$ \emph{nicht} stetig. Denn $\lim_{x\rightarrow 1}f(x)=2\neq
  1=f(1)$. Setzt man den Funktionswert $2$ für $x=1$, so wäre die Funktion
  stetig.
\end{beispiel}

\begin{theorem}[Rechenregeln]
\begin{enumerate}[(1)]
  \item Sei $(X,d)$ ein metrischer Raum und $D \subset X$. Dann gilt: Sind
  $f,g\colon D\rightarrow\R$ stetig in $a \in D$, so sind $f+g, f\cdot g,
  \lambda f$ mit $\lambda \in \R$ stetig in $a$. Ist $g(a)\neq 0$, so ist auch
  $\frac{f}{g}\colon D'\rightarrow \R$ stetig in $a$. Dabei ist $D'=\{x\in
  D\colon g(x)\neq 0\}$.
  \begin{proof}
    Siehe hierzu den \autoref{satz:wkonvkrit}. Sei beispielsweise $(x_n)$ eine
    Folge mit $x_n\rightarrow a$. Wegen der Stetigkeit von $f$ und $g$ folgt,
    $f(x_n)\rightarrow f(a)$ und $g(x_n)\rightarrow g(a)$. Also ist
    $(f+g)(x_n)=f(x_n)+g(x_n)\rightarrow f(a)+g(a)=(f+g)(a)$.
    Daraus folgt, dass $f+g$ stetig in $a$ sind.
  \end{proof}
  \item Seien $X,Y,Z$ metrische Räume mit $D\subset X, E\subset Y, f\colon
  D\rightarrow Y, g\colon E\rightarrow Z, f(D)\subset E$. Ist $f$ in $a\in D$
  und $g$ in $f(a)$ stetig, so ist $g\circ f$ in $a$ stetig.
  \begin{proof}
    Aus $x_n\rightarrow a$ folgt wegen der Stetigkeit von $f$, dass
    $f(x_n)\rightarrow f(a)$. Weiterhin ist $g$ stetig und es folgt, $(g \circ
    f)(x_n)=g(f(x_n))\rightarrow g(f(a))=(g\circ f) (a)$.
  \end{proof}
\end{enumerate}
\end{theorem}

\section{\texorpdfstring{$\varepsilon$-$\delta$}{Epsilon-Delta}-Stetigkeit}
\begin{theorem}[$\epsilon$"~$\delta$"~Definition der Stetigkeit]\label{satz:e-d-stetig}
  Sei $D\subset X, f\colon D\rightarrow Y$. Die Funktion $f$ ist genau dann im
  Punkt $a\in D$ stetig, wenn:
  \begin{gather*}
    \forall \varepsilon >0 \exists \delta_{\varepsilon}(a)>0 \forall x \in
       D\colon d(x,a)<\delta_{\varepsilon} (a)\Rightarrow
       \tilde{d}(f(x),f(a))<\varepsilon
  \end{gather*}
  In Worten: $f(x)$ weicht beliebig wenig von $f(a)$ ab, falls nur $x$
  hinreichend nahe bei $a$ liegt oder zu jeder $\varepsilon$-Kugel
  $\mathring{B_{\varepsilon}}(f(a))$ existiert eine
  $\delta_{\varepsilon}$-Kugel relativ zu $D$ mit
  $f(\mathring{B_{\varepsilon}}\cap D)\subset \mathring{B_{\varepsilon}}
  (f(a))$.
  \begin{gather*}
    \forall \varepsilon >0 \exists \delta_{\varepsilon}>0\colon
       f(\mathring{B_{\delta_{\varepsilon}}}(a) \cap D) \subset
       \mathring{B_{\varepsilon}}(f(a))
  \end{gather*}
  \begin{proof}
    \begin{itemize}
  \item["`$\Rightarrow$"'] Für alle $(x_n)\subset D$ setzen wir voraus, dass
      $x_n\rightarrow a \Rightarrow f(x_n)\rightarrow f(a)$. Dann  ist
    zu zeigen: $\forall \varepsilon >0 \exists \delta_{\varepsilon} >0 \forall
      x \in D\colon d(x,a)< \delta_{\varepsilon}\Rightarrow
      \tilde{d}(f(x),f(a))<\varepsilon$.
    Der Beweis wird indirekt geführt. Annahme: $\exists \varepsilon >0 \forall
      \delta >0 \exists x \in D\colon d(x,a)<\delta \wedge \tilde{d}
      (f(x),f(a))\geq \varepsilon$.
    Insbesondere gilt: $\forall n \in \N \exists x_n \in D\colon d(x_n,a)<\frac{1}{n} \wedge \tilde{d}(f(x_n),
    f(n))\geq \varepsilon \stackrel{n\rightarrow \infty}{\Longrightarrow} x_n \rightarrow a \wedge 
    f(x_n)\not\rightarrow f(a)$
   \lightning
  \item["`$\Leftarrow$"'] zu zeigen: $\forall (x_n) \subset D$ mit
      $x_n\rightarrow a$ gilt $f(x_n) \rightarrow f(a)$.
    Sei $(x_n)\subset D$ mit $x_n\rightarrow a$ und $\varepsilon >0$. Nach
      Voraussetzung existiert ein $\delta >0$, so dass
      $\tilde{d}(f(x),f(a))<\varepsilon \forall x \in D$ mit $d(x,a)<\delta$.
      Da $x_n\rightarrow a$ gibt es ein $n_0\in \N$, so dass $d(x_n,a)<\delta
      \forall n\geq n_0 \Rightarrow \tilde{d}(f(x_n),f(a))<\varepsilon$ für
      alle $n\geq n_0$.
\end{itemize}
  \end{proof}
\end{theorem}

\begin{beispiel}
  Die Funktion $f\colon\Q\rightarrow\R$ mit $f(x)\coloneqq\begin{cases}0 &
							    x<\sqrt{2}\\1 &
							    x>\sqrt{2}\end{cases}$
  ist auf $\Q$ stetig.
  \begin{proof}
    Sei $a\in \Q$. Zeige $\lim_{x\rightarrow a} f(x)=f(a)$.
    \begin{enumerate}[1.\,F{a}ll]
     \item Sei $a>\sqrt{2}$ und $(x_n)\subset \Q$, so dass $x_n\rightarrow a$.
      Setze $\varepsilon \coloneqq a-\sqrt{2}>0$. Für $\varepsilon$ gibt es
      ein $n_0\in \N$, so dass $\abs{x_n-a} <\varepsilon$ für alle $n\geq
      n_0$. Ferner gilt $x_n>\sqrt{2}$ für $n\geq n_0$, denn $-\varepsilon
      <x_n-a<\varepsilon$ für $n\geq n_0 \Rightarrow
      a-\varepsilon=a-(a-\sqrt{2})=\sqrt{2} <x_n\Rightarrow f(x_n)=1$ für alle
      $n\geq n_0$. Also ist $\lim_{n\rightarrow \infty} f(x)=1=f(a)$.
     \item Sei $a<\sqrt{2}$: analog
    \end{enumerate}
  \end{proof}
\end{beispiel}

\section{Grenzwerte und Häufungspunkte von Mengen}
\begin{definition}[Häufungspunkt einer Menge]
  Sei $X$ ein metrischer Raum und $D\subset X$. Ein Punkt $a\in X$
  heißt genau dann
  \highl[Menge!Häufungspunkt]{Häufungspunkt\index{Häufungspunkt}} von $D$,
  wenn:
  \begin{gather*}\forall \varepsilon >0\colon
  \left(\mathring{B_{\varepsilon}}(a)\backslash \{a\} \right)\cap D
  \neq \emptyset
  \end{gather*}
\end{definition}

\begin{remark}
  \emph{Achtung}: Die Häufungspunkte einer Folge $(x_n)$ stimmen i.\,A.
  \emph{nicht} mit dem Häufungspunkt der entsprechenden Menge $\{x_n\colon
  n\in\N\}$ überein. Zum Beispiel hat die konstante Folge $(a)_n$ hat den
  Häufungspunkt $a$. Aber $a$ selbst hat keinen Häufungspunkt. 
\end{remark}

\begin{theorem}
  Sei $f\colon D\rightarrow Y, D\subset Y$ und $a\in X$ ein Häufungspunkt
  von $D$. Dann gilt:
  \begin{gather*}\lim_{x\rightarrow a} f(x)=c\Leftrightarrow \forall\varepsilon >0
  \exists \delta >0\colon\forall x\in D\colon d(x,a) <\delta \Rightarrow
  \tilde{d}(f(x),c)<\varepsilon\end{gather*}
\end{theorem}
\begin{proof}
  Der Beweis wird analog zu \autoref{satz:e-d-stetig} geführt.
\end{proof}

\begin{remark}
\begin{description}
\item[Negation des Häufungspunktes] $a\in X$ ist genau dann kein
  Häufungspunkt von $D$, wenn es eine $\varepsilon$-Kugel um $a$ gibt,
  die kein Element aus $D$ enthält, ausser eventuell $a$ selbst.
  \begin{gather*}\exists \varepsilon >0\colon(B_{\varepsilon}(a)\backslash \{a\})\cap D=\emptyset\end{gather*}
\item[isolierter Punkt] $a\in D$ heißt \highl[Punkt!isolierter]{isolierter
    Punkt}
  \begin{gather*}\perdef \exists \varepsilon>0\colon(B_{\varepsilon}(a)\backslash
  \{a\})\cap D=\emptyset\end{gather*}
\item[Korollar] Sei $D\subset X, f\colon D\rightarrow Y$. Dann gilt
  \begin{enumerate}[i]
  \item $f$ ist in jedem isolierten Punkt von $D$ stetig.
  \item $f$ ist genau dann in einem Häufungspunkt von $D$ stetig, wenn
    $\lim_{x\rightarrow a}f(x)=f(a)$, d.\,h. bei der Untersuchung einer
    Funktion auf Stetigkeit genügt es, nur die Häufungspunkte zu
    betrachten.
  \end{enumerate}
\end{description}
\end{remark}

\section{Stetigkeit, offene und abgeschlossene Mengen}
\begin{definition}[Offene, abgeschlossene Menge]
Sei $X$ ein metrischer Raum.
\begin{enumerate}[(1)]
\item Eine Menge $O\subset X$ heißt genau dann
  \highl[Menge!offene]{offen\index{offen}},
  wenn es zu jedem Element in $O$ eine $\varepsilon$"=Kugel um dieses
  Element gibt, die ebenfalls ganz in $O$ liegt.
  \begin{gather*}\forall x\in O\colon\mathring{B_{\varepsilon}}(x)\subset O\end{gather*}
\item $A\subset X$ heißt genau dann
  \emph{abgeschlossen\index{Menge!abgeschlossene}}, wenn
  $X\backslash A$ offen ist.
\end{enumerate}
\end{definition}

\begin{beispiel}
  \begin{enumerate}[(i)]
  \item $\emptyset, X$ sind offen und abgeschlossen
    \begin{itemize}
      \item $X$ offen: klar!
      \item $\emptyset$ offen: Sei $\emptyset$ nicht offen, dann gilt
        $\exists x_0\in \emptyset$ \lightning $\forall \varepsilon>0\colon
        \mathring{B_{\varepsilon}}(x_0)\cap (X\backslash
        \emptyset)\neq \emptyset$\lightning 
      \item $X$ ist abgeschlossen, da $X\backslash X=\emptyset$. Die leere Menge ist offen.
      \item $\emptyset$ ist abgeschlossen, da $X\backslash
        \emptyset=X$ und $X$ ist offen.
    \end{itemize}
  \item Für $r\geq 0$ ist $\mathring{B_r}(a)$ offen und $B_r(a)$ abgeschlossen.
\end{enumerate}
\end{beispiel}

\begin{theorem}\label{satz:abgTeilmenge}
  Eine Teilmenge $A\subseteq X$ ist genau dann abgeschlossen, wenn für
  alle $(x_n) \subset A$ gilt, $(x_n)$ ist konvergent $\Rightarrow
  \lim x_n \in A$.
  \begin{proof}
    \begin{itemize}
     \item["`$\Rightarrow$"'] Der Beweis erfolgt durch Kontraposition: Sei $A$
      abgeschlossen. Dann nehmen wir an, dass $\exists (x_n)\subset
      A\colon(x_n) \text{ konvergent} \Rightarrow \lim x_n \notin A$. Wir
      setzen $a\coloneqq\lim x_n$ und es folgt, $a \in X\backslash A$ ist
      offen, da $A$ nach Voraussetzung abgeschlossen ist. Also existiert ein
      $\varepsilon >0 \mathring{B_{\varepsilon}}(a)\subset X\backslash A$. Da
      $x_n$ gegen $a$ strebt, existiert ein $n_0\in \N$, so dass
      $d(x_n,a)<\varepsilon$ für $n\geq n_0$ und es folgt, $x_n \in
      \mathring{B_{\varepsilon}}(a)$\lightning
     \item["`$\Leftarrow$"'] Sei $\forall (x_n)\subset A\colon x_n$ konvergent
      $\Rightarrow \lim x_n \in A$. Wir nehmen an, $A$ ist offen. Dann ist zu
      zeigen, dass $A$ abgeschlossen ist, genau dann, wenn
      $X\backslash A$  offen ist. Dies ist genau dann, wenn $\forall x
      \in X\backslash A \exists \varepsilon
      >0\colon\mathring{B_{\varepsilon}} (x)\subseteq X\backslash
      A$. Das ist aber genau dann der Fall, wenn $\forall x \in
      X\backslash A \exists \varepsilon
      >0\colon\mathring{B_{\varepsilon}} (x)\cap A = \emptyset$. Wir
      gehen wieder vom Gegenteil aus, also $A$ ist offen. Dann
      existiert ein $x_0 \in X\backslash A \forall \varepsilon
      >0\colon\mathring{B_{\varepsilon}}(x_0) \cap A \neq \emptyset$.
      Insbesondere existiert ein $x_n \in A \colon d(x_n,x_0)<\frac{1}{n}$.
      Nach Voraussetzung folgt, $x_0=\lim x_n \in A$\lightning
    \end{itemize}
  \end{proof}
\end{theorem}

\begin{lemma}
  Sei $A'$ die Menge der Häufungspunkte von $A$. Dann ist $A$ genau dann
  abgeschlossen, wenn $A'$ eine Teilmenge von $A$ ist.
  \begin{proof}
    \begin{itemize}
    \item["`$\Rightarrow$"'] Sei $a\in A'$ ein Häufungspunkt. Dann
      existiert $x_n \subset A, x_n\neq a, x_n\rightarrow a$. Nach dem
      \autoref{satz:abgTeilmenge} ist dann  $a \in A$.
    \item["`$\Leftarrow$"'] Annahme: $A$ ist nicht abgeschlossen. Dann
      existiert nach \autoref{satz:abgTeilmenge} $(x_n) \subset A,
      (x_n)$ ist konvergent, aber $\lim x_n\notin A$. Also ist $a$
      Häufungspunkt von $A$ und $A'\nsubseteq A$.\lightning
\end{itemize}
  \end{proof}
\end{lemma}

% Satz 5
\begin{theorem}\label{satz:fkt-aquiv}
  Seien $X,Y$ metrische Räume und $f\colon D\rightarrow Y$. Dann sind folgende
  Aussagen äquivalent:
  \begin{enumerate}[(1)]
   \item $f$ ist stetig auf $X$.
   \item $\forall O \subset Y$ offen gilt, $f^{-1}(O)\coloneqq\{x\in X\colon
    f(x)\in O\}$ offen.
   \item $\forall A \subset Y$ abgeschlossen gilt, $f^{-1}(A)$ abgeschlossen.
  \end{enumerate}
  \begin{proof}
    \begin{itemize}
     \item[(1)$\Rightarrow$ (2)] Sei $O\subset Y$ offen, $x\in
      f^{-1}(O)\Leftrightarrow f(x)\in O$. Da $O$ offen ist, gibt es ein
      $\varepsilon >0\colon\mathring{B_{\varepsilon}} (f(x))\subset O$. Wegen
      der Stetigkeit von $f$ existiert ein $\delta >0\colon
      f(\mathring{B_{\delta}}(x))\subset
      \mathring{B_{\varepsilon}}(f(x))\subset O \Longrightarrow
      \mathring{B_{\delta}}(x)\subset f^{-1}(O)$.
     \item[(2)$\Rightarrow$ (1)] Sei $x\in X, \varepsilon >0$. Aus der zweiten
      Aussage folgt, $f^{-1}(\mathring {B_{\varepsilon}}(f(x)))$ ist offen.
      Damit existiert ein $\delta >0\colon\mathring{B_{\delta}}(x)\subset
      f^{-1}(\mathring {B_{\varepsilon}}(f(x)))\Rightarrow
      f(\mathring{B_{\delta}}(x))\subset \mathring{B_{\varepsilon}} (f(x))
      \Rightarrow f$ stetig.
     \item[(2)$\Leftrightarrow$ (3)] $f^{-1}(Y\backslash
      M)=f^{-1}(Y)\backslash f^{-1}(M)=x\backslash f^{-1}(M)$
     \item[(2)$\Rightarrow$ (3)] Sei $A$ abgeschlossen. Dann ist
      $O=Y\backslash A$ offen $\Leftrightarrow A=Y\backslash O$. Also ist
      $f^{-1}(A)=f^{-1}(Y)\backslash f^{-1}(O)=X\backslash
      \underbrace{f^{-1}(O)}_{\text{offen}}$ abgeschlossen.
     \item[(3)$\Rightarrow$ (2)] Sei $O$ offen. Dann ist $A=Y\backslash O$
      abgeschlossen. Also folgt, $f^{-1}(A) =X\backslash
      \underbrace{f^{-1}(O)}_{\text{offen}}$ abgeschlossen.
\end{itemize}
  \end{proof}
\end{theorem}

\section{Stetigkeit und kompakte Mengen}
\begin{definition}[Kompakte Mengen]
  Sei $X$ ein metrischer Raum. Eine Menge $K\subset X$ heißt genau
  dann \highl[Menge!kompakte]{kompakt\index{kompakt}}, wenn jede Folge
  aus $K$ eine konvergente Teilfolge in $K$ enthält.
  \begin{gather*}
    \forall (x_n) \subset K \exists (x_{n_k})\subset
    (x_n)\colon\lim_{K\rightarrow \infty} x_{n_k}\in K
  \end{gather*}
\end{definition}

\begin{beispiel}
  Endliche Mengen sind kompakt.
\end{beispiel}

% Satz 6
\begin{theorem}\label{satz:beschr-abg}
  \begin{enumerate}[(1)]
  \item Sei $K\subset X$ kompakt. Dann ist $K$ beschränkt und
    abgeschlossen.
    \begin{proof}
      \begin{itemize}
      \item[Beschränkheit] Annahme: $K$ ist nicht beschränkt. Dann
        existiert ein $a \in K \forall n \in \N \exists x_n \in
        K\colon d(x_n,a)\geq n$. Also existiert keine konvergente
        Teilfolge $(x_{n_k})$ aus $(x_n)$. Das steht im Widerspruch
        zur Kompaktheit von $K$.
      \item[Abgeschlossenheit] Sei $(x_n)\subset K \colon x_n
        \rightarrow a\in X$. Dann ist zu zeigen: $a\in K$. Wegen der
        Kompaktheit von $K$ existiert eine Teilfolge $(x_{n_k})\subset
        X \colon\lim (x_{n_k})\in K\Rightarrow \lim x_n=\lim
        x_{n_k}=a\in K$.
      \end{itemize}
    \end{proof}
  \item In $\R$ gilt: $K\subset \R$ ist genau dann kompakt, wenn $K$
    beschränkt und abgeschlossen ist.
    \begin{proof}
      Sei $K\subset \R$ abgeschlossen und beschränkt. Dann ist zu
      zeigen, dass $K$ kompakt ist. Dazu sei  $(x_n)\subset K
      \Rightarrow (x_n)$ beschränkt. Nach dem \autoref{satz:bw} folgt,
      dass eine Teilfolge $(x_{n_k})\subset (x_n)$ mit  $\lim
      x_{n_k}\in\R$ existiert. Da $K$ abgeschlossen ist, folgt $\lim
      (x_{n_k})\in K$.
    \end{proof}
  \end{enumerate}
\end{theorem}

\begin{beispiel}
  \begin{enumerate}[(i)]
  \item $[a,b]$ ist kompakt, da beschränkt und abgeschlossen.
  \item Endliche Mengen sind kompakt.
  \item $\lsofint{0,1}$ ist nicht kompakt.
  \end{enumerate}  
\end{beispiel}

\subsubsection{Gleichmässige Stetigkeit}
\begin{definition}[Gleichmäßig stetig]
  Sei $D\subset X, f\colon D\rightarrow Y$. Dann heißt $f$  genau dann
  \highl{gleichmässig stetig}, wenn:
  \begin{gather*}
    \forall \varepsilon >0 \exists \delta_{\varepsilon}>0 \forall x,y
    \in D\colon d(x,y)<\delta_{\varepsilon} \Rightarrow \tilde{d}
    (f(x),f(y))<\varepsilon
  \end{gather*}
\end{definition}

\begin{remark}
  Die Abbildung $f$ ist stetig auf $D \perdef \forall x\in D \forall
  \varepsilon >0 \exists \delta_{\varepsilon} (x)>0 \forall y\in
  D\colon d(x,y)<\delta_{\varepsilon}(x)\Rightarrow
  \tilde{d}(f(x),f(y))<\varepsilon$. Offenbar gilt: $f$ ist
  gleichmässig stetig auf $D\Rightarrow f$ stetig auf $D$. Die
  Umkehrung gilt im Allgemeinen nicht.
\end{remark}

\begin{beispiel}
  Sei $D=\lsofint{0,1}\subset \R =X=Y, f(x)=\frac{1}{x}$. Es gilt,
  dass $f$ in $\lsofint{0,1}$ stetig, aber \emph{nicht} gleichmässig
  stetig ist.
\end{beispiel}

\begin{remark}[Negation von gleichmässiger Stetigkeit]
  Die Abbildung $f\colon D\rightarrow Y$ ist auf $D$ nicht
  gleichmässig stetig:
  \begin{gather*}
    \exists \varepsilon >0 \forall \delta>0 \exists
    x_{\delta},y_{\delta}\in D\colon
    \abs{x_{\delta}-y_{\delta}}<\delta \wedge
    \abs{f(x_{\delta})-f(y_{\delta})}\geq \varepsilon
  \end{gather*}
  In unserem Fall sei $\varepsilon=1$. Für $\delta>0$ wählen wir
  $x_{\delta}=\frac{\min\{1,\delta\}}{1+\delta}, y_{\delta} =
  \min\{1,\delta\} \in \lsofint{0,1}$. Dann:
  \begin{align*}
    \abs{x_{\delta}-y_{\delta}} &= y_{\delta}-x_{\delta}=
    \min\{1,\delta\}\left(1-\frac{1}{1+\delta}\right)=
    \min\{1,\delta\}\frac{\delta}{\delta+1} <\delta
    \intertext{und}
    \abs{f(x_{\delta})-f(y_{\delta})} &= \abs[\Big]{\frac{1}{x_{\delta}}
      -\frac{1}{y_{\delta}}}=
    \frac{1}{x_{\delta}}-\frac{1}{y_{\delta}} =
    \frac{1+\delta}{\min\{1,\delta\}}-\frac{1}{\min\{1,\delta\}} =
    \frac{\delta}{\min\{1,\delta\}}\geq \frac{\delta}{\delta}=1
  \end{align*}
  Somit ist $f(x)=\nicefrac{1}{x}$ nicht gleichmässig stetig auf
  $\lsofint{0,1}$.
\end{remark}

% Satz 7
\begin{theorem}\label{satz:gleichm-stetig}
  Sei $K\subset X$ kompakt und $f\colon K\rightarrow Y$ stetig. Dann gilt
  \begin{enumerate}[(1)]
  \item $f$ ist gleichmässig stetig auf $K$.
    \begin{proof}
      Annahme: $f$ ist stetig, aber nicht gleichmässig stetig auf
      $K$. Dann existiert $\varepsilon_0>0 \forall \delta >0 \exists
      x_{\delta},y_{\delta}\in K\colon d(x_{\delta},
      y_{\delta})<\delta\wedge\tilde{d}(f(x_{\delta}),f(y_{\delta}))\geq
      \varepsilon_0$. Insbesondere existiert für
      $\delta_n=\frac{1}{n}$ ein $x_n,y_n$ aus $K$ mit
      $d(x_n,y_n)<\frac{1}{n}$ und $\tilde{d}(f(x_1),f(y_1))\geq
      \varepsilon_0$.

      Wegen der Kompaktheit existiert eine Teilfolge $(x_{n_k})\subset
      (x_n)\colon x_{n_k}\rightarrow a\in K \Rightarrow
      (y_{n_k})\rightarrow a\in K$ gilt wegen $d(y_{n_k},a)\leq
      d(y_{n_k},x_{n_k})+d(x_{n_k},a)\xrightarrow{K\rightarrow\infty}0$.

      Stetigkeit: $f(x_{n_k})\rightarrow f(a), f(y_{n_k})\rightarrow
      f(a)$\lightning
    \end{proof}
  \item $f(K)$  ist kompakt.
    \begin{proof}
      Sei $(y_n)\subset f(K)$. Dann existiert $x_n \in K\colon
      f(x_n)=y_{n_k}$. Wegen der Kompaktheit von $K$ ergibt sich die
      Existenz einer Teilfolge $(x_{n_k})\subset (x_n)\colon x_{n_k}\rightarrow
    a \in K$. Da $f$ stetig ist, folgt $y_{n_k}=f(x_{n_k})\rightarrow
    f(a) \in f(K)$ und $f(K)$ ist kompakt.
    \end{proof}    
\end{enumerate}
\end{theorem}

% Satz 8
\begin{theorem}[Minimum und Maximum von Funktionen]\label{satz:max-fkt}
  Sei $K\subset X$ kompakt und $f\colon K\rightarrow\R$ stetig. Dann
  existiert ein $p \in K\colon f(p)=\sup_{x\in K}f(x)$\footnote{$f$
    nimmt auf $K$ ihr Maximum an.} und ein $q \in K\colon
  f(q)=\inf_{X\in K}f(x)$.\footnote{$f$ nimmt auf $K$ ihr Minimum an.}
  \begin{proof}
    Wegen der Stetigkeit von $f$ folgt nach
    \autoref{satz:gleichm-stetig} und nach \autoref{satz:beschr-abg}, dass
    $f(K)$ beschränkt ist. Wir setzen $M\coloneqq\sup_{x\in K}
    f(x)\in\R$. Da $K$ kompakt ist, existiert eine Teilfolge
    $(x_{n_k})\subset (x_n)\colon x_{n_k}\rightarrow p\in K$. Aufgrund
    der Stetigkeit von $f$ ist  $f(p)=\lim_{K\rightarrow \infty}
    f(x_{n_{k}})=M$.
  \end{proof}
\end{theorem}

\begin{remark}
  Der \autoref{satz:max-fkt} ist im Allgemeinen falsch, falls $K$
  nicht kompakt ist. Ein Beispiel hierfür ist die Funktion
  $f(x)=\frac{1}{x}$. Diese hat auf dem Intervall $\bsofint{0,\infty}$
  weder ein Maximum noch ein Minimum.
\end{remark}

\subsubsection{Ein Satz über inverse Funktionen}

%Satz 9
\begin{theorem}\label{satz:invFunkt}
  Sei $X$ ein kompakter metrischer Raum, die Abbildung $f\colon
  X\rightarrow Y$ stetig und injektiv. Dann gilt:
  \begin{gather*}
    f^{-1}\colon f(X)\rightarrow X\text{ist stetig}
  \end{gather*}
  \begin{proof}
    $Y_0 \coloneqq f(X)$ ist nach \autoref{satz:gleichm-stetig}
    kompakt. Nach \autoref{satz:fkt-aquiv} genügt es zu zeigen, dass
    die Urbilder von abgeschlossenen Mengen wieder abgeschlossen
    sind. Da $A\subset X$ abgeschlossen ist, folgt
    $(f^{-1})^{-1}(A)=f(A)$ abgeschlossen. Sei $(Y_n)\subset f(A),
    y_0\rightarrow b\in Y_{0}=f(X)$. Es ist zu zeigen, dass $b\in
    f(A)$. Dazu ist $x_n=f^{-1}(y_n)\in A\subset X$. Wegen der
    Kompaktheit von $X$ existiert eine Teilfolge $(x_{n_k})\subset (x_n)
    \colon x_{n_k}\rightarrow a\in X$ und aufgrund der Abgeschlossenheit
    von $A$ ist $a\in A$. Schließlich liefert die Stetigkeit von $f$
    das gewünschte Ergebnis: $b=\lim y_n=
    \lim_{n\rightarrow\infty}f(x_n)=\lim_{k\rightarrow\infty}f(x_{n_k})=f(a)\in
    f(A)= b\in f(A)$.
  \end{proof}
\end{theorem}

\section{Zwischenwert- und Fixpunktsatz}
\subsubsection{Zwischenwertsätze reeller Funktionen}

\begin{definition}[Reelle Funktion]
  Eine Funktion $f\colon D\rightarrow\R, D\subset \R$ nennt man
  \highl[Funktion!reelle]{reelle Funktion}.
\end{definition}

%Satz 10
\begin{theorem}[Zwischenwertsatz]\label{satz:zws}
  Sei $f\colon[a,b]\rightarrow \R$ stetig mit $f(a)<0$ und $f(b)>0$
  (bzw. umgekehrt). Dann existiert ein
  \begin{gather*}
    p\in[a,b]\colon f(p)=0
  \end{gather*}
  \begin{tikzpicture}[domain=-1.8:1.8]
    \draw[very thin,color=gray] (-2,-4) grid (2,4);
    \draw[->] (-2.2,0) -- (2.2,0) node[right] {$x$};
    \draw[->] (0,-4.2) -- (0,4.2) node[above] {$f(x)$};
    \draw[color=blue]   plot (\x,{(2*sin(\x r))-(3*cos(\x
      r))+(.25*\x*\x)})    node[right] {$f(x) = 2\sin x-3\cos
      x+0,25x^{2}$};
    \draw[dashed] (1.8,0) node[anchor=north] {$b$} -- (1.8,3.4393);
    \draw[dashed] (-1.8,0) node[anchor=south] {$a$} -- (-1.8,-.456);
    \draw (.9237,0) node[anchor=north] {$p$} circle (1pt);
  \end{tikzpicture}
  \begin{proof}
    Zur Beweisführung wird die Intervall-Halbierungsmethode heran
    gezogen: Sei $f(a)<0$ und $f(b)>0$. Wir definieren induktiv
    $[a_n,b_n]\subset [a,b]$ mit  $n\in \N$.
    \begin{enumerate}[(i)]
    \item $[a_n,b_n]\subset [a_{n-1},b_{n-1}], n\geq 1, [a_0,b_0]\coloneqq[a,b]$
    \item $b_n-a_n=2^{-n}(b-a)$
    \item $f(a_n)\leq 0, f(b_n)\geq 0$
    \end{enumerate}
    Der Induktionsanfang ist $[a_0,b_0]=[a,b]$. Im Induktionsschritt
    gehen wir von  $n$ zu $n+1$ über. Dazu sei $[a_n,b_n]$ bereits
    definiert und $m\coloneqq\frac{a_n+b_n}{2}$. Dann sind folgende
    zwei Fälle möglich:
    \begin{enumerate}[1.\,F{a}ll]
    \item $f(m)\geq 0$ Dann ist $[a_{n+1},b_{n+1}]\coloneqq[a_n,m]$.
    \begin{enumerate}[(i)]
    \item $[a_{n},m]\subset [a_{n}, b_{n}]$
    \item $b_{n+1}-a_{n+1} = m-a_n = \frac{a_n+b_n}{2}-a_n =
      \frac{1}{2}(b_n-a_n) = \frac{1}{2}2^{-n}(b-a)=2^{-(n+1)}(b-a)$
    \item $f(a_{n+1})=f(a_n)\geq 0, f(b_{n+1})=f(m)\geq 0$
    \end{enumerate}
  \item $f(m)<0$ Dann ist $[a_{n+1},b_{n+1}]\coloneqq[m,b_{n}]\subset [a_n,b_n]$
    \begin{enumerate}[(i)]
    \item $[m,b_{n}]\subset [a_n,b_n]$
    \item $b_{n+1}-a_{n+1} = b_n-m = b_n-\frac{a_n+b_n}{2} =
      \frac{1}{2}(b_n-a_n) = \frac{1}{2}2^{-n}(b-a) =2^{-(n+1)}(b-a)$
    \item $f(a_{n+1})=f(m)\leq 0, f(b_{n+1})\geq 0$
    \end{enumerate}
  \end{enumerate}
  Die Folge der $(a_n)$ ist monoton wachsend und beschränkt und die
  $(b_n)$ sind monoton fallend und beschränkt. Insgesamt ist
  $b_n-a_n=2^{-n}(b-a)$ und es folgt, $\lim a_n=\lim b_n=p$.

  Die Stetigkeit von $f$ und die vorige Fallunterscheidung liefern:
  \begin{gather*}
   \left.\begin{array}{rcl}
      f(p)=\lim f(a_n)\leq 0\\
      f(p)=\lim f(b_n)\geq 0
    \end{array}\right\}\Rightarrow f(p)=0 
  \end{gather*}
\end{proof}
\end{theorem}

\begin{Folg}[2.\,Zwischenwertsatz]
  Sei $f\colon[a,b]\rightarrow\R$ stetig und $c\in \R$ liegt zwischen
  $f(a)$ und $f(b)$. Dann existiert $p\in[a,b]\colon f(p)=c$.
  \begin{proof}
    Sei $f(a)<c<f(b)$. Wir definieren eine Funktion
    $g\colon[a,b]\rightarrow \R$ durch $g(x)\coloneqq f(x)-c$. Die
    Funktion $g$ ist stetig mit $g(a)=f(a)-c<0, g(b)=f(b)-c>0$. Dann
    folgt nach \autoref{satz:zws} $\exists p\in[a,b] \colon
    g(p)=f(p)-c=0\Rightarrow f(p)=c$.
  \end{proof}
\end{Folg}

\begin{Folg}
  Sei $f\colon[a,b]\rightarrow\R$ stetig mit $f([a,b])\subset
  [a,b]$. Dann existiert $p\in [a,b]\colon f(p)$. Der Punkt $p$ heißt
  \highl{Fixpunkt}.
\end{Folg}

\begin{remark}
  Der Zwischenwertsatz gilt nicht, wenn rationale Zahlen betrachtet
  werden. Beispielsweise gibt es für die Funktion $f(x)\coloneqq
  x^2-2$ keinen Fixpunkt im Intervall $[0,2]$, wenn das $x$ aus den
  rationalen Zahlen stammt.
\end{remark}


\subsection{Ein Satz über reelle inverse Funktionen}
\begin{definition}[monoton wachsend/fallend]
  Sei $f\colon D\rightarrow\R, D\subset \R$ eine reelle Funktion. Sie
  heißt genau dann \highl{monoton wachsend} auf $D$, wenn
  \begin{gather*}
    \forall x_1,x_2\in D\colon x_1<x_2\Rightarrow f(x_1)\leq f(x_2)
  \end{gather*}
  Sie heißt genau dann \highl{streng monoton wachsend} auf $D$, wenn
  \begin{gather*}
    \forall x_1,x_2\in D\colon x_1<x_2\Rightarrow f(x_1)<f(x_2)
  \end{gather*}
  Sie heißt genau dann \highl{monoton fallend} auf $D$, wenn
  \begin{gather*}
    \forall x_1,x_2\in D\colon x_1<x_2\Rightarrow f(x_1)\geq f(x_2)
  \end{gather*}
  Sie heißt genau dann \highl{streng monoton fallend} auf $D$, wenn
  \begin{gather*}
    \forall x_1,x_2\in D\colon x_1<x_2\Rightarrow f(x_1)>f(x_2)
  \end{gather*}
\end{definition}

%Satz 11
\begin{theorem}\label{satz:reellInvFkt}
  Sei $f\colon[a,b]\rightarrow\R$ eine stetige, streng monoton
  wachsende (fallende) Funktion und $A=f(a), B=f(b)$. Dann ist
  $f\colon[a,b]\rightarrow [A,B]$ bzw. $[B,A]$ bijektiv und
  $f^{-1}\colon[A,B]$ bzw. $[B,A]\rightarrow [a,b]$ ist stetig und
  streng monoton wachsend (fallend).
  \begin{proof}
    Sei $f\colon[a,b]\rightarrow\R$ stetig und streng monoton
    wachsend. Diese Funktion ist injektiv, denn für
    $x_1<x_2\Rightarrow f(x_1)<f(x_2)$. Weiterhin ist
    $f\colon[a,b]\rightarrow[A,B]$ surjektiv, denn wenn $A<c<B$ dann
    folgt nach dem zweiten Zwischenwertsatz $\exists p\in [a,b]\colon
    f(p)=c$. Daher ist $f$ bijektiv von $[a,b]\rightarrow [A,B]$.

    Die Umkehrabbildung $f^{-1}$ ist streng monoton wachsend. Es ist
    zu zeigen, dass $y_1,y_2\in [A,B]\colon y_1<y_2\rightarrow
    f^{-1}<f^{-1}$. Dazu nehmen wir an, $f^{-1}(y_1)\geq
    f^{-1}(y_2)\Rightarrow y_1=f(f^{-1}(y_1))\geq
    f(f^{-1}(y_2))=y_2$\lightning Schließlich ist
    $f^{-1}[A,B]\rightarrow [a,b]$ stetig. Denn nach
    \autoref{satz:invFunkt} ist auch $f$ auf der kompakten Menge
    $[a,b]$ stetig und bijektiv. Daher folgt, dass $^{-1}\colon
    f([A,B])=[A,B]\rightarrow [a,b]$ stetig.
  \end{proof}
\end{theorem}

\subsection{Der Banachsche Fixpunktsatz in vollständigen metrischen Räumen}

Zur Erinnerung sollte man sich nochmals \autoref{def:vollst}
anschauen. Dort wurde ein vollständiger metrischer Raum $X$ so
definiert, dass jede Cauchyfolge aus $X$ in $X$ konvergent ist.

\begin{remark}
  Eine abgeschlossene Teilmenge $A$ eines vollständigen metrischen
  Raumes $X$ ist in der Metrik von $X$ ebenfalls ein vollständiger
  metrischer Raum.
  \begin{proof}
    Sei $(x_n)\subset A$ eine Cauchyfolge. Dann ist $(x_n)\subset X$
    eine Cauchyfolge. Da $X$ vollständig ist, existiert ein $a\in X$
    für das gilt, $\lim x_n=a$. Aufgrund der Tatsache, dass $A$
    abgeschlossen ist, gilt nach \autoref{satz:abgTeilmenge}, dass
    $a\in A$ liegt. Daher folgt, dass $A$ abgeschlossen ist.
  \end{proof}
\end{remark}

\begin{beispiel}
  Sei $X=\R$. Dann sind $[a,b], \rsofint{a,\infty}$ und
  $\lsofint{\infty,a}$ ein vollständige metrische Räume. Hingegen ist
  $\bsofint{a,\infty}$ \emph{kein} vollständiger metrischer Raum.
\end{beispiel}

% Satz 12
\begin{theorem}[Banachscher Fixpunktsatz\index{Fixpunktsatz!Banachscher}]
  Dieser Satz wird auch das \highl{Prinzip der kontrahierenden
    Abbildung} genannt.

  Sei $(X,d)$ ein vollständiger metrischer Raum und $f\colon
  X\rightarrow X$ eine \highl[Abbildung!kontrahierende]{kontrahierende
    Abbildung}, d.\,h.
  \begin{gather*}
    \exists 0\leq\alpha <1 \forall x,y\in X\colon d(f(x),f(y))\leq
    \alpha d(x,y)
  \end{gather*}
  Dann gilt:
  \begin{enumerate}[(1)]
  \item $\exists!! a\in X\colon f(a)=a$. Man bezeichnet $a$ als
    \highl{Fixpunkt} von $f$.
  \item Sei $x_0\in X, x_{n+1}=f(x_{n}), n=0,1,2,\ldots \Rightarrow
    \lim x_n=a$. Wir haben die Fehlerabschätzung:
    $d(a,x_n)\leq\frac{\alpha^n}{1-\alpha}d(x_0,x_1)$.
  \end{enumerate}
  \begin{proof}
    Sei $x_0\in X$ beliebig und $x_{n+1}=f(x_{n}), n=0,1,2,\ldots$.
    \begin{enumerate}[1.\,Schr{i}tt]
    \item $(x_n)$ ist eine Cauchyfolge. Dann gilt:
      \begin{align*}
        d(x_{n+1},x_n) &= d(f(x_n),f(x_{n-1})) \leq \alpha
        d(x_n,x_{n-1}) \leq \alpha^2 d(x_{n-1},x_{n-2})\\
        & \leq \dotsb \leq \alpha^n d(x_1,x_0)
      \end{align*}
      Nach der Dreiecksungleichung gilt 
      \begin{align*}
        n>m\colon d(x_n,x_m) & \leq
        d(x_n,x_{x-1})+d(x_{n-1},x_{n-2})+\cdots +d(x_{m+1},x_m)\\
        & \leq (\alpha^{n-1}+\alpha^{n-2}+\cdots +\alpha^n)d(x_1,x_0)\\
        & = \alpha^m(\alpha^{n-m-1}+\alpha^{n-m-2}+\cdots +1)d(x_1,x_0)\\
        & = \alpha^m\left(\frac{1-\alpha^{n-m}}{1-\alpha}\right)d(x_1,x_0)\\
        & \leq \frac{\alpha^m}{1-\alpha}d(x_1,x_0)
      \end{align*}
      Also hat man $d(x_n,x_m)\leq
      \frac{\alpha^m}{1-\alpha}d(x_1,x_0)$ für $n>m$. Aus der
      Tatsache, dass $\alpha$ zwischen 0 und 1 liegt, folgt $\forall
      \varepsilon >0 \exists n_{\varepsilon}\in \N \forall n,m\geq
      n_{\varepsilon} \colon d(x_n,x_m)\leq \varepsilon$. Daher folgt
      weiter, dass $(x_n)$ eine Cauchyfolge ist. Weiterhin ist
      bekannt, dass $X$ vollständig ist. Dies bedingt, dass ein $a\in
      X$ existiert, für das $\lim x_n=a$ ist. Wegen der
      Dreiecksungleichung $\abs{d(a,x_m)-d(x_m,x_n)}\leq d(a,x_n)$
      ergibt sich für $n\rightarrow \infty$, dass $d(a,x_n)\rightarrow
      0\Rightarrow d(a,x_m)=\lim_{n\rightarrow\infty} d(x_n,x_m)\leq
      \frac{\alpha^m}{1-\alpha} d(x_1,x_0)$. Diese Formel impliziert
      die Fehlerabschätzung.
    \item $a$ ist Fixpunkt von $f$, also $a=\lim_{n\rightarrow\infty}
      x_{n+1} =\lim_{n\rightarrow\infty} f(x_n)$. Da $f$ stetig ist,
      kann man das wie folgt umformen: $\lim_{n\rightarrow\infty}
      f(x_n) =f(\lim_{n\rightarrow\infty} x_n)=f(a)$.
    \end{enumerate}

    Schließlich müssen wir noch die Eindeutigkeit des Fixpunktes
    zeigen. Dazu nehmen wir an, dass $a,b\in X$ mit $f(a)=a$ und
    $f(b)=b$  existieren. Dann gilt:
    \begin{align*}
      d(a,b) &=d(f(a),f(b)) \leq \alpha d(a,b)\\
      &\Rightarrow \underbrace{(1-\alpha)}_{>0}d(a,b) \Rightarrow
      d(a,b)\leq 0 \Rightarrow d(a,b)=0 \Rightarrow a=b
    \end{align*}
  \end{proof}
\end{theorem}

\begin{beispiel}
  Wir berechnen die zweite Wurzel $\sqrt{a}$ aus einer Zahl $a$. Dazu
  haben wir die Abbildung: $f(x)=\frac{1}{2}(x+\frac{a}{x})$ mit $X=
  \rsofint{\sqrt{a},\infty}$ und dem Betrag $d=\abs{\cdot}$. Damit ist
  $(X,d)$ ein vollständiger metrischer Raum.
  \begin{enumerate}
  \item $f(\rsofint{\sqrt{a},\infty})\subset
    \rsofint{\sqrt{a},\infty}$.
  \item $f$ ist kontrahierend: $\abs{f(x)-f(y)}\leq
    \frac{1}{2}\abs{x-y}$ mit $\alpha=\frac{1}{2}$.
  \item Der Fixpunkt $f(x)=x$ ist $x=\nicefrac{1}{2}
    (x+\nicefrac{a}{x}) \Rightarrow 2x-x = \nicefrac{a}{x} \Rightarrow
    x = \sqrt{a}$.
  \end{enumerate}
  
  Wir beginnen das Rechenbeispiel mit $a=2$. Dann ist
  $f(x)=\frac{1}{2}(x+\frac{2}{x})$ im Intervall $\rsofint{\sqrt{2},\infty}$.
  \begin{align*}
    x_0 & = 2\\
    x_1 & = f(x_0)=f(2)=\nicefrac{3}{2}\\
    x_2 & = f(x_1)= f(\nicefrac{3}{2})= \nicefrac{1}{2} (\nicefrac{3}{2}
    +\nicefrac{4}{3})=\nicefrac{17}{12}=1,41\overline{6}\\
    x_3 & = f(x_2)= f(\nicefrac{17}{12})= \nicefrac{1}{2}
    (\nicefrac{17}{12} +\nicefrac{24}{17})= \nicefrac{579}{408}=
    1,41415\overline{6}\\
    x_4 & = 1,4142135623746\ldots
  \end{align*}  
\end{beispiel}

\section{Elementare Funktionen}

\begin{remark}[Grenzwerte und Stetigkeit von reellen Funktionen]
  Sei $D\subset \R , f\colon D\rightarrow \R$ eine reelle Funktion,
  $a\in\R$ ist Häufungspunkt von $D$. Man schreibt:
  \begin{enumerate}[(1)]
  \item $\lim_{x\rightarrow a+0}f(x)=c\perdef \forall (x_n)\subset
    D\colon x_n>a, x_n\rightarrow a\Rightarrow f(x_n)=c$. Dann hat $f$ in $c$
    den \highl[Grenzwert!rechtsseitig]{rechtsseitigen Grenzwert}.
  \item $\lim_{x\rightarrow a-0}f(x)=c\perdef \forall (x_n)\subset
    D\colon x_n<a,x_n\rightarrow a\Rightarrow f(x_n)=c$. Dann hat $f$
    in $c$ den \highl[Grenzwert!linksseitig]{linksseitigen Grenzwert}.
  \item $\lim_{x\rightarrow a+0}f(x)=f(a)\perdef \forall \varepsilon
    >0 \exists \delta >0 \forall x \in D\colon 0\leq x-a<\delta
    \Rightarrow \abs{f(x)-f(a)}<\varepsilon$. Dann ist $f$
    \highl[Stetigkeit!linksseitig]{linksseitig stetig}.
  \item $\lim_{x\rightarrow a-0}f(x)=f(a)\perdef \forall \varepsilon
    >0 \exists \delta >0 \forall x \in D\colon 0\leq a-x<\delta
    \Rightarrow \abs{f(x)-f(a)}<\varepsilon$. Dann ist $f$
    \highl[Stetigkeit!rechtsseitig]{rechtsseitig stetig}.
  \item $\lim_{x\rightarrow\infty} f(x)=c\perdef \forall (x_n)\subset
    D (x_n \rightarrow \infty \Rightarrow f(x_n)\rightarrow c)$.
  \item $\lim_{x\rightarrow a} f(x)=\infty\perdef \forall (x_n)\subset
    D \setminus\{a\} (x_n \rightarrow a \Rightarrow f(x_n)\rightarrow
    \infty)$.
\end{enumerate}  
\end{remark}

\subsection{Polynome und rationale Funktionen}

\begin{definition}[Polynom, rationale Funktion]
  Eine Funktion $P\colon\R\rightarrow \R$ mit $P(x) =a_0 x^k + a_1
  x^{k-1} +\dotsb + a_{k-1} x+a_k$ mit $a_0\neq 0, k=0,1,2,\ldots)$
  heißt \highl{Polynom} $k$"=ten Grades.

  Eine Funktion $R(x)=\frac{P(x)}{Q(x)}$ mit $P,Q$ Polynomen heißt
  \highl[Funktion!rationale]{rationale Funktion}.
\end{definition}

Es gilt, $P\colon\R\rightarrow\R$ und $R\colon D\rightarrow\R$ mit
$D=\{x\in \R\colon Q(x)\neq0\}$ sind stetig.
\begin{proof}
  siehe \autoref{satz:e-d-stetig}
\end{proof}

Ferner gilt:
\begin{align*}
  \lim_{x\rightarrow\infty} P(x) &=
  \begin{cases}
    \infty, a_0>0, k\geq 1\\
    -\infty, a_0<0, k\geq 1
  \end{cases}\\
  \lim_{x\rightarrow\infty} P(x) &=
  \begin{cases}
    \infty, a_0>0, k \text{ gerade}\\
    -\infty, a_0<0, k \text{ gerade}\\-\infty, a_0>0, k \text{
      ungerade}\\\infty, a_0<0, k \text{ ungerade}
  \end{cases}\\
  P(x) &= x^k(a_0+\frac{a_1}{x}+\cdots + \frac{a_k}{x^k}), x \neq 0
\end{align*}

\subsection{Exponential-, Logarithmus- und Potenzfunktionen}

Zur Erinnerung: Die Funktion
\begin{gather*}
  \exp(x)\coloneqq\sum_{k=0}^\infty \frac{x^k}{k!}= 1+x+\frac{x^2}{2}+
  \frac{x^3}{3!}+\frac{x^4}{4!}+\dotsb
\end{gather*}
ist absolut konvergent für alle $x\in \R$. Somit definiert
$\exp\colon\R\rightarrow\R$ eine Funktion auf $\R$. Sie heißt
\highl{Exponentialfunktion}.

%Satz 13
\begin{theorem}\label{satz:expEigenschaft}
  Für $\exp\colon\R\rightarrow\R$ gelten folgende Eigenschaften:
  \begin{enumerate}[(i)]
  \item $\exp(0)=1, \exp(1)=e, \exp(x+y)=\exp(x)\cdot \exp(y), x,y \in
    \R$.
  \item $\exp(x)>0, x\in \R$
  \item $\exp(-x)=\exp(x)^{-1}$
  \item $e^n=\exp(n), n\in \Z$
  \item Abschätzung des Restgliedes:
    Es ist $\exp(x)=\sum_{k=0}^N \frac{x^k}{k!} + r_{N+1}(x)$, wobei
    $\abs{r_{N+1}(x)} \leq 2\frac{\abs{x}^{N+1}}{(N+1)!}$ für
    $\abs{x}\leq 1+\frac{N}{2}$ ist.
    \begin{proof}
      Die Beweise zu den ersten Punkten können im \autoref{cha:konvergenz}
      nachvollzogen werden. Zur Abschätzung des Restgliedes:
      \begin{align*}
        \abs{r_{N+1}(x)} &= \abs[\Big]{\sum_{k=N+1}^\infty
          \frac{x^k}{k!}} \leq \sum_{k=N+1}^\infty\frac{\abs{x}^k}{k!}\\
        &= \frac{\abs{x}^{N+1}}{(N+1)!} +\frac{\abs{x}^{N+2}}{(N+2)!}
        +\frac{\abs{x}^{N+3}}{(N+3)!} +\cdots\\
        &= \frac{\abs{x}^{N+1}}{(N+1)!} \left(1+\frac{\abs{x}}{N+2}
          +\frac{\abs{x}^2}{(N+2)(N+3)}+\dotsb\right)\\
        &\leq \frac{\abs{x}^{N+1}}{(N+1)!} \left(
          1+\frac{\abs{x}}{N+2}+ \frac{\abs{x}^2}{(N+2)^2}+
          \frac{\abs{x}^3}{(N+2)^3}+ \dotsb \right)\\
        &\leq \frac{\abs{x}^{N+1}}{(N+1)!} \left( 1+
          \frac{1}{2}\left(\frac{1}{2}\right)^2 +\dotsb +
          \left(\frac{1}{2}\right)^k\right) \text{ für }
        \frac{\abs{x}}{N+2}\leq \frac{1}{2}\\
        &= \frac{\abs{x}^{N+1}}{(N+1)!}\cdot \frac{1}{1-\frac{1}{2}}\\
        &= 2\frac{\abs{x}^{N+1}}{(N+1)!} \text{ für } \abs{x}\leq
        1+\frac{N}{2}
      \end{align*}      
    \end{proof}
  \end{enumerate}
\end{theorem}

% Satz 14
\begin{theorem}
  \begin{enumerate}[(i)]
  \item Die Exponentialfunktion $\exp\colon \R\rightarrow\R$ ist
    stetig, streng monoton wachsend und bildet $\R$ bijektiv auf
    $\bsofint{0,\infty}$ ab.
  \item Die Umkehrfunktion $ln\colon\bsofint{0,\infty}\rightarrow\R$
    ist stetig, monoton wachsend und heißt der
    \highl[Logarithmus!natürlicher]{natürliche Logarithmus}. Es gilt
    die Funktionalgleichung $ln(xy)=ln(x)+ln(y)$.
  \end{enumerate}
  \begin{tikzpicture}
    \draw[very thin,color=gray] (-2,-4) grid (2,4);
    \draw[->] (-2.2,0) -- (2.2,0) node[right] {$x$};
    \draw[->] (0,-4.2) -- (0,4.2) node[above] {$f(x)$};
    \draw[color=blue] plot[domain=-2:1.4] (\x, {exp(\x)}) node[right] {$f(x) =
      \exp(x)$};
    \draw[color=blue] plot[smooth] file {skript.ln.table} node[right] {$f(x)= \ln (x)$};
  \end{tikzpicture}
  \begin{proof}
\begin{enumerate}[zu (i)]
  \item zur Stetigkeit von $\exp$: $\exp$ ist in $x=0$ stetig, denn $0
    \leq\abs{\exp(x)-\exp(0)}= \abs{\exp(x)-1}\leq
    2\frac{\abs{x}}{1!}= 2x$ für $\abs{x}\leq 1$ und $(N=0)$. Somit
    folgt, $\lim_{x\rightarrow 0} \exp(x)= \exp(0)=1$ und damit die
    Stetigkeit in $x=0$. Die Stetigkeit in beliebigem $x_0\in \R$
    ergibt sich durch: $\lim_{x\rightarrow x_0} \exp(x)
    =\lim_{x\rightarrow x_0} (\exp(x-x_0)\cdot \exp(x_0))=
    \lim_{xß x_0\rightarrow 0} \exp(x-x_0)\cdot \lim_{x\rightarrow
      x_0} \exp(x_0)= \exp(0)\cdot \exp(x_0) =\exp(x_0)$.

    Nun müssen wir zeigen, dass $\exp$ streng monoton wachsend ist:
    Sei $x_0<x_1$. Dann ist $\exp(x_1)= \exp(x_1-x_0)\cdot \exp(x_0)>
    \exp(x_0)$ streng monoton wachsend.

    Schließlich bleibt die Bijektivität: Die Exponentialfunktion ist
    injektiv, da sie streng monoton wachsend ist. Ferner gilt:
    $0<\exp(x)<\infty$ für $x\in\R$ (nach
    \autoref{satz:expEigenschaft}). Es ist $\exp(x)\geq 1+x$ für
    $x\geq 0$. Damit ist der Grenzwert der Funktion für
    $x\rightarrow\infty$ unendlich. Andererseits gilt,
    $\lim_{x\rightarrow -\infty} \exp(x)= \lim_{x\rightarrow -\infty}
    \frac{1}{\exp(-x)}=0$.

    Sei $0<q<\infty$. Dann existieren $x_{0},
    x_{1}\in\R$ mit $x_{0}<x_{1}$ und $\exp(x_{0})<q<\exp(x_{1})$. Nach
    dem \autoref{satz:reellInvFkt} folgt, $\exp\colon[x_{0}, x_{1}]
    \rightarrow [\exp(x_{0}), \exp(x_{1})]$ und weiter existiert ein
    $p\in [x_{0}, x_{1}]$ mit $\exp(p)=q$. Damit ist die
    Exponentialfunktion in $\bsofint{0,\infty}$ injektiv und surjektiv.
  \item $\ln\coloneqq(\exp)^{-1}\colon \bsofint{0,\infty}\rightarrow\R$ ist stetig
    und streng monoton wachsend auf jedem kompakten Intervall
    $[a,b]\subset \bsofint{0, \infty}$ nach \autoref{satz:reellInvFkt}
    und damit auch auf $\bsofint{0,\infty}$.

    Die Funktionalgleichung ist:
    \begin{align*}
      \ln(\exp(\ln (x)+\ln(y))) &=\ln(\exp(\ln(x))\cdot \exp(\ln(y))) =
      \ln(x\cdot y)\\
      \ln(x)+\ln(y) &= \ln (\exp (\ln(x))\cdot \exp (\ln(y)))= \ln
      (x\cdot y)
    \end{align*}
  \end{enumerate}    
\end{proof}
\end{theorem}


\subsection{Exponentialfunktion zur Basis \texorpdfstring{$a$}{a}}

\begin{definition}[Exponentialfunktion zur Basis $a$]
  Sei $a>0, a\neq 1$. Dann heißt $\exp_a \colon\R\rightarrow\R$
  definiert durch $\exp_a (x)\coloneqq exp(x \ln (a))$
  \highl{Exponentialfunktion} zur Basis $a$.
\end{definition}

% Satz 15
\begin{theorem}\label{satz:expa}
  Die Funktion $\exp_a \colon\R\rightarrow\R$ ist stetig und es gilt:
  \begin{enumerate}[(i)]
  \item $\exp_a(x+y)=\exp_a(x)\cdot \exp_a(y)$ für  $x,y \in \R$
  \item $\exp_a(n)=a^n$ für $n\in \Z$
  \item $\exp_a (\frac{p}{q})= \sqrt[q]{a^p}=\colon a^{\frac{p}{q}}$
    für $p\in \Z , q\in \N$
  \end{enumerate}
  \begin{proof}
    Die Stetigkeit ergibt sich wegen $x \mapsto x \cdot \ln (a)$. Dabei
    ist $\ln(a)$ eine Konstante. Weiterhin ist $f(x)=x\cdot \ln(a)$
    und $g(x)=\exp(x)$. Insgesamt ist somit $\exp_a(x)=g(f(x))$. Die
    Komposition von stetigen Funktionen ist wieder stetig.
    \begin{enumerate}[i)]
    \item \begin{align*}
        \exp(x+y) & = \exp((x+y)\ln (a))= \exp(x \cdot \ln (a))\cdot
        \exp(y\cdot \ln(a))\\
        & = \exp_a(x)\cdot \exp_a(y)
      \end{align*}
    \item Für $n\in \N$ ist $\exp_a (n)=\exp(n\cdot \ln(a))=
      \exp(\ln(a^n))= a^n$ und für $-n\in \N$ ist
      $\exp_a(n)=\frac{1}{\exp(-n)} =\frac{1}{a^{-n}}=a^n$.
    \item Sei $p\in \Z, q\in \N$. Dann ist $a^p=\exp_a(p)=
      \exp_a(q\frac{p}{q})= \left(\exp_a(\frac{p}{q})\right)^q$ und es
      folgt, $\exp_a(\frac{p}{q})=\sqrt[q]{a^p}=a^{\frac{p}{q}}$.
    \end{enumerate}
  \end{proof}
\end{theorem}

\begin{remark}
  Der \autoref{satz:expa} rechtfertigt die Bezeichnung $a^x\coloneqq
  \exp_a(x)$. Für $a=e$ hat man $e^x=\exp_e(x)=\exp(x)$, da
  $\ln(e)=1$. Die Funktionalgleichung aus \autoref{satz:expa} Punkt~(i) hat
  jetzt die Form $a^{x+y}=a^x\cdot a^y$ für $x,y\in \R$.
\end{remark}

% Satz 16
\begin{theorem}
  Für $a,b>0$ und $x,y\in \R$ gilt:
  \begin{enumerate}[i)]
  \item $(a^x)^y=a^{xy}$, denn wegen $\ln(a^x)=\ln(\exp(x \cdot \ln(a)))$ gilt
    $\ln (a^x)=x \cdot \ln (a)$. Damit $(a^x)^y=\exp(y\cdot
    \ln(a^x))=\exp(xy\cdot \ln(a)) =a^{xy}$.
  \item $a^x\cdot b^x=(ab)^x$, denn $a^x b^x= \exp(x\cdot \ln(a))
    \cdot \exp(x\cdot \ln(b))= \exp(x(\ln(a)+\ln(b)))=
    \exp(x(\ln(ab)))= (ab)^x$.
  \item $(\frac{1}{a})^x=\frac{1}{a^x}=a^{-x}$, denn $(\frac{1}{a})^x=
    (a^{-1})^x=a^{-x}$.
  \end{enumerate}
\end{theorem}

\begin{remark}
  Es gilt $\exp_a \colon\R\rightarrow \bsofint{0,\infty}$ ist stetig
  und bijektiv für $a>0, a\neq 1$. Ferner: streng monoton wachsend für
  $a>1$ und streng monoton fallend für $a<1$.  Die Umkehrfunktion
  $\log_a\coloneqq(\exp_a)^{-1}$ heißt \highl{Logarithmus} zur Basis
  $a$. Es gilt $\log_a\colon \bsofint{0,\infty} \rightarrow \R$ ist
  stetig und streng monoton wachsend für $a>1$ und streng monoton
  fallend für $a<1$.
  \begin{proof}
    $\log_ax=\frac{\ln(x)}{\ln(a)}$, denn $\exp_a \log_a(x)=
    \exp(\frac{\ln(x)}{\ln(a)}\cdot \ln (a))= \exp (\ln (x))=x$.
  \end{proof}
\end{remark}

\subsection{Die Potenzfunktion}
\begin{definition}[Potenzfunktion]
  Sei $\alpha>0$. Dann heißt $f_{\alpha}(x)=x^{\alpha}$ für $x\geq 0$
  \highl{Potenzfunktion} mit \highl[Exponent]{Exponenten} $\alpha$.
\end{definition}

\begin{remark}
  Es gilt: $f_{\alpha}\colon \rsofint{0,\infty}\rightarrow
  \rsofint{0,\infty}$ ist stetig, bijektiv und streng monoton
  wachsend.
  \begin{proof}
    $x^{\alpha}=\exp(\alpha \ln x)=e^{\alpha \ln x}$.
  \end{proof}
\end{remark}

\section{Konvergenz in \texorpdfstring{$\C$}{C}}
\subsection{Der vollständige metrische Raum der komplexen Zahlen}

Sei $\C$ der Körper der komplexen Zahlen. Dann ist $z\coloneqq x+iy$
mit $i=\sqrt{-1}$ und $x,y \in \R$. Man bezeichnet $x$ als den
\highl{Realteil} von $z$ mit $x=\Re z$ und $y$ als den
\highl{Imaginärteil} von $z$ mit $y=\Im z$. Für $z_1 = x_1+iy_1$ und $z_2
= x_2+iy_2$ gelten folgende Rechenregeln:
\begin{align*}
  z_1+z_2 &\coloneqq (x_1+x_2)+i(y_1+y_2)\\
  z_1z_2 &\coloneqq (x_1x_2-y_1y_2)+i(x_1y_2+x_2y_1)\\
  z_1=x_1+iy_1=z_2=x_2+iy_2 & \Leftrightarrow x_1=x_2, y_1=y_2, \Re z_1=\Re z_2, \Im z_1=\Im z_2
\end{align*}

\begin{description}
  \item[konjugiert komplexe Zahl\index{Zahl!konjugiert komplexe}]
    definiert durch $\overline{z}=x-iy$. Für $z \in \R$ gilt,
    $z=\overline{z}$. Außerdem ist $\Re z=\frac{1}{2}(z+\overline{z})$
    und $\Im z=\frac{1}{2i}(z-\overline{z})$.
  \item[Rechenregeln]
    $\overline{\overline{z}}=\overline{\overline{x+iy}}=
    \overline{x-iy}= x-(-iy)= x+iy= z,
    \overline{z_1+z_2}=\overline{x_{1}+iy_{1}+ x_{2}+iy_{2}}=
    \overline{x_{1}+x_{2}+i (y_{1}+y_{2})}= x_{1}+x_{2}-i
    (y_{1}+y_{2})= x_{1}-iy_{1}+ x_{2}-iy_{2}= \overline{z_1}+\overline{z_2},
    \overline{z_1z_2}=\overline{z_1}\cdot\overline{z_2}$
  \item[Betrag einer komplexen Zahl] definiert durch $\abs{z}=
    \sqrt{z\overline{z}}= \sqrt{x^2+y^2}$. Real- und Imaginärteil
    einer komplexen Zahl $z$ sind immer kleiner oder gleich $z$.
    \begin{enumerate}[(1)]
      \item $\abs{z}\geq 0, \abs{z}=0\Leftrightarrow z=0$\\
        Der Nachweis hierzu ist trivial zu führen.
      \item $\abs{z_1z_2}=\abs{z_1}\abs{z_2}$, denn $\abs{z_1z_2}^2=
        (z_1z_2) (\overline{z_1z_2})= (z_1z_2)
        (\overline{z_1}\cdot\overline{z_2})= (z_1\overline{z_1})
        (z_2\overline{z_2})= \abs{z_1}^2\abs{z_2}^2$.
      \item $\abs{z_1+z_2}\leq \abs{z_1}+\abs{z_2}$, denn
        $\abs{z_1+z_2}^2= (z_1+z_2) (\overline{z_1+z_2})=
        z_1\overline{z_1}+ z_1\overline{z_2}+ z_2\overline{z_1}+
        z_2\overline{z_2}= \abs{z_1}^2+ (z_1\overline{z_2}+
        z_2\overline{z_1})+\ abs{z_2}^2	=\abs{z_1}^2+ 2\Re
        (z_1\overline{z_2})+ \abs{z_2}^2 \leq \abs{z_1}^2+
        2\abs{z_1\underbrace{\overline{z_2}}_{=\abs{z_2}}}
        +\abs{z_2}^2=(\abs{z_1}^2+\abs{z_2}^2)^2$
      \item $d(z_1,z_2)=\abs{z_1-z_2}$.
        Hierdurch wird eine Metrik auf $\C$ erklärt.
    \end{enumerate}
\end{description}

%Satz 17
\begin{theorem}
\begin{enumerate}[(1)]
  \item Es gilt, $\lim z_n= z\Leftrightarrow \lim\Re z_n =\Re z \wedge
    \lim \Im z_n=\Im z$. Dies folgt aus $\max\{\abs{\Re z},\abs{\Im
      z}\}\leq \abs{z}\leq 2\max\{\abs{\Re z},\abs{\Im z}\}$.
  \item Es gilt, $\lim z_n= z\Leftrightarrow \lim \overline{z_n}
    =\overline{z_n}$, denn
    $\abs{z_n-z}=\abs{\overline{z_n-z}}=\abs{\overline{z_n}-\overline{z}}$.
  \item $(\C,\abs{\cdot })$ ist ein vollständiger metrischer
    Raum. Dies folgt aus dem Punkt~(1) und der Tatsache, dass $\R$
    vollständig ist.
  \end{enumerate}
\end{theorem}

\subsubsection{Reihen in \texorpdfstring{$\C$}{C}}

Sei $(z_n)\subset \C$ eine Folge in $\C$ und $s_n\coloneqq\sum_{k=0}^n
z_k$ die $n$"=te \highl{Partialsumme}. Dann heißt,
$\sum_{k=0}^{\infty} z_k\coloneqq(s_n)$ \highl{Reihe}. Für den Wert
der Reihe gilt, falls $(s_{n})$ konvergiert:
\begin{gather*}
  \sum_{k=0}^{\infty} z_k\coloneqq\lim s_n 
\end{gather*}
Weiterhin gilt:
\begin{gather*}
  \overline{\sum_{k=0}^{\infty} z_k}=\sum_{k=0}^\infty \overline{z_k}
\end{gather*}
\begin{proof}
  Es gilt, $\overline{\lim s_n}= \overline{\lim\sum_{k=0}^\infty z_k}=
  \lim \overline{\sum_{k=0}^\infty z_k}= \lim \sum_{k=0}^\infty
  \overline{z_k}=\lim \overline{s_n}$. In $\C$ existiert \emph{keine}
  Kleiner"=Gleich"=Beziehung. Für Reihen gelten im wesentlichen die
  gleichen Aussagen wie für Reihen in $\R$.
\end{proof}

\subsubsection{Die Exponentialfunktion in \texorpdfstring{$\C$}{C}}

Die Reihe $\sum_{k=0}^\infty \frac{z^k}{k!}$ ist für jedes $z\in\C$
absolut konvergent, d.\,h. $\sum \frac{\abs{z^k}}{k!}  <\infty$.
\begin{definition}[Exponentialfunktion in $\C$]
  Man bezeichnet
  \begin{gather*}
    e^z\coloneqq\exp(z)=\sum_{k=0}^\infty \frac{z^k}{k!}\quad
    z\in\C, \exp\colon\C\rightarrow\C
  \end{gather*}
  als \highl{Exponentialfunktion} in $\C$.
\end{definition}

\begin{remark}[Eigenschaften]
  \begin{enumerate}[(i)]
  \item Funktionalgleichung: $e^{z_1+z_2} =e^{z_1}e^{z_2}$ für
    $z_1,z_2\in\R$. Die Multiplikation von Reihen ist ähnlich wie im
    Reellen (siehe voriges Kapitel).
  \item $\overline{e^z}=e^{\overline{z}}$, denn
    $\overline{\sum_{k=0}^\infty \frac{z^k}{k!}}= \sum_{k=0}^\infty
    (\overline{\frac{z^k}{k!}})= \sum_{k=0}^\infty
    \frac{\overline{z^k}}{k!}$.
  \item $\abs{e^z}=e^{\Re (z)}>0$, denn $e^z= e^{\Re (z)+ i\Im (z)}=
    e^{\Re (z)}\cdot e^{i\Im (x)}\Rightarrow \abs{e^z}= \abs{e^{\Re (z)}}
    \abs{e^{i\Im (x)}} =e^{\Re (z)}\cdot \abs{e^{i\Im (x)}}$. Nun ist
    zu zeigen, $\abs{e^{i\Im (z)}}=1$. Dazu:
    $\abs{e^{i\Im (z)}}= e^{i\Im (z)}\cdot \overline{e^{i\Im (z)}}=
    e^{i\Im (z)} e^{-i\Im (z)}=1$.
  \item $\abs{e^z-\sum_{k=0}^N \frac{z^k}{k!}}\leq
    2\frac{\abs{z}^{N+1}}{(N+1)!}$ für $\abs{z}\leq 1+\frac{N}{2}$.
    Der Beweis wird wie im Reellen geführt.
  \item Die Funktion $\exp\colon\C\rightarrow\C$ ist stetig. Der
    Beweis wird wie im Reellen geführt.
  \item Es gilt, $\lim_{z\rightarrow 0}\frac{e^z-1}{z}=1$. Denn
    $\abs{e^z-(1+z)} \leq \abs{z}^2$ für $\abs{z}\leq
    \frac{3}{2}$. Damit folgt, $\abs{\frac{e^z-1}{z}-1}\leq \abs{z}^2$
    und $\lim_{z\rightarrow 0}\frac{{e^z}-1}{z}=1$.
  \end{enumerate}  
\end{remark}

\subsection{Trigonometrische Funktionen}
\begin{definition}[Sinus und Kosinus]
  Sei $x\in\R$. Dann gilt:
  \begin{align*}
    \cos x &\coloneqq \Re (e^{ix})\\
    \sin x &\coloneqq \Im (e^{ix})
  \end{align*}
  Man bezeichnet $\cos$ als \highl{Kosinus} und $\sin$ als
  \highl{Sinus}.
\end{definition}

Also ist $\abs{e^{ix}}^2=1=\cos^2 x+\sin^2 x$. Insbesondere folgt,
dass $\abs{\cos x}, \abs{\sin x}\leq 1$.

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}
  [scale=3,line cap=round
  % Styles
  axes/.style=,
  important line/.style={very thick},
  information text/.style={rounded corners,fill=red!10,inner sep=1ex}]
  % Local definitions
%skript-check aus
  \def\costhirty{0.8660256}
%skript-check an
  % Colors
  \colorlet{anglecolor}{green!50!black}
  \colorlet{sincolor}{red}
  \colorlet{tancolor}{orange!80!black}
  \colorlet{coscolor}{blue}
  % The graphic
  \draw[help lines,step=0.5cm] (-1.4,-1.4) grid (1.4,1.4);
  \draw (0,0) circle (1cm);
  \begin{scope}
    \draw[->] (-1.5,0) -- (1.5,0) node[right] {$x$} coordinate(x axis);
    \draw[->] (0,-1.5) -- (0,1.5) node[above] {$y$} coordinate(y axis);
    \foreach \x/\xtext in {-1, -.5/-\frac{1}{2}, 1}
      \draw[xshift=\x cm] (0pt,1pt) -- (0pt,-1pt) node[below,fill=white] {$\xtext$};
    \foreach \y/\ytext in {-1, -.5/-\frac{1}{2}, .5/\frac{1}{2}, 1}
      \draw[yshift=\y cm] (1pt,0pt) -- (-1pt,0pt) node[left,fill=white] {$\ytext$};
  \end{scope}
  \filldraw[fill=green!20,draw=anglecolor] (0,0) -- (3mm,0pt) arc(0:30:3mm);
  \draw (15:2mm) node[anglecolor] {$\alpha$};
  \draw[important line,sincolor]
    (30:1cm) -- node[left=1pt,fill=white] {$\sin \alpha$} (30:1cm |- x axis);
  \draw[important line,coscolor]
    (30:1cm |- x axis) -- node[below=2pt,fill=white] {$\cos \alpha$} (0,0);
  \draw[important line,tancolor] (1,0) -- node[right=1pt,fill=white] {
    $\displaystyle \tan \alpha \color{black}=
    \frac{{\color{sincolor}\sin \alpha}}{\color{coscolor}\cos \alpha}$}
    (intersection of 0,0--30:1cm and 1,0--1,1) coordinate (t);
  \draw (0,0) -- (t);
\end{tikzpicture}
  \caption{Sinus und Kosinus}
  \label{fig:sin-cos}
\end{figure}

%Satz 18
\begin{theorem}
  Seien $x,y\in\R$:
  \begin{enumerate}[i)]
  \item \begin{align*}
      \cos x &= \frac{1}{2}(e^{ix}+e^{-ix})= \sum_{k=0}^\infty
      (-1)^k \frac{x^{2k}}{(2k)!}\\
      \sin x &= \frac{1}{2i}(e^{ix}-e^{-ix}) = \sum_{k=1}^\infty
      (-1)^{k-1}\frac{x^{2k-1}}{(2k-1)!}
    \end{align*}
  \item \begin{align*}
    \cos (-x) & = \cos x & \cos 0 &= 1\\
    \sin (-x) & = -\sin x & \sin 0 &=0
  \end{align*}
  \item Additionstheoreme:
  \begin{align*}
    \cos (x\pm y) & = \cos x \cos y \mp \sin x \sin y\\
    \sin (x\pm y) & = \sin x \cos y \pm \cos x \sin y\\
    \sin x - \sin y & = 2\cos (\frac{x+y}{2})\sin (\frac{x-y}{2})\\
    \cos x - \cos y & = -2\sin (\frac{x+y}{2})\sin(\frac{x-y}{2})
  \end{align*}
  \item $\lim_{x\rightarrow 0} \frac{\sin x}{x}=1$
  \item $\left.\begin{array}{rcl}
    \cos \colon\R\rightarrow\R\\
    \sin \colon \R\rightarrow\R\end{array}\right\}$ stetig
  \item Der Kosinus hat eine kleinste positive Nullstelle $a$ mit $1<a<2$. Man setzt $\pi\coloneqq2a\Rightarrow
    \sin \frac{\pi}{2}=1$\todo{Beweis aus Hefter einfuegen}
  \item Kosinus und Sinus sind $2\pi$"=periodisch:
    \begin{alignat*}{2}
      \cos (x+2\pi) & = \cos x & \qquad \cos (x+\frac{\pi}{2}) & = -\sin x\\
      \sin (x+2\pi) & = \sin x & \qquad \sin (x+\frac{\pi}{2}) & = \cos x
    \end{alignat*}
  \item $\sin \colon [-\frac{\pi}{2},\frac{\pi}{2}]$ ist streng monoton wachsend.\\
    $\cos \colon [0,\pi]$ ist streng monoton fallend
\end{enumerate}
\end{theorem}

\chapter{Differentiation reeller Funktionen}
\section{Definition, Rechenregeln und Beispiele}

\begin{definition}[Differenzierbarkeit]
  Sei $D\subseteq \R$ und $f\colon D\rightarrow\R$ eine reelle
  Funktion sowie $a\in D$ ein Häufungspunkt von $D$. Die Funktion $f$
  heißt genau dann
  \highl{differenzierbar}\index{Funktion!differenzierbare} in $a$,
  wenn gilt:
  \begin{align*}
    \exists c \in\R \exists r\colon D\backslash\{a\}\rightarrow\R
    &\colon \lim_{x\rightarrow a} \frac{r(x)}{x-a}=0\\
    \forall x \in D &\colon f(x)=f(a)+c(x-a)+r(x)
  \end{align*}
\end{definition}

Es gilt, $c$ ist eindeutig bestimmt. Denn seien $c_1,c_2 \in \R$. Dann
ist für alle $x \in D$:
\begin{align*}
  f(x) &= f(a)+c_1(x-a)+r_1(x)\\
  f(x) &=f(a)+c_2(x-a)+r_2(x)\\
  \lim_{x\rightarrow a} \frac{r_1(x)}{x-a} &=\lim_{x\rightarrow
    a}\frac{r_2(x)}{x-a}=0\\
  &\Rightarrow c_1(x-a)+r_1(x)=c_2(x-a)+r_2(x)\\
  &\Rightarrow c_1=c_2+\frac{r_2(x)}{x-a}-\frac{r_1(x)}{x-a}\\
  &\Rightarrow c_1=c_2\text{ für } \lim_{x\rightarrow a}
\end{align*}

\begin{remark}
  Wir schreiben, $f'(a)=c$ oder $\diff{f}{x}(a)=c$. Weiterhin heißt
  $c$ \highl{Ableitung} von $f$ an der Stelle $a$ und $f$ heißt genau
  dann \emph{differenzierbar} in $D$, wenn $f$ in jedem Punkt $a\in D$
  diffenzierbar ist.

  Die Differenzierbarkeit einer Funktion $f$ in $a\in D$ ist
  gleichbedeutend mit der Approximierbarkeit durch eine affin"=lineare
  Funktion, d.\,h. ein Polynom\index{Polynom} ersten Grades:
  \begin{gather*}
    L(x)=f(a)+c(x-a)
  \end{gather*}
  Der Graph von $L$ ist die Tangente an dem Graphen von $f$ in
  $(a,f(a))$.
\end{remark}

%Satz 1
\begin{theorem}["`Schulversion"' der Differenzierbarkeit]
  Die Funktion $f$ ist genau dann in $a\in D$ differenzierbar, wenn
  $\lim_{x\rightarrow a} \frac{f(x)-f(a)}{x-a}$
  existiert.
  \begin{proof}
    \begin{itemize}
    \item["`$\Rightarrow$"'] Sei $f$ in $a\in D$ differenzierbar. Dann
      ist $f(x)=f(a)+c(x-a)+r(x)$ mit $\lim_{x\rightarrow a}
      \frac{r(x)}{x-a}=0$. Umstellen der Gleichung ergibt
      $\frac{f(x)-f(a)}{x-a}=c+\frac{r(x)}{x-a}$. Aufgrund der
      Limesbedingung ergibt sich dann $\lim_{x\rightarrow a}
      \frac{f(x)-f(a)}{x-a}=c$.
    \item["`$\Leftarrow$"'] Sei $\lim_{x\rightarrow a}
      \frac{f(x)-f(a)}{x-a}\coloneqq c$ und $r(x)\coloneqq
      f(x)-f(a)-c(x-a)$. Dann ist $f(x)=f(a)+c(x-a)+r(x)$ und
      $\frac{r(x)}{x-a}=
      \frac{f(x)-f(a)}{x-a}-c\xrightarrow{x\rightarrow a} c-c=0$.
    \end{itemize}
  \end{proof}
\end{theorem}

\begin{remark}[Geometrische Interpretation]
  Der \highl{Differenzenquotient} $\frac{f(x)-f(a)}{x-a}$ ist die
  Steigung der \highl{Sekante} von $f$ durch die Punkte $(x,f(x))$ und
  $(a,f(a))$. Beim Grenzübergang $x\rightarrow a$ geht die Sekante in
  die \highl{Tangente} vom Graphen $f$ im Punkt $(a,f(a))$ über. Also
  ist $f'(a)$ die Steigung der Tangente in $(a,f(a))$.
\end{remark}

\begin{beispiel}
  \begin{enumerate}[(1)]
  \item $f\colon\R\rightarrow\R, f(x)=c$ konstante Funktion. Es gilt:
    $f'(a)=0$. Denn $f'(a)=\lim_{x\rightarrow a} \frac{f(x)-f(a)}{x-a}
    =\lim_{x\rightarrow a} \frac{c-c}{x-a}=0$.
  \item $f\colon\R\rightarrow\R, f(x)=cx, f'(a)=c$. Denn: $f'(a)=
    \lim_{x\rightarrow a} \frac{f(x)-f(a)}{x-a} =\lim_{x\rightarrow a}
    \frac{cx-ca}{x-a} =\lim_{x\rightarrow a}\frac{c(x-a)}{x-a}=c$.
  \item $f\colon\R\rightarrow\R, f(x)=e^x, f'(a)=e^x$
    Exponentialfunktion. Denn: $f'(a)=\lim_{x\rightarrow a}
    \frac{f(x)-f(a)}{x-a} =\lim_{x\rightarrow a} \frac{e^x-e^a}{x-a}=
    \lim_{x\rightarrow a}e^a\frac{e^{x-a}-1}{x-a}= \lim_{x\rightarrow
      a} \underbrace{e^a}_{\text{konstant}}
    \underbrace{\lim_{x\rightarrow
        a}\frac{e^{x-a}-1}{x-a}}_{=1}=e^a\cdot 1$.
 \end{enumerate}
\end{beispiel}

\begin{theorem}
  Ist $f\colon D\rightarrow\R$ in $a\in D$ differenzierbar, so ist $f$
  in $a$ stetig.
  \begin{proof}
    $f(x)=f(a)+f'(a)(x-a)+r(x), \lim_{x\rightarrow
      a}\frac{r(x)}{x-a}=0, \frac{r(x)}{x-a}\rightarrow 0 \Rightarrow
    \lim_{x\rightarrow a}r(x)=0$. Denn es gilt: $\lim_{x\rightarrow a}
    r(x)=\lim_{x\rightarrow a} (x-a)\frac{r(x)}{x-a}=\lim_{x\rightarrow a}
    (x-a) \lim_{x\rightarrow a} \frac{r(x)}{x-a}=0\cdot 0=0$. Somit folgt:
    $\lim_{x\rightarrow a} f(x)=\lim_{x\rightarrow a}
    (f(a)+f'(a)(x-a)+r(x))=\lim_{x\rightarrow a}
    f(a)+\lim f'(a)(x-a)+\lim r(x) =f(a)+0+0=f(a)$ und es folgt die Stetigkeit.
  \end{proof}
\end{theorem}

%Satz 2
\begin{theorem}[Rechenregeln für differenzierbare Funktionen]
\begin{enumerate}[(1)]
\item Seien $f,g\colon D\rightarrow \R$ in $x\in D$ differenzierbar
  und $\lambda\in\R$. Dann sind die Funktionen $f+g, \lambda f, f\circ
  g\colon D\rightarrow\R$ in $x\in D$ differenzierbar und es gilt:
  \begin{itemize}
  \item $(f+g)'(x)=f'(x)+g'(x)$
  \item $(\lambda f)'(x)=\lambda f'(x)$
  \item \highl{Produktregel}: $(f\cdot g)'(x)=f'(x)g(x)+f(x)g'(x)$
  \end{itemize}
  Ist $g(\xi)\neq 0$ für alle $\xi\in D$, so ist $\frac{f}{g}\colon
  D\rightarrow\R$ in $x\in D$ differenzierbar und es gilt:
  \begin{itemize}
  \item $(\frac{f}{g})' (x) =\frac{f'(x)g(x)-f(x)g'(x)}{(g(x))^2}$
  \end{itemize}
\item \highl{Kettenregel}: Seien $f\colon D\rightarrow\R, g\colon
  E\rightarrow\R$ Funktionen mit $f(D)\subset E$ und $f$ sei in $x\in
  D$ und $g$ in $y=f(x)$ differenzierbar. Dann ist $g\circ f\colon
  D\rightarrow\R$ in $x$ differenzierbar und es gilt:
  \begin{itemize}
  \item $(g\circ f)'(x)=g'(f(x))\cdot f'(x)$
  \end{itemize}
\item \highl[Umkehrfunktion!Ableitung]{Ableitung der Umkehrfunktion}:
  Sei $D\subset \R$ ein abgeschlossenes Intervall und $f\colon
  D\rightarrow\R$ eine stetige, streng monotone Funktion sowie
  $f^{-1}\colon\tilde{D}=f(D)\rightarrow\R$ die Umkehrfunktion. Ist
  weiterhin $f$ in $x\in D$ differenzierbar und $f'(x)\neq 0$, so ist
  $f^{-1}$ in $y=f(x)$ differenzierbar. Es gilt
  \begin{itemize}
  \item $(f^{-1})'(x)=\frac{1}{f'(x)}=\frac{1}{f'(f^{-1}(y))}$
  \end{itemize}
\end{enumerate}
\begin{proof}
  Die Produktregel lässt sich wie folgt beweisen: Sei $x\in D$ und
  $x+h\in D$. Für den Differenzenquotient ergibt sich dann:
  \begin{align*}
    \frac{(fg)(x+h)-(fg)(x)}{h} &= \frac{f(x+h)g(x+h)-f(x)g(x)}{h} =
       \frac{f(x+h)g(x+h)-f(x+h)g(x)+f(x+h)g(x)-f(x)g(x)}{h}\\
    &= f(x+h)\frac{g(x+h)-g(x)}{h}+ g(x)\frac{f(x+h)-f(x)}{h}\\
    &\xrightarrow{h\rightarrow0} f(x)g'(x)+f'(x)g(x)
  \end{align*}

  Zum Beweis der Quotientenregel betrachten wir zunächst den Spezialfall
  $\nicefrac{1}{g}$:
  \begin{align*}
    \frac{(\frac{1}{g})(x+h)-(\frac{1}{g})(x)}{h} &= \frac{\frac{1}{g(x+h)}-
       \frac{1}{g}}{h}=\frac{\frac{g(x)-g(x+h)}{g(x+h)g(x)}}{h}\\
    &= -\frac{1}{g(x+h)g(x)} \frac{g(x+h)-g(x)}{h}\\
    &\xrightarrow{h\rightarrow0} -\frac{g'(x)}{(g(x))^{2}}
  \end{align*}
  Allgemein haben wir dann:
  \begin{align*}
    \left(\frac{f}{g}\right)'(x) &= f'(x)\cdot(\frac{1}{g})(x)+
       f(x)\cdot(\frac{1}{g})'(x)=
       \frac{f'(x)}{g(x)}-f(x)\cdot\frac{g'(x)}{(g(x))^{2}}\\
    &= \frac{f'(x)g(x)-f(x)g'(x)}{(g(x))^{2}}
  \end{align*}

  Für den Beweis der Kettenregel definieren wir $g^{*}\colon E\rightarrow\R$
  durch:
  \begin{gather*}
    g^{*}(\rho)=
       \begin{cases}
	 \frac{g(\rho)-g(y)}{\rho-y} & \rho\neq y\\
	 g'(y) & \rho=y
       \end{cases}
  \end{gather*}
  Es gilt, $\lim_{\rho\rightarrow y} g^{*}(\rho)= g'(y)$, d.\,h. $g^{*}$ ist
  in $y$ stetig. Für $\rho\in E$ ist $g(\rho)-g(y)= g^{*}(\rho)(\rho-y)$.
  Somit haben wir:
  \begin{align*}
    (g\circ f)'(x) &= \lim_{\xi\rightarrow x} \frac{g(f(\xi))-g(f(x))}{\xi-x}=
       \lim_{\xi\rightarrow x} g^{*}(f(\xi))\cdot\frac{f(\xi)-f(x)}{\xi-x}\\
    &= \lim_{\xi\rightarrow x} g^{*}(f(\xi))\cdot\lim_{\xi\rightarrow x}
       \frac{f(\xi)-f(x)}{\xi-x}= g'(f(x))f'(x)
  \end{align*}
\end{proof}
\end{theorem}

\begin{beispiel}
  \begin{enumerate}[(1)]
  \item $f(x)=\ln x, f'(x)=\frac{1}{x}$. Denn: $f(x)=\ln x=g^{-1}(x)$ mit
    $g(x) =e^x$ und $(g^{-1})'(x)= \frac{1}{(g(x))'(g^{-1}(x))}=
    \frac{1}{e^{\ln x}}=\frac{1}{x}$.
   \item $f(x)=h(x)^{g(x)}$ für $h>0$ differenzierbar und $g$ differenzierbar.
    Dann ist $f'(x)=h(x)^{g(x)}(\frac{h'(x)g(x)}{h(x)}+g'(x)\ln h(x))$. Denn:
    $(h(x)^{g(x)})'=(e^{g(x)\ln h(x)})'=e^{g(x)\ln h(x)} (g(x)\ln h(x))'
    =h(x)^{g(x)}(g'(x)\ln h(x)+g(x)\frac{h'(x)}{h(x)})$.
  \item $f(x) = x^\alpha, f'(x) = \alpha x^{\alpha-1}$. Denn: $h(x)=x$ und
    $g(x)=\alpha$. Also $f'(x)=(x^\alpha)'=x^\alpha
    (0x+\frac{\alpha 1}{x})=\alpha x^{\alpha-1}$.
  \item $f(x) = a^x, f'(x) = a^x \ln a$. Denn: $h(x)=a, g(x)=x$ und
    $f'(x)=(a^x)' =a^x(1\ln a+0)=a^x\ln a$.
  \item $f(x) = x^x, f'(x) = x^x(1+\ln x)$. Denn: $h(x)=x, g(x)=x$ und
    $f'(x)=(x^x)'=x^x(\ln x+1)$.
  \item $(\cos x)'=-\sin x, (\sin x)'=\cos x$. Denn: $(e^z)'=e^z$ für $z\in\C$
    und $(e^z)'=\lim_{h\rightarrow 0} \frac{e^{z+h}-e^z}{h}=e^z$. Für $x\in\R$
    gilt, $e^{ix}=\cos x+i\sin x$.
    \begin{align*}
      (\cos x+i\sin x)' &= (\cos x)'+i(\sin x)'=(e^{ix})'=ie^{ix}\\
     &= (\cos x+i\sin x)i=i\cos x-\sin x\\
      &\Rightarrow (\cos x)'=-\sin x, (\sin x)'=\cos x
    \end{align*}
\end{enumerate}
\end{beispiel}

\section{Ableitung höherer Ordnung}
\begin{definition}
  \begin{enumerate}[(1)]
    \item Sei $f\colon D\rightarrow\R$ differenzierbar in $D$.
      Falls $f'\colon D\rightarrow\R$ in $x\in D$ differenzierbar ist, so
      heißt $\diff[2]{f}{x}(x)=f''(x)\coloneqq(f')'(x)$ die
      \highl[Ableitung!zweite]{zweite Ableitung} von $f$ an der Stelle $x$.
    \item Allgemein durch Induktion: $f\colon D\rightarrow\R$ heißt
      $k$"=mal differenzierbar in $x\in D\perdef \exists \varepsilon>0
      \colon f\colon D\cap
      \bsofint{x-\varepsilon,x+\varepsilon}\rightarrow\R$ ist
      $(k-1)$"=mal in $D\cap\bsofint{x-\varepsilon,x+\varepsilon}$
      differenzierbar und die $(k-1)$"=te Ableitung von $f$ in $x$
      differenzierbar ist.
  \end{enumerate}
\end{definition}

\begin{remark}[Leibnitzsche Produktformel]
  Seien $f,g\colon D\rightarrow\R$ und $n$-mal differenzierbar. Dann
  ist $(f\circ g)^{(n)} (x) =\sum_{k=0}^n \binom{n}{k} f^{(k)} (x)
  g^{(n-k)}(x)$ mit $f^{(0)}\coloneqq f$.
\end{remark}

\section{Lokale Extrema, Mittelwertsatz, Konvexität}

\begin{definition}[Lokales Extremum]
  Eine Funktion $f\colon\bsofint{a,b}\rightarrow\R$ hat in $x\in
  \bsofint{a,b}$ genau dann ein \highl[Maximum!lokales]{lokales
    (relatives)
    Maximum/Minimum\index{Maximum!relatives}\index{Minimum!lokales}\index{Minimum!relatives}},
  wenn
  \begin{gather*}
    \exists \varepsilon>0\,\forall\xi\in
    \bsofint{a,b}\colon\abs{x-\xi}<\varepsilon \Rightarrow f(\xi)\leq
    f(x) \text{ bzw. } f(\xi)\geq f(x)
  \end{gather*}
  Trifft das $f(\xi)=f(x)$ nur für $\xi=x$ zu, so sagt man in $x$ liegt
  ein isoliertes lokales Maximum/Minimum vor.
\end{definition}

%Satz 3
\begin{theorem}\label{satz:lokExtremum}
  Es besitze $f\colon\bsofint{a,b}\rightarrow\R$ in $x\in
  \bsofint{a,b}$ ein lokales Extremum
  und sei in $x$ differenzierbar. Dann gilt $f'(x)=0$.
  \begin{proof}
    Die Funktion $f$ habe in $x$ ein lokales Maximum. Dann gilt:
    \begin{align*}
      \exists\varepsilon>0 &\colon D=
      \bsofint{x-\varepsilon,x+\varepsilon} \subset\bsofint{a,b}\,\forall\xi\in D\colon f(\xi)\leq f(x)\\
      \intertext{Somit}
    f'_+(x) &\coloneqq \lim_{\xi\searrow x}\frac{f(\xi)-f(x)}{\xi-x}\leq 0 \text{ da } f(\xi)\leq f(x)\\
    f'_-(x) &\coloneqq \lim_{\xi\nearrow x}\frac{f(\xi)-f(x)}{\xi-x}\geq 0 \text{ da } f(\xi)\geq f(x)
  \end{align*}
  Da $f$ in $x$ differenzierbar folgt, dass $f'_+(x)-f'_-(x)=0$
  \end{proof}
\end{theorem}

Bemerkungen:
\begin{enumerate}[(1)]
  \item $f'(x)=0$ ist eine notwendige, aber keine hinreichende 
    Bedingung für ein lokales Extremum. Ein Beispiel ist die Funktion
    $f(x)=x^3$. Die Ableitung ist $f'(x)=3x^2$ und es gilt $f'(0)=0$.
    $f$ hat in 0 aber kein lokales Extremum.
  \item Hinreichende Bedingung für lokales Extremum: $f'(x)=0\wedge f''(x)\neq 0$
  \item Jede in einem kompakten Intervall $[a,b]$ stetige Funktion nimmt
    in dem Intervall ihr absolutes Maximum $f(p)=\max_{x\in[a,b]}f(x)$
    und ihr absolutes Minimum $f(q)=\min_{x\in[a,b]}f(x)$.\\
    Liegt ein Extremum jedoch am Rand, d.\,h. in $a$ oder $b$ vor, so ist
    dort $f'(x)=0$ nicht notwendig.
\end{enumerate}

\subsection{Satz von Rolle und Mittelwertsatz}
%Satz 4
\begin{theorem}[Mittelwertsätze]
  \begin{enumerate}[(1)]
    \item \highl[Rolle!Satz von]{Satz von Rolle}: Sei
      $f\colon[a,b]\rightarrow\R$ stetig und sei $f\colon
      \bsofint{a,b}\rightarrow\R$ differenzierbar in $\bsofint{a,b}$
      und $f(a)=f(b)$. Dann existiert $\xi\in \bsofint{a,b}\colon
      f'(\xi)=0$.
      \begin{proof}
        \begin{enumerate}[1.\,F{a}ll]
	\item Falls $f$ konstant ist, ist der Beweis trivial. Denn die
          Ableitung ist für jedes $\xi\in\bsofint{a,b}$ gleich Null.
	\item Falls $f$ nicht konstant ist, existiert ein $x_0\in
	  \bsofint{a,b}\colon f(x_0)>f(a)=f(b)$ oder
          $f(x_{0})<f(a)$. Dann wird das absolute Maximum/Minimum von
	  $f\colon[a,b]\rightarrow\R$ in einem Punkt $\xi\in\bsofint{a,b}$
	  angenommen. Nach \autoref{satz:lokExtremum} gilt $f'(\xi)=0$.
      \end{enumerate}  
      \end{proof}
      
    \item \highl{Mittelwertsatz}: Sei $f\colon[a,b]\rightarrow\R$
      stetig und sei $f\colon \bsofint{a,b}\rightarrow\R$
      differenzierbar in $\bsofint{a,b}$. Dann existiert ein
      $\xi\in\bsofint{a,b}$ mit $\frac{f(b)-f(a)}{b-a}=f'(\xi)$. Dies
      folgt aus dem untenstehenden zweiten Mittelwertsatz mit $g(x)=x$.

    \item 2.\,Mittelwertsatz: Seien $f,g\colon[a,b]\rightarrow\R$ stetig und 
      in $\bsofint{a,b}$ differenzierbar und sei $g'(\xi)\neq 0$ in
      $\bsofint{a,b}$. 
      Dann existiert $\xi\in\bsofint{a,b}$ mit $\frac{f(b)-f(a)}{g(b)-g(a)}=
      \frac{f'(\xi)}{g'(\xi)}$.
      \begin{proof}
        Wegen $g'\neq 0$ in $\bsofint{a,b}$ folgt nach dem Satz von
        Rolle $g(b)\neq g(a)$. Wir betrachten $\varphi(x)\coloneqq
        f(x)-f(a) -\frac{f(b)-f(a)}{g(b)-g(a)}(g(x)-g(a))$. Die
        Funktion $\varphi\colon [a,b]\rightarrow\R$ ist stetig und in
        $\bsofint{a,b}$ differenzierbar. Es gilt, $\varphi
        (a)=\varphi(b)=0$. Damit haben wir das Problem auf den Satz
        von Rolle zurückgeführt. Danach existiert ein
        $\xi\in\bsofint{a,b}$ mit
        $0=\varphi'(\xi)=f'(\xi)-\frac{f(b)-f(a)}{g(b)-g(a)}g'(\xi)$
        und es folgt, $\frac{f(b)-f(a)}{g(b)-g(a)}=\frac{f'(\xi)}{g'(\xi)}$.
      \end{proof}
    \end{enumerate}
\end{theorem}

\begin{remark}
  Folgende Folgerungen lassen sich ziehen:
\begin{enumerate}[(1)]
\item Sei $f\colon[a,b]\rightarrow\R$ stetig und $f'=0$ in
  $\bsofint{a,b}$. Dann ist $f(x)=c$ konstant auf $[a,b]$. Denn sei
  $x\in\lsofint{a,b}$ beliebig. Wir betrachten das Intervall
  $[a,x]$. Nach dem Mittelwertsatz existiert ein
  $\xi\in\bsofint{a,x}\subset\bsofint{a,b}$ mit
  $\frac{f(x)-f(a)}{x-a}=f'(\xi)=0$. Damit gilt für alle
  $x\in\rsofint{a,b}$ die Gleichheit von $f(x)=f(a)$ und wegend er
  Stetigkeit haben wir dann $f(x)=f(a)$ für alle  $x\in[a,b]$.

\item Sei $f\colon\R\rightarrow\R$ differenzierbar und genüge der
  Differentialgleichung $f'=f$ auf $\R$ mit $f(0)=1$. Dann ist
  $f(x)=e^x$. Denn sei $F(x)=f(x)e^{-x}$. Dann ist
  $F'(x)=f'(x)e^{-x}-f(x)e^{-x}= (f'(x)-f(x))e^{-x}= 0$, da
  $f'=f$ nach Voraussetzung. Also ist $F(x)=c=f(x)e^{-x}$ und
  $f(x)=ce^x$. Wegen der Voraussetzung $f(0)=1$ gilt, $f(0)=
  ce^{0}=c=1$. Also ist $f(x)=e^x$.
\end{enumerate}
\end{remark}

\subsection{Berechnung von Grenzwert, Regel von L'Hospital}
\begin{tabular}{c|l|l}
  & \textsc{Grenzübergänge} & \textsc{Differenzierbarkeitsintervalle}\\
  \hline
  (1) & $x\searrow a$ & $a<x<a+h$\\
  (2) & $x\nearrow a$ & $a-h<x<a$\\
  (3) & $x\rightarrow a$ & $0<\abs{x-a}<h$\\
  (4) & $x\rightarrow\infty$ & $ x>R$\\
  (5) & $x\rightarrow -\infty$ & $x<-R\,R>0$
\end{tabular}

Unter diesen Voraussetzungen gilt die \highl{Regel von
  L'Hospital}\index{L'Hospital!Regel von}:
Seien $\lim f(x)=\lim g(x)=0$ und existiert $\lim \frac{f'(x)}{g'(x)}$
eigentlich oder uneigentlich, so gilt $\frac{\lim f(x)}{\lim g(x)}=\lim
\frac{f'(x)}{g'(x)}$.

\begin{beispiel}
  \begin{align*}
    \lim_{x\rightarrow 0} \frac{e^x-1}{x} &= \lim_{x\rightarrow 0}
    \frac{(e^x-1)'}{x'} =\lim_{x\rightarrow 0}
    \frac{e^x}{1}=\frac{e^0}{1}=1\\
    \lim_{x\rightarrow 0} \frac{e^x-1-x}{x^2} &= \lim_{x\rightarrow 0}
    \frac{(e^x-1-x)'}{(x^2)'} =\lim_{x\rightarrow 0} \frac{e^x-1}{2x}=
    \lim_{x\rightarrow 0}\frac{e^x}{2}=\frac{1}{2}
  \end{align*}
\end{beispiel}

\subsection{Monotonie differenzierbarer Funktionen}
\begin{theorem}
  \label{satz:monoton}
  Sei $f\colon[a,b]\rightarrow\R$ stetig und in $\bsofint{a,b}$ differenzierbar. Dann
  gilt:
  \begin{enumerate}
    \item $\forall x \in \bsofint{a,b}\colon f'(x)\geq0 \Rightarrow f$ auf $[a,b]$
      monoton wachsend
    \item $\forall x \in \bsofint{a,b}\colon f'(x)> 0\Rightarrow f$ auf $[a,b]$ 
      streng monoton wachsend
    \item $\forall x \in \bsofint{a,b}\colon f'(x)\leq0 \Rightarrow f$ auf $[a,b]$
      monoton fallend
    \item $\forall x \in \bsofint{a,b}\colon f'(x)< 0\Rightarrow f$ auf $[a,b]$
      streng monoton fallend
  \end{enumerate}
  \begin{proof}[für den zweiten Fall]
    Sei $f'(x)>0$ für alle $x\in \bsofint{a,b}$. Man nehme an, dass
    $f$ nicht streng monoton wachsend ist. Dann existieren
    $x_1,x_2\in\bsofint{a,b}$ mit $x_1<x_2$ und $f(x_1)\geq
    f(x_2)$. Nach dem Mittelwertsatz folgt die Existenz eines
    $\xi\in\bsofint{a,b}$ mit $\frac{f(x_2)-f(x_1)}{x_2-x_1}
    =f'(\xi)\leq 0$\lightning.
  \end{proof}
  Die anderen Fälle werden in analoger Weise gezeigt.
\end{theorem}

\subsection{Hinreichende Bedingungen für lokale Extrema}
%Satz 6
\begin{theorem}\label{satz:lokExtrema}
  Sei $f\colon\bsofint{a,b}\rightarrow\R$ differenzierbar. In $x \in
  \bsofint{a,b}$ sei $f$ zweimal differenzierbar und es gelte,
  $f'(x)=0$ und $f''(x)\neq 0$.  Dann besitzt $f$ in $x$ ein
  isoliertes lokales Extremum.
  \begin{proof}
    Sei $f''(x)>0$. Wegen $f''(x)=\lim_{\xi\rightarrow x}
    \frac{f'(\xi)-f'(x)}{\xi-x}>0$ existiert ein $\xi>0$ mit
    $\frac{f'(\xi)-f'(x)}{\xi-x}>0$ und für alle $\xi$ gilt,
    $<\abs{\xi-x}<\varepsilon$.  Da $f'(x)=0$ ist, folgt,
    $\frac{f'(\xi)}{\xi-x}>0$ für alle $\xi$ gilt,
    $<\abs{\xi-x}<\varepsilon$. Somit ist $f'(\xi)<0$ für
    $x-\xi<\xi<x$ und $f'(\xi)>0$ für $x<\xi<x+\xi$. Nach dem
    \autoref{satz:monoton} besitzt $f$ in $x$ ein isoliertes lokales
    Minimum. Die Beweisführung erfolgt analog für das Maximum.
  \end{proof}
\end{theorem}

\subsection{Konvexität}
\begin{definition}[Konvexe und konkave Funktion]
  \begin{enumerate}[(1)]
  \item Sei $D\subset\R$ ein (endliches oder unendliches) Intervall.
    Eine Funktion $f\colon D\rightarrow\R$ heißt genau dann
    \highl{konvex}\index{Funktion!konvexe}, wenn:
    \begin{gather*}
      \forall x_0,x_1\in D\,\forall 0<\Theta<1\colon f(
      (1-\Theta)x_0+\Theta x_1)\leq(1-\Theta)f(x_0)+\Theta f(x_1)
    \end{gather*}
  \item $f$ heißt genau dann \highl{konkav}\index{Funktion!konkave},
    wenn $(-f)$ konvex ist.
  \end{enumerate}
  Gegebenenfalls unterscheidet man streng konvexe oder streng konkave
  Funktionen.
\end{definition}

%Satz 7
\begin{theorem}
  \begin{enumerate}[(i)]
  \item \emph{Konvexität und Stetigkeit}: 
    Sei $D\subset\R$ ein offenes Intervall und $f\colon D\rightarrow\R$
    konvex. Dann ist $f$ stetig auf $D$.
    \begin{proof}
      Sei $p\in D$. Dann existieren $x_0, x_1\in D$ mit $x_0<p<x_1$
      und $[x_0,x_1]\subset D$. Mann kann zeigen, dass für
      $x\in[x_0,x_1]$ die Abschätzung gilt, $\abs{f(x)-f(p)}\leq
      L\abs{x-p}$, wobei $L= \frac{2\max\{\abs{f(x_0)},
        \abs{f(x_1)}\}}{\min\{\abs{x_0- p}, \abs{x_1-p}\}}$
      ist. Dann folgt, $\lim_{x\rightarrow p} f(x)=f(p)$. Also ist
      $f$ in $p$ stetig.
    \end{proof}
    
  \item \emph{Konvexität und Differenzierbarkeit}: 
    Sei $D\subset\R$ ein offenes Intervall und $f\colon D\rightarrow\R$
    zweimal differenzierbar. Dann gilt, dass $f$ genau dann auf $D$
    konvex ist, wenn $\forall x\in D\colon f''(x)\geq 0$.
    \begin{proof}
      \begin{itemize}
      \item["`$\Rightarrow$"'] Sei $f\colon D\rightarrow\R$
        konvex. Wir nehmen an, dass für alle $x\in D$ \emph{nicht}
        gilt, $f''(x)\geq0$. Dann existiert ein $x_{0}\in D$ mit
        $f''(x_{0})< 0$. Wir setzen $\varphi(x)\coloneqq
        f(x)-f'(x_0)(x-x_0)$ für $x_0\in D$. Dann hat man
        $\varphi\colon D\rightarrow\R$ ist zweimal differenzierbar mit
        $\varphi'(x_0)=0$ und $\varphi''(x_0)=f''(x)<0$. Nach
        \autoref{satz:lokExtrema} hat $\varphi$ in $x_0$ ein
        isoliertes lokales Minimum. Somit existiert ein $h>0$ mit
        $[x_0-h, x_0+h]\subset D$ und $\varphi(x_0-h)<\varphi(x_0),
        \varphi(x_0+h)<\varphi(x_0)$. Damit folgt:
        \begin{align*}
          f(x_0) &= \varphi(x_0) > \frac{1}{2}(\varphi(x_0-h)+\varphi(x_0+h))\\
          &= \frac{1}{2}(f(x_0-h)-f'(x_0)(-h)+f(x_0+h)-f'(x_0)(h))\\
          &=\frac{1}{2}(f(x_0-h)+f(x_0+h))
        \end{align*}
        Man setzt $x_1=x_0-h, x_2=x_0+h, \Theta=\frac{1}{2}$. Dann ist
        $x_0=\frac{1}{2}(x_0-h)+\frac{1}{2}(x_0+h)=(1-\Theta)x_1+
        \Theta x_2$ und $f(x_0)=f( (1-\Theta)x_1+\Theta
        x_2)>(1-\Theta) f(x_1)+\Theta f(x_2)$\lightning
      \item["`$\Leftarrow$"'] Sei $f''\geq 0$ auf $D$. Dann ist $f'$
        nach dem \autoref{satz:monoton} monoton wachsend. Seien
        $x_1,x_2\in D, 0<\Theta<1$ und $x=(1-\Theta)x_2+\Theta
        x_1$. Weiterhin sei o.\,B.\,d.\,A. $x_1<x_2$. Dann folgt nach
        dem Mittelwertsatz, dass $\xi_1\in\bsofint{x_1,x}$ und
        $\xi_2\in\bsofint{x,x_2}$ existieren mit
        $\frac{f(x)-f(x_1)}{x-x_1} =f'(\xi_1)\leq f'(\xi_2)=
        \frac{f(x_2)-f(x)}{x_2-x}$. Mit $x-x_1= (1-\Theta)(x_2-x_1)$
        und $x_2-x=\Theta(x_2-x_1)$ folgt,
        $\frac{f(x)-f(x_1)}{1-\Theta} \leq\frac{f(x_2)-f(x)}{\Theta}$
        oder $\Theta(f(x)-f(x_1))\leq (1-\Theta)(f(x_2)-f(x))$. Somit
        ist $f(x)\leq \Theta f(x_1)+ (1-\Theta)f(x_2)\Rightarrow f$
        ist konvex.
      \end{itemize}
    \end{proof}
  \end{enumerate}
\end{theorem}

\subsection{Wendepunkt}
\begin{definition}[Wendepunkt]
  Eine Funktion $f\colon\bsofint{a,b}\rightarrow\R$ hat in
  $x_0\in\bsofint{a,b}$ genau dann einen \highl{Wendepunkt}, wenn ein
  $\varepsilon>0$ mit der Eigenschaft existiert, dass $f$ auf
  $\lsofint{x_0-\varepsilon,x_0}$ konkav und $f$ auf
  $\rsofint{x_0,x+\varepsilon}$ konvex ist oder dies auf $(-f)$
  zutrifft.
\end{definition}

\begin{remark}
  \begin{itemize}
  \item Nach der obigen Definition hat eine lineare Funktion
    $f(x)=cx+d$  in jedem Punkt einen Wendepunkt.
  \item Ist $f$ auf $\lsofint{x_0-\varepsilon,x_0}$ streng konkav und auf
    $\rsofint{x_0,x_0+\varepsilon}$ streng konvex, so liegt ein isolierter
    Wendepunkt vor.
  \end{itemize} 
\end{remark}

\subsection{Hinreichende Bedingungen für (isolierte) Wendepunkte}
% Satz 8
\begin{theorem}
  \begin{enumerate}[(i)]
  \item Sei $f\colon\bsofint{a,b}\rightarrow\R$ in
    $x_0\in\bsofint{a,b}$ differenzierbar. Dann besitzt
    $f$ in $x_0$ einen Wendepunkt, falls ein $\varepsilon>0$
    existiert und für $0<\abs{h}<\varepsilon$ stets
    \begin{enumerate}[(1)]
    \item Übergang von konkav in konvex:
      \begin{gather*}\frac{f(x_0+h)-f(x_0)}{h}>f'(x_0)\end{gather*}
    \item Übergang von konvex in konkav:
      \begin{gather*}\frac{f(x_0+h)-f(x_0)}{h}<f'(x_0)\end{gather*}
    \end{enumerate}
    gilt.
    \begin{proof}
      $\frac{f(x_0+h)-f(x_0)}{h}>0f'(x_0)$ für $0<\abs{h}
      <\varepsilon\Leftrightarrow$
      \begin{align*}
        f(x_0+h) &< f(x_0)+f'(x_0)h \text{ für } h<0\\
        f(x_0+h) &< f(x_0)+f'(x_0)h \text{ für } h>0
      \end{align*}
      Sei $h\coloneqq x-x_0$ und die 
      Tangente in $(x_0,f(x_0))$ ist $y=f(x_0)+f'(x_0)(x-x_0)$.
    \end{proof}
  \item Sei $f\colon\bsofint{a,b}\rightarrow\R$
    differenzierbar. Dann besitzt $f$ in $x_0\in\bsofint{a,b}$ einen
    Wendepunkt, wenn $f'\colon\bsofint{a,b}\rightarrow\R$
    in $x_0$ ein isoliertes lokales Extremum hat.
    \begin{proof}
      Die Funktion $f'$ habe in $x_0$ ein isoliertes lokales
      Maximum, d.\,h. es existiert ein $\varepsilon>0$ mit
      $f'(\xi)<f'(x_0)$ für $0< \abs{\xi-x_0}<\varepsilon$. Sei
      $\abs{h}<\varepsilon$, dann folgt nach dem Mittelwertsatz:
      $\exists\xi_0\in \bsofint{x_0,x_0+h}$ für $h>0$ bzw. $\xi_0\in
      \bsofint{x_0+h,x_0}$ für $h<0$ mit $\frac{f(x_0+h)-f(x_0)}{h}
      =f'(\xi_0)<f'(x_0)$. Nach (i)(2) folgt: Übergang von konvex in
      konkav. Analog kann man dies für das isolierte lokale Minimum
      zeigen.
    \end{proof}
  \item Sei $f\colon\bsofint{a,b}\rightarrow\R$ in $\bsofint{a,b}$
    zweimal differenzierbar.
    \begin{enumerate}[(1)]
    \item Ist $f''(x)>0$ für $x<x_0$ und $f''(x)<0$ für $x>x_0$, so
      hat $f$ in $x_0$ einen Wendepunkt (Übergang konvex nach konkav).
    \item Ist $f''(x)<0$ für $x<x_0$ und $f''(x)>0$ für $x>x_0$, so
      hat $f$ in  $x_0$ einen Wendepunkt (Übergang konkav nach konvex).
    \item Sei $f\colon\bsofint{a,b}\rightarrow\R$ dreimal
      differenzierbar. Ist $f''(x_0)=0$ und $f'''(x_0)\neq 0$, so
      hat $f$ in $x_0$ einen Wendepunkt.
      \begin{itemize}
      \item $f''(x_0)=0, f'''(x_0)<0$ Dann hat $f'$ in $x_0$ ein
        isoliertes lokales Maximum (Übergang konvex nach konkav).
      \item $f''(x_0)=0, f'''(x_0)>0$ Dann hat $f'$ in $x_0$ ein
        isoliertes lokales Minimum (Übergang konkav nach konvex)
      \end{itemize}
    \end{enumerate}
  \end{enumerate}
\end{theorem}

\subsection{Kurvendiskussionen von reellen Funktionen}
Mögliches Vorgehen beim Studium einer Funktion $f\colon D\rightarrow\R$:
\begin{itemize}
\item Bestimmen der Definitionsbereiche und der Symmetrieeigenschaften
\item Bestimmung der Nullstellen von $f, f', f''$
\item Untersuchung des Monotonie- und Konvexitätsverhaltens
\item Bestimmung lokaler Extremalstellen
\item Wendepunkte
\item Unstetigkeitsstellen
\end{itemize}

\section{Taylorreihen und Satz von Taylor}
Problem: Approximation von Funktionen in der Nähe eines Punktes durch
möglichst einfache Funktionen (Polynome).

\begin{lemma}
  Sei $p(x)=\sum_{k=0}^n a_kx^k$ ein Polynom $n$"=ten Grades. Dann gilt:
  \begin{gather*}
    p(x)=\sum_{k=0}^n \frac{p^{(k)}(x_0)}{k!} (x-x_0)^k
  \end{gather*}
  oder: Ein Polynom kann durch seine Ableitungen in einem Punkt
  $x_{0}$ vollständig beschrieben werden.
  \begin{proof}
    \begin{enumerate}[1.\,F{a}ll]
    \item Sei $x_0=0$
      \begin{align*}
	p'(x)&= a_1+2a_2x+\cdots+na_nx^{n-1}\\
	p''(x)&= 2a_2+\cdots+n(n-1)a_nx^{n-2}\\
	\vdots\\
	p^{(k)}(x)&= k!a_k+\cdots+n(n-1)(n-k+1)a_nx^{n-k}\\
	\Rightarrow p^{(k)}(0)&= k!a_k\text{ für } 0\leq k\leq n\\
	p^{(k)}(0)&= 0 \text{ für } k\geq n+1\\
	\Rightarrow p(x) &=\sum_{k-0}^n \frac{p^{(k)}(0)}{k!}x^k
      \end{align*}
    \item Sei $x_0$ beliebig. Wir setzen $q(y)\coloneqq p(y+x_0)$. Es
      gilt also,  $q^{(k)} (y)=p^{(k)}(y+x_0),
      q^{(k)}(0)=p^{(k)}(x_0)$. Unter Einbeziehung des ersten Falles
      erhalten wir dann $p(y+x_0)= q(y) =\sum_{k=0}^n
      \frac{p^{(k)}(0)}{k!}y^k =\sum_{k=0}^n
      \frac{p^{(k)}(x_0)}{k!}y^k$. Nun setzen wir
      $y\coloneqq x-x_0$ und bekommen $p(x)=\sum_{k=0}^n
      \frac{p^{(k)}(0)}{k!}(x-x_0)^k$.
    \end{enumerate}
  \end{proof}
\end{lemma}

\begin{remark}
  Sei $f$ eine $n$-mal stetig differenzierbare Funktion in $x_0$. Man
  verwendet
  \begin{gather*}
    \sum_{k=0}^n \frac{f^{(k)}(x_0)}{k!}(x-x_0)^k
  \end{gather*}
  zur Approximation von $f$ in der "`Nähe"' von $x_0$.
\end{remark}

\begin{definition}[Taylorpolynom, -reihe]
  \begin{enumerate}[(1)]
  \item Sei $I\subset\R$ ein Intervall und $f\colon I\rightarrow\R$ in
    $x_0 \in I$ eine $n$"=mal differenzierbare Funktion. Dann heißt:
    \begin{gather*}
      T_n(f;x_0)\colon\R\rightarrow\R
    \end{gather*}
    definiert durch
    \begin{gather*}
      T_n(f;x_0) (x)\coloneqq\sum_{k=0}^n \frac{f^{(k)}(x_0)}{k!}(x-x_0)^k
    \end{gather*}
    $n$"=tes \highl{Taylorpolynom} von $f$ im Punkt $x_0$.
  \item Sei $f\colon I\rightarrow\R$ beliebig oft differenzierbar in
    $x_{0}\in I$. Dann heißt
    \begin{gather*}
      T(f;x_0)(x)\coloneqq\sum_{k=0}^\infty
      \frac{f^{(k)}(x_0)}{k!}(x-x_0)^k
    \end{gather*}
    \highl{Taylorreihe} von $f$ in $x$ mit Entwicklungspunkt $x_0$.
  \item Gilt für eine unendlich oft differenzierbare Funktion 
    $f\colon I\rightarrow\R$ in $x_0\in I\colon f(x)=\sum_{k=0}^\infty
    \frac{f^{(k)}(x_0)}{k!}(x-x_0)^k$, so sagt man, $f$ ist in $I$
    taylorentwickelbar mit dem Entwicklungspunkt $x_0$.
  \end{enumerate}
\end{definition}

\begin{beispiel}
  \begin{enumerate}[(1)]
  \item Sei $f(x)=e^x, f\colon\R\rightarrow\R, x_0\in\R$.
    \begin{align*}
      f^{(k)}(x_0) &= e^{x_0}\\
      f(x) &= e^x=e^{x_0}e^{x-x_0}= e^{x_0}\sum_{k=0}^\infty
      \frac{(x-x_0)^k}{k!} = \sum_{k=0}^\infty \frac{e^{x_0}}{k!}(x-x_0)^k\\
      &= \sum_{k=0}^\infty \frac{f^{(k)}(x_0)}{k!}(x-x_0)^k
    \end{align*}
    Also $f(x)=e^x$ ist für $x_0\in\R$ in jedem Punkt taylorentwickelbar.
  \item Sei
    \begin{gather*}
      f(x)=
      \begin{cases}
        e^{-\frac{1}{x^2}} & x\neq 0\\
        0 & x=0
      \end{cases}
      \qquad f\colon\R\rightarrow\R    
    \end{gather*}
    Es gilt, $f^{(k)}(0)=0$ mit $k=0,1,2,\dots$. Somit ist
    $T(f;x_0=0)= \sum_{k=0}^\infty \frac{f^{(k)}(0)}{k!} x^k =0$ für
    $x\in\R$. Aber $f(x) \neq 0$ für $x\neq 0$. Damit ist $f$ in
    $x_0=0$ \emph{nicht} taylorentwickelbar.
  \end{enumerate}
\end{beispiel}

\begin{remark}
  Man bezeichnet $R_n(f;x_0)=f-T_n(f;x_0)$ als
  \highl{Restglied}. Kürzer schreibt man auch $R_n\coloneqq
  R_n(f;x_0)$. Die Funktion $f\colon I\rightarrow\R$ ist genau dann in
  $x_0$ taylorentwickelbar, wenn $\lim_{n\rightarrow\infty} R_n(x)=0$.
\end{remark}

%Satz 9
\begin{theorem}[Taylorscher Satz]
  \begin{gather*}
    I\colon
    \begin{cases}
      [x_0,x] & x>x_0\\
      [x.x_0] & x<x_0
    \end{cases}
    \qquad f\colon I\rightarrow\R
  \end{gather*}
  Die Funktion $f$ sei $n$"=mal stetig auf $I$ differenzierbar und $n+1$"=mal
  differenzierbar in $\mathring{I}\coloneqq I\setminus\{x,x_0\}$ und
  $p\in\N$. Dann
  \begin{gather*}
    \forall x\in I\,\exists 0<\Theta<1\colon R_n(x) =
    \frac{f^{(n+1)}(x_0+ \Theta(x-x_0))}{n!p} (1-\Theta)^{n+1-p}
    (x-x_0)^{n+1}
  \end{gather*}
  (\highl{Restglied von Schlömilch}\index{Schlömilch!Restglied von}) und
  \begin{gather*}
    f(x)=\sum_{k=0}^n \frac{f^{(k)}(x_0)}{k!}(x-x_0)+R_n(x)
  \end{gather*}
  (\highl{Taylorsche Formel}\index{Formel!Taylorsche}).
  \begin{proof}
    Wir setzen:
    \begin{gather*}
      F(t)\coloneqq f(x)-\sum_{k=0}^n
      \frac{f^{(k)}(t)}{k!}(x-t)^k\text{ und } G(t)\coloneqq(x-t)^p
    \end{gather*}
    Dann ist $F(x_0)-\underbrace{F(x)}_{=0} =R_n(x)$ und
    $G(x_0)-\underbrace{G(x)}_{=0} =(x-x_0)^p$. Nun leiten wir beide
    Funktionen einmal ab und erhalten: $F'(t)= -\sum_{k=0}^n
    \frac{f^{(k+1)}t}{k!} (x-t)^k + \sum_{k=1}^n \frac{f^{(k)}t}{k!}k
    (x-t)^{k-1} =-\frac{f^{(n+1)}(t)}{n!}(x-t)^n$ sowie
    $G'(t)=p(x-t)^{p-1}$. Nach dem zweiten Mittelwertsatz folgt die
    Existenz eines $0<\Theta<1$ mit:
    \begin{align*}
      \frac{F(x_0)-F(x)}{G(x_0)-G(x)} &= \frac{F'(x_0+ \Theta(x-
        x_0))}{G'(x_0+ \Theta(x-x_0))}\\
      \Rightarrow\frac{R_n(x)}{(x-x_0)^p} &= \frac{f^{(n+1)}(x_0
        +\Theta(x- x_0))\cdot (x- (x_0+ \Theta(x- x_0)))^n}{n! p(x-
        (x_0+ \Theta(x-x_0)))^{p-1}}\\
      &= \frac{f^{(n+1)}(x+ \Theta(x- x_0))}{n!p} (1-\Theta)^{n+1-p}
      (x-x_0)^{n+1-p}\\
      \Rightarrow R_n(x) &= \frac{f^{(n+1)}(x+ \Theta(x- x_0))}{n!p}
      (1- \Theta)^{n+1-p}(x-x_0)^{n+1}
    \end{align*}    
  \end{proof}
\end{theorem}

\begin{remark}[Spezialfälle des Restglieds]
  \begin{description}
  \item[Lagrange] $p=n+1\Rightarrow
    R_n(x)=\frac{f^{(n+1)}(x_0+\Theta(x-x_0))}{(n+1)!}(x-x_0)^{n+1}$\index{Restglied!Lagrange}%
    \index{Lagrangesches Restglied}
  \item[Cauchy] $p=1\Rightarrow
    R_n(x)=\frac{f^{(n+1)}(x+\Theta(x-x_0))}{n!}(1-\Theta)^n(x-x_0)^{n+1}$\index{Restglied!Cauchy}%
    \index{Cauchysches Restglied}
  \end{description}
\end{remark}

\begin{beispiel}[Logarithmusfunktion]
  Gegeben sei die Funktion $f(x)=\ln(1+x)$ mit dem Entwicklungspunkt
  $x_0=0$. Es gilt,
  \begin{gather}\label{eq:y2}
    \ln(1+x)=\sum_{k=1}^n \frac{(-1)^{k-1}}{k}x^k+R_n(x)
  \end{gather}
  wobei
  \begin{enumerate}
  \item $R_n(x)=(-1)^n\Theta_1\frac{x^{n+1}}{n+1}, 0<\Theta_1<1, 0\leq x\leq 1$
  \item $R_n(x)=(-1)^n\Theta_2\frac{x^{n+1}}{1+x}, 0<\Theta_2<1, -1<x<0$
  \end{enumerate}
  Die $\Theta_1$ und $\Theta_2$ hängen von $n$ und $x$ ab. Wir
  interessieren uns, ob der Rest gegen $0$ konvergiert.

  Die Taylorreihe
  \begin{gather*}
    \ln(1+x)=\sum_{k=1}^\infty \frac{(-1)^{k-1}}{k}x^k\qquad -1<x\leq
    1
  \end{gather*}
  ist für $-1<x<1$ absolut konvergent und für $\abs{x}>1$
  divergent. Wir können daher folgern, dass für $1\leq y<\infty$ gilt: 
  \begin{align*}
    \ln y &= 2\sum_{k=1}^n \frac{1}{2k-1}
    \left(\frac{y-1}{y+1}\right)^{2k-1} +\widetilde{R_n}(y)\\
    \widetilde{R_n}(y) &= \left(\frac{\Theta_1}{2n+1}+
      \frac{\Theta_2}{2} (y+1)\right) \left(\frac{y-1}{y+
        1}\right)^{2n+1}\qquad 0<\Theta_1,\Theta_2<1
  \end{align*}
  Für $0<y\leq 1$ nutzt man $\ln y= -\ln(\frac{1}{y})$. Insbesondere
  \begin{align*}
    \sum_{k=1}^\infty \frac{(-1)^{k-1}}{k} &=\ln 2=\sum_{k=1}^n
    \frac{(-1)^{k-1}}{k}+R_n(1)\\
    \abs{R_n(1)} &= \abs{(-1)^n} \abs{\Theta_1} \frac{1}{n+1} \leq
    \frac{1}{n+1}
    \xrightarrow{n\rightarrow\infty}0\\
    \abs{R_n(1)} &\leq \frac{1}{n+1}\leq \frac{1}{n}\leq 10^{-6}
    \Rightarrow n\geq 10^6
  \end{align*}

  Die Genauigkeit auf sechs Stellen erhält man mit Sicherheit für
  $n\geq 10^6$ (schlechte Konvergenz).

  Setzt man $y=2$ in \autoref{eq:y2} ein, erhält man $\ln 2=2\sum_{k=1}^n 
  \frac{1}{2k-1}\left( \frac{1}{3} \right)^{2k-1}+\widetilde{R_n}(2)$ mit
  \begin{align*}
    \abs{\widetilde{R_n}(2)} &=\abs{\frac{\Theta_1}{2n+1}+\frac{1}{2}\Theta_2}
    \left( \frac{3}{2} \right)^{2n+1}\leq\left(
      \frac{1}{2n+1}+\frac{3}{2} \right)
    \left(\frac{1}{3}\right)^{2n+1}\\
    n=6 &\colon \abs{\widetilde{R_6}(2)}\leq \left( \frac{1}{13}+\frac{3}{2} \right)
    \left( \frac{1}{3} \right)^{13}<10^{-6}\\
    n=10 &\colon \abs{\widetilde{R_{10}}(2)}\leq \left( \frac{1}{21}+\frac{3}{2} \right)
    \left( \frac{1}{3} \right)^{21}<1,5\cdot 10^{-10}
  \end{align*}
  Man sieht, dass dies viel schneller geht. So wird der Logarithmus
  auch berechnet. Zum Nachweis sei $f(x)=\ln(1+x)$. Dann ist $f'(x)=
  \frac{1}{1+x}, f''(x)= -\frac{1}{(1+x)^{2}}$ und $f'''(x)=
  2\frac{1}{(1+x)^{3}}$. Insgesamt haben wir $f^{(n)}= (n-1)!
  (-1)^{n-1} \frac{1}{(1+x)^{n}}$. Die Taylorformel liefert dann:
  $\ln(1+x)= f(x)= \sum_{k=0}^{n} \frac{f^{(k)} (0)}{k!} x^{k}+
  R_{n} (x)= \sum_{k=1}^n (-1)^{k-1}\frac{x^k}{k}+R_n(x)$. Das
  Restglied erhalten wir durch:
  
  \begin{enumerate}[1.\,F{a}ll]
  \item $0\leq x\leq 1$: Restglied von Lagrange:
    \begin{gather*}
      R_n(x)=\frac{f^{(n+1)}(\Theta x)}{(n+1)!}x^{n+1}=(-1)^n
      \underbrace{\frac{1}{(1+\Theta x)^{n+1}}}_{=\colon \Theta_1}
      \frac{x^{n+1}}{n+1}
    \end{gather*}
    mit $0<\Theta\leq 1$. Es gilt $0<\Theta_1<1$,
    denn $1+\Theta x\geq 1$. Daher folgt, $\frac{1}{1+\Theta x}\leq 1$.
    Somit ist $R_n(x)=(-1)^n\Theta_1\frac{x^{n+1}}{n+1}$ für alle
    $0\leq x\leq 1$ und es folgt $\abs{R_n(x)}\leq\frac{\abs{x}^{n+1}}{n+1}
    \xrightarrow{n\rightarrow\infty} 0\Rightarrow\lim_{n\rightarrow\infty}
    R_n(x)=0$ für $0\leq x \leq 1$.
  \item $-1<x\leq 0$: Cauchysches Restglied:
    \begin{align*}
      R_n(x)&= \frac{f^{(n+1)}(\Theta x)}{n!}(1-\Theta)^nx^{n+1}\text{ für }
      0<\Theta <1\\
      &= (-1)^n\frac{1}{(1+\Theta x)^{n+1}}(1-\Theta)^nx^{n+1}\\
      &= (-1)^n\underbrace{\left( \frac{1-\Theta}{1+\Theta x} \right)^n
      \frac{1+x}{1+\Theta x}}_{=\colon\Theta_2}\frac{x^{n+1}}{1+x}
    \end{align*}
    Es gilt $0<\Theta_{2}<1$, da $0<1-\Theta<1+\Theta x$ und $0<1+x<1+\Theta x$.
    Somit ist:
    \begin{align*}
      R_n(x) &= (-1)^n\Theta_2\frac{x^{n+1}}{1+x}\\
      &\Rightarrow
      \abs{R_n(x)}\leq\frac{\abs{x}^{n+1}}{1+x}\xrightarrow{n\rightarrow\infty}
      0\\
      &\Rightarrow& \lim_{n\rightarrow\infty} R_n(x)=0\text{ für }
      -1<x\leq 0
    \end{align*}
  \end{enumerate}
  Beide Fälle liefern die Konvergenz der Taylorreihe und es gilt, $\ln
  (1+x)= \sum_{k=1}^{\infty} (-1)^{k-1} \frac{x^{k}}{k}$.

  Folgerung: Für $1\leq y<\infty$ gilt:
  \begin{align*}
    \ln y &= 2\sum_{k=1}^n \frac{1}{(2k-1)}\left(\frac{y-1}{y+1}\right)^{2k-1}
    +\widetilde{R_n}(y)\\
    \widetilde{R_n}(y) &= \left(\frac{\Theta_1}{2n+1}+
      \frac{\Theta_2}{2}(y+1)\right)
    \left(\frac{y-1}{y+1}\right)^{2n+1}\quad 0<\Theta_1,\Theta_2<1
  \end{align*}
  \begin{proof}
    Sei $1\leq y \leq\infty$ und $x\coloneqq\frac{y-1}{y+1}$. Es gilt
    $0\leq x<1$ und $y=\frac{1+x}{1-x}$:
    \begin{align*}
      \ln(1+x) &= \sum_{k=1}^{2n}\frac{(-1)^{k-1}}{k} x^k+ R_{2n}(x)\\
      \ln(1-x) &= \sum_{k=1}^{2n}\frac{(-1)^{k-1}}{k}(-x)^k+R_{2n}(-x)\\
      \ln\left(\frac{1+x}{1-x}\right) &= \ln(1+x)-\ln(1-x)\\
      &= \sum_{k=1}^{2n} \frac{(-1)^{k-1}}{k}x^k+R_{2n}(x)-
      \sum_{k=1}^{2n}\frac{(-1)^{k-1}}{k}(-x)^k+R_{2n}(-x)\\
      &= \sum_{k=1}^{2n}\frac{(-1)^{k-1}-(-1)^{k}}{k} x^k+
      \underbrace{(R_{2n} (x)-R_{2n}(-x))}_{=\colon\widetilde{R_n}(x)}\\
      &= 2\sum_{k=1}^n \frac{x^{2k-1}}{2k-1} +\widetilde{R_n}(x)\\
      R_{2n}(x)&= \Theta_1\frac{x^{2n+1}}{2n+1}\\
      R_{2n}(-x)&= \Theta_2\frac{(-x)^{2n+1}}{1-x}\\
      \widetilde{R_n}(x)&= \left(\frac{\Theta_1}{2n+1}+
        \frac{\Theta_2}{1-x}\right) x^{2n+1}
    \end{align*}
    Damit ist:
    \begin{gather*}
      \boxed{\ln(y)=2\sum_{k=1}^n\frac{1}{2k-1}\left( \frac{y-1}{y+1}
        \right)^{2k-1} +\widetilde{R_n}(y)}
    \end{gather*}
    mit
    \begin{gather*}
      \boxed{\widetilde{R_n}=\left(
          \frac{\Theta_1}{2n+1}+\frac{\Theta_2}{2} (y+1)\right)\left(
          \frac{y-1}{y+1} \right)^{2n+1}}
    \end{gather*}
  \end{proof}
\end{beispiel}

\chapter{Integration}
\section{Das Riemannsche Integral}
Die Integralrechnung umfasst die klassische Problemstellung, für eine
reelle und nicht negative Funktion $f\colon[a,b]\rightarrow\R$ den
Inhalt der so genannten "`Ordinatenmenge"' (Fläche) $\{(x,y)\colon
a\leq x\leq b, 0\leq y\leq f(x)\}$ zu berechnen.

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}[domain=0.5:4]
    \draw[->] (-0.2,0) -- (6.2,0) node[right] {$x$};
    \draw[->] (0,-1.2) -- (0,6.2) node[above] {$f(x)$};
    \draw plot (\x,\x*\x-4*\x+5.5) node[right] {$f(x)=
      (x-2)^{2}+1,5$};
    \draw[thick] (1,0) -- (1,2.5);
    \draw[thick] (3,0) -- (3,2.5);
    \draw[black,fill] (1,2.5) circle (2pt);
    \draw[black,fill] (3,2.5) circle (2pt);
  \end{tikzpicture}
  \caption{Schematische Darstellung der Fläche unterhalb einer Kurve}
  \label{fig:riemann}
\end{figure}

Zur Untersuchung dieses Problems braucht man diverse Begriffe:
\begin{description}
  \item[Zerlegung\index{Zerlegung}] $\ZZ\coloneqq\{I_1,\cdots,I_n\}$
    mit dem Intervall
    $I_i\coloneqq[x_{i-1},x_i]$ und $a=x_0<x_1<\cdots<x_n=b$
  \item[Verfeinerung\index{Verfeinerung}] $\ZZ'\perdef\forall
    I'\in\ZZ'\,\exists I\in\ZZ\colon I'\subset I$, 
    Schreibweise: $\ZZ\prec\ZZ'$
  \item[Länge des Intervalls] $I=[c,d]\colon l(I)\coloneqq d-c$
  \item[Durchmesser der Zerlegung] $d(\ZZ)\coloneqq\max\{l(I)\colon
    I\in\ZZ\}$
  \item[Überlagerung zweier Zerlegungen] $\ZZ\coloneqq\{I=I'\cap I''\colon
    I'\in\ZZ_1, I''\in\ZZ_2, l(I)>0\}$, 
    $\ZZ$ ist wieder eine Zerlegung und $\ZZ_1,\ZZ_2\prec\ZZ$,
    Schreibweise: $\ZZ=\ZZ_1\vee\ZZ_2$
  \item[Menge der beschränkten Funktionen] $B[a,b]\coloneqq\{f\colon
    [a,b]\rightarrow\R\colon f\text{ beschränkt}\}$
  \item[Infimum/Supremum\index{Infimum!Integration}\index{Supremum!Integration}]
    Sei $M\subset[a,b]$.
    \begin{align*}
      \underline{f}(M) &\coloneqq\inf\{f(x)\colon x\in M\}\\
      \overline{f}(M) &\coloneqq\sup\{f(x)\colon x\in M\}
    \end{align*}
  \item[Flächeninhalt]
    \highl{Untersumme}:
    \begin{gather*}
      \underline{S}(f;\ZZ)=\sum_{I\in\ZZ}\underline{f}(I)l(I)
    \end{gather*}
    \highl{Obersumme}:
    \begin{gather*}
      \overline{S}(f;\ZZ)=\sum_{I\in\ZZ}\overline{f}(I)l(I)
    \end{gather*}
    Es gilt:
    \begin{gather*}
      \underline{S}(f;\ZZ)\leq\overline{S}(f;\ZZ)
    \end{gather*}
\end{description}

% Lemma 1.1
\begin{lemma}\label{lemma:int}
  Sei $f\in B[a,b]$ und $\ZZ\prec \ZZ'$. Dann gilt
  \begin{enumerate}[(i)]
  \item $\underline{S}(f;\ZZ')\geq \underline{S}(f;\ZZ)$
    bzw. $\underline{S}(f;\ZZ) \leq \underline{S}(f; \ZZ')$.
    \begin{proof}
      Wir nehmen an, dass $\ZZ'$ genau einen Punkt $x'$ mehr als
      $\ZZ$ mit $x_{i-1}<x'<x_i$ enthält. Es gilt:
      \begin{gather*}
        \underline{f}([x_{i-1},x']),\underline{f}([x',x])\geq \underline{f}
        ([x_{i-1},x_i])
      \end{gather*}
      Also ist $\underline{f}([x_{i-1},x_i])l([x_{i-1},x_i])\leq 
      \underline{f}([x_{i-1},x'])l([x_{i-1},x'])+\underline{f}([x',x_i])
      l([x',x_i])$ und somit
      \begin{align*}
        \underline{S}(f;\ZZ) &= \underline{f} ([x_{i-1}, x']) l
        ([x_{i-1}, x'])+ \sum_{\substack{k=1\\ k\neq i}} f (I_{k})l
        (I_{k})\\
        &\leq \underline{f} ([x_{i-1}, x']) l([x_{i-1}, x'])+
        \underline{f} ([x', x_{i}]) l (x', x_{i})+
        \sum_{\substack{k=1\\ k\neq i}} f (I_{k})l(I_{k})\\
        &= \sum_{\substack{k=1\\ k\neq i}} f(I_{k}) l(I_{k})= \underline{S}(f;\ZZ')
      \end{align*}
      Falls $\ZZ'$ mehr als einen Punkt ($p>1$) hat, wendet man den Schluss
      $p$"=mal an.
    \end{proof}
  \item $\overline{S}(f;\ZZ')\leq \overline{S}(f;\ZZ)$
    \begin{proof}
      Der Beweis erfolgt analog zu oben.
    \end{proof}
  \item $\overline{S}(f;\ZZ')-\underline{S}(f;\ZZ')\leq \overline{S}(f;\ZZ)
    -\overline{S}(f;\ZZ)$
    \begin{proof}
      Der Schluss folgt aus den obigen Aussagen.
    \end{proof}
  \item $\forall \ZZ_1,\ZZ_2\colon \underline{S}(f;\ZZ_1)\leq \overline{S}
    (f;\ZZ_2)$.
    \begin{proof}
      Sei $\ZZ=\ZZ_1\prec \ZZ_2$. Dann ist $\underline{S}
      (f;\ZZ_1)\leq \underline{S}(f;\ZZ)\leq \overline{S}(f;\ZZ)\leq
      \overline{S}(f;\ZZ_2)$
    \end{proof}
  \end{enumerate}
\end{lemma}

\begin{definition}[Darbouxsches Integral]
  Sei $f$ eine beschränkte Funktion auf $[a,b]$. Dann heissen die
  Größen
  \begin{gather*}
    \int_{\underline{a}}^b f\,dx \coloneqq \sup_\ZZ
    \underline{S}(f;\ZZ)\\
    \int_a^{\overline{b}} f\,dx \coloneqq \inf_\ZZ \overline{S}(f;\ZZ)
  \end{gather*}
  wobei $\ZZ$ die Menge aller Zerlegungen von $[a,b]$ durchläuft, unteres
  und oberes \highl[Integral!Darbouxsches]{Darbouxsches Integral}.
\end{definition}

\begin{remark}
  Nach \autoref{lemma:int} Punkt (iv) gilt immer
  $\int_{\underline{a}}^b f\,dx\leq \int_a^{\overline{b}}f\,dx$. Es
  gibt beschränkte Funktionen für die $\int_{\underline{a}}^b f\,dx<
  \int_a^{\overline{b}}f\,dx$.
\end{remark}

\begin{beispiel}
  \begin{gather*}
    f(x)\coloneqq
    \begin{cases}
      1 & x\in [0,1], x \text{ irrational}\\
      0 & x\in [0,1], x \text{ rational}
    \end{cases} \in B[0,1]   
  \end{gather*}

  Sei $\ZZ$ eine beliebige Zerlegung von $[0,1]$ und $I\in \ZZ$ ein
  Intervall.  Dann gilt $\underline{f}(I)=0$ und
  $\overline{f}(I)=1$. Denn in jedem beliebigen Intervall liegen
  rationale und irrationale Zahlen.
  \begin{align*}
    \underline{S}(f;\ZZ)&= \sum_{I\in\ZZ} \underline{f}(I)l(I)=0&
    \overline{S}(f;\ZZ)&= \sum_{I\in\ZZ} \overline{f}(I)l(I)=l([0,1])=1\\
    &\Rightarrow \int_{\underline{a}}^b f\,dx =0 < 1= \int_a^{\overline{b}} f\,dx
  \end{align*}
\end{beispiel}

\begin{definition}[Riemannsches Integral]
  Eine Funktion $f\in B[a,b]$ heißt genau dann Riemann"=integrierbar
  (R"=integrierbar), wenn gilt:
  \begin{gather*}
    \int_{\underline{a}}^b f\,dx = \int_a^{\overline{b}} f\,dx
  \end{gather*}
  Man bezeichnet $\int_a^b$ als das
  \highl[Integral!Riemannsches]{Riemannsche Integral}.
\end{definition}

\begin{theorem}[Riemannsches Integrabilitätskriterium]
  Die Funktion $f\in B[a,b]$ ist genau dann R"=integrierbar, wenn
  \begin{gather*}
    \forall \varepsilon>0\,\exists \ZZ \colon \overline{S}(f;\ZZ)-
    \underline{S}(f;\ZZ)\leq \varepsilon
  \end{gather*}
  \begin{proof}
    \begin{itemize}
    \item["`$\Rightarrow$"'] Sei $f\in B[a,b]$ R"=integrierbar. Dann folgt
      $\int_a^b f\,dx=\int_{\underline{a}}^b f\,dx = \int_a^{\overline{b}} f\,dx$,
      d.\,h.
      \begin{gather*}
        \forall\varepsilon>0\,\exists\ZZ_1,\ZZ_2\colon\int_a^b fdx
        -\underline{S}(f;\ZZ_1)<\frac{\varepsilon}{2},
        \overline{S}(f;\ZZ_2)-\int_a^b fdx < \frac{\varepsilon}{2}
      \end{gather*}
      Für $\ZZ=\ZZ_1\prec\ZZ_2$ gilt:
      $\overline{S}(f;\ZZ)-\underline{S}(f;\ZZ) \leq
      \overline{S}(f;\ZZ_2)-\underline{S}(f;\ZZ_2) =
      \overline{S}(f;\ZZ_2)+\int_a^b f\,dx-\int_a^b
      f\,dx-\underline{S}(f;\ZZ_2)
      <\frac{\varepsilon}{2}+\frac{\varepsilon}{2}=\varepsilon$.
    \item["`$\Leftarrow$"'] Sei $\varepsilon>0$. Dann gilt: $0\leq
      \int_a^{\overline{b}} fdx - \int_{\underline{a}}^b fdx\leq
      \overline{S}(f;\ZZ)-\underline{S}(f;\ZZ)<\varepsilon$.  Daher
      folgt für alle positiven $\varepsilon\colon0\leq
      \int_a^{\overline{b}} f\,dx - \int_{\underline{a}}^b f\,dx\leq
      \varepsilon \Rightarrow \overline{\int}=\underline{\int}$. Womit
      klar ist, dass $f$ R"=integrierbar ist.
    \end{itemize}
  \end{proof}
\end{theorem}

\subsection{Definition des Riemannsches Integrals über Zwischensummen}

\begin{definition}[Auswahlfunktion]
  Sei $\ZZ$ eine Zerlegung von $[a,b]$. Dann heißt die Funktion
  \begin{gather*}
    \xi\colon\ZZ\rightarrow[a,b] \text{ mit } \xi(I)=\xi\in I\in\ZZ
  \end{gather*}
  \highl{Auswahlfunktion}. Sie ordnet jedem Intervall $I$ ein Element
  $\xi(I)$ des Intervalls zu.
\end{definition}

\begin{definition}[Zwischensumme]
  Man bezeichnet
  \begin{gather*}
    S(f;\ZZ;\xi)\coloneqq\sum_{I\in\ZZ} f(\xi(I)) l(I)
  \end{gather*}
  als \highl{Zwischensumme} von $f$ mit der Zerlegung
  $\ZZ$ und der Auswahlfunktion $\xi\colon\ZZ\rightarrow[a,b]$.  

  Wegen $\underline{f}\leq f(\xi(I))\leq\overline{f}(I)$ gilt
  $\underline{S} (f;\ZZ)\leq S(f;\ZZ;\xi)\leq\overline{S}(f;\ZZ)$.
\end{definition}

% Lemma 1.3
\begin{lemma}
  Sei $f\in B[a,b]$ und $\ZZ\prec\ZZ'$. Dann gilt für alle Auswahlfunktionen
  $\xi\colon\ZZ\rightarrow[a,b]$ und $\xi'\colon\ZZ'\rightarrow
  [a,b]$:
  \begin{gather*}
    \abs{S(f;\ZZ;\xi) -S(f;\ZZ';\xi')}\leq\max_{I\in\ZZ}
    (\overline{f}(I)-\underline{f}(I)) \underbrace{l([a,b])}_{=b-a}
  \end{gather*} 
\end{lemma}

%Lemma 1.4
\begin{theorem}
  Sei $f\in B[a,b]$. Dann ist $f$ genau dann R"=integrierbar, wenn gilt:
  \begin{gather*}
    \exists A\in\R\,\forall\varepsilon>0\,\exists\delta_\varepsilon>
    0\,\forall \ZZ(d(\ZZ)<\delta_\varepsilon)\,\forall \xi(\xi\colon\ZZ\rightarrow
    [a,b])\colon\abs{S(f;\ZZ;\xi)-A}\leq \varepsilon\end{gather*}
\end{theorem}

% Lemma 1.5
\begin{theorem}
  Sei $f\in B[a,b]$. Dann ist $f$ genau dann R"=integrierbar, wenn
  \begin{gather*}
    \forall (\ZZ_n)\,\forall (\xi_n)\,(d(\xi_n)\rightarrow 0)\colon
    \lim_{n\rightarrow\infty} S(f;\ZZ_n;\xi_n)
  \end{gather*}
  existiert und es gilt $\lim_{n\rightarrow\infty} S(f;\ZZ_n;\xi_n)=\int_a^b
  f\,dx$.
\end{theorem}

\subsection{Beispiele von R-integrierbaren Funktionen}

% Lemma 1.6
\begin{theorem}
  \begin{enumerate}[(i)]
  \item Jede \emph{monotone} Funktion $f\in B[a,b]$ ist
    R"=integrierbar.
    \begin{proof}
      Sei o.\,B.\,d.\,A. $f(b)\neq f(a)$ und $f$ monoton wachsend.
      $\ZZ=\{I_1,\dots,I_n\}, I_k=[x_{k-1},x_k], x_0=a,x_n=b$ und $d (
      \ZZ)= \max_{I\in\ZZ} l (I)$. Es ist
      \begin{align*}
        \overline{S}(f;\ZZ)-\underline{S}(f;\ZZ) &= \sum_{I\in\ZZ}
        \overline{f}(I) l(I)-\underline{f}(I)l(I) = \sum_{i=1}^n
        (f(x_i)-f(x_{i-1}))l(I_i)\\
        &\leq \left( \sum_{i=1}^n (f(x_i)-f(x_{i-1})) \right)d(\ZZ)=
        (f(b)-f(a))(d(\ZZ))
      \end{align*}
      Für $\varepsilon>0$ wählt man $\ZZ$ derart, dass $d(\ZZ)\leq
      \frac{\varepsilon}{f(b)-f(a)}$. Dann gilt, $\overline{S}(f;\ZZ)-
      \underline{S}(f;\ZZ)\leq f(b)-f(a)d(\ZZ)\leq \varepsilon\Rightarrow f$
      ist R"=integrierbar.
    \end{proof}

    \item Jede \emph{stetige} Funktion $f\in B[a,b]$ ist
      R"=integrierbar.
      \begin{proof}
        Sei $f$ auf $[a,b]$ stetig. Dann ist $f$ auch beschränkt
        und gleichmässig stetig. Das heißt, 
        $\forall\varepsilon>0\,\exists\delta_\varepsilon>0\,\forall
        x_1, x_2\in [a,b]\colon \abs{x_1-x_2}\leq \delta_\varepsilon
        \Rightarrow\abs{f(x_1)-f(x_2)}\leq
        \frac{\varepsilon}{b-a}$. Man wählt $\ZZ$ mit $d(\ZZ)\leq 
        \delta_\varepsilon$. Dann gilt $\overline{f}(I)-\underline{f}(I)\leq
        \frac{\varepsilon}{b-a}$ für $I \in\ZZ$. Somit ist
        \begin{align*}
          \overline{S}(f;\ZZ)-\underline{S}(f;\ZZ)&= \sum_{I\in\ZZ}
          (\overline{f}(I)-\underline{f}(I))l(I)\leq \sum_{I\in\ZZ}
          \frac{\varepsilon}{b-a} l(I)=\left( \sum_{I\in\ZZ} 
          \right)\frac{\varepsilon}{b-a}\\
          &= b-a\frac{\varepsilon}{b-a}=\varepsilon
        \end{align*}
      \end{proof}
  \end{enumerate}
\end{theorem}

% Lemma 1.7
\begin{theorem}
  Ändert man eine R"=integrierbare Funktion $f\in B[a,b]$ an endlich vielen
  Stellen ab, so ist die neu entstandene Funktion $\tilde{f}$ ebenfalls
  R"=integrierbar und es gilt
  \begin{gather*}
    \int_a^b f\,dx = \int_a^b \tilde{f}\,dx
  \end{gather*}
\end{theorem}

Ein Beispiel zur numerischen Auswertung eines Riemannschen Integrals
über Zwischensummen ist die Funktion $f(x)=x^\alpha$.

\subsection{Eigenschaften des R-Integrals}
\begin{gather*}
  \RR[a,b]\coloneqq\{f\in B[a,b] | f \text{ ist R-integrierbar}\}
\end{gather*}

% Satz 1.8
\begin{theorem}
  \begin{enumerate}
  \item Sei $f\in\RR[a,b]$. Dann gilt $\underline{f}([a,b])(b-a)\leq
    \int_a^b f\,dx\leq \overline{f}([a,b])(b-a)$.
  \item Sei $f\in\RR[a,b]$ und $c\in\R$. Dann folgt, $c\cdot
    f\in\RR[a,b]$ und $\int_a^b cf\,dx =c\int_a^b f\,dx$.
  \item Additivität: $f_1,f_2\in\RR[a,b]\Rightarrow
    f_1+f_2\in\RR[a,b]$ und $\int_a^b (f_1+f_2)\,dx= \int_a^b f_1\,dx
    + \int_a^b f_2\,dx$
  \item $f_1,f_2\in\RR[a,b], f_1\leq f_2\Rightarrow \int_a^b f_1\,dx\leq 
    \int_a^b f_2\,dx$
  \item Sei $a<c<b$ und $f_i[a,b]\rightarrow\R$. Dann gilt $f\in\RR[a,b]
    \Leftrightarrow f_{[a,c]}\in\RR[a,c]\wedge f_{[c,b]}\in\RR[c,b], 
    \int_a^b f\,dx=\int_a^c f\,dx + \int_c^b f\,dx$
  \item Sei $f\in\RR[a,b], m\leq f\leq M,
    \varphi\colon[m,M]\rightarrow\R$ stetig. Dann gilt $h=\varphi\circ
    f\in\RR[a,b]$.
  \item $f,g\in\RR[a,b]\Rightarrow f\circ g \in\RR[a,b]$
  \item $f\in\RR[a,b]\Rightarrow \abs{f}\in\RR[a,b], \abs{\int_a^b
      f\,dx}\leq\int_a^b \abs{f}\,dx$
  \end{enumerate}
  \todo{Beweis noch einfügen}
\end{theorem}

\section{Integration und Differentiation}

\begin{definition}[Unbestimmtes Integral]
  Sei $f\in\RR[a,b]$ und $x_0\in[a,b]$. Dann heißt
  \begin{gather*}
    F\colon[a,b]\rightarrow\R\text{ definiert durch }
    F(x)\coloneqq\int_{x_0}^x fdx\,x\in[a,b]
  \end{gather*}
  \highl[Integral!unbestimmtes]{unbestimmtes Integral}.
\end{definition}

% Satz 2.1
\begin{lemma}\label{lem:5.21}
  Sei $f\in\RR[a,b], c\in[a,b]$. Dann gilt für $F(x)=\int_{c}^{x} f(t)\,dt$:
  \begin{enumerate}[(i)]
   \item $F\colon[a,b]\rightarrow\R$ stetig.
    \begin{proof}
      Da $f\in\RR[a,b]$ stetig ist, folgt für alle $t\in[a,b]$, dass
      $\abs{f(t)}\leq k$. Für $a\leq x<y\leq b$ gilt, $\abs{F(y)-F(x)}=
      \abs{\int_{c}^{y} f\,dt- \int_{c}^{x} f\,dt}= \abs{\int_{x}^{y}
      f(t)\,dt}\leq \int_{x}^{y} \abs{f(t)}\,dt\leq \int_{x}^{y} k\,dt=
      k(y-x)= k\abs{y-x}$. Insgesamt ist also $F$ gleichmäßig stetig.
    \end{proof}
   \item Ist $f$ in $x_{0}$ stetig, so ist $F$ differenzierbar in $x_{0}$ und
    es gilt, $F'(x_{0})= f(x_{0})$.
    \begin{proof}
      Sei $\varepsilon>0$. Dann existiert $\delta_{\varepsilon}(x_{0})>0$ mit
      $\abs{f(t)-f(x_{0})}\leq\varepsilon$ für
      $\abs{t-x_{0}}\leq\delta_{\varepsilon}$. Für
      $x_{0}-\delta_{\varepsilon}\leq s\leq x_{0}\leq t\leq
      x_{0}+\delta_{\varepsilon}$ und $a\leq s<t<b$ gilt:
      \begin{align*}
	\abs[\big]{\frac{F(t)- F(s)}{t-s} -f(x_{0})} &=
	   \abs[\big]{\frac{1}{t-s} \int_{s}^{t} f(u)\,du-f(x_{0})}
	   =\abs[\big]{\frac{1}{t-s} \int_{s}^{t} (f(u)-f(x_{0})\,du})\\
	&\leq \frac{1}{\abs{t-s}} \int_{s}^{t} \abs{f(u)-f(x_{0})}\,du
	   \leq\frac{1}{\abs{t-s}} \int_{s}^{t} \varepsilon\,du=
	   \frac{\varepsilon}{\abs{t-s}} (t-s)\\
	&=\varepsilon
      \end{align*}
      Insbesondere ist $\abs{\frac{F(t)-F(x_{0})}{t-x_{0}} -f(x_{0})}\leq
      \varepsilon$ für $0<\abs{t-x_{0}}\leq\delta_{\varepsilon}$, d.\,h.
      $F'(x_{0})= \lim_{t\rightarrow x_{0}} \frac{F(t)- F(x_{0})}{t-x_{0}}=
      f(x_{0})$.
    \end{proof}
  \end{enumerate}
\end{lemma}

\begin{definition}[Stammfunktion]
  Eine differenzierbare Funktion $F\colon I\rightarrow\R$ heißt genau dann
  \highl{Stammfunktion} einer Funktion $f$, wenn $F'=f$.
\end{definition}

\begin{remark}
  Nach \autoref{lem:5.21} gilt: Ist $f\colon[a,b]\rightarrow\R$ stetig, so ist
  $F(x)= \int_{c}^{x} f(t)\,dt$ eine Stammfunktion von $f$.
\end{remark}

%Satz 2.2
\begin{lemma}\label{lem:5-22}
  Seien $F,G\colon I\rightarrow\R$ Stammfunktionen von $I\rightarrow\R$, so
  ist $F-G=c$ konstant.
  \begin{proof}
    $F'=G'=f\Rightarrow(F-G)'=F'-G'=0\Rightarrow F-G$ konstant.
  \end{proof}
\end{lemma}

\section{Hauptsatz der Differential- und Integralrechnung}

% SAtz 2.3
\begin{theorem}[Hauptsatz der Differential- und Integralrechnung]
  Sei $f\colon I\rightarrow\R$ eine stetige Funktion und $F$ eine
  Stammfunktion von $f$. Dann gilt für alle $a,b\in I$:
  \begin{gather*}
    \int_{a}^{b} f(t)\,dt= F(b)-F(a)
  \end{gather*}
  \begin{proof}
    Für $x\in I$ sei $F_{0}(x)\coloneqq\int_{a}^{x} f(t)\,dt$. Dann ist
    $F_{0}\colon I\rightarrow\R$ eine Stammfunktion von $f$ mit $F_{0}(a)=0$
    und $F_{0}(b)=\int_{a}^{b} f(t)\,dt$. Ist nun $F$ eine beliebige
    Stammfunktion von $f$, so gilt nach \autoref{lem:5-22}: $F(b)-F(a)=
    F_{0}(b)- F_{0}(a)= \int_{a}^{b} f(t)\,dt$.
  \end{proof}
\end{theorem}

\clearpage
\begin{thebibliography}{99}
\bibitem{foster} \textsc{Otto Foster}: Analysis~I.
\bibitem{kaballo} \textsc{Winfried Kaballo}: Einführung in die Analysis~I.
\bibitem{behrends} \textsc{Ehrhardt Behrends}: Analysis~I.
\bibitem{heuser} \textsc{Harro Heuser}: Lehrbuch der Analysis~I.
\bibitem{barner} \textsc{Barner}, \textsc{Flohr}: Analysis, Band I.
\end{thebibliography}

\printindex
\end{document}

