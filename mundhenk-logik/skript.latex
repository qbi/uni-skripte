% ToDo:
%  * überlegen, ob description global entfettet werden soll.
%    % In der Doku zu paralist auf Seite 3 steht die Originaldefinition. Diese
%    % hier entfettet die Punkte einer description
%    \renewcommand{\descriptionlabel}[1]{\hspace\labelsep\normalfont #1}

% Einige zusätzliche Informationen für rubber
%  rubber erkennt nicht, dass die Datei weg kann, daher sagen wir es ihm
% rubber: clean $base.thm
%  rubber soll nach Änderungen an der Datei nochmal bauen
% rubber: watch $base.thm
% rubber: makeidx.tool      xindy
% rubber: makeidx.language  german-din
% rubber: makeidx.modules   indexstyle.xdy

% scrreprt trifft am Besten die Bedürfnisse eines Skripts, das ganze wird
% zweiseitig (twoside), d.h. es wird zwischen linker und rechter Seite
% unterschieden, und wir verwenden zwischen den Absätzen einen Abstand
% von einer halben Zeile (halfparskip) und dafür keinen Absatzeinzug,
% wobei die letzte Zeile eines Absatzes zu min. 1/4 leer ist.

\RequirePackage[l2tabu,orthodox]{nag}  % nag überprüft den Text auf verältete Befehle
                          % oder solche, die man nicht in LaTeX verwenden
                          % soll -- l2tabu-Checker in LaTeX

\documentclass[parskip=half*,ngerman,draft,twoside]{scrreprt}

\usepackage{ifthen}
\usepackage{makeidx}
\usepackage[final]{graphicx}  % Für Grafiken
\usepackage{xcolor}
\usepackage[draft=false,colorlinks,bookmarksnumbered,linkcolor=blue,breaklinks]{hyperref}

\usepackage[utf8]{inputenc}
\usepackage{babel}

\usepackage{lmodern}	    % Latin Modern als Schrift verwenden
\usepackage[T1]{fontenc}    % T1-Schriften verwenden -- notwendig für PDFs
\usepackage{textcomp}       % wird benötigt, damit der \textbullet für
                            % itemize in lmodern/TS1 gefunden wird.

\usepackage[intlimits,leqno]{amsmath}
\usepackage{amssymb}     % wird für \R, \C,... gebraucht
\usepackage{fixmath}     % ISO-konforme griech. Buchstaben
\usepackage[all,warning]{onlyamsmath}  % warnt bei Verwendung von nicht
                                       % amsmath-Umgebungen z.\,B. $$...$$

\usepackage[thmmarks,hyperref,amsmath]{ntheorem} % für die Theorem-Umgebungen
                                                 % (satz, defini, bemerk)
\usepackage{xspace}      % wird weiter unten gebraucht
\usepackage{slashbox}    % für schräge Striche links oben in der
                         % Tabelle; s. texdoc slashbox

\usepackage{paralist}    % besseres enumerate und itemize und neue
                         % compactenum/compactitem; s. texdoc paralist

\usepackage{svn}         % Zum Auswerten und ordentlichen Darstellen der
                         % SVN-Schlüsselwörter (s. vor \begin{document})
                         % dafür muss in SVN noch das Flag svn:keywords
                         % auf "LastChangedRevision LastChangedDate"
                         % gesetzt werden
\usepackage{xkeyval}     % für die Auswertung von Argumentenlisten; s.
                         % Neudefinition von \emph
% \usepackage{mparhack}    % Korrigiert einige Probleme mit \marginpar; die
                         % Option [debug] ist hilfreich bei Problemen
\usepackage{ellipsis}    % Korrektur für \dots
\usepackage{fixltx2e}
\usepackage[final]{microtype} % Verbesserung der Typographie
\usepackage{ifpdf}
\usepackage{fancyvrb}
\usepackage{ragged2e}
\usepackage{caption}

% Damit auch die Zeichen im Mathemode in Überschriften fett sind
% <news:lzfyyvx3pt.fsf@tfkp12.physik.uni-erlangen.de>
\addtokomafont{sectioning}{\boldmath}

% nach dem Theoremkopf wird ein Zeilenumbruch eingefügt, die Schrift des
% Körpers ist normal und der Kopf wird fett gesetzt
\theoremstyle{break}
\theorembodyfont{\normalfont}
\theoremheaderfont{\normalfont\bfseries}
\theoremnumbering{arabic}
\theoremsymbol{\ensuremath{\triangleleft}}

% Die folgenden Umgebungen werden einzeln nummeriert und am Ende jedes
% Kapitels zurückgesetzt
\newtheorem{satz}{Satz}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\newtheorem{bemerk}{Bemerkung}[chapter]
\newtheorem{defini}{Definition}[chapter]
\newtheorem{korol}{Korollar}[chapter]
\newtheorem{bsp}{Beispiel}[chapter]

% Die folgenden Theoremumgebungen bekommen keine Nummer
\theoremstyle{nonumberbreak}

\theoremheaderfont{\scshape}
\theorembodyfont{\normalfont}
% Das Zeichen am Ende eines Beweises
\theoremsymbol{\ensuremath{_\blacksquare}}
% \theoremsymbol{q.\,e.\,d.}
\newtheorem{proof}{Beweis:}

% Hier die Definition, wie \autoref die Umgebungen nennen soll, die mit
% \newtheorem definiert wurden
\newcommand*{\satzautorefname}{Satz}
\newcommand*{\lemmaautorefname}{Lemma}
\newcommand*{\bemerkautorefname}{Bemerkung}
\newcommand*{\definiautorefname}{Definition}
\newcommand*{\korolautorefname}{Korollar}
\newcommand*{\bspautorefname}{Beispiel}
\newcommand*{\proofautorefname}{Beweis}
% Zwischen Unter- und Unterunterabschnitten sollte nicht unterschieden
% werden.
\renewcommand*{\subsectionautorefname}{Abschnitt}
\renewcommand*{\subsubsectionautorefname}{Abschnitt}

\pagestyle{headings}

\newcommand*{\R}{\mathbb{R}}      % reelle Zahlen
\newcommand*{\N}{\mathbb{N}}      % natürliche Zahlen
\newcommand*{\Z}{\mathbb{Z}}      % ganze Zahlen
\newcommand*{\ThS}{\mathrm{S}}    % die form, Theorie zur Zahlenth. in Kap 3

% Wenn irgendwo Unklarheiten zum Inhalt im Skript auftreten, können sie
% einfach mit \help{Ich verstehe das nicht} hervorgehoben werden. Dies
% macht es leichter sie alle zu finden und auch ganz einfach
% auszublenden, indem man den Befehl einfach leer definiert
\newcommand*{\help}[1]{\textcolor{green}{help: #1}}

% \todo ist das gleiche wie \help nur für offene Aufgaben
\newcommand*{\todo}[1]{\textcolor{red}{todo: #1}}

% Um wichtige Begriffe im Text überall gleich vorzuheben (gleiches
% Markup), sollte dieser Befehl verwendet werden. Das Argument wird
% automatisch als Indexeintrag verwendet und am Rand wiederholt. Da unter
% Umständen der Eintrag im Index oder am Rand anders lauten soll --
% z.\,B. Oberbegriff!Unterbegriff für den Index --, akzeptiert der Befehl
% ein optionales Argument in Form einer Liste, die mit
% index=<Indexeintrag>, rand=<Randeintrag> und indexrand=<Index- und
% Randeintrag> die jeweiligen Felder anders belegt.
\makeatletter
\newcommand*{\local@index}{}
\newcommand*{\local@rand}{}
\newcommand*{\local@indexrand}{}
\define@key{local}{index}{\renewcommand*{\local@index}{#1}}
\define@key{local}{rand}{\renewcommand*{\local@rand}{#1}}
\define@key{local}{indexrand}{\renewcommand*{\local@indexrand}{#1}}

\renewcommand*{\emph}[2][]{%
  \begingroup%
    \setkeys{local}{indexrand={#2}}%
    \setkeys{local}{{#1}}%
    \setkeys{local}{index={\local@indexrand},rand={\local@indexrand}}%
    \setkeys{local}{#1}%
    % \textit{#2}%
    \textsf{\textsl{#2}}%
    \if\@empty\local@index\relax\else\index{\local@index}\fi%
    % \if\@empty\local@rand\relax\else%
    %   \marginpar{\raggedright\small\itshape\local@rand}%
    % \fi%
  \endgroup%
}
\renewcommand*{\see}[2]{\textit{\seename} #1}
\makeatother

% Definition für Xindy für die Trennung der einzelnen Abschnitte im
% Index. siehe auch die Datei indexstyle.xdy
\newcommand*{\indexsection}{\minisec}

% Diese Befehle sind dafür gedacht, dass die Symbole für "genau dann wenn"
% im ganzen Dokument gleich aussehen. Außerdem erlaubt es eine schnelle
% Veränderung aller Stellen, falls der Prof. doch nicht mehr gdw nimmt,
% sondern \Leftrightarrow.
\newcommand*{\gdw}{\ifthenelse{\boolean{mmode}}%
			       {\mspace{8mu}gdw\mspace{8mu}}%
			       {$gdw$\xspace}}
% \newcommand*{\gdwdef}{\ifthenelse{\boolean{mmode}}%
% 			       {\mspace{8mu}gdw_{def}\mspace{8mu}}%
% 			       {$gdw_{def}$\xspace}}

% Um sicherzustellen, dass jeder Betrag-/jede Norm links und rechts die
% Striche bekommt, sind diese Befehle da. Damit kann man nicht die
% rechten Striche vergessen und es wird etwas übersichtlicher. (Vorschlag
% ist aus amsldoc) \abs[\big]{\abs{a}-\abs{b}} \leq \abs{a+b}
\newcommand*{\abs}[2][]{#1\lvert#2#1\rvert}
\newcommand*{\lcorner}[1]{\raisebox{-1mm}{$\llcorner$}#1\raisebox{-1mm}{$\lrcorner$}}
\newcommand*{\ucorner}[2][]{#1\ulcorner\!#2#1\!\urcorner}

% Das original Epsilon sieht nicht so toll aus
\renewcommand*{\epsilon}{\varepsilon}
% ... und mancheinem gefällt auch das Phi nicht
\renewcommand*{\phi}{\varphi}
% \vdash und \models mit verlängerter Strichlänge und so, dass man
% drunterschreiben kann. \xvdash{drunter} und \xmodels{drunter}
\newcommand*{\xvdash}[1]{\mathrel\vert\joinrel%
  \mathrel{\mkern-1mu\mathop{\relbar\joinrel\mkern-.5mu\relbar}\limits_{#1}}}
\newcommand*{\xmodels}[1]{\mathrel\vert\joinrel%
   \mathrel{\mkern-.9mu\mathop{\Relbar\joinrel\Relbar}\limits_{#1}}}

% ... damit man sich nicht immer die Finger wund tippt.
\newcommand*{\Lvdash}{\xvdash{\mathrm{L}}}
\newcommand*{\Svdash}{\xvdash{\ThS}}
\newcommand*{\Mmodels}{\xmodels{\scriptscriptstyle\mathcal{M}}}

% Umdefinierung von \vdash und \models, damit die Striche länger sind.
\renewcommand*{\vdash}{\xvdash{\hphantom{L}}}
\renewcommand*{\models}{\xmodels{\hphantom{L}}}

% für primitiv-rekursive Funktionen:
%   das Minus - mit 'nem Punkt drüber
\newcommand*{\dminus}{-\hspace{-2.6mm}\raisebox{1mm}{$\cdot$}\hspace{2mm}}
\newcommand*{\prim}{\mathrm{prim}}
\newcommand*{\fib}{\mathit{fib}}
\newcommand*{\sonst}{\text{ sonst}}

% Zur Vereinheitlichung und leichteren Anpassbarkeit des Zeichens nach einem
% Quantor im 2. Kapitel
\newcommand*{\quantsep}{~}

\newcommand*{\cA}{\mathcal{A}}    % Schreibschrift A
\newcommand*{\cB}{\mathcal{B}}    % Schreibschrift B
\newcommand*{\cM}{\mathcal{M}}    % Schreibschrift M

\newcommand*{\lneg}{\neg}
\newcommand*{\limplies}{\rightarrow}

% Für Schlüsselwörter in Algorithmen
\newcommand*{\schlwort}[1]{\underline{#1}}

% Manchmal möchte man Begriffe erklären oder etwas aufzählen, das aber
% nicht fett gedruckt werden soll. Dazu diese Umdefinition einer
% description mit normaler Schrift
\newenvironment*{mdescription}%
               {\renewcommand*{\descriptionlabel}[1]%
			      {\hspace{\labelsep}\normalfont ##1}%
		 \begin{description}}%
		 {\end{description}}

% Eine einfache Listenumgebung ohne
% große Einrückung
\newenvironment*{simplelist}{\begin{list}{\textbf{$\bullet$}}
{\setlength{\labelwidth}{2mm}
\setlength{\labelsep}{3mm}
\setlength{\leftmargin}{5mm}}}{\end{list}}

% Nach Vorschlag von Norbert Stuhrmann in
% <news:e6kc7d$pr8$1@f1node01.rhrz.uni-bonn.de>
\newcounter{falli}
\newcounter{fallii}
\newcounter{falldepth}
\setcounter{falldepth}{0}
% skript-check aus
\newcommand*{\falliformat}{\itshape Fall \arabic{falli}}
\newcommand*{\falliiformat}{\falliformat\alph{fallii}}
% skript-check an
\newenvironment*{faelle}%
     {\stepcounter{falldepth}%
      \begin{list}{\csname fall\roman{falldepth}format\endcsname:}
                  {\usecounter{fall\roman{falldepth}}%
           \settowidth{\labelwidth}{\csname fall\roman{falldepth}\endcsname}%
                      \setlength{\leftmargin}{1.3cm}%
                      \setlength{\itemindent}{3mm}%
                      \addtolength{\itemindent}{\labelwidth}%
                      \addtolength{\itemindent}{-\leftmargin}%
                    }}%
             {\end{list}\addtocounter{falldepth}{-1}}

\makeindex

\newcounter{cnt}
\setcounter{cnt}{1}
\whiledo{\thecnt < 17}{%
  \DeclareGraphicsRule{.\thecnt}{\ifpdf mps\else eps\fi}{*}{}%
  \stepcounter{cnt}%
}

\SVN $LastChangedRevision$
\SVN $LastChangedDate$

\begin{document}

\title{Logik}
\author{Prof.\,Dr.\,Mundhenk}
\date{Semester: SS 2006}
\maketitle

\clearpage
\chapter*{Vorwort}

{\itshape
  Dieses Dokument wurde als Skript für die auf der
  Titelseite genannte Vorlesung erstellt und wird jetzt im Rahmen des
  Projekts
  "`\href{http://www.minet.uni-jena.de/~joergs/skripte/}
  {Vorlesungsskripte der Fakultät für Mathematik}
  \href{http://www.minet.uni-jena.de/~joergs/skripte/}{und Informatik}"'
  weiter betreut. Das
  Dokument wurde nach bestem Wissen und Gewissen angefertigt. Dennoch
  garantiert weder der auf der Titelseite genannte Dozent, die Personen,
  die an dem Dokument mitgewirkt haben, noch die
  Mitglieder des Projekts für dessen Fehlerfreiheit. Für etwaige Fehler
  und dessen Folgen wird von keiner der genannten Personen eine Haftung
  übernommen. Es steht jeder Person frei, dieses Dokument zu lesen, zu
  verändern oder auf anderen Medien verfügbar zu machen, solange ein
  Verweis auf die Internetadresse des Projekts
  \url{http://www.minet.uni-jena.de/~joergs/skripte/}
  enthalten ist.

  Diese Ausgabe trägt die Versionsnummer~\SVNLastChangedRevision\ und ist
  vom \SVNDate. Eine (mögliche) aktuellere Ausgabe ist auf der Webseite
  des Projekts verfügbar.

  Jeder ist dazu aufgerufen Verbesserungen, Erweiterungen und
  Fehlerkorrekturen für das Skript einzureichen bzw. zu melden oder diese
  selbst einzupflegen -- einfach eine E-Mail an die
  \href{mailto:skripte@listserv.uni-jena.de}{Mailingliste
  \texttt{<skripte@listserv.uni-jena.de>}} senden. Weitere Informationen
  sind unter der oben genannten Internetadresse verfügbar.

  Hiermit möchten wir allen Personen, die an diesem Skript mitgewirkt
  haben, vielmals danken:
  \begin{itemize}
   \item \href{mailto:joerg@alea.gnuu.de}{Jörg Sommer
    \texttt{<joerg@alea.gnuu.de>}} (2006)
   \item \href{mailto:mundhenk@informatik.uni-jena.de}{Martin Mundhenk
    \texttt{<mundhenk@informatik.uni-jena.de>}} (2006)
  \end{itemize}
}

\clearpage
\pdfbookmark[0]{Inhaltsverzeichnis}{inhaltsverzeichnis}
\tableofcontents

\clearpage
\pdfbookmark[0]{Auflistung der Sätze}{theoremlist}
\chapter*{Auflistung der Theoreme}

\pdfbookmark[1]{Sätze}{satzlist}
\section*{Sätze}
\theoremlisttype{optname}
\listtheorems{satz}

\pdfbookmark[1]{Definitionen und Festlegungen}{definilist}
\section*{Definitionen und Festlegungen}
% \theoremlisttype{all}
\listtheorems{defini}

\clearpage
\pdfbookmark[0]{Literaturverzeichnis}{literaturverzeichnis}
\begin{thebibliography}{9}
 \bibitem{Mendelson} Elliott Mendelson: Introduction to mathematical logic,
  4.~Auflage (1997), Chapman~\& Hall/CRC
 \bibitem{Boolos-Jeffrey} George S.\,Boolos, Richard C.\,Jeffrey: Computability and logic
 \bibitem{Nerode-Shore} Anil Nerode, Richard A.\,Shore: Logic for applications
 \bibitem{Fitting} Melvin Fitting: First-order logic and automated theorem proving
 \bibitem{Wolf} Robert S.\,Wolf: A tour through mathematical logic
\end{thebibliography}


\addchap{Vorbemerkung}

Diese Vorlesung bietet eine Einführung in die mathematische Logik.

Logik stellt eine (formale) Sprache zur Verfügung,
in der Aussagen gemacht werden können,
und einen \glqq{}Mechanismus\grqq{}, mit dem
Aussagen bewiesen werden können.
Die beweisbaren Aussagen heißen Theoreme,
und die Logik soll garantieren, dass die
Theoreme genau die wahren Aussagen sind.
Der Begriff des Beweises ist hier ein rein
mechanischer -- syntaktischer -- Begriff,
der auf der formalen Definition der Logik basiert.
Dort werden Axiome aufgestellt, die
genau die grundlegenden Wahrheiten ausdrücken sollen.
Aus ihnen lassen sich mit festgelegten Schlussregeln
logische Schlüsse ziehen.
Der Begriff der wahren Aussage ist dagegen
ein inhaltlicher -- semantischer -- Begriff,
der aus unserer Vorstellung von Wahrheit stammt
(und trotzdem formal definiert sein kann).
Ziel ist stets, zu untersuchen, ob diese beiden
Begriffswelten übereinstimmen (\glqq{}Vollständigkeit und Korrektheit\grqq{}).

Wir werden Aussagenlogik, Prädikatenlogik
und Formale Zahlentheorie als grundlegende Logiken betrachten.
Während die Ausdrucksmöglichkeiten der
Sprachen von Aussagenlogik und Prädikatenlogik
eher auf die rein logischen Dinge (was immer das heißen soll)
beschränkt ist, kann man in der Formalen Zahlentheorie
schon schöne Aussagen wie z.\,B.
\glqq{}Es gibt unendlich viele Primzahlen.\grqq{} oder
\glqq{}Es gibt unendlich viele Primzahlzwillinge\footnote{Ein
Primzahlzwilling ist ein Paar von Primzahlen mit Differenz $2$,
z.\,B. $17$ und $19$.}.\grqq{} machen.
Während wir wissen, dass die erste Aussage wahr ist,
wissen wir nichts genaues über die zweite Aussage.
Wir können sie nicht beweisen, und wir können ihr
Gegenteil auch nicht beweisen.


Für Aussagenlogik und Prädikatenlogik werden wir Axiome
und Schlussregeln kennen lernen, mit denen
unser Wahrheitsbegriff exakt dargestellt wird.
Für die Formale Zahlentheorie ist das nicht möglich!
Der Unvollständigkeitssatz von Gödel sagt aus,
dass es keine Möglichkeit zur Auswahl von Axiomen
und Schlussregeln gibt (die bestimmte vernünftige Anforderungen erfüllen),
mit denen alle wahren Aussagen der Zahlentheorie
formal bewiesen werden können.
Es gibt also wahre Aussagen
(\glqq{}Es gibt unendlich viele Primzahlzwillinge.\grqq{}
 könnte eine solche sein (was aber nicht wirklich geglaubt wird)),
die man nicht formal beweisen kann.
Wir werden eine solche Aussage am Ende der Vorlesung sehen.

Damit ist der Inhalt der Vorlesung grob beschrieben.
Sie beginnt mit Betrachtung von Aussagenlogik (über die gewisse Grundkenntnisse
vorausgesetzt werden) und Prädikatenlogik.
Für diese beiden Logiken werden
Axiome und Schlussregeln formuliert,
und deren Vollständigkeit und Korrektheit wird bewiesen.
Zum Abschluss wird die Formale Zahlentheorie betrachtet
und der Unvollständigkeitssatz von Gödel bewiesen.
Aufgrund von Zeitmangel werden dazu nicht alle Zwischenschritte bewiesen.
Aber man erhält einen guten Einblick in die Materie.

Die Vorlesung richtet sich hauptsächlich nach dem Buch
\glqq{}Introduction to mathematical logic\grqq{}
von Elliott Mendelson\cite{Mendelson}.
Die Vorlesung bei Prof.\,V.\,S.\,Cherniavsky an der TU~Braunschweig
im Jahre 1983 nach einer früheren Auflage dieses Werkes ist
mir unvergesslich geblieben.
Sie gehörte in vielerlei Hinsicht zu den Höhepunkten meines Studiums.
Das Buch hat mich auch bei der Vorbereitung der Vorlesung wieder tief beeindruckt.
Auch wenn dieses Skript mal fertiggestellt sein sollte,
kann ich nur empfehlen: Lest das Buch von Mendelson!!
\vspace{2ex}

\begin{flushright}
  Martin Mundhenk
\end{flushright}


\chapter{Aussagenlogik}

Aussagenlogik beschäftigt sich mit Aussagen
(\glqq{}Die Straße ist nass.\grqq{}, \glqq{}Es regnet.\grqq{})
und deren Verknüpfung zu komplexeren Aussagen
(\glqq{}Wenn es regnet, dann ist die Straße nass.\grqq{},
\glqq{}Es regnet nicht und die Straße ist nass.\grqq{}).
Durch Verknüpfungen können Aussagen entstehen,
die inhärent wahr sind, sogenannte Tautologien
(\glqq{}Die Straße ist nass oder die Straße ist nicht nass.\grqq{},
 \glqq{}Wenn die Aussage
      \glq Wenn es regnet, dann ist die Straße nass.\grq\xspace
       wahr ist und die Straße nicht nass ist, dann regnet es nicht.\grqq{}).
Sie machen z.\,B. Aussagen über das korrekte Schlussfolgern.
Nun möchte man z.\,B. gerne wissen, ob eine Schlussfolgerung korrekt ist.
Das heißt, man will wissen, ob eine Aussagenverknüpfung eine Tautologie ist.
Dazu gibt es verschiedene Ansätze.
Der semantische Ansatz basiert auf dem Begriff Wahrheit\footnote{In der
Aussagenlogik ist der Wahrheits-Begriff noch handhabbar, in der
Prädikatenlogik nicht mehr.}, wärend der syntaktische Ansatz auf der Struktur
der Aussagenverknüpfungen basiert.
Wir werden hier verschiedene syntaktische Ansätze (Theorien)
kennenlernen.
Während der semantische Ansatz durch den Wahrheits-Begriff klar definiert ist,
benutzen Theorien den Wahrheits-Begriff nicht.
Deshalb muss man nachweisen, dass sie das Ziel erreichen,
Tautologien von den übrigen Formeln zu unterscheiden.
Dieses Ziel wird durch die beiden Eigenschaften der
Korrektheit und der Vollständigkeit gekennzeichnet.

Damit ist umrissen, was in diesem Kapitel passiert.
Zuerst werden Verknüpfungen von Aussagen
(aussagenlogische Formeln) betrachtet und
der (semantische) Begriff der Tautologie definiert.
Anschließend werden zwei Theorien vorgestellt,
und es wird gezeigt, dass sie korrekt und vollständig sind.




\section{Aussagen, Formeln und Tautologien}\label{sec:1}

Eine \emph{Aussage} ist entweder \emph{wahr} oder \emph{falsch}.

Beispiele für Aussagen:
\begin{itemize}
 \item Die Straße ist nass. (falsche Aussage)
 \item Jena liegt an der Saale. (wahre Aussage)
 \item Hamburg liegt in Thüringen. (falsche Aussage)
\end{itemize}

\emph{Negation} einer Aussage:
\begin{itemize}
 \item Die Straße ist nicht nass. (wahre Aussage)
 \item Jena liegt nicht an der Saale. (falsche Aussage)
\end{itemize}

\emph{Konjunktion} zweier Aussagen:
\begin{itemize}
 \item Jena liegt an der Saale \emph{und} die Straße ist nicht nass.
  (wahre Aussage)
\end{itemize}

\emph{Disjunktion} zweier Aussagen:
\begin{itemize}
 \item Jena liegt an der Saale \emph{oder} die Straße ist nicht nass.
  (wahre Aussage)
\end{itemize}

\textit{Vorsicht:} Umgangssprachlich versteht man unter "`oder"' oft ein
"`entweder \ldots{} oder"' (genau eine der beiden Aussagen ist wahr).
Logisch betrachtet ist die Disjunktion zweier Aussagen wahr,
wenn mindestens eine der beiden Aussagen wahr ist.
Eine Disjunktion ist also auch wahr, wenn beide Aussagen wahr sind.

\emph{Implikation} zweier Aussagen:
\begin{itemize}
 \item \emph[indexrand=wenn \ldots{} dann]{Wenn
  \textnormal{die Straße nass ist,} dann} liegt Hamburg in
  Thüringen.
  (wahre Aussage)
\end{itemize}

\emph{Äquivalenz} zweier Aussagen:
\begin{itemize}
 \item Jena liegt an der Saale \emph{genau dann, wenn} Hamburg in
  Thüringen liegt.
  (falsche Aussage)
\end{itemize}

Für die formale Beschreibung von Aussagen verwendet man \emph{Variablen}
bzw. Aussagezeichen wie $A_{0}, A_{1}, A_{2}, \dotsc, B_{0}, B_{1},
B_{2},\dotsc$ und für Verknüpfungen setzt man Symbole: $\neg$
(Negation), $\wedge$ (Konjunktion), $\vee$ (Disjunktion), $\rightarrow$
(Implikation), $\leftrightarrow$ (Äquivalenz).

\begin{defini}[Aussagenlogische Formel]
  Aussagenlogische Formeln sind wie folgt definiert:
  \begin{enumerate}
   \item Jede Variable $A_{0}, A_{1}, A_{2}, \dotsc,B_{0}, B_{1}, B_{2},
    \dotsc$ ist eine aussagenlogische Formel.
   \item Wenn $\alpha$ und $\beta$ aussagenlogische Formeln sind, dann
    sind auch die fünf daraus entstehenden Verknüpfungen
    \begin{gather*}
      (\neg \alpha), \quad (\alpha\wedge\beta), \quad(\alpha\vee\beta),
         \quad (\alpha\rightarrow\beta), \quad (\alpha\leftrightarrow\beta)
    \end{gather*}
    aussagenlogische Formeln.
  \end{enumerate}
\end{defini}

\begin{bsp}[Beispiele für aussagenlogische Formeln]
  $A_{12}$ ist eine aussagenlogische Formel.
  $B_{1}$ ist eine aussagenlogische Formel.
  $(A_{12} \wedge B_{1})$ ist eine aussagenlogische Formel.
  $\big((\neg A_{12}) \rightarrow B_{1}\big)$ ist eine aussagenlogische Formel,
  und
  $\big((A_{12}\wedge B_{1}) \vee \big(\neg ((\neg A_{12})\rightarrow B_{1})\big)\big)$
  ist ebenfalls eine aussagenlogische Formel.
\end{bsp}

\begin{bemerk}
  Wir geben den Verknüpfungszeichen unterschiedliche Bindungsstärke,
  um Klammern beim Aufschreiben von Formeln weglassen zu können.
  Die größte Bindungsstärke hat $\neg$, und die kleinste hat $\leftrightarrow$.
  Die Ordnung ist durch folgende Reihenfolge gegeben.
  \begin{enumerate}
   \item $\neg$
   \item $\wedge$, $\vee$
   \item $\rightarrow$
   \item $\leftrightarrow$
  \end{enumerate}
  Die Formel $\neg A \rightarrow B \vee C$
  bedeutet also $((\neg A) \rightarrow (B \vee C))$.

  Jetzt können unnötige Klammern weggelassen werden.
  Zur Vereinfachung der Schreibweise können auch $A,B,C,\dotsc$
  als Variablen genommen werden.
\end{bemerk}

Jede Variable einer aussagenlogischen Formel kann einen der beiden
\emph[indexrand=Wahrheitswert]{Wahrheitswerte} $w$ ("`\emph{wahr}"', $T$, 1) und $f$
("`\emph{falsch}"', $F$, 0) annehmen. Der Wahrheitswert einer
zusammengesetzten Formel ergibt sich aus den Wahrheitswerten ihrer Teile;
siehe \autoref{tab:einfache-wahrheitstafel}.

\begin{table}[ht]
  \centering
  \begin{tabular}{cc*{5}{|c}}
    $\alpha$ & $\beta$ & $\alpha\wedge\beta$ & $\alpha\vee\beta$ &
       $\alpha\rightarrow\beta$ & $\alpha\leftrightarrow\beta$ &
       $\neg\alpha$\\
    \hline
    $f$ & $f$ & $f$ & $f$ & $w$ & $w$ & $w$\\
    $f$ & $w$ & $f$ & $w$ & $w$ & $f$ &\\
    $w$ & $f$ & $f$ & $w$ & $f$ & $f$ & $f$\\
    $w$ & $w$ & $w$ & $w$ & $w$ & $w$ &
  \end{tabular}
  \caption{Wahrheitstafeln}
  \label{tab:einfache-wahrheitstafel}
\end{table}

Wenn $\underbrace{\text{die Straße nass ist}}_{A}$, dann
$\underbrace{\text{liegt Hamburg in Thüringen}}_{B}$, wobei $A$ und $B$ den
Wahrheitswert~$f$ haben. Also ist laut \autoref{tab:einfache-wahrheitstafel}
$A\rightarrow B$ wahr.

Für die etwas komplexere Formel $(A\rightarrow(B\vee C)\leftrightarrow \neg
(A\rightarrow(B\vee C)))$ bestimmt man den Wahrheitswert in mehreren
Schritten; siehe \autoref{tab:wht1}. Um sich größere Formeln besser
veranschaulichen zu können, beschreibt man diese mit
\emph[rand=Verknüpfungsbaum]{Verknüpfungsbäumen}. Als Beispiel ist der
Verknüpfungsbaum für die obige Formel in \autoref{fig:verknbaum1} abgebildet.

\begin{table}[ht]
  \centering
  \begin{tabular}{ccc*{5}{|c}}
    $A$ & $B$ & $C$ & $A\wedge B$ & $B\vee C$ & $A\rightarrow(B\vee C)$ &
       $\neg(A\rightarrow(B\vee C))$ & $\dotso \leftrightarrow \dotso$\\
    \hline
    $f$ & $f$ & $f$ & $f$ & $f$ & $w$ & $f$ & $w$\\
    $f$ & $f$ & $w$ & $f$ & $w$ & $w$ & $f$ & $w$\\
    $f$ & $w$ & $f$ & $f$ & $w$ & $w$ & $f$ & $w$\\
    $f$ & $w$ & $w$ & $f$ & $w$ & $w$ & $f$ & $w$\\
    $w$ & $f$ & $f$ & $f$ & $f$ & $f$ & $w$ & $f$\\
    $w$ & $f$ & $w$ & $f$ & $w$ & $w$ & $f$ & $w$\\
    $w$ & $w$ & $f$ & $w$ & $w$ & $w$ & $f$ & $f$\\
    $w$ & $w$ & $w$ & $w$ & $w$ & $w$ & $f$ & $f$\\
  \end{tabular}
  \caption{Die Wahrheitswerttafel für $(A\rightarrow(B\vee C)\leftrightarrow
    \neg (A\rightarrow(B\vee C)))$}
  \label{tab:wht1}
\end{table}

\begin{figure}
  \centering
  \input{verkn-baum.pdf_t}
  \caption{\emph[rand=]{Verknüpfungsbaum} für die Formel
    $\big(A\rightarrow(B\vee C)\big) \leftrightarrow
    \big(\neg(A\rightarrow(B\vee C))\big)$}
  \label{fig:verknbaum1}
\end{figure}

Die Zuordnung von Wahrheitswerten zu Variablen nennt man \emph{Belegung}.
Die Belegung ist eine Abbildung von Variablen auf Wahrheitswerte.
Wir beschreiben eine Belegung durch eine Menge
\begin{gather*}
  \mathcal{A} \subseteq \{ A_{0}, A_{1}, A_{2}, \dotsc,B_{0}, B_{1},
     B_{2}, \dotsc \} \cup \{ \neg A_{0}, \neg A_{1}, \neg A_{2}, \dotsc,
     \neg B_{0}, \neg B_{1}, \neg B_{2}, \dotsc \}
\end{gather*}
mit $\{A_{i}, \neg A_{i}\}\nsubseteq \mathcal{A}$ und $\{B_{i}, \neg
B_{i}\}\nsubseteq \mathcal{A}$ für alle $i$.
Dabei gilt für jede Belegung $\cA$ und jede Variable $X$:
\begin{gather*}
    \mathcal{A}(X) = \begin{cases}
                            w &\text{falls}\ X\in\mathcal{A}\\
                            f &\text{falls}\ \neg X\in\mathcal{A}\\
                          \end{cases}
\end{gather*}



Als ein \emph{Literal} bezeichnet man eine Variable oder deren Negation:
$A_{i},B_{i}, \neg A_{i}$ und $\neg B_{i}$.

Eine Belegung $\mathcal{A}$ \emph{passt} zur Formel $\alpha$, falls für
jede Variable $X$, die in der Formel $\alpha$ vorkommt, gilt:
\begin{gather*}
  X\in\mathcal{A}\quad\text{oder}\quad\neg X\in\mathcal{A}
\end{gather*}


Sei $\mathcal{A}$ eine Belegung, die zu der aussagenlogischen
Formel $\alpha$ passt.
Wir betrachten $\cA$ auch als Funktion von Formeln auf Wahrheitswerte.
Für Formel $\alpha$ ist $\cA(\alpha)$ der Wahrheitswert
von $\alpha$ unter der Belegung $\cA$.
Aus der Semantik der Verknüpfungszeichen
ergibt sich folgende induktive Definition von $\mathcal{A}(\alpha)$.
\begin{faelle}
 \item $\alpha$ ist eine Variable $X$:
  \begin{gather*}
    \mathcal{A}(\alpha) = \cA(X)
  \end{gather*}

 \item $\alpha$ ist eine \emph{Konjunktion} $(\beta\wedge\gamma)$:
  \begin{gather*}
    \mathcal{A}(\alpha) =
       \begin{cases}
         w & \text{falls } \mathcal{A}(\beta)=w\ \text{und}\ \mathcal{A}(\gamma)=w\\
         f & \text{sonst}
       \end{cases}
  \end{gather*}

 \item $\alpha$ ist eine \emph{Disjunktion} $(\beta\vee\gamma)$:
  \begin{gather*}
    \mathcal{A}(\alpha) =
       \begin{cases}
         w & \text{falls } \mathcal{A}(\beta)=w\ \text{oder}\ \mathcal{A}(\gamma)=w\\
         f & \text{sonst}
       \end{cases}
  \end{gather*}

 \item $\alpha$ ist eine \emph{Implikation} $(\beta\rightarrow\gamma)$:
  \begin{gather*}
    \mathcal{A}(\alpha) =
       \begin{cases}
         f & \text{falls } \mathcal{A}(\beta)=w\ \text{und}\ \mathcal{A}(\gamma)=f\\
         w & \text{sonst}
       \end{cases}
  \end{gather*}

 \item $\alpha$ ist eine \emph{Äquivalenz} $(\beta\leftrightarrow\gamma)$:
  \begin{gather*}
    \mathcal{A}(\alpha) =
       \begin{cases}
         w & \text{falls } \mathcal{A}(\beta)=\mathcal{A}(\gamma)\\
         f & \text{sonst}
       \end{cases}
  \end{gather*}
\end{faelle}

\begin{bsp}
Wir betrachten den Wahrheistwert der Formel
$\alpha=A\rightarrow\neg(\neg B\vee A)$ unter der Belegung $\cA=\{A,\neg B\}$.
Es gilt
  \begin{align*}
    \cA(A\rightarrow\neg(\neg B\vee A)) &=f &\gdw &&
       \cA(A)&=w\text{ und }\cA(\neg(\neg B\vee A))=f\\
    &&\gdw&& \cA(A)&=w\text{~und~}\cA(\neg B\vee A)=w\\
    &&\gdw&& \cA(A)&=w\text{~und~}\lcorner{\cA(\neg B)=w
       \text{~oder~} \cA(A)=w}\\
    &&\gdw&& \cA(A)&=w\text{~und~}\lcorner{\cA(B)=f \text{~oder~}\cA(A)=w}
  \end{align*}
Da mit der Belegung der Variablen -- $\cA(A)=w$ und $\cA(B)=f$ -- die letzte
  Aussage wahr ist, gilt $\cA(A\rightarrow\neg(\neg B\vee A))=f$.
\end{bsp}

\begin{defini}[Tautologie und Kontradiktion]
  Eine Formel, die unter jeder passenden Belegung den Wahrheitswert $w$
  hat, nennt man \emph{Tautologie}. Eine Formel, dessen Wahrheitswert unter
  allen passenden Belegungen $f$ ist, nennt man \emph{Kontradiktion}.
\end{defini}

Beispiele für Tautologien sind $A\vee\neg A$ oder
$A\rightarrow(B\rightarrow A)$ oder der nicht so leicht überschaubare
Ausdruck $\big((A\rightarrow B)\wedge (B\rightarrow C) \big) \rightarrow
(A\rightarrow C)$.

% 2006-04-19

\subsection{Äquivalenz von Formeln}

\begin{defini}[Formeläquivalenz]
  Zwei Formeln $\alpha$ und $\beta$ sind \emph{äquivalent}, wenn sie bei jeder passenden
  Belegung den gleichen Wahrheitswert haben. Die symbolische Schreibweise
  dafür ist $\alpha\equiv \beta$.
\end{defini}

\begin{bsp}
  $A\rightarrow B \equiv \neg(A\wedge \neg B)$
  \begin{center}
    \begin{tabular}{cc|c|c}
      $A$ & $B$ & $A\rightarrow B$ & $\neg(A\wedge\neg B)$\\
      \hline
      $f$ & $f$ & $w$ & $w$\\
      $f$ & $w$ & $w$ & $w$\\
      $w$ & $f$ & $f$ & $f$\\
      $w$ & $w$ & $w$ & $w$
    \end{tabular}
  \end{center}
\end{bsp}

Grundlegende Äquivalenzen:
\begin{itemize}
 \item $A \wedge B \equiv B\wedge A$ \hfill (\emph{Kommutativität})\\
  $A \vee B \equiv B\vee A$
 \item $A\wedge (B\wedge C) \equiv (A\wedge B)\wedge C$ \hfill
  (\emph{Assoziativität})\\
  $A\vee (B\vee C) \equiv (A\vee B)\vee C$
 \item $A\wedge (B\vee C) \equiv (A\wedge B) \vee (A\wedge C)$
  \hfill (\emph{Distributivität})\\
  $A\vee (B\wedge C) \equiv (A\vee B) \wedge (A\vee C)$
 \item $A \equiv \neg(\neg A)$ \hfill (\emph{Doppelnegation})
 \item $\neg(A\wedge B) \equiv \neg A \vee \neg B$
  \hfill (\emph{de Morgan'sche Regeln})\\
  $\neg(A\vee B) \equiv \neg A \wedge \neg B$
 \item $A \wedge A \equiv A$ \hfill (\emph{Absorption})\\
  $A\vee A \equiv A$
 \item $A \wedge \phi \equiv A$ für alle Tautologien $\phi$\\
  $A \vee \psi \equiv A$ für alle Kontradiktionen $\psi$.
 \item $A\rightarrow B \equiv \neg A\vee B$
 \item $A\leftrightarrow B \equiv (A\wedge B) \vee (\neg A\wedge\neg B)$
\end{itemize}

Diese Äquivalenzen bleiben erhalten,
wenn man für die Aussagenvariablen beliebige Formeln einsetzt.
(Alle Vorkommen der gleichen Variablen werden durch die gleiche Formel ersetzt.)
Folgende Äquivalenz entsteht aus $A\wedge B\equiv B\wedge A$,
indem $A$ durch $A\rightarrow B$ und $B$ durch $C \vee \neg B$ ersetzt wird.
\begin{gather*}
  (A\rightarrow B) \wedge (C \vee \neg B) \equiv (C\vee \neg B) \wedge
     (A\rightarrow B)
\end{gather*}

\begin{bsp}
  Die Aussage $A\rightarrow B$ ist nicht äquuivalent zur Aussage $B\rightarrow A$
  ($A\rightarrow B \not\equiv B\rightarrow A$), denn für die Belegung
$\mathcal{A} = \{A,\neg B\}$ ist $\mathcal{A}(A\rightarrow B) = f$ und
$\mathcal{A}(B\rightarrow A) = w$.

  Wohingegen die Äquuivalenz $A\rightarrow B \equiv \neg B \rightarrow \neg A$
  gilt, denn
  \begin{gather*}
    A\rightarrow B \equiv \neg A \vee B \equiv B \vee \neg A
    \equiv \neg\neg B \vee\neg A
    \equiv \neg B \rightarrow \neg A
  \end{gather*}
\end{bsp}


Die Äquivalenz von Formeln lässt sich auch mit dem Verknüpfungszeichen $\leftrightarrow$
ausdrücken.

\begin{center}
  \begin{tabular}{ccc}
    $\underbrace{\alpha\equiv\beta}$ & $\underbrace{\text{genau dann, wenn}}$
       & $\underbrace{\alpha\leftrightarrow\beta}$ eine Tautologie ist.\\
    \parbox[t]{3.5cm}{\centering Äquivalenz zwischen Formeln} &
       \parbox[t]{3.5cm}{\centering umgangssprachl. Äquivalenz} &
       \parbox[t]{5.5cm}{\centering Verknüpfungszeichen für aussagenlog.
         Formeln für Äquivalenz}
  \end{tabular}
\end{center}



\begin{lemma}\label{lemma-mp-semantik}
  Wenn $\alpha$ und $\alpha \rightarrow \beta$ Tautologien sind,
  dann ist auch $\beta$ eine Tautologie.
\end{lemma}

\begin{proof}
  Das Lemma hat die logische Struktur $(C\wedge D)\rightarrow E$,
  wobei $C$ für \glqq{}$\alpha$ ist eine Tautologie\grqq{},
  $D$ für  \glqq{}$\alpha\rightarrow\beta$ ist eine Tautologie\grqq{}
  und  $E$ für \glqq{}$\beta$ ist eine Tautologie\grqq{} steht.
  Es gilt $(C\wedge D)\rightarrow E \equiv (C\wedge \neg E)\rightarrow \neg D$,
  und wir zeigen letztere Aussage.

  Sei also $\alpha$ eine Tautologie, und $\beta$ sei keine Tautologie.
  Dann gibt es eine Belegung $\mathcal{A}$ mit
  $\mathcal{A}(\alpha)=w$ und $\mathcal{A}(\beta)=f$.
  Also gilt $\mathcal{A}(\alpha\rightarrow\beta)=f$,
  d.\,h. $\alpha\rightarrow\beta$ ist keine Tautologie.
\end{proof}


\subsection{Adäquate Verknüpfungszeichen}

Jede Formel mit $k$ Variablen
lässt sich durch eine Wahrheitstafel mit $k+1$ Spalten beschreiben:
die ersten $k$ Spalten enthalten die möglichen Wahrheitswerte
der Variablen, und die letzte Spalte enthält den Wahrheitswert
der Formel unter der durch die ersten $k$ Spalten festgelegten Belegung;
siehe \autoref{tab:wahrheitstafel}.

\begin{table}[ht]
  \centering
  \begin{gather*}
    \begin{array}{ccc|cl}
      A_{1} & A_{2} & A_{3} & \cA\big(\neg \big(A_{1}\vee(A_{3}\leftrightarrow
      A_{2})\big) \vee (A_{1}\wedge\neg A_{3})\big) \\ % g(A_{1},A_{2}, A_{3}) & \\
      \hline
      f & f & f & f &\\
      f & f & w & w & \star\\
      f & w & f & w & \star\\
      f & w & w & f &\\
      w & f & f & w & \star\\
      w & f & w & f &\\
      w & w & f & w & \star\\
      w & w & w & f &\\
    \end{array}
  \end{gather*}
  \caption{Wahrheitstafel der Funktion $g$}
  % g(A_{1},A_{2},A_{3})=\neg \big(A_{1}\vee(A_{3}\leftrightarrow
  % A_{2})\big) \vee (A_{1}\wedge\neg A_{3})$}
  \label{tab:wahrheitstafel}
\end{table}

Aus der Wahrheitstafel kann man direkt eine Formel ablesen,
die zu der Formel, für die die Wahrheitstafel konstruiert wurde,
äquivalent ist (die also die gleiche Wahrheitstafel hat).
Man wählt alle Zeilen mit dem Wahrheitswert~$w$ in der letzten Spalte
(Zeilen mit $\star$ in \autoref{tab:wahrheitstafel}).
Für jede dieser Zeilen bildet man eine Konjunktion von Literalen,
die genau durch die in der Zeile angegebene Belegung wahr wird; siehe
\autoref{tab:aquiv-formel}.

\begin{table}[ht]
  \centering
  \begin{gather*}
    \begin{array}{ccc|cl|c}
      A_{1} & A_{2} & A_{3} & \cA(\alpha) & & \text{Konjunktion von Literalen} \\
      \hline
      f & f & w & w & \star & \neg A_1 \wedge \neg A_2 \wedge      A_3 \\
      f & w & f & w & \star & \neg A_1 \wedge      A_2 \wedge \neg A_3 \\
      w & f & f & w & \star &      A_1 \wedge \neg A_2 \wedge \neg A_3 \\
      w & w & f & w & \star &      A_1 \wedge      A_2 \wedge \neg A_3 \\
    \end{array}
  \end{gather*}
  \parbox{.7\linewidth}{\caption{Erster Schritt für die Bestimmung einer
    äquivalenten Formeln zur Formel aus \autoref{tab:wahrheitstafel}.}
  \label{tab:aquiv-formel}}
\end{table}

Diese Konjunktionen verknüpft man mittels Disjunktion und erhält so eine zur
Ausgangsformel äquivalente Formel.
\begin{gather*}
  \phi = (\neg A_{1} \wedge \neg A_{2} \wedge A_{3}) \vee (\neg A_{1}\wedge
     A_{2} \wedge \neg A_{3}) \vee (A_{1} \wedge \neg A_{2}\wedge \neg
     A_{3}) \vee (A_{1}\wedge A_{2} \wedge \neg A_{3})
\end{gather*}
Diese spezielle Struktur -- Disjunktion von Konjunktionen von Literalen -- der
neuen Formel~$\varphi$ bezeichnet man als \emph{disjunktive Normalform}
(\emph[index=]{DNF}). \index{DNF|see{disjunktive Normalform}}

\begin{lemma}\label{lemma-DNF}
Für jede beliebige aussagenlogische Formel gibt es eine äquivalente
Formel in disjunktiver Normalform.
\end{lemma}

Formeln in DNF enthalten keine Verknüpfungszeichen
$\rightarrow$ und $\leftrightarrow$.
Man braucht also nicht alle Verknüpfungszeichen
zum Beschreiben von Verknüpfungen von Aussagen.

\begin{korol}
Für jede aussagenlogische Formel gibt es eine äquivalente Formel
mit den Verknüpfungszeichen $\neg$, $\vee$ und $\wedge$.
\end{korol}

Man kann auch noch auf das $\vee$ (oder auch das $\wedge$ (aber nicht auf beide))
verzichten.


\begin{satz}
  Für jede aussagenlogische Formel gibt es eine äquivalente Formel, die
  nur die Verknüpfungszeichen $\neg$ und $\wedge$ enthält.

  \begin{proof}
    Sei $\alpha$ eine aussagenlogische Formel, die o.\,B.\,d.\,A. nur die
    Verknüpfungszeichen $\neg, \wedge$ und $\vee$ enthält. Wir führen
    eine Induktion über den Formelaufbau.

    \begin{mdescription}
     \item[IA:] $\alpha$ ist eine Variable $A$.
                Dann enthält $\alpha$ gar keine Verknüpfungszeichen.

     \item[IV:] Für beliebige Formeln $\beta$ und $\gamma$ gibt es
      äquivalente Formeln $\beta' \equiv \beta$ und
      $\gamma'\equiv\gamma$, die nur $\neg$ und $\wedge$ enthalten.

     \item[IS:] Es ist zu zeigen, dass zu jeder Formel, deren Teilformeln
      nur $\neg$ und $\wedge$ enthalten, eine äquivalente Formel mit nur
      den Verknüpfungen $\neg$ und $\wedge$ existiert.
      \begin{faelle}
       \item Sei $\alpha=\neg\beta$. Dann gilt: $\alpha\equiv\neg\beta'$ und
        $\neg\beta'$ enthält nach Induktionsvorraussetzung nur $\neg$ und $\wedge$.

       \item Habe $\alpha$ die Gestalt $\beta\wedge\gamma$. Dann gilt:
        $\alpha\equiv\beta'\wedge\gamma'$. Nach Induktionsvorraussetzung enthalten
        $\beta'$ und $\gamma'$ nur $\neg$ und $\wedge$ als
        Verknüpfungszeichen.

       \item Ist $\alpha$ von der Gestalt $\beta\vee\gamma$. Dann gilt:
        $\alpha\equiv\beta'\vee\gamma'\equiv\neg(\neg\beta'\wedge\gamma')$
        Nach Induktionsvorraussetzung enthält $\neg(\neg\beta'\wedge\gamma')$ nur $\neg$ und
        $\wedge$ als Verknüpfungszeichen.
      \end{faelle}
    \end{mdescription}
  \end{proof}
\end{satz}

\begin{bsp}
  $A\vee B$ kann unter Nutzung der Doppelnegation ($\neg\neg A \equiv A$) und
  der de Morgan'schen Regel ($\neg(A\wedge B) \equiv \neg A\vee \neg B$)
  umgeformt werden:
  \begin{gather*}
    A\vee B \equiv \neg\neg A \vee \neg\neg B \equiv \neg(\neg
       A\wedge\neg B)
  \end{gather*}
  weiteres Beispiel:
  \begin{align*}
    A\rightarrow(B\leftrightarrow C) &\equiv \neg A \vee \big((B\wedge C)
       \vee (\neg B\wedge \neg C)\big)\\
    &\equiv \neg \big(A\wedge \neg \big((B\wedge C) \vee (\neg B \wedge \neg
       C)\big)\big)\\
    &\equiv \neg\big(A\wedge \neg(B\wedge C) \wedge \neg(\neg B \wedge \neg
       C) \big)
  \end{align*}
\end{bsp}

\begin{defini}
Eine Menge $V$ von Verknüpfungszeichen heißt \emph{adäquat},
falls es für jede aussagenlogische Formel eine äquivalente
Formel gibt, die nur Verknüpfungszeichen aus $V$ enthält.
\end{defini}

Man ist natürlich daran interessiert,
möglichst kleine adäquate Mengen von Verknüpfungszeichen zu finden.

\begin{lemma}
Die folgenden Mengen von Verknüpfungszeichen sind adäquat.
\begin{enumerate}
\item $\{\neg,\wedge\}$
\item $\{\neg,\vee\}$
\item $\{\neg,\rightarrow\}$
\end{enumerate}
\end{lemma}

\begin{bemerk}
  Die beiden Verknüpfungszeichen $\neg$ und $\leftrightarrow$ reichen nicht
  aus! Eine Formel, die nur die Verknüpfungen Negation und Implikation
  verwendet, hat entweder die Struktur $\alpha \leftrightarrow \beta$ oder
  $\neg \alpha$ mit $\alpha$ und $\alpha$ als beliebig komplexe Formeln, die
  wiederum nur die
  Verknüpfungen $\neg$ und $\leftrightarrow$ verwenden. Da
  die Wahrheitswerttabelle für die Äquivalenz \autoref{tab:1} immer eine
  gerade Anzahl an Einträgen $w$ und eine gerade Anzahl an Einträgen $f$ hat
  (unabhängig davon, ob das Ergebnis nochmal negiert wird),
  kann man keine Formel aufstellen, die eine ungerade Anzahl an Einträgen $w$ hat
  (wie z.\,B. eine zu $A\wedge B$ äquivalente Formel).

  Formeln, die nur Konjunktion und Disjunktion als Verknüpfungszeichen enthalten,
  nennt man \emph{monotone Formeln}.
  Man stelle sich die Wahrheitswerte $w$ als $1$ und $f$ als $0$ vor.
  Also gilt $f <  w$.
  Eine Belegung $\mathcal{A}$ kann zu einer Belegung $\mathcal{B}$
  vergrößert werden, indem einige Variablen, die in $\mathcal{A}$ den Wert $f$
  erhalten, in $\mathcal{B}$ den Wert $w$ bekommen.
  Dann gilt $\mathcal{A}(\alpha)\leq \mathcal{B}(\alpha)$
  für jede monotone Formel $\alpha$.

  Daraus folgt, dass es keine monotone Formel gibt,
  mit der die Negation ausgedrückt werden kann.
  Sei angenommen, dass es eine monotone Formel $\alpha$ mit $\alpha\equiv \neg A$ gibt.
  Sei $\mathcal{A}$ eine Belegung mit $\neg A\in\mathcal{A}$.
  $\mathcal{B}$ sei die Belegung, die man aus $\mathcal{A}$ erhält,
  indem man die Belegung von $A$ verändert und die Belegungen
  aller anderen Variablen unverändert lässt.
  Dann ist $\mathcal{B}$ eine Vergrößerung von $\mathcal{A}$.
  Aber es gilt $\mathcal{A}(\alpha)=w$ und
  $\mathcal{B}(\alpha)=f$, also $\mathcal{A}(\alpha) > \mathcal{B}$.
\end{bemerk}


\begin{table}
  \hfill
  \begin{tabular}{cc|c}
    $A$ & $B$ & $A\leftrightarrow B$\\
    \hline
    $f$ & $f$ & $w$\\
    $f$ & $w$ & $f$\\
    $w$ & $f$ & $f$\\
    $w$ & $w$ & $w$
  \end{tabular}
  \hfill
  \begin{tabular}{cc|c}
    $A$ & $B$ & $A\downarrow B$\\
    \hline
    $f$ & $f$ & $w$\\
    $f$ & $w$ & $f$\\
    $w$ & $f$ & $f$\\
    $w$ & $w$ & $f$\\
    \multicolumn{3}{c}{$A \uparrow B\equiv\neg(A\wedge B)$}
  \end{tabular}
  \hfill
  \begin{tabular}{cc|c}
    $A$ & $B$ & $A\uparrow B$\\
    \hline
    $f$ & $f$ & $w$\\
    $f$ & $w$ & $w$\\
    $w$ & $f$ & $w$\\
    $w$ & $w$ & $f$\\
    \multicolumn{3}{c}{$A \downarrow B\equiv\neg(A\vee B)$}
  \end{tabular}
  \hfill\null\\
  \centering
  \parbox{.8\linewidth}{\caption{Wahrheitswerttabelle für Äquivalenz (links),
    \emph[rand=]{NOR} (mitte) und \emph[rand=]{NAND} (rechts)}
  \label{tab:1}}
\end{table}

Es gibt zwei (bisher noch nicht betrachtete)
Verknüpfungszeichen, die jeweils einzeln
eine adäquate Menge von Verknüpfungszeichen darstellen.
Das ist das \emph{NAND} ($\uparrow$) und das \emph{NOR} ($\downarrow$).
Die Namen spiegeln ihre Definition wieder.
Es gilt $A\uparrow B \equiv \neg(A\wedge B)$
und $A\downarrow B \equiv \neg(A\vee B)$.

\begin{lemma}
$\{\uparrow\}$ und $\{\downarrow\}$ sind adäquate Mengen
von Verknüpfungszeichen.

\begin{proof}
Es reicht aus, zu zeigen, dass das jeweilige Verknüpfungszeichen
alle Verknüpfungszeichen einer anderen adäquaten Menge \glqq{}simulieren\grqq{}
kann.
Es gilt $\neg A \equiv A \downarrow A \equiv A \uparrow A$,
und
\begin{align*}
  A\wedge B &\equiv \neg\neg(A\wedge B)\\
  &\equiv \neg(\neg A\vee \neg B)\\
  &\equiv \neg( (A\downarrow A) \vee (B\downarrow B))\\
  &\equiv (A\downarrow A) \downarrow (B\downarrow B)
\end{align*}
Da $\{\neg,\wedge\}$ adäquat ist,
ist $\{\downarrow\}$ ebenfalls adäquat.

Mit
\begin{align*}
 A\downarrow B & \equiv \neg(A\vee B) \\
             & \equiv \neg\neg(\neg A\wedge\neg B) \\
             & \equiv \neg\neg((A\uparrow A) \wedge (B\uparrow B)) \\
             & \equiv \neg ((A\uparrow A) \uparrow (B\uparrow B)) \\
             & \equiv ((A\uparrow A) \uparrow (B\uparrow B)) \uparrow
                     ((A\uparrow A) \uparrow (B\uparrow B))
\end{align*}
folgt, dass $\{\uparrow\}$ ebenfalls adäquat ist.
\end{proof}

Wie man sieht, werden die Formeln, in denen nur NAND und NOR verwendet werden,
schnell groß.
\end{lemma}


Jede andere adäquate Menge von Verknüfungszeichen
ist eine Obermenge der fünf genannten adäquaten Mengen.




\section{Formale Theorien}


Mathematiker beweisen wahre mathematische Aussagen.
Die \glqq{}grundlegenden\grqq{} Wahrheiten sind
die Tautologien.
Ein Beweis für eine Tautologie $\alpha$ ist etwas,
was jeden davon überzeugt, dass $\alpha$ eine Tautologie ist.
Zum Beispiel kann eine Wahrheitstafel, in der in der rechten
Spalte nur $w$ stehen, als Beweis für eine Tautologie
aufgefasst werden.
Man kann den Beweis einfach überprüfen,
indem man jede Zeile der Wahrheitstafel überprüft
und dazu den Wahrheitswert der Fomel unter der
der Zeile entsprechenden Belegung ausrechnet.
Wahrheitstafeln werden aber schnell sehr groß
und sind dann nicht mehr handhabbar.
Deshalb werden Beweise auch anders geführt.
Betrachten wir dazu einen Beweis der folgenden Behauptung.
\begin{mdescription}
 \item[Behauptung:] Sei $n$ eine natürliche Zahl. Wenn $n$
  ungerade ist, dann ist $n^{2}$ ungerade.
 \item[Beweis:] Sei $n$ eine natürliche Zahl
     und $n$ sei ungerade.

  Weil $n$ ungerade ist, hat $n$ nicht den Primfaktor $2$.
  $n^{2}$ hat die gleichen Primfaktoren wie $n$.
  Folglich hat $n^{2}$ nicht den Primfaktor 2.
  Also ist $n^{2}$ nicht gerade.
\end{mdescription}

Wir schreiben den Beweis nochmal mit Bemerkungen dazu
auf, wie die einzelnen Beweisschritte zustande kommen.
\begin{center}
  \begin{tabular}{l|l|l}
    Aussage & Erläuterung & formal \\ \hline
    $n$ ist eine ungerade Zahl & Hypothese & $A$ \\
    $n$ ist ungerade $\leftrightarrow$ $n$ hat nicht
       Primfaktor $2$ & Definition & $A\leftrightarrow B$ \\
    $n$ hat nicht Primfaktor $2$
       $\rightarrow$ $n^{2}$ hat nicht Primfaktor $2$ & wahre Aussage & $B\rightarrow C$ \\
    $n^{2}$ hat nicht Primfaktor $2$ $\leftrightarrow$ $n^{2}$ ist ungerade &
       Definition & $C\leftrightarrow D$ \\
    $n^{2}$ ist ungerade & Folgerung & $D$
  \end{tabular}
\end{center}

Zuerst wird die Hypothese $A$ als wahr angenommen.
Im nächsten Schritt wird die Definition von \glqq{}ungerade Zahl\grqq{}
auf die Zahl $n$ angewendet.
Im darauffolgenden Beweisschritt zeigt man,
dass die Aussage $B\rightarrow C$ wahr ist.
Danach wendet man wieder die Definition \glqq{}ungerade Zahl\grqq{} an,
aber diesmal auf die Zahl $n^2$.
Im abschließenden Schritt folgert man daraus $D$.
Insgesamt wird
$(A\wedge (A\leftrightarrow B) \wedge (B\rightarrow C)
 \wedge (C\leftrightarrow D)) \rightarrow D$ bewiesen.
Das ist in der Tat eine Tautologie.
(Das zeigt aber nur, dass die Schlussfolgerungen im Beweis korrekt sind.)

Wir wollen diese Art des Beweisens nun auf formale Füße stellen.
Dazu wir der Begriff der formalen Theorie eingeführt.
Eine formale Theorie dient dazu, über Beweise sprechen zu können.
Die Grundlage bildet eine Menge von Formeln.
Eine Teilmenge davon sind die Theoreme (=Formeln, die man beweisen kann).
Ein Beweis ist eine Kette von Schlussfolgerungen
basierend auf grundlegenden Wahrheiten.
Die grundlegenden Wahrheiten werden durch Axiome festgelegt.
Die Art der Schlussfolgerungen wird durch die Ableitungsregeln festgelegt.
(Es empfiehlt sich, zu folgenden Definitionen parallel
 die Definition der Theorie $\mathrm{L}$ für die Aussagenlogik
 in \autoref{subsec-Theorie-L} zu lesen, die gleichzeitig auch als
 Beispiel für die Defintionen angesehen werden kann.)

\begin{defini}[formale Theorie]\label{def:theorie}
  Eine \emph[index=Theorie!formale]{formale Theorie} $\mathcal{S}$
  ist ein Tripel $(\mathcal{F}, \mathrm{Ax}, \mathrm{R})$ bestehend aus
  \begin{enumerate}
   \item einer Menge von \emph{Formeln} $\mathcal{F}$,
   \item einer Menge von \emph[indexrand=Axiom]{Axiomen}
    $\mathrm{Ax} \subseteq \mathcal{F}$ und
   \item einer endlichen Menge entscheidbarer Relationen
    $\mathrm{R}\subseteq\mathcal{F}^{n}\rightarrow\mathcal{F}$, die man als
    \emph{Ableitungsregeln} bezeichnet.
  \end{enumerate}
\end{defini}

Die Formelmenge $\mathcal{F}$ bezeichnet man auch als \emph{Sprache}
der Theorie.
Jede Formel in $\mathcal{F}$ wird auch als
\emph[indexrand=Formel i.\,d. Theorie]{Formel in der Theorie} bezeichnet.
Theoreme einer Theorie sind die Formeln, die man beweisen kann.

\begin{defini}[Beweis und Theorem]
  Ein \emph{Beweis} in einer (formalen) Theorie $\mathcal{S}$ ist eine Folge
  $\alpha_1, \alpha_2, \dotsc, \alpha_n$ von Formeln von $\mathcal{S}$, so
  dass für $\alpha_{i}$ ($i=1,2,\dotsc, n$) gilt:
  \begin{enumerate}
   \item $\alpha_{i}$ ist ein Axiom von $\mathcal{S}$ oder
   \item $\alpha_{i}$ ist aus vorhergehenden Formeln
    $\alpha_{j_{1}},\dotsc,\alpha_{j_{m}}$ ($j_1,j_2,\dotsc,j_m < i$) mit
    einer Ableitungsregel von $\mathcal{S}$ ableitbar, d.\,h. die
    Ableitungsregel
    $R(\alpha_{j_1},\alpha_{j_2},\dotsc,\alpha_{j_m},\alpha_i)$ gehört zu
    $\mathcal{S}$.
  \end{enumerate}

  Ein \emph{Theorem} von $\mathcal{S}$ ist eine Formel, die am Ende eines
  Beweises in $\mathcal{S}$ steht.
\end{defini}

Beim Beweisen geht es auch um das korrekte Ziehen von
Schlussfolgerungen aus (bewiesenen oder unbewiesenen) Hypothesen.
Auch dieser Begriff wird formal erfasst.

\begin{defini}[Folgerung]
  $\alpha$ ist eine \emph{Folgerung} aus der Formelmenge $\Gamma$ in
  $\mathcal{S}=(\mathcal{F}, \mathrm{Ax}, \mathrm{R})$, falls es einen
  Beweis für $\alpha$ in der Theorie~$\mathcal{S}' =(\mathcal{F},
  \mathrm{Ax}\cup\Gamma, \mathrm{R})$ gibt, in der man die Menge $\Gamma$
  zu den Axiomen von $\mathcal{S}$ hinzugenommen hat.

  Schreibweisen:\\[.5ex]
  \begin{tabular}{rcl}
    $\Gamma \xvdash{\mathcal{S}} \alpha$ & bedeutet & $\alpha$ ist
       Folgerung von $\Gamma$ in $\mathcal{S}$\\
    $ \xvdash{\mathcal{S}} \alpha$ & schreibt man für &
       $\emptyset \xvdash{\mathcal{S}} \alpha$\\
    $\xvdash{\mathcal{S}} \alpha$ & bedeutet &
       $\alpha$ ist Theorem von $\mathcal{S}$
  \end{tabular}

  Falls $\Gamma=\{\beta_1,\dotsc,\beta_k\}$ eine endliche Menge ist,
  schreibt man\\[.5ex]
  \begin{tabular}{rcl}
    $\beta_1,\dotsc,\beta_k \xvdash{\mathcal{S}} \alpha$ & anstelle von &
       $\{ \beta_1,\dotsc,\beta_k \} \xvdash{\mathcal{S}} \alpha$ \\
    $\Gamma, \beta \xvdash{\mathcal{S}} \alpha$ & anstelle von & $\Gamma
       \cup \beta \xvdash{\mathcal{S}} \alpha$ \\
  \end{tabular}
\end{defini}




\section{Die Theorie \texorpdfstring{$\mathrm{L}$}{L} für die Aussagenlogik}
\label{subsec-Theorie-L}

Wir wollen nun die Aussagenlogik als Theorie formulieren.
Die Formeln der Theorie sind alle aussagenlogischen Formeln.
Die Theoreme sollen genau die Tautologien sein.
Nun könnten wir uns die Arbeit leicht machen und eine Theorie
formulieren, in der die Axiome genau die Tautologien sind
und keine Ableitungsregeln existieren.
Offensichtlich sind dann die Theoreme genau die Tautologien,
da in den Beweisen keine Ableitungsschritte gemacht werden können
und in ihnen deshalb nur Axiome -- also Tautologien -- vorkommen.
In dieser Theorie ist es aber nicht einfach, einen Beweis zu
verifizieren -- also von einer Folge von Formeln festzustellen,
ob sie tatsächlich ein Beweis ist.
Das liegt daran, dass es nicht einfach ist, von einer Formel
festzustellen, ob sie ein Axiom ist -- also eine Tautologie.
Die Grundidee ist, dass das Verifizieren von Beweisen einfach sein muss.
Es soll also einfach sein, von einer Formel festzustellen, ob sie
ein Axiom ist, und es soll einfach festzustellen sein,
ob eine Formel mittels einer Ableitungsregel aus anderen Formeln entsteht.
Diese \glqq{}Einfachheit\grqq{} steckt zwar nicht in der Definition
einer formalen Theorie (man kann ihn dort aber auch konkret unterbringen),
ist aber die Intention der Schöpfer des Begriffes.

Die Axiome sollen also möglichst einfache Formeln
und im intuitiven Sinne grundlegende Wahrheiten der Theorie sein.
Ebenso sollen die Ableitungsregeln möglichst einfach sein.
Wenn man eine Theorie definiert hat,
muss man anschließend nachweisen, dass
die Theoreme genau die Formeln sind, die man als wahre Formeln betrachtet.
Für die folgende Theorie für die Aussagenlogik werden wir
im Anschluss zeigen, dass ihre Theoreme genau die Tautologien sind.
Wir werden auch eine andere Theorie sehen,
für die wir beweisen werden,
dass die Theoreme genau die Kontradiktionen sind.



In der folgenden Theorie für die Aussagenlogik beschränken
wir uns auf eine adäquate Menge von Verknüpfungszeichen.
Das macht die Beschreibung der Theorie einfacher.
Und wir wissen ja bereits, dass dadurch nichts an
Ausdruckstärke verloren geht.

\begin{defini}[Theorie für Aussagenlogik]
  Die \emph[index=Theorie!Aussagenlogik]{Theorie für Aussagenlogik}
  $\mathrm{L}$ besteht aus
  \begin{enumerate}
   \item allen aussagenlogischen Formeln mit den Verknüpfungszeichen
    $\neg$ und $\rightarrow$

   \item den \emph[rand=Axiome d. Auss.logik,index=Axiome!Aussagenlogik]{Axiomen}, die aus dem Axiomenschemata (A1), (A2) und (A3)
    durch Einsetzen von beliebigen aussagenlogischen Formeln für $\alpha$,
    $\beta$ und $\gamma$ entstehen: \index{Axiome}
    \begin{enumerate}[({A}1)]
     \item $\alpha \rightarrow (\beta\rightarrow \alpha)$
     \item $\big(\alpha\rightarrow (\beta\rightarrow\gamma)\big)
      \rightarrow \big( (\alpha\rightarrow\beta) \rightarrow
      (\alpha\rightarrow\gamma) \big)$
     \item $( \neg\beta \rightarrow \neg\alpha )
      \rightarrow \big( ( \neg\beta \rightarrow \alpha) \rightarrow
      \beta\big)$
    \end{enumerate}

   \item der Ableitungsregel \emph{modus ponens} (MP) \index{MP|see{modus ponens}}
    \begin{gather*}
      \mathrm{MP}(\alpha, \beta,\gamma) \gdw \beta=\alpha \rightarrow\gamma
    \end{gather*}

    Andere Schreibweise:
    \begin{gather*}
      \frac{\alpha, \alpha\rightarrow\gamma}{\gamma}
    \end{gather*}
  \end{enumerate}
\end{defini}

\begin{lemma}\label{lemma-axiome-tautologien}
  Alle Axiome von $\mathrm{L}$ sind Tautologien.

  \begin{proof}
    Wir betrachten das Axiom (A1) $\gamma=\alpha\rightarrow(\beta\rightarrow
    \alpha)$. Sei $\cA$ eine passende Belegung für $\gamma$, dann gilt
    $\cA(\gamma)=w$ genau dann, wenn $\cA(\alpha)=f$ oder $\cA(\beta)=f$ oder
    $\cA(\alpha)=w$. Da $\cA(\alpha)$ für jede passende Belegung wahr ist,
    gilt auch $\cA(\gamma)=w$ für jede passende Belegung $\cA$ und damit ist
    $\gamma$ eine Tautologie.

    Der Beweis, dass das Axiom (A2) eine Tautologie ist, lässt sich am
    Einfachsten mit einer Wahrheitstabelle führen:
    \begin{gather*}
      \begin{array}{ccc|ccccc|c}
        \alpha& \beta& \gamma& \beta\rightarrow\gamma&
        \alpha\rightarrow(\beta\rightarrow\gamma)& \alpha\rightarrow\beta&
        \alpha\rightarrow\gamma& (\alpha\rightarrow\beta) \rightarrow
        (\alpha\rightarrow\gamma)& \dotso\\
        \hline
        f& f& f& w& w& w& w& w& w\\
        f& f& w& w& w& w& w& w& w\displaybreak[0]\\
        f& w& f& f& w& w& w& w& w\\
        f& w& w& w& w& w& w& w& w\displaybreak[0]\\
        w& f& f& w& w& f& f& w& w\\
        w& f& w& w& w& f& w& w& w\displaybreak[0]\\
        w& w& f& f& f& w& f& f& w\\
        w& w& w& w& w& w& w& w& w
      \end{array}
    \end{gather*}

    Das Axiom (A3) wird für eine passende Belegung $\cA$ $wahr$ genau dann,
    wenn $\cA(\neg\beta\rightarrow\neg\alpha)=f$ oder
    $\cA(\neg\beta\rightarrow\neg\alpha)=f$ oder $\cA(\beta)=w$. Dies gilt
    genau dann, wenn $\lcorner{\cA(\neg\beta)=w\text{~und~}\cA(\neg\alpha)=f}$
    oder $\lcorner{\cA(\neg\beta)=w\text{~und~}\cA(\alpha)=f}$ oder
    $\cA(\beta)=w$. Mit Hilfe des Distributivgesetzes können wir den Ausdruck
    zu $\cA(\beta)=f$ oder $\lcorner{\cA(\alpha)=w\text{~und~}\cA(\alpha)=f}$
    oder $\cA(\beta)=w$ umformen, womit leicht ersichtlich ist, dass das
    Axiom~(A3) unter allen möglichen Belegungen von $\beta$ $wahr$ wird.
  \end{proof}
\end{lemma}

Die Ableitungsregel modus ponens (vollständig
\href{http://de.wikipedia.org/wiki/Modus_ponens}{modus ponendo ponens})
besagt: wenn $\alpha$ und $\alpha\rightarrow\gamma$ abgeleitet werden können,
dann kann auch $\gamma$ abgeleitet werden.
Dies ist auch mit der Deutung der Implikation aus \autoref{sec:1}
anschaulich: Wenn $\alpha$ wahr ist und die Implikation
$\alpha\rightarrow\gamma$ wahr ist, dann muss auch $\gamma$ wahr sein.

% 26.4.06

\begin{bsp}[Ein Beweis für $B\rightarrow B$ in $\mathbf{\mathrm{L}}$]
  \label{bsp:1}
  Wir konstruieren eine Folge $\alpha_1,\dotsc,\alpha_5$ wie folgt:
  \begin{align*}
    \alpha_1 &= B\rightarrow(B\rightarrow B)
       &\text{A1}\\
    \alpha_2 &= B\rightarrow((B\rightarrow B) \rightarrow B)
       &\text{A1}\\
    \alpha_3 &= (B\rightarrow((B\rightarrow B) \rightarrow B)) \rightarrow\\
    &\hspace{1.4cm} ((B\rightarrow(B\rightarrow
       B))\rightarrow(B\rightarrow B)) &\text{A2}\\
    \alpha_4 &= (B\rightarrow(B\rightarrow B))\rightarrow(B\rightarrow B)
       &\text{MP auf $\alpha_2$, $\alpha_3$}\\
    \alpha_5 &= B\rightarrow B
       &\text{MP auf $\alpha_1$, $\alpha_4$}
  \end{align*}
  Die Folge $\alpha_1,\dotsc,\alpha_5$ ist ein Beweis von $\mathrm{L}$,
  da $\alpha_1$, $\alpha_2$ und $\alpha_3$ Axiome sind,
  $\alpha_4$ mittels modus ponens aus $\alpha_2$ und $\alpha_3$
  ensteht (es gilt $MP(\alpha_2,\alpha_3,\alpha_4)$) und
  $\alpha_5$ mittels modus ponens aus $\alpha_1$ und $\alpha_4$
  ensteht (es gilt $MP(\alpha_1,\alpha_4,\alpha_5)$).
  Also ist $B\rightarrow B$ ein Theorem von $\mathrm{L}$.
\end{bsp}

Der Beweis $\alpha_{1},\dotsc,\alpha_{5}$ ist ohne Einschränkungen bzgl.
$B$ geführt worden.
Deshalb kann man ihn statt für $B$ auch für jede beliebige Formel $\beta$ führen.

\begin{lemma}\label{lem:0}
Für jede aussagenlogische Formel $\beta$ gilt: $\Lvdash \beta\rightarrow\beta$.
\end{lemma}

Also ist zum Beispiel
  $(A_1\rightarrow \neg(A_2\rightarrow A_1))
            \rightarrow(A_1\rightarrow \neg(A_2\rightarrow A_1))$ ebenfalls
  ein Axiom von $\mathrm{L}$.

Um zu verifizieren, dass eine Formel ein Axiom ist,
muss man versuchen, sie in die Struktur eines der drei Axiomenschemata
zu zerlegen. Das ist einfach (und auf jeden Fall viel einfacher, als
festzustellen, ob die Formel eine Tautologie ist).
Es ist noch viel einfacher, festzustellen, ob Formel $\gamma$ mittels
modus ponens aus $\alpha$ und $\beta$ entsteht.
Dazu muss man nur testen, ob die Formeln $\alpha\rightarrow\gamma$ und
$\beta$ gleich sind.
In diesem Sinne erfüllt die Theorie $\mathrm{L}$ die Ansprüche an die Einfachheit.


\begin{bsp}\label{bsp:2}
  Wir beweisen für die Theorie $\mathrm{L}$ die Folgerung
  \begin{gather*}
    \alpha\rightarrow\beta, \beta\rightarrow\gamma
       \Lvdash \alpha\rightarrow\gamma
  \end{gather*}
  Wir werden sehen (\autoref{al-Deduktionstheorem}), dass man Folgerungen
  wie Ableitungsregeln benutzen kann.
  Obige Folgerung wird auch als \emph{modus barbara} bezeichnet.

  \begin{align*}
    (1)\quad & \alpha\rightarrow\beta & \text{Hypothese}\\
    (2)\quad & \beta\rightarrow\gamma & \text{Hypothese}\\
    (3)\quad & (\beta\rightarrow\gamma) \rightarrow
       (\alpha\rightarrow(\beta\rightarrow\gamma)) &
       \text{A1} \\
    (4)\quad & \alpha\rightarrow(\beta\rightarrow\gamma) & \text{MP 2,3}\\
    (5)\quad & (\alpha\rightarrow(\beta\rightarrow\gamma)) \rightarrow
       ( (\alpha\rightarrow\beta) \rightarrow ( \alpha\rightarrow\gamma))
       & \text{A2} \\
    (6)\quad & (\alpha\rightarrow\beta) \rightarrow ( \alpha\rightarrow\gamma)
       & \text{MP 4,5} \\
    (7)\quad & \alpha\rightarrow\gamma & \text{MP 1,6}
  \end{align*}
\end{bsp}

Aus widersprüchlichen Hypothesen lässt sich alles folgern.

\begin{lemma}\label{lem:01}
  Für alle aussagenlogischen Formeln $\alpha$ und $\beta$ gilt $\neg\alpha,
  \alpha \Lvdash \beta$.
\begin{proof}
  \begin{align*}
    (1)\quad & \alpha & \text{Hypothese} \\
    (2)\quad & \neg \alpha & \text{Hypothese} \\
    (3)\quad & \alpha \rightarrow (\neg\beta \rightarrow \alpha) &
       \text{A1} \\
    (4)\quad & \neg\beta \rightarrow \alpha & \text{MP 1,3} \\
    (5)\quad & \neg\alpha \rightarrow (\neg\beta \rightarrow \neg\alpha) &
       \text{A1} \\
    (6)\quad & \neg\beta \rightarrow \neg\alpha & \text{MP 2,5} \\
    (7)\quad & (\neg \beta \rightarrow \neg \alpha) \rightarrow
       \big((\neg\beta \rightarrow \alpha) \rightarrow \beta\big) &
       \text{A3} \\
    (8)\quad & (\neg\beta \rightarrow \alpha) \rightarrow \beta &
       \text{MP 6,7} \\
    (9)\quad & \beta & \text{MP 4,8} \\
  \end{align*}
\end{proof}
\end{lemma}



Unser Ziel ist der Beweis,
dass die Theoreme von $\mathrm{L}$ genau die Tautologien sind.
Die eine Beweisrichtung ist relativ einfach:
jedes Theorem ist eine Tautologie.
Diese Eigenschaft von $\mathrm{L}$ heißt \emph{Korrektheit}.
Man kann nichts \glqq{}falsches\grqq{} -- was keine Tautologie ist --
beweisen.

\begin{satz}[Korrektheit von $\mathrm{L}$]\label{satz:1}
  \index{Korrektheit}
  Jedes Theorem von $\mathrm{L}$ ist eine aussagenlogische Tautologie.

  \begin{proof}
    Sei $\beta$ ein Theorem von $\mathrm{L}$. Wir führen eine Induktion über die
    Länge $k$ des Beweises von $\beta$.

    \begin{mdescription}
     \item[IA:] Sei $k=1$, d.\,h. $\beta$ ist ein Axiom. Alle Axiome sind
      Tautologien (\autoref{lemma-axiome-tautologien}),
      also ist $\beta$ auch eine Tautologie.

     \item[IV:] Jedes Theorem von $\mathrm{L}$, dessen Beweis Länge
      $\leq n$ hat, ist eine Tautologie.

     \item[IS:] $\beta$ habe einen Beweis der Länge $n+1$.
      \begin{faelle}
       \item Falls $\beta$ ein Axiom ist, dann ist $\beta$ eine Tautologie.
       \item Andernfalls geht $\beta$ durch modus ponens aus $\alpha$ und
        $\alpha\rightarrow\beta$ hervor, wobei $\alpha$ und $\alpha\rightarrow\beta$
        zwei bereits hergeleitete Formeln des Beweises von $\beta$ sind,
        deren Beweise also $\leq n$ sind.
        Deshalb sind $\alpha$ und $\alpha\rightarrow\beta$ nach Induktionsvorraussetzung
        Tautologien.
        Nach \autoref{lemma-mp-semantik} ist $\beta$ dann ebenfalls eine Tautologie.
      \end{faelle}
    \end{mdescription}
  \end{proof}
\end{satz}

Die andere Beweisrichtung ist schwieriger:
jede Tautologie ist ein Theorem.
Diese Eigenschaft von $\mathrm{L}$ heißt \emph{Vollständigkeit}.
Die folgenden Sätze und Lemmata führen dorthin.


\subsection{Das Deduktionstheorem}

Folgerungen aus Hypothesen sind typische Beweisschritte.
Deshalb gibt es den Begriff der Folgerung auch für formale Theorien.
Letztlich ist die Folgerung nichts anderes als eine Implikation
(informell gesprochen).
Die Aussage des folgenden Deduktionstheorems (für einen einfachen Fall) lautet:
\begin{quote}
wenn man $\beta$ aus der Hypothese $\alpha$ folgern kann ($\alpha \vdash \beta$),
dann ist $\alpha\rightarrow\beta$ beweisbar ($\vdash\alpha\rightarrow\beta$).
\end{quote}
Mit Benutzung des Deduktionstheorems kann also $\vdash B\rightarrow B$
(\autoref{bsp:1}) sehr schnell
bewiesen werden.
$B\vdash B$ geht mit einem Beweisschritt ($B$ wird als Hypothese benutzt),
und mit dem Deduktionstheorem folgt direkt $\vdash B\rightarrow B$.
Der Sinn des Deduktionstheorems ist seine Benutzung zur Vereinfachung von Beweisen.

\begin{satz}[Deduktionstheorem]\label{al-Deduktionstheorem}\index{Deduktion}
  Sind $\alpha$ und $\beta$ zwei aussagenlogische Formeln und $\Gamma$
  eine Formelmenge, dann gilt:
  \begin{gather*}
    \Gamma, \alpha \Lvdash \beta \quad\gdw\quad \Gamma \Lvdash \alpha\rightarrow\beta
  \end{gather*}

  \begin{proof}
    \begin{mdescription}
     \item[\glqq$\Leftarrow$\grqq{}] Es gelte $\Gamma \Lvdash
      \alpha\rightarrow\beta$. Nimmt man zusätzlich $\alpha$ zur Menge
      $\Gamma$ hinzu, gilt $\Gamma, \alpha \Lvdash \alpha$
      und $\Gamma, \alpha \Lvdash \alpha\rightarrow\beta$.
      Daraus kann man mittels Anwendung von modus ponens: $\Gamma,\alpha
      \Lvdash \beta$ zeigen.

     \item[\glqq$\Rightarrow$\grqq{}] Es gelte $\Gamma, \alpha \Lvdash \beta$.

      Wir führen eine Induktion über die Länge $k$ des Beweises von
      $\beta$ aus $\Gamma,\alpha$.

      \begin{mdescription}
       \item[IA:] $k=1$: Der Beweis von $\beta$ besteht nur aus $\beta$.
        \begin{faelle}
         \item $\beta$ ist ein Axiom oder $\beta\in\Gamma$.

          Dann gilt $\Gamma \Lvdash \beta$. Mit Axiom A1
          $\beta \rightarrow (\alpha\rightarrow\beta)$ und modus ponens folgt
          $\Gamma \Lvdash \alpha \rightarrow\beta$.
          \begin{align*}
            (1)\quad &\beta&\text{Hypothese}\\
            (2)\quad &\beta\rightarrow(\alpha\rightarrow\beta)
               &\text{A1}\\
            (3)\quad &\alpha\rightarrow\beta &\text{MP 1,2}
          \end{align*}

         \item $\beta=\alpha$. Dann ist $\alpha\rightarrow\beta =
          \beta\rightarrow\beta$.

          Da $\Lvdash \beta\rightarrow\beta$
          (\autoref{bsp:1}), folgt $\Gamma \Lvdash
          \beta\rightarrow\beta$.
        \end{faelle}

       \item[IV:] Die Behauptung $\Gamma,\alpha\Lvdash \beta
        \gdw \Gamma\Lvdash\alpha\rightarrow\beta$ gilt für alle
        Formeln $\beta$ mit Beweisen der Länge $\leq n$.

       \item[IS:] Der Beweis von $\Gamma, \alpha \Lvdash \beta$
        habe die Länge $n+1$ und die Formeln
        \begin{gather*}
          \alpha_{1}, \dotsc,\alpha_{i},\dotsc,\alpha_{j},\dotsc,
             \alpha_{n+1} = \beta
        \end{gather*}

        \begin{faelle}
         \item $\beta$ ist ein Axiom oder aus $\Gamma$ oder
          $\beta=\alpha$.

          geht genauso wie Induktionsanfang.

         \item Die Formel $\beta$ entsteht durch modus ponens aus $\alpha_{i}$ und
          $\alpha_{j}$ ($i,j\leq n$), wobei o.\,B.\,d.\,A.
          $\alpha_{j}=(\alpha_{i}\rightarrow \beta)$

          Nach Induktionsvorraussetzung gilt $\Gamma \Lvdash
          \alpha\rightarrow\alpha_{i}$ und $\Gamma \Lvdash
          \alpha\rightarrow (\alpha_{i}\rightarrow\beta)$. Mit der
          Ausprägung $(\alpha\rightarrow(\alpha_{i}\rightarrow\beta))
          \rightarrow \big((\alpha\rightarrow\alpha_{i}) \rightarrow
          (\alpha\rightarrow\beta)\big)$ von Axiom A2 folgt durch Anwendung
          von modus ponens mit $\Gamma \Lvdash
          \alpha\rightarrow\beta$.
        \end{faelle}
      \end{mdescription}
    \end{mdescription}
  \end{proof}
\end{satz}

Im Beweis des folgenden Lemmas werden wir das Deduktionstheorem benutzen.

\begin{lemma}\label{lem:1}
  $\alpha\rightarrow(\beta \rightarrow\gamma), \beta \Lvdash
  \alpha\rightarrow\gamma$
\begin{proof}
  Wir beweisen zuerst
     $\alpha \rightarrow (\beta\rightarrow\gamma), \beta,\alpha \Lvdash \gamma$.
  \begin{align*}
    (1)\quad &\alpha \rightarrow(\beta\rightarrow\gamma)&\text{Hypothese}\\
    (2)\quad &\beta &\text{Hypothese}\\
    (3)\quad &\alpha &\text{Hypothese}\\
    (4)\quad &\beta\rightarrow\gamma &\text{MP 3,1}\\
    (5)\quad &\gamma &\text{MP 2,4}\\
  \end{align*}
  Damit ist $\alpha \rightarrow (\beta\rightarrow\gamma), \beta,\alpha \Lvdash \gamma$
  bewiesen.
  Mit dem Deduktionstheorem folgt dann $\alpha\rightarrow(\beta\rightarrow
  \gamma), \beta \Lvdash \alpha\rightarrow\gamma$.
\end{proof}
\end{lemma}

Bereits bewiesene Theoreme können in Beweisen direkt verwendet werden.
(Man könnte auch alle Beweisschritte des bewiesenen Theorems
 in den neu geführten Beweis kopieren.)
Das Deduktionstheorem liefert zudem noch die Möglichkeit,
auch zusätzliche Ableitungsregeln zu benutzen.
Zum Beispiel kann
$\alpha\rightarrow(\beta \rightarrow\gamma), \beta \Lvdash \alpha\rightarrow\gamma$
wie eine zusätzliche Ableitungsregel verwendet werden.
Mit dem Deduktionstheorem folgt daraus
$\Lvdash \alpha\rightarrow(\beta \rightarrow\gamma)\rightarrow
  ( \beta \rightarrow \alpha\rightarrow\gamma)$.
Wenn man in einem Beweis
bereits $\alpha\rightarrow(\beta \rightarrow\gamma)$ und
$\beta$ bewiesen hat,
dann kann daraus mit zweimaliger Anwendung des modus ponens
$\alpha\rightarrow\gamma$  bewiesen werden.
Im folgenden Beweis werden wir bereits bewiesene Theoreme
und Folgerungen benutzen.

\begin{lemma}\label{lem:2}
Für jede aussagenlogische Formel $\beta$ gilt $\Lvdash \neg\neg \beta \rightarrow\beta$.
  \begin{proof}
    \begin{align*}
      (1)\quad &(\neg\beta \rightarrow \neg\neg\beta) \rightarrow \big( (\neg\beta
         \rightarrow\neg\beta) \rightarrow \beta \big)
         &\text{A3}\\
      (2)\quad &\neg\beta \rightarrow \neg\beta&\text{\autoref{lem:0}}\\
      (3)\quad &(\neg\beta \rightarrow \neg\neg\beta) \rightarrow \beta
         &\text{aus 1,2 mit \autoref{lem:1}}\\
      (4)\quad &\neg\neg\beta \rightarrow (\neg\beta \rightarrow \neg\neg\beta)
         &\text{A1}\\
      (5)\quad &\neg\neg \beta \rightarrow\beta &\text{aus 4, 3 mit
         \autoref{lem:1}}
    \end{align*}
  \end{proof}
\end{lemma}

\begin{lemma}\label{lem:4}
  Für alle aussagenlogischen Formeln $\alpha$ und $\beta$ kann man die
  folgenden Formeln ableiten:
    $\Lvdash \neg\alpha \rightarrow  (\alpha \rightarrow \beta)$
und $\Lvdash \alpha \rightarrow  (\neg\alpha \rightarrow \beta)$.
\begin{proof}
Folgt mit dem Deduktionstheorem aus \autoref{lem:01}.
\end{proof}
\end{lemma}


\begin{lemma}\label{lem:3}
  $\Lvdash \beta \rightarrow \neg\neg\beta$
  \begin{proof}
    \begin{align*}
      (1)\quad & (\neg\neg\neg \beta\rightarrow \neg\beta)\rightarrow
         \big((\neg\neg\neg\beta\rightarrow\beta)\rightarrow \neg\neg\beta\big) &
         \text{A3}\\
      (2)\quad & \neg\neg\neg\beta \rightarrow \neg\beta &
         \text{\autoref{lem:2}}\\
      (3)\quad & (\neg\neg\neg\beta\rightarrow\beta)\rightarrow
         \neg\neg\beta &\text{MP 2,1}\\
      (4)\quad & \beta \rightarrow (\neg\neg\neg\beta \rightarrow \beta)
         &\text{A1}\\
      (5)\quad & \beta \rightarrow \neg\neg\beta
         &\text{\autoref{bsp:2} mit 4,3}
    \end{align*}
  \end{proof}
\end{lemma}

\begin{lemma}\label{lem:5}
  $\Lvdash (\alpha \rightarrow \beta) \rightarrow (\neg \beta \rightarrow \neg \alpha)$.
  Dieser Schluss heißt \emph{modus tollens}.

  \begin{proof}
    Wir zeigen zuerst $\alpha \rightarrow \beta\ \Lvdash\ \neg\beta\rightarrow\neg\alpha$.
    \begin{align*}
      (1)\quad & \alpha \rightarrow \beta & \text{Hypothese}\\
      (2)\quad & \neg\neg\alpha \rightarrow \alpha & \text{\autoref{lem:2}} \\
      (3)\quad & \neg\neg\alpha \rightarrow \beta
         & \text{\autoref{bsp:2} mit 2,1}\\
      (4)\quad & \beta \rightarrow \neg\neg\beta & \text{\autoref{lem:3}} \\
      (5)\quad & \neg\neg\alpha \rightarrow \neg\neg \beta &
         \text{\autoref{bsp:2} mit 3,4}\\
      (6)\quad & (\neg\neg\alpha \rightarrow \neg\neg \beta) \rightarrow
         (\neg\beta \rightarrow \neg \alpha) & \text{\autoref{enu:1} auf
         Aufgabenblatt 2}\\
      (7)\quad & \neg\beta \rightarrow \neg \alpha & \text{MP 5,6}
    \end{align*}
    Das Lemma folgt durch Anwendung des Deduktionstheorems.
  \end{proof}
\end{lemma}

\begin{lemma}\label{lem:6}
  $\Lvdash \alpha \rightarrow (\neg \beta \rightarrow \neg (\alpha
  \rightarrow \beta))$
  \begin{align*}
    (a)\quad& \Lvdash (\alpha\rightarrow\beta) \rightarrow
       (\alpha\rightarrow\beta) & \text{\autoref{lem:0}}\\
    (b)\quad & \alpha\rightarrow \beta, \alpha\Lvdash\beta &\text{mit
       DT aus $(a)$}\\
    (c)\quad & \Lvdash \alpha \rightarrow \big(( \alpha \rightarrow \beta)
       \rightarrow \beta\big) & \text{mit DT aus $(b)$} \\
    (d)\quad & \Lvdash \big((\alpha\rightarrow\beta)
       \rightarrow \beta\big) \rightarrow (\neg \beta \rightarrow \neg
       (\alpha\rightarrow\beta)) &\text{\autoref{lem:5}}\\
    (e)\quad & \Lvdash \alpha \rightarrow (\neg \beta \rightarrow \neg
       (\alpha\rightarrow\beta)) & \text{\autoref{bsp:2} mit $(c)$, $(d)$}
  \end{align*}
  Dies ist keine streng formale Beweisführung (daher auch die Buchstaben
  und keine Zahlen als Bezeichnung der Schritte), da ein Beweis in der
  Theorie~$\mathrm{L}$ eine Folge von Formeln ist, in denen jedoch nicht
  das Zeichen $\vdash$ vorkommen darf. Jede Zeile mit einem $\vdash$ steht
  eigentlich als Abkürzung für einen korrekten formalen Beweis \ldots{}

  Uns soll dies hier jedoch genügen, da damit der Beweis skizziert ist.
  Der formale Beweis ist einfach nur länger.
\end{lemma}

\begin{lemma}\label{lem:7}
  $\Lvdash (\alpha \rightarrow \beta) \rightarrow ((\neg \alpha
  \rightarrow \beta) \rightarrow \beta)$
\begin{proof}
  Wir zeigen zuerst
  $\alpha \rightarrow \beta, \neg \alpha \rightarrow \beta \Lvdash \beta$.
  \begin{align*}
    (1)\quad & \alpha \rightarrow \beta & \text{Hypothese} \\
    (2)\quad & \neg \alpha \rightarrow \beta & \text{Hypothese} \\
    (3)\quad & (\alpha \rightarrow \beta) \rightarrow (\neg
       \beta\rightarrow\neg\alpha) & \text{\autoref{lem:5}} \\
    (4)\quad & \neg \beta\rightarrow\neg\alpha & \text{MP 1,3} \\
    (5)\quad & (\neg \alpha \rightarrow \beta) \rightarrow (\neg
       \beta\rightarrow \neg\neg\alpha) & \text{\autoref{lem:5}} \\
    (6)\quad & \neg \beta\rightarrow \neg\neg\alpha & \text{MP 2,5} \\
    (7)\quad & (\neg \beta \rightarrow \neg\neg \alpha) \rightarrow
       ((\neg\beta\rightarrow\neg\alpha) \rightarrow \beta) &
       \text{A3}\\
    (8)\quad & (\neg\beta\rightarrow\neg\alpha) \rightarrow \beta &
       \text{MP 6,7} \\
    (9)\quad & \beta & \text{MP 4,8}
  \end{align*}
  Das Lemma folgt mittels Deduktionstheorem.
\end{proof}
\end{lemma}


\subsection{Übersicht der gezeigten Theoreme}

Nocheinmal als Zusammenfassung alle gezeigten Theoreme:
\begin{align*}
  \alpha &\rightarrow\alpha &\text{\autoref{lem:0}}\\
  \neg\neg\alpha &\rightarrow \alpha  &\text{\autoref{lem:2}}\\
  \alpha &\rightarrow \neg\neg \alpha &\text{\autoref{lem:3}}\\
  \neg\alpha &\rightarrow (\alpha \rightarrow \beta)
     &\text{\autoref{lem:4}}\\
  (\neg \beta \rightarrow \neg \alpha) &\rightarrow (\alpha \rightarrow
     \beta) & \text{\autoref{enu:1} auf Blatt 2}\\
  (\alpha \rightarrow \beta) &\rightarrow (\neg \beta \rightarrow \neg
     \alpha) & \text{\autoref{lem:5}}\\
  \alpha &\rightarrow (\neg \beta \rightarrow \neg (\alpha \rightarrow \beta))
     &\text{\autoref{lem:6}}\\
  (\alpha \rightarrow \beta) &\rightarrow ((\neg \alpha \rightarrow
     \beta) \rightarrow \beta) &\text{\autoref{lem:7}}
\end{align*}


\subsection{Vollständigkeit von \texorpdfstring{$\mathrm{L}$}{L}}

Mit \autoref{satz:1} hatten wir bereits gezeigt, dass jedes Theorem von
$\mathrm{L}$ eine Tautologie ist. In diesem Abschnitt soll die die
\emph{Vollständigkeit} von $\mathrm{L}$ gezeit werden, also dass jede
Tautologie ein Theorem von $\mathrm{L}$ ist.

Im ersten Schritt (\autoref{satz:2}) werden wir zeigen, dass
aus einer Belegung -- das ist ja eine Menge von Literalen -- $\cA$,
unter der die Formel $\alpha$ den Wahrheitswert $w$ hat,
die Formel $\alpha$ gefolgert werden kann (d.\,h. $\cA\Lvdash \alpha$).

Im zweiten Schritt (\autoref{satz:3}) wird gezeigt,
wie man die Hypothesenmengen für tautologien verkleiner kann.
Für eine Tautologie $\alpha$ und jede Belegung $\cA$
gilt folglich $\cA \Lvdash \alpha$.
Wenn die Belegungen $\cA$ und $\cA'$ fast gleich sind
und sich nur in der Belegung einer einzigen Variablen $B$ unterscheiden,
kann man diese Variable aus den Belegungen entfernen.
Falls $B\in \cA$ und $\neg B\in\cA'$,
dann gilt $\cA\setminus\{B\} \Lvdash \alpha$.
Für eine Tautologie $\alpha$ kann man diesen Prozess wiederholen,
bis die Hypothesenmenge leer ist, und damit folgt $\Lvdash \alpha$.


\begin{satz}[Belegung und Hypothesen]\label{satz:2}
  Sei $\phi$ eine aussagenlogische Formel und $\mathcal{A}$ eine zu
  $\phi$ passende Belegung. Dann gilt:
  \begin{enumerate}
   \item $\mathcal{A} \Lvdash \phi$, falls
    $\mathcal{A}(\phi)=w$, und

   \item $\mathcal{A} \Lvdash \neg\phi$, falls
    $\mathcal{A}(\phi)=f$.
  \end{enumerate}

  \begin{proof}
    % 3.5.06

    Sei $\phi_{\mathcal{A}} = \begin{cases} \phi & \mathcal{A}(\phi)=w\\
    \neg\phi & \mathcal{A}(\phi)=f\end{cases}$

    Wir müssen $\cA\Lvdash \varphi_{\cA}$ zeigen und
    machen das mittels Induktion über den Formelaufbau.

    \begin{mdescription}
     \item[IA:] $\phi$ ist eine Variable, d.\,h.~$\phi=B$.
      \begin{itemize}
       \item $B\in\mathcal{A}$. Dann gilt $\mathcal{A}\Lvdash B$
        (Deduktionstheorem).
        Da $\mathcal{A}(B)=w$, folgt die Behauptung.
       \item $\neg B\in\mathcal{A}$. Dann gilt $\mathcal{A}\Lvdash \neg B$.
        Da $\mathcal{A}(B)=f$, folgt die Behauptung.
      \end{itemize}

     \item[IV:] für alle Formeln $\phi$ gilt $\mathcal{A}
      \Lvdash \phi_{\mathcal{A}}$

     \item[IS:] die Formel $\phi$ kann die Gestalt $\neg\alpha$ oder $\alpha
      \rightarrow\beta$ mit zwei beliebigen Formeln $\alpha$ und $\beta$ haben.

      \begin{faelle}
       \item $\phi$ ist eine Negation -- $\phi=\neg\alpha$
        \begin{faelle}
         \item Unter der Belegung $\cA$ ist $\phi$ $wahr$. Dann muss $\alpha$
          unter der Belegung $falsch$ sein. Nach der Induktionsvorraussetzung
          gilt $\mathcal{A} \Lvdash \alpha_{\mathcal{A}} = \neg\alpha = \phi$,
          d.\,h. $\mathcal{A} \Lvdash \phi = \phi_{\mathcal{A}}$.

         \item $\phi$ ist $falsch$ unter der Belegung $\cA$, also ist
          $\mathcal{A}(\alpha)=w$.
          \begin{align*}
            (1)\quad & \alpha & \text{IV}\\
            (2)\quad & \alpha\rightarrow\neg\neg\alpha
               &\text{\autoref{lem:3}}\\
            (3)\quad & \neg\neg\alpha &\text{MP 1,2}
          \end{align*}
          Es gilt also $\cA \Lvdash \neg\neg\alpha = \phi_{\mathcal{A}}$.
        \end{faelle}

       \item $\phi$ ist eine Implikation -- $\phi=\alpha\rightarrow\beta$
        \begin{faelle}
         \item $\phi$ ist $falsch$ unter der Belegung $\mathcal{A}$. Dann muss
          gelten, dass $\mathcal{A}(\alpha)=w$ und $\mathcal{A}(\beta)=f$ ist.
          \begin{align*}
            (1)\quad & \alpha &\text{IV}\\
            (2)\quad & \neg\beta &\text{IV}\\
            (3)\quad & \alpha\rightarrow(\neg\beta\rightarrow
               \neg(\alpha\rightarrow\beta)) &\text{\autoref{lem:6}}\\
            (4)\quad & \neg\beta \rightarrow \neg(\alpha\rightarrow\beta)
               &\text{MP 1,3}\\
            (5)\quad & \neg(\alpha\rightarrow\beta) &\text{MP 2,4}
          \end{align*}
          Also gilt $\mathcal{A} \Lvdash
          \neg(\alpha\rightarrow\beta) = \phi_{\mathcal{A}}$.

         \item $\phi$ ist $wahr$ unter der Belegung $\mathcal{A}$, d.\,h.
          $\phi_{\mathcal{A}}=\alpha\rightarrow\beta$. Für die beiden
          Teilformeln gibt es folgende Möglichkeiten:
          \begin{itemize}
           \item Die Formel $\alpha$ ist $falsch$ unter der Belegung $\cA$.
            Nach Induktionsvorraussetzung gilt dann $\mathcal{A} \Lvdash
            \neg\alpha$.
            \begin{align*}
              (1)\quad & \neg\alpha &\text{IV}\\
              (2)\quad & \neg\alpha \rightarrow (\alpha\rightarrow\beta)
                 &\text{\autoref{lem:4}}\\
              (3)\quad & \alpha\rightarrow\beta & \text{MP 1,3}
            \end{align*}
            Also gilt $\mathcal{A} \Lvdash \alpha\rightarrow\beta=
            \phi_{\mathcal{A}}$.

           \item Die Teilformel $\beta$ ist $wahr$ unter der Belegung
            $\mathcal{A}$. Nach Induktionsvorraussetzung gilt dann
            $\mathcal{A} \Lvdash \beta$.
            \begin{align*}
              (1)\quad & \beta &\text{IV}\\
              (2)\quad & \beta\rightarrow(\alpha\rightarrow\beta) &
                 \text{A1}\\
              (3)\quad & \alpha\rightarrow\beta &\text{MP 1,2}
            \end{align*}
            Also gilt $\mathcal{A} \Lvdash
            \alpha\rightarrow\beta = \phi_{\mathcal{A}}$.
          \end{itemize}
        \end{faelle}
      \end{faelle}
    \end{mdescription}
  \end{proof}
\end{satz}

Dieser Beweis ist so schön konstruktiv, dass man mal sehen will,
wie der aus einer Belegung konstruierte Beweis aussieht.

\begin{bsp}\label{bsp-Belegungen}
  Wir betrachten die Formel
  $\phi = A\rightarrow \neg(\neg A\rightarrow B)$
  und die Belegung $\mathcal{A}=\{A, \neg B\}$.
  Da $\cA(\phi)=f$ ist
  $\phi_{\mathcal{A}} = \neg(A\rightarrow \neg(\neg A\rightarrow B))$.
  Der Beweis für $\cA\Lvdash \varphi_{\cA}$ wird induktiv aus dem
  Formelaufbau von $\varphi$ konstruiert.

  Der induktive Aufbau der Formel,
  die sich aus den Teilen ergebenden beweisbaren Folgerungen
  und der Aufbau des Beweises
  sind graphisch in \autoref{fig-formelaufbau} und \autoref{fig-beweisaufbau} dargestellt.
  Interessanterweise wird die Hypothese $\neg B$ in dem Beweis
  nicht benutzt.
  Wenn man den Wahrheitswert von $\phi$ unter $\cA$ ausrechnet,
  sieht man auch, dass der $\cA(A)=w$ zu seiner Bestimmung ausreicht
  -- die Belegung von $B$ spielt keine Rolle.
\end{bsp}

\begin{figure}[ht]
\centering
\includegraphics{resolution.14}
\qquad \qquad
\includegraphics{resolution.15}\\
\caption{Induktiver Aufbau der Formel $A\rightarrow\neg(\neg A\rightarrow B)$
und die für Belegung $\cA=\{A,\neg B\}$ beweisbaren (Teil-)Formeln
(\autoref{bsp-Belegungen})}.
\label{fig-formelaufbau}
\end{figure}

\begin{figure}
\centering
\includegraphics{resolution.16}\\
\caption{Fortsetzung von \autoref{fig-formelaufbau}:
Induktiver Aufbau des Beweises gemäß \autoref{satz:2}}
\label{fig-beweisaufbau}
\end{figure}

Im nächsten Schritt geht es darum,
die Hypothesenmenge zu verkleinern.
Dazu betrachten wir zuerst ein Beispiel.

\begin{bsp}
Die Formel $A \rightarrow (B\rightarrow B)$ ist eine Tautologie.
  Nach dem eben bewiesenen \autoref{satz:2} kann man eine beliebige Belegung nehmen
und daraus die Formel beweisen.
Wir nehmen die beiden Belegungen
$\mathcal{A}_{1}=\{\neg A, B\}$ und $\mathcal{A}_{2}=\{\neg A,B\}$.
Nach obigem Satz gilt
  \begin{gather*}
    \neg A, B \Lvdash A \rightarrow (B\rightarrow B)\text{~und~}
       \neg A, \neg B \Lvdash A \rightarrow (B\rightarrow B)
  \end{gather*}
Wir wenden auf beide Folgerungen das Deduktionstheorem an und erhalten
  \begin{gather*}
    \neg A \Lvdash B\rightarrow(A \rightarrow (B\rightarrow B))\text{~und~}
       \neg A \Lvdash \neg B\rightarrow (A \rightarrow (B\rightarrow B))
  \end{gather*}
Die beiden Folgerungen haben nun die gleichen Hypothesen.
  Unter Verwendung von \autoref{lem:7}
($\Lvdash (\alpha \rightarrow \beta) \rightarrow ((\neg \alpha
  \rightarrow \beta) \rightarrow \beta)$ mit der Zuordnung $\alpha=B$ und
  $\beta=A\rightarrow(B\rightarrow B)$) und zweimaliger Anwendung des modus
  ponens folgt daraus
  \begin{gather}\label{eq:1}
    \neg A \Lvdash A \rightarrow (B\rightarrow B)
  \end{gather}

Wir haben also einen Beweis der Tautologie
als Folgerung aus einer Hypothesenmenge, in der eine Variable weniger vorkommt.
Entsprechend
kann aus
  \begin{gather*}
    A, B \Lvdash A \rightarrow (B\rightarrow B)\text{~und~}
       A, \neg B \Lvdash A \rightarrow (B\rightarrow B)
  \end{gather*}
mit dem Deduktionstheorm und \autoref{lem:7}
  \begin{gather}\label{eq:2}
    A \Lvdash A \rightarrow (B\rightarrow B)
  \end{gather}
bewiesen werden.
Aus \autoref{eq:1} und \autoref{eq:2} kann auf die gleiche Weise
  \begin{gather*}
    \Lvdash A \rightarrow (B\rightarrow B)
  \end{gather*}
bewiesen werden.
Damit haben wir einen Beweis für die Tautologie
aus ihren Beweisen mit den verschiedenen Belegungen
als Hypothesen konstruiert.
\end{bsp}

Im Beweis des folgenden Satzes wird dieses Vorgehen benutzt.

\begin{satz}[Hypothesenmengen bei Tautologien verkleinern]\label{satz:3}
  Sei $\phi$ eine Tautologie.
  Dann gilt für jede Belegung $\cA$ der Variablen von $\varphi$ und
  für jede Teilmenge $\mathcal{B}\subseteq
  \mathcal{A}$:
  \begin{gather*}
    \mathcal{B} \Lvdash \phi
  \end{gather*}

  \begin{proof}
    Sei $\phi$ eine Formel, und $\cA$ sei eine Belegung der Variablen
    von $\phi$. Das heißt, $\cA$ enthält kein Literal mit einer Variablen,
    die nicht in $\phi$ vorkommt.
    Also ist $\cA$ eine endliche Menge.
    Wir führen eine Induktion über die Größe $\abs{\mathcal{B}}$
    von $\mathcal{B}\subseteq\cA$.
    \begin{mdescription}
     \item[IA:] Sei $|\mathcal{B}|=|\mathcal{A}|$.
      Da $\mathcal{B}\subseteq \cA$, folgt $\mathcal{B}=\mathcal{A}$.
      Da $\mathcal{B}$ eine zu $\varphi$ passende Belegung ist
      und $\phi$ eine Tautologie ist, gilt $\mathcal{B}(\phi)=w$.
      Mit \autoref{satz:2} folgt
      $\mathcal{B}\Lvdash \phi$.

     \item[IV:] Für jede Belegung $\cA$ und für jede Belegung $\mathcal{B}\subseteq \cA$
      der Größe $\abs{\mathcal{B}}=|\cA|-k$ gilt $\mathcal{B} \Lvdash\phi$.

     \item[IS:] Sei $\mathcal{B}\subseteq \cA$ eine Belegung der Größe $|\cA|-k-1$.
      Dann gibt es eine Variable $A_{l}$ in $\mathcal{A}$, die nicht von
      $\mathcal{B}$ belegt wird. Nach Induktionsvorraussetzung gilt
      $\mathcal{B}\cup\{A_{l}\} \Lvdash \phi$ und $\mathcal{B}\cup\{\neg A_{l}\}
      \Lvdash \phi$. Mit dem Deduktionstheorem folgt
      $\mathcal{B} \Lvdash A_{l} \rightarrow \phi$ und
      $\mathcal{B} \Lvdash \neg A_{l} \rightarrow \phi$. Wendet man
      zweimal den modus ponens auf die Instanz von \autoref{lem:7}
      $(A_{l} \rightarrow \phi)\rightarrow ((\neg A_{l} \rightarrow\phi)
      \rightarrow\phi)$ an, folgt $\mathcal{B} \Lvdash \phi$.
    \end{mdescription}
  \end{proof}
\end{satz}

\begin{satz}[Vollständigkeit der Theorie $\mathbf{\mathrm{L}}$]\label{satz:4}
  Wenn $\phi$ eine aussagenlogische Tautologie ist, dann ist $\phi$ ein
  Theorem von $\mathrm{L}$, d.\,h. $\Lvdash \phi$.

  \begin{proof}
    \autoref{satz:3} gilt auch für $\mathcal{B}=\emptyset$.
  \end{proof}
\end{satz}

\begin{korol}\label{korrektkeit-und-vollst-von-L}
  Aufgrund der Korrektheit (\autoref{satz:1}) und Vollständigkeit
  (\autoref{satz:4}) von $\mathrm{L}$ gilt für jede aussagenlogische Formel
  $\phi$\,:
  \begin{center}
    $\phi$ ist eine aussagenlogische Tautologie \gdw $\Lvdash \phi$.
  \end{center}
\end{korol}

Der Begriff "`Tautologie"' ist ein semantischer Ausdruck
-- er basiert auf der Bedeutung (dem Wahrheitswert) von Formeln.
Dagegen ist "`$\Lvdash$"' ein syntaktischer Ausdruck --
er basiert auf der äußeren Form von Formeln.
Ob eine Formel ein Axiom ist oder ob sie aus anderen Formeln
 abgeleitet werden kann, ergibt sich nur aus ihrer Form; man
 muss dazu nichts über ihre Wahrheitswerte wissen.
\autoref{korrektkeit-und-vollst-von-L} besagt, dass beide
Begriffe gleichbedeutend sind.
Die semantische und die syntaktische Betrachtungsweise
der Aussagenlogik sind also gleich.


\section{Resolution für die Aussagenlogik}

Resolution ist eine Methode zum Nachweis der Unerfüllbarkeit
aussagenlogischer Formeln.
Sie basiert auf der äußeren Form von Formeln und ist daher eine
\glqq{}syntaktische Methode\grqq{}.
Die Resolution ist beliebt für Computeranwendungen und ist z.\,B. in die
Grundlage der Programmiersprache PROLOG (allerdings für die Prädikatenlogik).
Wir werden in diesem Abschnitt die Resolution in der
Aussagenlogik vorstellen und anschließend zeigen, dass
sie auch als formale Theorie ausgedrückt werden kann.

Eine Formel $\phi$ heißt \emph{unerfüllbar} (auch \emph{Kontradiktion}),
falls $\phi$ unter jeder
passenden Belegung $\mathcal{A}$ den Wert $\mathcal{A}(\phi)=f$ hat. Den
Nachweis einer Tautologie erhält man über die Beziehung: $\alpha$ ist
eine Tautologie \gdw $\neg\alpha$ ist unerfüllbar. Zum Beispiel ist die
Formel $\neg(A\rightarrow(B\rightarrow A))$ unerfüllbar.

\begin{figure}
  \centering
   \includegraphics{resolution.13}
  \caption{Die Zerlegung aussagenlogischer Formeln bzgl. Erfüllbarkeit}
  \label{figure-zerlegung-al-Formeln}
\end{figure}

Die Resolution arbeitet mit Formeln in konjunktiver Normalform:
\begin{enumerate}
 \item Ein \emph{Literal} ist eine Variable oder eine negierte Variable
  (z.\,B. $A$ oder $\neg A$).

  Für ein Literal $\ell$ bezeichnet $\bar{\ell}$ die Negation von $\ell$
  mit aufgelöster Doppelnegation.
  Für $\ell=A$ ist $\bar{\ell}=\neg A$,
  und für  $\ell=\neg A$ ist $\bar{\ell}=A$.

 \item Eine \emph{Klausel} ist eine Disjunktion von Literalen (z.\,B.
  $A\vee B\vee \neg C \vee\neg E$).

 \item Eine Formel in \emph[rand=konjunktive Normalform]{konjunktiver Normalform}
  (KNF) ist eine Konjunktion von Klauseln
  (z.\,B. $(A\vee B)\wedge(\neg A\vee C\vee \neg D)\wedge (C)\wedge
  (\neg B\vee\neg C)$).
\end{enumerate}

\begin{lemma}\label{satz:5}
  Zu jeder aussagenlogischen Formel gibt es eine äquivalente Formel in
  konjunktiver Normalform.
  \begin{proof}
    Sei $\alpha$ eine aussagenlogische Formel.
    Nach \autoref{lemma-DNF} gibt es zu $\neg \alpha$
    eine äquivalente Formel $\beta$ in disjunktiver Normalform.
    Also gilt $\alpha\equiv\neg\beta$.
    Zieht man das Negationszeichen von $\neg\beta$ nach innen,
    dann erhält man eine äquivalente Formel in konjunktiver Normalform.
  \end{proof}
\end{lemma}

Der Nachteil der Wahrheitstafelmethode zur Umformung in die konjunktive
Normalform ist, dass sie sehr zeitaufwendig ist und man mit der
Wahrheitstafel auch gleich die Frage nach der Erfüllbarkeit beantwortet
bekommt.

Da es bei dem Erfüllbarkeitstest aber nur auf die Erhaltung der
Erfüllbarkeit der Formel ankommt, können wir auch ein einfacheres
Verfahren für die Umformung verwenden.

\begin{satz}
  Für jede Formel $\phi$ kann in polynomieller Rechenzeit eine
  erfüllbarkeitsäquivalente Formel $\phi'$ in konjuktiver Normalform berechnet werden.
  Dabei bedeutet \emph[rand=erfüllbarkeitsäqu.]{erfüllbarkeitsäquivalent}, dass
  $\phi$ erfüllbar ist \gdw $\phi'$ erfüllbar ist.
\end{satz}


\begin{figure}
  \captionsetup{justification=RaggedRight,format=hang}
  \begin{minipage}[b]{7.2cm}
    \centering
    \input{verkn-baum-bsp.pdf_t}
    \caption{Der Verknüpfungsbaum für $(A\wedge B) \rightarrow \neg(A\vee
      \neg B)$ mit Knotenmarkierungen.}
    \label{fig:vknb-bsp}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{6.8cm}
    \centering
    \begin{tabular}{ccc|cc}
      $c_{0}$ & $c_{3}$ & $c_{4}$ & $c_{0}\rightarrow c_{3}$ &
         $c_{4}\leftrightarrow c_{0}\rightarrow c_{3}$\\
      \hline
      0 & 0 & 0 & 1 & 0\\
      0 & 0 & 1 & 1 & 1\\
      0 & 1 & 0 & 1 & 0\\
      0 & 1 & 1 & 1 & 1\\
      1 & 0 & 0 & 0 & 1\\
      1 & 0 & 1 & 0 & 0\\
      1 & 1 & 0 & 1 & 0\\
      1 & 1 & 1 & 1 & 1
    \end{tabular}\\ %[3.75mm]
    \captionof{table}{Wahrheitstabelle für $c_{4}\leftrightarrow
      c_{0}\rightarrow c_{3}$ um die konjunktive Normalform zu bestimmen.}
    \label{tab:wtab-erfaeq}
  \end{minipage}
\end{figure}

\begin{bsp}
    Wir betrachten ein Beispiel statt eines Beweises.
    Daraus sollte klar werden, wie der Beweis geht.

  Wir kontruieren eine erfüllbarkkeitsäquivalente Formel $\phi'$ zu $\phi =
  (A\wedge B) \rightarrow \neg(A\vee\neg B)$. Der induktive Aufbau von $\phi$
  ist in dem Baum in \autoref{fig:vknb-bsp} dargestellt. Für jeden Knoten --
  also jedes Verknüpfungszeichen -- wird eine neue Variable $c_i$ eingeführt.
  In die Formel~$\phi'$ wird für jedes $c_i$ eine Äquivalenz
  $c_i\leftrightarrow (l~op~r)$ eingefügt, wobei $op$ das Verknüpfungszeichen
  des mit $c_i$ markierten Knotens, $l$ die Variable, mit der der linke Sohn
  von $c_i$ markiert ist, und $r$ die Variable ist, mit der der rechte Sohn
  von $c_i$ markiert ist. Falls $c_i$ die Markierung eines Knotens mit dem
  Verknüpfungszeichen $\neg $ ist, dann hat dieser Knoten nur einen rechten
  und keinen linken Sohn. Die Formel $\phi'$ ist dann die Konjunktion aller
  Äquivalenzen.

    Jede dieser "`kleinen"' Äquivalenzen aus 3~Variablen hat eine
    konjunktive Normalform (\autoref{satz:5}) aus höchstens 8~Klauseln zu
    je 3~Literalen.
    Die Markierung $c_m$ der Wurzel des Baumes wird auch zu einem Konjunkt von $\phi'$.

    Für die Beispielformel ergibt sich folgende
    erfüllbarkeitsäquivalente Formel $\phi'$:
  \begin{multline*}
    \phi' = (c_{0} \leftrightarrow (A\wedge B))
       \wedge (c_{1} \leftrightarrow \neg B)
       \wedge (c_{2} \leftrightarrow (A\vee c_{1}))\\
    \wedge (c_{3} \leftrightarrow \neg c_{2})
       \wedge (c_{4} \leftrightarrow (c_{0}\rightarrow c_{3}))
       \wedge c_{4}
  \end{multline*}

  Für $\mathcal{A}=\{A, \neg B\}$, z.\,B., gilt $\mathcal{A}(\phi)=
  \mathcal{A}'(\phi)=w$ wobei $\mathcal{A}'=\{A, \neg B, \neg c_{0},
  c_{1}, c_{2}, \neg c_{3}, c_{4}\}$ ist.

  Aus $\mathcal{A}(\phi')=w$ folgt $\mathcal{A}(\phi)=w$, z.\,B.
  $\mathcal{A}=\{c_{4}, c_{3}, \neg c_{2}, c_{1}, c_{0}, \neg B, \neg A\}$.

  Mit der Wahrheitswerttabelle (\autoref{tab:wtab-erfaeq}) kann man
  z.\,B. für die Verknüpfung $c_{4}\leftrightarrow c_{0}\rightarrow
  c_{3}$ die konjunktive Normalform herleiten:
  \begin{gather*}
    (c_{0} \vee c_{3} \vee c_{4}) \wedge
       (c_{0} \vee \neg c_{3} \vee c_{4}) \wedge
       (\neg c_{0} \vee c_{3} \vee \neg c_{4}) \wedge
       (\neg c_{0} \vee \neg c_{3} \vee c_{4})
  \end{gather*}

  Mit den konjunktiven Normalformen aller "`kleinen"' Äquivalenzen kann
  man so eine erfüllbarkeitsäquivalente Formel in konjunktiver Normalform
  aufstellen.
\end{bsp}


\begin{defini}
  Wenn $\cA(\phi)=w$, dann \emph{erfüllt} die Belegung $\cA$ die Formel $\phi$.
  Die erfüllende Belegung $\cA$ wird auch \emph{Modell} von $\phi$ genannt.
\end{defini}

Im Zusammenhang mit Resolution stellt man Formeln in konjunktiver Normalform
als Mengen dar.
Jede Klausel wird als Menge ihrer Literale dargestellt,
z.\,B.~steht die Menge $\{A, \lneg B, C\}$ für die Klausel $(A \vee \lneg
B \vee C)$.

Eine Belegung $\cA$ erfüllt eine Klausel $C$ genau dann, wenn $\cA\cap C\ne\emptyset$.
Die \emph{leere Klausel} -- also die leere Menge von Literalen --
wird mit dem Symbol $\Box$ dargestellt.
Da $\cA \cap \Box=\emptyset$ für jede Belegung $\cA$ gilt,
ist die leere Klausel unerfüllbar.

Eine Konjunktion von Klauseln
wird \emph{Klauselmenge} genannt,
z.\,B.~$(A \vee \lneg B \vee C)\wedge(B \vee \lneg C) \wedge \lneg A$
als die Menge $\big\{ \{A, \lneg B, C \}, \{B, \lneg C\},\{\lneg A\} \big\}$.
Die Belegung $\cA$ erfüllt die Klauselmenge $S$,
wenn $\cA\cap C\ne\emptyset$ für jede Klausel $C\in S$.
Deshalb ist die leere Klauselmenge eine Tautologie.


Sei $\cA_{\ell}$ eine Belegung mit $\ell\in\cA_{\ell}$,
die eine Klauselmenge $S$ erfüllt.
Dann erfüllt $\cA_{\ell}$ auch die Klauselmenge,
die man wie folgt aus $S$ erhält:
\begin{enumerate}
 \item Entferne jede Klausel aus $S$, die $\ell$ enthält, und
 \item entferne das Literal $\bar{\ell}$
  aus den verbleibenden Klauseln.
\end{enumerate}
Die so konstruierte Klauselmenge wird mit $S^{\ell}$ bezeichnet.
Formal definiert sieht das so aus:
$S^{\ell} = \{C\setminus\{\bar{\ell}\}\colon C\in S, \ell\notin C\}$.

Für
$S=\big\{\{A,\lneg B, C\},\{\lneg A, C\}, \{\lneg A, B\},\{\lneg B, C\}\big\}$
ist
$S^{A} = \big\{\{C\}, \{ B\},\{\lneg B, C\}\big\}$ und
$S^{\lneg A}=\big\{ \{\lneg B, C\} \big\}$.

Wir betrachten die erfüllende Belegung $\cA=\{\lneg B, \lneg C\}$
der obigen Menge $S^{\lneg A}$.
Jede Klausel in $S$, aus der eine Klausel in $S^{\lneg A}$ wurde
-- also die Klauseln $\{A,\lneg B, C\}$ und $\{\lneg B, C\}$ --,
werden von $\cA$ erfüllt.
Alle übrigen Klauseln in $S$ ernthalten das Literal $\lneg A$
und werden von $\cA\cup\{\lneg A\}$ erfüllt.
Entsprechend wird aus der $S^{A}$ erfüllenden Belegung
$\cB=\{B,C\}$ die $S$ erfüllende Belegung $\cB\cup\{A\}$.

\begin{lemma}\label{ALogik-Sell}
  Sei $S$ eine Klauselmenge und $\ell$ ein Literal.
  Wenn $S^{\ell}$ oder $S^{\bar{\ell}}$ erfüllbar ist,
  dann ist auch $S$ erfüllbar.

\begin{proof}
  Sei $S^{\ell}$ erfüllbar,
  und $\cA$ sei ein Modell von $S^{\ell}$.
  Dann ist $\cB=(\cA\setminus\{\bar{\ell}\})\cup\{\ell\}$
  ebenfalls Modell von $S^{\ell}$, da weder $\ell$ noch $\bar{\ell}$
  in einer Klausel in $S^{\ell}$ vorkommt.
  Da jede Klausel in $S$ entweder
  (1) in $S^{\ell}$ vorkommt
  oder
  (2) aus einer Klausel in $S^{\ell}$ durch Hinzufügen von $\bar{\ell}$
  entsteht
  oder
  (3) $\ell$ enthält, ist $\cB$ auch Modell von $S$.

  Ist $S^{\bar{\ell}}$ erfüllbar, dann kann entsprechend
  gezeigt werden, dass $\cB'=(\cA\setminus\{{\ell}\})\cup\{\bar{\ell}\}$
  Modell von $S$ ist.
\end{proof}
\end{lemma}

Um die Erfüllbarkeit oder Unerfüllbarkeit
einer Klauselmenge nachzuweisen,
wird die vorgegebene Klauselmenge
in der Resolutionsmethode solange um neue Klauseln
-- so genannte Resolventen -- erweitert,
bis die leere Klausel erzeugt ist.
Gelingt das, dann ist die Ausgangsmenge unerfüllbar.
Kann die leere Klausel dagegen nicht erzeugt werden, dann ist
die Ausgangsmenge erfüllbar.

\begin{defini}[Resolvent]
  Sei $C_1$ eine Klausel, die das Literal $\ell$ enthält,
  und $C_2$ sei eine Klausel, die das Literal $\bar{\ell}$
  enthält.
  Dann heißt die Klausel
  $R=\big(C_1\setminus\{\ell\})\cup(C_2\setminus\{\bar{\ell}\}\big)$
  \emph{Resolvent} der Klauseln $C_1$ und $C_2$ (nach dem Literal $\ell$).
\end{defini}

Zum Beispiel kann aus den Klauseln $\{A,B\}$ und $\{\lneg A, B,\lneg
C\}$ der Resolvent $\{B,\lneg C\}$ (nach dem Literal $A$) gebildet
werden.

Aus den Klauseln $\{A,B\}$ und $\{\lneg A,\lneg B\}$ können die
Resolventen $\{A, \lneg A\}$ (nach $B$) und $\{B, \lneg B\}$ (nach $A$)
gebildet werden (und keine anderen).

\begin{lemma}[Resolutionslemma]\label{Resolutionslemma}
  Sei $R$ Resolvent der Klauseln $C_1$ und $C_2$.
  Wenn $\cA$ beide Klauseln $C_1$ und $C_2$ erfüllt,
  dann erfüllt $\cA$ auch den Resolventen $R$.

  \begin{proof}
    Sei $R$ Resolvent der Klauseln $C_1$ und $C_2$ nach dem Literal $\ell$,
    und erfülle $\cA$ die Klauseln $C_1$ und $C_2$,
    d.\,h. $\cA\cap C_1\ne\emptyset$ und $\cA\cap C_2\ne\emptyset$.
    Ist $\ell\notin\cA$, dann ist $\cA\cap(C_1\setminus\{\ell\})\ne\emptyset$;
    ist $\bar{\ell}\notin\cA$,
    dann ist $\cA\cap(C_2\setminus\{\bar{\ell}\})\ne\emptyset$.
    Da einer dieser beiden Fälle eintreten muss,
    ist $\cA\cap((C_1\setminus\{\ell\})\cup(C_2\setminus\{\bar{\ell}\}))\ne\emptyset$.
    Also wird $R$ von $\cA$ erfüllt.
  \end{proof}
\end{lemma}

Vereinigt man also eine Klauselmenge mit den Resolventen,
die sich aus ihren Klauseln bilden lassen,
erhält man eine logisch äquivalente Klauselmenge.
Diese Klauselmenge kann man wiederum mit ihren Resolventen
vereinigen ohne die Erfüllbarkeit zu beeinflussen, und so weiter.
Lässt sich schließlich die unerfüllbare leere Klausel
als Resolvent bilden, so ist die
Unerfüllbarkeit der Ausgangsmenge nachgewiesen.
Dieses Verfahren wird als
\emph{Resolutionsmethode}
bezeichnet.
Es besteht aus einer syntaktischen Formalisierung von Beweisen
für die Unerfüllbarkeit von Formeln.

\begin{defini}[Resolutionsbeweis]
  Sei $C$ eine Klausel und $S$ eine Klauselmenge.
  Ein \emph{Resolutionsbeweis} aus $S$
  ist eine endliche Folge von Klauseln $C_1,C_2,\dotsc,C_n$, wobei
  \begin{enumerate}
   \item $C_n=C$, und
   \item $C_i\in S$ oder $C_i$ ist Resolvent von $C_a$ und $C_b$, $a,b<i$,
    für alle $1\leq i\leq n$.
  \end{enumerate}

  Eine \emph[rand=Resol.herleitung]{Resolutionsherleitung}
  der Klausel $C$ aus der Klauselmenge $S$ ist ein Resolutionsbeweis aus $S$,
  der $C$ enthält.

  Eine \emph[rand=Resol.widerlegung]{Resolutionswiderlegung} von $S$
  ist eine Resolutionsherleitung der leeren Klausel $\Box$ aus $S$.
\end{defini}

Betrachten wir die Klauselmenge $S=\{\{A,B\},\{\lneg A\}, \{\lneg B\}\}$.
Dann ist
$\{A,B\}, \{\lneg A\} ,\{B\}$
eine Herleitung von $\{B\}$ aus $S$.
Die Folge von Klauseln
$\{A,B\},\{\lneg A\},\{B\},\{\lneg B\}, \Box$
ist eine Herleitung von $\Box$ aus $S$:
\begin{align*}
  C_1 &= \{A,B\} &\text{Klausel aus $S$}\\
  C_2 &= \{\lneg A\} &\text{Klausel aus $S$}\\
  C_3 &= \{B\} &\text{Resolvent aus $C_1$ und $C_2$}\\
  C_4 &= \{\lneg B\} &\text{Klausel aus $S$}\\
  C_5 &= \Box &\text{Resolvent aus $C_3$ und $C_4$}
\end{align*}
$S$ ist also widerlegt.

Die Klauselmenge
$S=\{\{A,B\},\{\lneg A,B\},\{A,\lneg B\},\{\lneg A,\lneg B\}\}$
kann man mit folgender Herleitung widerlegen:
\begin{align*}
  C_1 &= \{A,B\} & \text{Klausel aus $S$}\\
  C_2 &= \{\lneg A,B\} & \text{Klausel aus $S$}\\
  C_3 &= \{B\} & \text{Resolvent aus $C_1$ und $C_2$}\\
  C_4 &= \{A,\lneg B\} & \text{Klausel aus $S$}\\
  C_5 &= \{\lneg A,\lneg B\} & \text{Klausel aus $S$}\\
  C_6 &= \{\lneg B\} & \text{Resolvent aus $C_4$ und $C_5$}\\
  C_7 &= \Box & \text{Resolvent aus $C_3$ und $C_6$}
\end{align*}

Die Herleitungen mittels Resolution kann man auch als
Bäume veranschaulichen.
Die Knoten des Baumes sind mit Klauseln markiert.
Ist eine Klausel $R$ ein Resolvent, so sind die
Klauseln $C_1$ und $C_2$, aus denen er gebildet wurde, seine beiden
Vorgänger. ($C_1$ und $C_2$ heißen auch Elternklauseln von $R$.)

\begin{center}
  \includegraphics{resolution.1}
\end{center}

Die beiden Herleitungen aus obigem Beispiel
lassen sich wie in \autoref{Res-Baeume} veranschaulichen.

\begin{figure}[t]
  \hfill
  \includegraphics{resolution.2}
  \hfill
  \includegraphics{resolution.3}
  \hfill
  \caption{Widerlegungen mittels Resolution}\label{Res-Baeume}
\end{figure}

Wir wollen nun die Korrektheit und die Vollständigkeit
der Resolutionsmethode nachweisen.

\index{Resolutionsmethode!Korrekheit der}
\begin{satz}[Korrektheit der Resolutionsmethode]
  \label{satz-korrektheit-resolution-vor}
  Ist eine Klauselmenge $S$ erfüllbar,
  dann ist $S$ nicht mittels Resolution widerlegbar.
\begin{proof}
  Sei $S$  eine erfüllbare Klauselmenge.
  Dann gibt es ein Modell $\cA$ von $S$.
  Sei $C_1,C_2,\dotsc,C_n$ eine Herleitung von $C_n$ aus $S$.
  Da $C_1\in S$, ist $\cA$ ein Modell von $C_1$.
  Ist $C_{i+1}\in S$, dann ist $\cA$ ebenfalls Modell von $C_{i+1}$.
  Anderenfalls ist $C_{i+1}$ Resolvent von $C_a$ und $C_b$ für $a,b<i+1$.
  Ist $\cA$ ein Modell von $C_a$ und $C_b$, so ist nach dem Resolutionslemma
  (\autoref{Resolutionslemma}) $\cA$ ebenfalls ein Modell von $C_{i+1}$.
  Also folgt schließlich, dass $\cA$ Modell von $C_{n}$ ist.
  Da $\Box$ unerfüllbar ist, ist $\cA$ kein Modell von $\Box$.
  Demnach ist $C_n\ne\Box$.
  Folglich gibt es keine Herleitung von $\Box$ aus $S$,
  das heißt $S$ ist nicht widerlegbar.
\end{proof}
\end{satz}

\autoref{satz-korrektheit-resolution-vor} zeigt tatsächlich die
\textit{Korrektheit der Resolutionsmethode}:
Ist eine Klauselmenge~$S$ mittels Resolution widerlegbar,
dann ist $S$ unerfüllbar.

Nun müssen wir noch die
Vollständigkeit der Resolutionsmethode
beweisen.
\index{Resolutionsmethode!Vollständigkeit der}
Dazu überlegen wir uns zunächst anhand eines Beispiels,
wie man aus den Herleitungen der leeren Klausel aus $S^{\ell}$ und
aus $S^{\bar{\ell}}$ eine Herleitung der
leeren Klausel aus $S$ konstruieren kann.

Sei die Klauselmenge $S$ beispielsweise gegeben als
\begin{gather*}
  S=\big\{ \{B,\neg C, D,A\},\{B,C,D,A\},
     \{B,\neg D\},\{B,D,\neg A\},\{\lneg B,A\},\{\lneg B,\lneg A\}
     \big\}. % Der Punkt vom Satzende
\end{gather*}
Um die Unerfüllbarkeit von $S$
gemäß \autoref{ALogik-Sell}
zu beweisen,
müssen wir Widerlegungen der beiden Klauselmengen
\begin{gather*}
  S^A = \big\{\{B,\lneg D\},\{B,D\},\{\lneg B\}\big\}
  \quad\text{und}\quad
  S^{\lneg A} = \big\{\{B,\neg C, D\}, \{B,C,D\}, \{B,\neg D\}, \{\lneg B\}\big\}
\end{gather*}
angeben.
Diese Widerlegungen sind in \autoref{zweiwiderlegungen} dargestellt.
Die \glqq{}Blätter\grqq{} der beiden Bäume in \autoref{zweiwiderlegungen}
sind Klauseln aus $S^A$ bzw. Klauseln aus $S^{\lneg A}$.
Nun fügen wir in alle Blätter, die nicht durch Klauseln in $S$
beschriftet sind,
das entfernte Literal $A$ bzw. $\lneg A$ wieder ein
und führen die Resolutionsschritte wie gehabt durch
(siehe \autoref{auszweimacheins}).
Wir bekommen so aus den beiden Herleitungen von $\Box$
aus $S^A$ und aus $S^{\neg A}$
zwei Herleitungen aus $S$: Die eine von $\{A\}$ und
die andere von $\{\lneg A\}$.
Die leere Klausel kann nun gerade als der Resolvent von
$\{A\}$ und $\{\lneg A\}$ erhalten werden.
Wir können also die beiden Herleitungen
zusammenfügen und durch den zusätzlichen Resolutionsschritt
zu einer Herleitung von $\Box$ aus $S$ ergänzen.

\begin{figure}
  \centering \includegraphics[width=\textwidth]{resolution.6}
  \caption{Widerlegungen von $S^A$ und $S^{\neg A}$}\label{zweiwiderlegungen}
\end{figure}

\begin{figure}
  \centering \includegraphics[width=\textwidth]{resolution.7}
  \caption{Widerlegung von $S$}\label{auszweimacheins}
\end{figure}

\begin{lemma}\label{lemma-vollst-resolution}
  Ist $S^{\ell}$ widerlegbar,
  dann ist $\Box$ oder $\{\bar{\ell}\}$ aus $S$ herleitbar.

  \begin{proof}
    Sei $S^{\ell}$ widerlegbar.
    Dann gibt es eine Herleitung $C_1,\dotsc,C_m$ der leeren Klausel aus $S^{\ell}$.
    Wir fügen das entfernte Literal $\bar{\ell}$
    in die Herleitung der leeren Klausel aus $S^{\ell}$ auf folgende Weise ein:
    Für $1\leq i\leq m$ definieren wir Klauseln $C'_i$ durch
    \begin{gather*}
      C_i' =
         \begin{cases}
           C_i &\text{falls~} C_i\in S\\
           C_i\cup\{\bar{\ell}\} & \text{falls~}
           C_i\cup\{\bar{\ell}\}\in S \text{~und~} C_i\notin S\\
           C &\text{falls $C_i$ Resolvent von $C_a$ und $C_b$ nach $\ell'$
           ist,}\\
           &\text{\hspace{5mm} wobei $C$ Resolvent von $C'_a$ und $C'_b$ nach
           $\ell'$ ist.}
         \end{cases}
    \end{gather*}

    Da $C'_i\in\big\{C_i,C_i\cup\{\bar{\ell}\}\big\}$
    und $C_m=\Box$ ist, ist  $C'_1,\dotsc,C'_m$ eine
    Herleitung von $\Box$ oder $\{\bar{\ell}\}$ aus $S$.
  \end{proof}
\end{lemma}

\index{Resolutionsmethode!Vollständigkeit der}
\begin{satz}[Vollständigkeit der Resolutionsmethode]\label{satz-vollst-resolution}
  Ist eine Klauselmenge $S$ unerfüllbar,
  dann ist $S$ mittels Resolution widerlegbar.

  \begin{proof}
    Sei $S$ unerfüllbar.
    Wir führen einen induktiven Beweis über die
    Anzahl der verschiedenen in $S$ enthaltenen Variablen.

    \begin{mdescription}
     \item[IA:]
      $S$ enthält keine Variablen.
      Wenn $S$ unerfüllbar ist, muss $S=\{\Box\}$ gelten.
      Also gibt es eine Resolutionsherleitung von $\Box$ aus $S$.

     \item[IV:]
      Für jede Klauselmenge mit $n$ Variablen gilt:
      wenn $S$ unerfüllbar ist, dann gibt es eine Resolutionswiderlegung von $S$.

     \item[IS:]
      $S$ enthalte $n+1$ Variablen und sei unerfüllbar.
      Dann sind nach \autoref{ALogik-Sell} auch $S^{\ell}$ und $S^{\bar{\ell}}$
      unerfüllbar.
      Nach IV sind $S^{\ell}$ und $S^{\bar{\ell}}$ widerlegbar.
      Nach obigem \autoref{lemma-vollst-resolution} ist
      (1) $\Box$ aus $S$ herleitbar
      oder (2) $\{\ell\}$ und $\{\bar{\ell}\}$ sind aus $S$ herleitbar.
      Im Fall~(1) haben wir bereits die Widerlegbarkeit von $S$ gezeigt.
      Im Fall~(2)
      ist $\Box$ Resolvent von $\{\ell\}$ und $\{\bar{\ell}\}$.
      Deshalb lässt sich aus den Herleitungen von
      $\{\ell\}$ und $\{\bar{\ell}\}$
      ergänzt um einen weiteren Resolutionsschritt,
      mit dem $\Box$ aus $\{\ell\}$ und $\{\bar{\ell}\}$ resolviert wird,
      eine Herleitung von $\Box$ aus $S$ konstruieren.
      Also ist $S$ widerlegbar.
    \end{mdescription}
  \end{proof}
\end{satz}

Aus der Korrektheit und der Vollständigkeit der Resolutionsmethode
ergibt sich der Resolutionssatz der Aussagenlogik.

\index{Resolutionssatz}
\begin{korol}\label{resolutionssatz}
  \help{Ich habe hieraus auch ein Korolar gemacht, weil
    \autoref{korrektkeit-und-vollst-von-L} auch ein Korolar ist.}
  Die Klauselmenge $S$ ist unerfüllbar genau dann,
  wenn $S$ mittels Resolution widerlegbar ist.
\end{korol}


Die Unerfüllbarkeit
einer Formel $\alpha$
kann man nun dadurch beweisen,
dass man eine zu $\alpha$ erfüllbarkeitsäquivalente Formel $\alpha'$
in konjunktiver Normalform bildet, diese als
Klauselmenge darstellt und mittels Resolution
die leere Klausel herleitet.

Entsprechend kann man die {Gültigkeit}
einer Formel $\alpha$
dadurch beweisen, dass man wie eben beschrieben
die Unerfüllbarkeit von $\lneg\alpha$
nachweist.
Dazu noch ein abschließendes Beispiel.

\begin{bsp}\label{bsp:4}
  Wir zeigen, dass der Ringschluss
  \begin{gather*}
    \alpha=\big((A\rightarrow B)\wedge(B\rightarrow C)\wedge
       (C\rightarrow A) \wedge (A \lor B \lor C)\big)
       \limplies (A \wedge B\wedge C)
  \end{gather*}
  eine Tautologie ist.

  Es genügt, dazu die Unerfüllbarkeit von $\lneg \alpha$
  nachzuweisen,
  \begin{gather*}
    \lneg\alpha\equiv(\lneg A\lor B)\wedge(\lneg B\lor C)\wedge
       (A\lor \lneg C) \wedge (A \lor B \lor C)
       \wedge (\lneg A \lor \lneg B \lor \lneg C)\ \ .
  \end{gather*}
  \autoref{last-resolution} veranschaulicht
  die Resolutionswiderlegung von $\lneg \alpha$.
  Also ist $\alpha$ eine Tautologie.
\end{bsp}

\begin{figure}[t]
  \centering
  \includegraphics{resolution.8}
  \caption{Widerlegung von $\lneg\alpha$ aus \autoref{bsp:4} mittels Resolution}
  \label{last-resolution}
\end{figure}

% 16.5.06

\subsection{Algorithmus zum Test auf Unerfüllbarkeit einer Klauselmenge}

Eingabe $S$ als Klauselmenge
\begin{Verbatim}[commandchars=\\\{\}]
T := \ensuremath{\emptyset}
\schlwort{wiederhole}
    S := S \ensuremath{\cup} T
    T := die Menge aller Resolventen, die aus Klauseln in S gebildet
                werden können
\schlwort{bis} T \ensuremath{\subseteq} S
\schlwort{falls} \ensuremath{\Box\in} S
\schlwort{dann} Ausgabe \glqq{}unerfüllbar\grqq{}
\schlwort{sonst} Ausgabe \glqq{}erfüllbar\grqq{}
\end{Verbatim}

Optimierungen:
\begin{itemize}
 \item $\exists A, B\in S\colon A \subset B $ $\Rightarrow$ $S
  := S\setminus \{ B \}$
 \item $\exists A\in S\colon x\in A, \neg x\in A$ $\Rightarrow$ $S := S\setminus
  \{A\}$
\end{itemize}

Es gibt Klauselmengen, deren Resolutionswiderlegungen exponentiell lang sind.
Ein Beispiel dafür sind die
Taubenschlagformeln $PHP_{k}$ (\glqq{}pigeon hole principle\grqq{} für $k$
Tauben) -- in einem Taubenschlag mit $k-1$ Löchern können nicht $k$
Tauben sitzen, wenn in jedem Loch höchstens eine Taube sitzen darf.
Variable $A_{i,j}$ entspricht \glqq{}Taube $j$ sitzt in Loch~$i$\grqq{}
($i=1,2,\dotsc,k; j=1,2,\dotsc,k-1$).
Die Formeln bestehen aus zwei Teilen.
Der erste Teil drückt aus, dass jede Taube in (mindestens) einem Loch sitzt,
und der zweite Teil drückt aus,
dass in jedem Loch höchstens eine Taube sitzt.

Taube $j$ sitzt in einem der $k-1$ Löcher:
\begin{gather*}
  A_{1,j} \vee A_{2,j} \vee \dotsb \vee A_{k-1,j}\quad =  \theta_j
\end{gather*}
Jede der $k$~Tauben sitzt in einem der $k-1$~Löcher:
\begin{gather*}
  \theta_1 \wedge \theta_2 \wedge \cdots \wedge \theta_k
  = \bigwedge_{j=1}^{k} \bigvee_{i=1}^{k-1} A_{i,j}
  = \alpha_k
\end{gather*}
In Loch $i$ sitzt höchstens eine der $k$ Tauben:
\begin{multline*}
  \begin{aligned}
    (A_{i,1} \rightarrow \neg A_{i,2}) \wedge \cdots \wedge (A_{i,1}
    \rightarrow \neg A_{i,k-1}) \wedge \\
    \quad(A_{i,2} \rightarrow \neg A_{i,1}) \wedge (A_{i,2} \rightarrow \neg
    A_{i,3}) \wedge \cdots \wedge (A_{i,2} \rightarrow \neg A_{i,k-1})\wedge\\
    \vdots \\
    \quad(A_{i,k-1} \rightarrow \neg A_{i,1}) \wedge \cdots \wedge (A_{i,k-1}
    \rightarrow \neg A_{i,k-2})\\
  \end{aligned}\\
  \begin{aligned}
    &\equiv
    (\neg A_{i,1} \vee \neg A_{i,2}) \wedge \cdots \wedge (\neg A_{i,1} \vee \neg A_{i,k-1}) \wedge \\
    &\qquad\vdots \\
    &\qquad(\neg A_{i,k-1} \vee \neg A_{i,1}) \wedge \cdots \wedge (\neg A_{i,k-1} \vee \neg A_{i,k-2}) \wedge \\
    &\equiv \bigwedge_{p=1}^{k}
    \bigwedge_{\substack{q=1\\q\ne p}}^{k} (\neg A_{i,p} \vee \neg A_{i,q})\quad = \sigma_i
  \end{aligned}
\end{multline*}
In jedem der $k-1$ Löcher sitzt höchstens eine Taube:
\begin{gather*}
  \sigma_1 \wedge \sigma_2 \wedge \cdots \wedge \sigma_{k-1}
  \equiv \bigwedge_{i=1}^{k-1}\bigwedge_{p=1}^{k}
     \bigwedge_{q=p+1}^{k} (\neg A_{i,p} \vee \neg A_{i,q})
  = \beta_k
\end{gather*}
Die Taubenschlagformel $PHP_k$ lautet
\begin{gather*}
  PHP_{k} = \alpha_{k} \wedge \beta_{k}
\end{gather*}

\subsection{Formulierung der Resolution als Theorie}

Zur Erinnerung: Eine Theorie (\autoref{def:theorie}) besteht aus Formeln,
Axiomenschemata und Ableitungsregeln.
Ein Beweis einer Formel besteht aus einer
Folge von Formeln, die Axiome sind oder mittels Ableitungsregeln
aus bereits abgeleiteten Formeln abgeleitet werden.
In einem Beweis der Unerfüllbarkeit einer Klauselmenge $S$ (=Formel)
muss also $S$ am Ende des Beweises stehen.
(Das ist genau andersherum als bei der Resolution.)

\begin{mdescription}
 \item[Formeln:] die Klauselmengen
 \item[Axiomenschema:] $\{\Box\}$
 \item[Ableitungsregeln:]~\\
  \begin{enumerate}
   \item[(Res)] Für die Klauselmenge $S$ und die Klausel $R\in S$, die
    Resolvent von $C_1$ und $C_2$ ist:
    \begin{gather*}
      \frac{S}{(S\setminus\{R\})\cup\{C_1, C_2\}}
    \end{gather*}
   \item[(Einf)] Für Klauselmenge $S$ und beliebige Klausel $C$:
    \begin{gather*}
      \frac{S}{S \cup\{C\}}
    \end{gather*}
  \end{enumerate}
\end{mdescription}

Alle Beweise beginnen also mit der Klauselmenge, die nur aus der leeren Klausel besteht
(einziges Axiom).
Diese Klauselmenge ist unerfüllbar.
Durch die Ableitungsregel (Res) wird ein Resolutionsschritt \glqq{}rückwärts\grqq{}
ausgeführt,
und durch (Einf) wird eine beliebige zusätzliche Klausel in
die Klauselmenge eingefügt.

\begin{bsp}
  Beweis der Unerfüllbarkeit von
  $S= \big\{ \{\neg A, B\}, \{\neg A, \neg B\}, \{A\}, \{A, \neg C\} \big\}$
  \begin{align*}
    (1)\quad & \{\Box\} & \text{Axiom} \\
    (2)\quad & \{ \{ A \}, \{\neg A \} \}
       & \text{(Res) auf (1)} \\
    (3)\quad & \{ \{ A \}, \{ \neg A, B\}, \{\neg A, \neg B\} \}
       & \text{(Res) auf (2)}  \\
    (4) \quad & \{ \{ A \}, \{ \neg A, B\}, \{\neg A, \neg B\}, \{A, \neg C\}  \} &
       \text{(Einf) auf (3)}
  \end{align*}
\end{bsp}

\begin{bsp}
  Beweis der Unerfüllbarkeit von $S$ aus \autoref{last-resolution},

  $S= \big\{ \{\neg B, C\}, \{A, B, C\}, \{A, \neg C\}, \{\neg A, B\}, \{\neg A, \neg B, \neg C\} \big\}$
  \begin{align*}
    (1)\quad & \{\Box\} & \text{Axiom} \\
    (2)\quad & \{ \{ B\}, \{\neg B \} \}
       & \text{(Res) für $B$ auf $\Box$ in (1)} \\
    (3)\quad & \{ \{ B \}, \{ A \}, \{\neg A, \neg B\} \}
       & \text{(Res) für $\neg A$ auf $\{\neg B\}$ in (2)}  \\
    (4)\quad & \{ \{ \neg A, B \}, \{ A \}, \{\neg A, \neg B\} \}
       & \text{(Res) für $\neg A$ auf $\{B\}$ in (3)}  \\
    (5)\quad & \{ \{ \neg A, B \}, \{C\}, \{A, \neg C\}, \{\neg A, \neg B\} \}
       & \text{(Res) für $\neg C$ auf $\{A\}$ in (4)}  \\
    (6)\quad & \{ \{ \neg A, B \}, \{C\}, \{A, \neg C\}, \{\neg A, \neg B, \neg C\} \}
       & \text{(Res) f. $\neg C$ auf $\{\neg A, \neg B\}$ in (5)}  \\
    (7)\quad & \big\{ \{ \neg A, B \}, \{B, C\}, \{\neg B, C\}, \{A, \neg C\},
       & \text{(Res) für $B$ auf $\{C\}$ in (6)}  \\
    &\quad  \{\neg A, \neg B, \neg C\} \big\}\\
    (8)\quad & \big\{ \{ \neg A, B \}, \{\neg A, C\}, \{A, B, C\},
       \{\neg B, C\},
       & \text{(Res) für $A$ auf $\{B,C\}$ in (7)}  \\
    &\quad  \{A, \neg C\}, \{\neg A, \neg B, \neg C\} \big\}\\
    (9)\quad & \big\{ \{ \neg A, B \}, \{A, B, C\},
       \{\neg B, C\}, \{A, \neg C\},
       & \text{(Res) für $B$ auf $\{\neg A, C\}$ in (8)}\\
    &\quad \{\neg A, \neg B, \neg C\} \big\}
  \end{align*}
\end{bsp}

Man kann (leicht) zeigen,
dass die Ableitungsregeln die Unerfüllbarkeit der Klauselmenge nicht ändern
und dass jede unerfüllbare Klauselmenge einen Beweis besitzt
(entsprechend \autoref{satz-korrektheit-resolution-vor} und \autoref{satz-vollst-resolution}).
Die Resolution als Theorie ist also auch vollständig und korrekt.

%% Ende des Abschnittes ueber Resolution

% 17. Mai 2006

\chapter{Theorien 1.~Ordnung -- Prädikatenlogik}
\label{cha:prlogik}

\begin{bsp}
  Jeder der mich mag, mag auch meine Frau. Peter mag meine Frau nicht.
  Daraus folgt: Peter mag auch mich nicht.

  Sprachliche Mittel:
  \begin{itemize}
   \item Eigenschaft $M(x,y)$ mit der Bedeutung \glqq{}$x$ mag $y$\grqq
   \item Individuen $a$ bedeutet \glqq{}ich\grqq{}, $b$ bedeutet \glqq{}meine Frau\grqq{} und
    $c$ bedeutet \glqq{}Peter\grqq
   \item Quantoren über Variablen: "`$\forall x\quantsep P(x)$"' heißt \glqq{}für alle $x$
    gilt Eigenschaft $P$\grqq{}
     (im Bsp.: $\forall x\quantsep(M(x,a) \rightarrow M(x,b))$)
  \end{itemize}
\end{bsp}

\begin{bsp}
  Der Nachfolger jeder geraden ganzen Zahl ist ungerade. 2 ist eine
  gerade ganze Zahl. Also ist der Nachfolger von 2 ungerade.

  \begin{tabular}{r@{~\ldots{}~}l}
    $G(x)$ & $x$ ist eine ganze Zahl\\
    $E(x)$ & $x$ ist gerade\\
    $f(x)$ & bezeichne den Nachfolger von $x$\\
    $b$ & Symbol 2
  \end{tabular}\\
  $G$ und $E$ sind Eigenschaften, $f$ ist eine Funktion

  Damit können wir nun die Aussage formal ausdrücken:
  $\forall x\quantsep (G(x) \wedge E(x))\rightarrow \neg E(f(x))$

  Also folgt aus $G(b)$ und $E(b)$, dass $\neg E\big(f(b)\big)$ gilt.
\end{bsp}

\begin{defini}[Quantoren]
  \index{Quatoren}
  $\forall$ bezeichnet man als \emph{Allquantor} und $\exists$ als
  \emph{Existenzquantor}. $\forall x\quantsep P(x)$ bedeutet "`für alle $x$
  gilt $P(x)$"' und $\exists x\quantsep P(x)$ bedeutet \glqq{}es gibt
  (mindestens) ein $x$ für das $P(x)$ gilt\grqq{}.
\end{defini}

Beispiele:\\
\begin{tabular}{l@{\qquad}l}
  Alle Vierbeiner können laufen & $\forall x\quantsep V(x) \rightarrow L(x)$\\
  Es gibt Tiere, die Vierbeiner sind & $\exists x\quantsep T(x) \wedge V(x)$\\
  Also gibt es Tiere, die laufen können & $\exists x\quantsep T(x) \wedge L(x)$
\end{tabular}

Die \glqq{}Sprache\grqq{} der Theorien 1.~Ordnung besteht aus folgenden
Elementen:
\begin{enumerate}
 \item Zeichen:
  \begin{enumerate}
   \item logische Verknüpfungszeichen wie $\neg$, $\rightarrow$,
    $\wedge$, $\vee$, $\leftrightarrow$,
   \item \emph{Variablensymbole} wie $x_{1}, x_{2}, x_{3}, \dotsc$,
   \item \emph{Konstantensymbole} $a_{1}, a_{2}, a_{2},\dotsc$,
   \item \emph{Prädikatensymbole} $A_{k}^{n}$, wobei $n\in\N^+$ die
    Stelligkeit und $k\in\N^+$ ein Index zur Unterscheidung verschiedender
    Prädikatensymbole ist, z.\,B. $A_{1}^{1}, A_{1}^{2}, A_{1}^{3}, A_{2}^{5}$,
   \item \emph{Funktionensymbole} $f_{k}^{n}$, $n\in\N^+$ ist die Stelligkeit
    der Funktion und $k\in\N^+$ ein Index zur Unterscheidung verschiedender
    Funktionen ist und
   \item \emph{Quantoren} $\forall$ und $\exists$
  \end{enumerate}

 \item Terme:
  \begin{enumerate}
   \item Jedes Variablen- oder Konstantensymbol ist ein \emph{Term}
   \item Wenn $t_{1},\dotsc,t_{n}$ Terme sind, dann ist auch
    $f^{n}_{k}(t_{1},\dotsc,t_{n})$ ein Term
  \end{enumerate}
\end{enumerate}

\begin{bsp}
  $x_{15}$ ist ein Variablensymbol, $a_{3}$ ist ein Konstantensymbol,
  $f_{3}^{2}(x_{15}, a_{3})$ und $f_{3}^{1}(f_{3}^{2}(x_{15},a_{3}))$
  sind Terme
\end{bsp}

\begin{defini}[Atomare Formeln]
  Für Terme $t_{1},t_{2},\dotsc,t_{n}$ ist $A_{k}^{n}
  (t_{1},\dotsc,t_{n})$ eine \emph[index=Formel!atomare]{atomare Formel}.
\end{defini}

\begin{defini}[Formeln]\label{def:formeln}
  \begin{enumerate}
   \item Jede atomare Formel ist eine \emph{Formel}.
   \item Wenn $\alpha$ und $\beta$ Formeln sind, dann sind auch $(\neg
    \alpha), (\alpha\rightarrow\beta)$ und $(\forall x_{i}\quantsep \alpha)$
    Formeln.

    \textit{[$\wedge$, $\vee$ $\leftrightarrow$ können wie bisher als
    abkürzende Schreibweise gebraucht werden. $(\exists x_{i}\quantsep \alpha)$
    ist Abkürzung für $\neg (\forall x_{i}\quantsep (\neg \alpha))$]}

    Unnötige Klammern können zur Vereinfachung der Schreibweise
    weggelassen werden.
  \end{enumerate}
\end{defini}

Beispiele für Formeln:
\begin{itemize}
 \item $\big(\forall x_{2}\quantsep A_{1}^{1}(x_{2}) \rightarrow
  A_{0}^{2}(x_{2}, f_{1}^{1}(x_{2})) \big)$
 \item $A_{1}^{1}(x_{2}) \rightarrow (\forall x_{3}\quantsep
  A_{1}^{2}(x_{1},x_{2}))$
 \item $(\exists x_{1}\quantsep A_{1}^{2}(x_{1},x_{2})) \rightarrow (\forall
  x_{1}\quantsep (\neg A_{2}^{2}(x_{1},x_{2})))$
\end{itemize}

In $(\forall x_{i}\quantsep \alpha)$ ist $\alpha$ der \emph{Gültigkeitsbereich}
des Quantors \glqq$\forall x_{i}$\grqq{}. Eine Variable $y$, die im
Gültigkeitsbereich eines Quantors $\forall y$ liegt oder die Teil des
Quantors sind, heißt \emph[index=Variable!gebundene]{gebunden}. Falls
eine Variable nicht gebunden ist, dann heißt sie
\emph[index=Variable!freie]{frei}.

\begin{bsp}
  In der Formel $A_{1}^{2}(x_{1},x_{2})$ sind $x_{1}$ und $x_{2}$ freie
  Variablen. In der Formel $A_{1}^{2}(x_{1},x_{2}) \rightarrow (\forall
  x_{2}\quantsep A_{1}^{1}(x_{2}))$ ist die Variable $x_{1}$ frei und $x_{2}$ ist
  im ersten Teil frei, im zweiten Teil aber durch den Allquantor
  gebunden.

  In $(\forall x_{2}\quantsep A_{1}^{2}(x_{1},x_{2}) \rightarrow (\forall x_{2}\quantsep
  A_{1}^{1}(x_{2})))$ ist $x_{1}$ frei und $x_{2}$ gebunden.
  Achtung: jedes Vorkommen von $x_2$ ist durch einen anderen Quantor gebunden!
\end{bsp}

Eine Variable ist \emph[index=Variable!freie]{frei} in $\alpha$, falls
alle Vorkommen der Variablen in $\alpha$ frei sind und analog ist eine
Variable \emph[index=Variable!gebunden]{gebunden}, falls alle Vorkommen der
Variablen in $\alpha$ gebunden sind.

\begin{bsp}
In der Formel
$(\forall x_1\quantsep ( \forall x_2\quantsep A^2_1(x_1,x_2)) \rightarrow  A^3_1(x_1,x_2,x_3))$
sind alle Vorkommen von $x_1$ gebunden
und alle Vorkommen von $x_3$ frei.
Also ist $x_1$ in dieser Formel gebunden, und $x_3$ ist frei.
Das Variablensymbol $x_2$ kommt einmal gebunden und einmal frei vor.
Also ist $x_2$ in dieser Formel weder frei noch gebunden.
\end{bsp}

Eine Formel heißt \emph[index=Formel!geschlossene]{geschlossen},
falls alle Variablen in der Formel gebunden sind -- d.\,h. es gibt kein freies
Vorkommen einer Variablen.

Der \emph[index=Formel!Abschluss einer]{Abschluss}
einer Formel $\alpha$ entsteht aus $\alpha$,
indem für jede frei in $\alpha$ vorkommende Variable
ein Allquantor an den Anfang der Formel geschrieben wird.

\begin{bsp}
In der Formel
$\bigl(\forall x_1\quantsep ( \forall x_2\quantsep A^2_1(x_1,x_2)) \rightarrow
  A^3_1(x_1,x_2,x_3)\bigr)$
kommen $x_2$ und $x_3$ frei vor.
Also ist
$(\forall x_2 \quantsep (\forall x_3\quantsep
        (\forall x_1 \quantsep ( \forall x_2 \quantsep A^2_1(x_1,x_2)) \rightarrow  A^3_1(x_1,x_2,x_3))))$
der Abschluss der Formel.
\end{bsp}


$\alpha[x/t]$ entsteht aus $\alpha$ durch Ersetzen aller freien Vorkommen
der Variablen $x$ durch den Term $t$.
\begin{bsp}
  \begin{itemize}
   \item $A_{1}^{2}(x_{1},x_{2})[x_{1}/f_{1}^{1}(x_{2})] =
       A_{1}^{2}(f_{1}^{1}(x_{2}), x_{2})$

   \item $( A_{1}^{2}(x_{1},x_{2}) \rightarrow
    (\forall x_2\quantsep A_{1}^{2}(x_{1},x_{2})))[x_{1}/f_{1}^{1}(x_{2})] =
    A_{1}^{2}(x_{1},f_{1}^{1}(x_{2})) \rightarrow
    (\forall x_2\quantsep A_{1}^{2}(x_{1},x_{2}))$
  \end{itemize}
\end{bsp}


Der Term $t$ heißt \emph[index=Term!frei für]{frei für} $x_{i}$ in
$\alpha$, falls kein freies Vorkommen von $x_{i}$ in $\alpha$ im
Gültigkeitsbereich eines Quantors für eine Variable in $t$ liegt.

\begin{bsp}
  $x_{2}$ ist frei für $x_{1}$ in $A_{1}^{1}(x_{1})$, nicht jedoch in
  $\forall x_{2}\quantsep A_{1}^{1}(x_{1})$.
\end{bsp}

\section{Interpretation von Formeln}

\begin{bsp}
  Betrachten wir folgende Formeln:
  \begin{enumerate}
   \item $A_{1}^{2}(x_{1},x_{2})$
   \item $\forall x_{1}\quantsep A_{1}^{2}(x_{1},x_{2})$
   \item $\exists x_{1}\quantsep \forall x_{2}\quantsep A_{1}^{2}(x_{1},x_{2})$
  \end{enumerate}

  Für die Grundmenge $\N$ und $A_{1}^{2}$ mit der Bedeutung $\leq$
  ($A_{1}^{2}=\{(n,m)\in\N\times\N\colon n\leq m\}$) bedeuten die Aussagen:
  \begin{enumerate}
   \item $x_{1}\leq x_{2}$
   \item Für alle $x_{1}\in\N$ gilt $x_{1}\leq x_{2}$, d.\,h. $x_{1}=0$
   \item Es gibt ein $x_{1}\in\N$, so dass für alle $x_{2}\in\N$ gilt:
    $x_{1}\leq x_{2}$, d.\,h. $\N$ besitzt ein untere Schranke
  \end{enumerate}
\end{bsp}

% 23. Mai 2006

\begin{defini}[Interpretation]
  Eine \emph{Interpretation} $\mathcal{M}$ besteht aus
  \begin{itemize}
   \item einer nicht leeren Grundmenge $D$,

   \item einer Abbildung von der Menge alle Funktionssymbole in die Menge
    aller Funktionen auf $D$, die jedem Funktionssymbol $f_{k}^{n}$ eine
    $n$-stellige Funktion $(f_{k}^{n})^{\mathcal{M}}\colon D^{n} \rightarrow D$
    zuordnet,

   \item einer Abbildung von der Menge aller Konstantensymbole in die Menge
    $D$, die jedem Konstantensymbol $a_{k}$ ein Element $(a_{k})^{\mathcal{M}}\in D$
    zuordnet und

   \item einer Abbildung von der Menge aller Prädikatensymbole in die
    Potenzmenge von $\bigcup_{i\in\N} D^{i}$, die jedem Prädikatensymbol
    $A_{k}^{n}$ eine Menge $(A_{k}^{n})^{\mathcal{M}}\subseteq D^{n}$ zuordnet.
  \end{itemize}
\end{defini}

$\Sigma_{\mathcal{M}}$ bezeichne die Menge aller Funktionen von der Menge aller
Variablensymbole nach $D$, $\Sigma_{\mathcal{M}} = \big\{s\big| s\colon
\{x_{1},x_{2},x_{3},\dotsc\}\rightarrow D\big\}$ (Variablenbelegungen)
($x_{j}$ sind Variablensymbole)

Für Variablenbelegungen $s$ und eine Interpretation $\mathcal{M}$ ist $s^{\ast}(t)$
für alle Terme $t$ definiert als:
\begin{enumerate}
 \item Wenn $t=x_{j}$ eine Variable ist, dann ist $s^{\ast}(t) = s(x_{j})$.
 \item Wenn $t=a_{j}$ eine Konstante ist, dann ist $s^{\ast}(t) =
  (a_{j})^{\mathcal{M}}$.
 \item Wenn $t=f_{k}^{n}(t_{1},\dotsc,t_{n})$ für Terme
  $t_{1},\dotsc,t_{n}$, dann ist $s^{\ast}(t) =
  (f_{k}^{n})^{\mathcal{M}}\big(s^{\ast}(t_{1}), \dotsc, s^{\ast}(t_{n}) \big)$.
\end{enumerate}

$s$ erfüllt die Formel $\alpha$, falls
\begin{gather*}
  \begin{cases}
    \big(s^{\ast}(t_{1}),\dotsc,s^{\ast}(t_{n})\big)\in (A_{k}^{n})^{\mathcal{M}}
    &\text{und\ } \alpha=A_{k}^{n}(t_{1},\dotsc,t_{n})\text{\ eine
    atomare Formel ist}\\
    s\text{\ erfüllt\ }\beta\text{\ nicht} &\text{und\ }
    \alpha=(\neg\beta)\\
    \text{$s$ erfüllt $\beta$ nicht oder $s$ erfüllt $\gamma$} &\text{und\ }
    \alpha=(\beta\rightarrow\gamma)\\
    \multicolumn{2}{l}{\text{jedes $s'$ mit $s'(x_{j})=s(x_{j})$ für alle $j\ne i$ erfüllt
    $\beta$} \text{\ und\ }a=(\forall x_{i}\quantsep\beta)}
  \end{cases}
\end{gather*}

% 2006-05-24

\begin{bsp}
  Wir betrachten die Formel
      $\alpha_0=\exists x_{2}\quantsep A_{1}^{2}(f_{1}^{2}(x_{1},x_{2}), x_{3})$.

  Die Interpretation $\cM_0$ wird angegeben durch eine
  nicht leere Grundmenge $D$ und die Interpretation der
  in den Formeln vorkommenden Konstanten-, Funktions- und Prädikatensymbole.
  \begin{itemize}
    \item   die Grundmenge von $\cM_0$  sei $\N$
    \item die Interpretation des Funktionssymbols $f_{1}^{2}$ sei
       $(f_{1}^{2})^{\cM_0} = ((a,b) \mapsto a\cdot b)$
    \item die Interpretation des Prädikatensymbols $A_{1}^{2}$ sei
       $(A_{1}^{2})^{\cM_0} = \{ (a,b)\in \N^{2}\colon a=b\}$
  \end{itemize}

  In der Interpretation $\cM_0$ hat
    $\exists x_{2}\quantsep A_{1}^{2}(f_{1}^{2}(x_{1},x_{2}), x_{3})$
  die Bedeutung $\exists z\quantsep x\cdot z=y$.

  Als nächstes legen wir eine
  Variablenbelegung $s_{1}$ fest.
  Sie weist jedem Variablensymbol $x_i$ einen Wert aus der Grundmenge zu.
  \begin{gather*}
    \begin{array}{r*{6}{|c}}
      & x_{1} & x_{2} & x_{3} & x_{4} & x_{5} & \dotso\\
      \hline
      s_{1}(x_{i}) & 2 & 3 & 8 & 9 & 10 & \dotso
    \end{array}
  \end{gather*}
  In der Interpretation $\cM_0$ mit Variablenbelegung $s_1$ hat
    $\exists x_{2} \quantsep A_{1}^{2}(f_{1}^{2}(x_{1},x_{2}), x_{3})$
  die Bedeutung $\exists z \quantsep 2\cdot z=8$.

  Nun wollen wir feststellen, ob
    $\exists x_{2}\quantsep  A_{1}^{2}(f_{1}^{2}(x_{1},x_{2}), x_{3})$
  von $s_1$ erfüllt wird. Dazu wenden wir (wiederholt)
  obige Definitionen an.

  \begin{tabular}{p{5mm}cp{0.85\textwidth}}
  \multicolumn{3}{l}{$s_{1}$ erfüllt
          $(\exists x_{2}\quantsep A_{1}^{2}(f_{1}^{2}(x_{1},x_{2}),x_{3}) )$} \\
    & $\Leftrightarrow$ &
         $s_{1}$ erfüllt
       $\neg(\forall x_{2}\quantsep \neg A_{1}^{2}(f_{1}^{2}(x_{1},x_{2}),x_{3}))$ \\
    & $\Leftrightarrow$ &
          $s_{1}$ erfüllt nicht
         $(\forall x_{2}\quantsep\neg A_{1}^{2}(f_{1}^{2}(x_{1},x_{2}),x_{3}))$  \\
    & $\Leftrightarrow$ &
          nicht jede Variablenbelegung $s$ mit
           $s(x_{i}) = s_{1}(x_{i})$ für alle $i\ne2$ erfüllt
         $\neg A_{1}^{2}(f_{1}^{2}(x_{1},x_{2}), x_{3})$ \\
    & $\Leftrightarrow$ &
          nicht jede Variablenbelegung $s$ mit
             $s(x_{i}) = s_{1}(x_{i})$ für alle $i\ne2$ erfüllt nicht
           $A_{1}^{2}(f_{1}^{2}(x_{1},x_{2}), x_{3})$ \\
    & $\Leftrightarrow$ &
       nicht jede Variablenbelegung $s$ mit
           $s(x_{i}) = s_{1}(x_{i})$ für alle $i\ne2$ erfüllt nicht
        $(s^{\ast}(f_{1}^{2}(x_{1},x_{2})), s^{\ast}(x_{3}))\in(A_{1}^{2})^{\cM_0}$ \\
    & $\Leftrightarrow$ &
       nicht jede Variablenbelegung $s$ mit $s(x_{i}) = s_{1}(x_{i})$ für
          alle $i\ne2$ erfüllt nicht
       $((f_{1}^{2})^{\cM_0}(s(x_{1}),s(x_{2})), s(x_{3}))\in (A_{1}^{2})^{\cM_0}$
  \end{tabular}

  Die letzte Aussage dieser Folge von äquivalenten Aussagen nennen wir $\star$.
  Wir wollen zeigen, dass $\star$ wahr ist.
  Also müssen wir eine Variablenbelegung $s$ finden,
  so dass die Aussage $(f_{1}^{2})^{\cM_0}(s(x_{1}),s(x_{2})) = s(x_{3})$ gilt
  (d.\,h. $s(x_1)\cdot s(x_2)=s(x_3)$),
  wobei $s(x_{1})=s_{1}(x_{1})=2$ und $s(x_{3})=s_{1}(x_{3})=8$.
  Wir wählen $s$ so, dass $s(x_{2})=4$.
  Also
  \begin{gather*}
    \begin{array}{r*{6}{|c}}
      & x_{1} & x_{2} & x_{3} & x_{4} & x_{5} & \dotso\\
      \hline
      s(x_{i}) & 2 & 4 & 8 & 9 & 10 & \dotso
    \end{array}
  \end{gather*}

  Für die Variablenbelegung $s$ gilt: $2\cdot 4 = s(x_1)\cdot s(x_2) =
  s(x_3)=8$, also erfüllt sie die Bedingungen
       $((f_{1}^{2})^{\cM_0}(s(x_{1}),s(x_{2})), s(x_{3}))\in (A_{1}^{2})^{\cM_0}$
  und
      \glqq$s(x_{i}) = s_{1}(x_{i})$ für alle $i\ne2$\grqq{}.
  Folglich ist die Aussage
  \glqq{}jede Variablenbelegung $s$ mit \ldots{} erfüllt  nicht
       $((f_{1}^{2})^{\cM_0}(s(x_{1}),s(x_{2})), s(x_{3}))\in (A_{1}^{2})^{\cM_0}$\grqq{}
  falsch.
  Deshalb ist die Negation der Aussage wahr,
  und diese Negation ist genau die Aussage $\star$.
  Da $\star$ äquivalent zur Aussage \glqq{}$s_1$ erfüllt $\alpha_0$\grqq{} ist,
  gilt: $s_{1}$ erfüllt die Formel
       $(\exists x_{2}\quantsep A_{1}^{2}(f_{1}^{2}(x_{1},x_{2}),x_{3}))$.

  Für jede Variablenbelegung $s_2$ mit $s_2(x_1)=0$ und $s_2(x_3)\ne0$ gilt:
  $s_2$ erfüllt $\alpha_0$ nicht (unter $\cM_0$).
  In der Interpretation $\cM_0$ mit Variablenbelegung $s_2$ hat
    $\exists x_{2}\quantsep A_{1}^{2}(f_{1}^{2}(x_{1},x_{2}), x_{3})$
  die Bedeutung $\exists z\quantsep 0\cdot z\ne0$.
\end{bsp}

\begin{defini}[Modell]
  \begin{itemize}
   \item
    Eine Formel $\alpha$ ist \emph{wahr} unter der Interpretation $\cM$,
    falls
    $\alpha$ von jeder Variablenbelegung $s\in\Sigma_{\cM}$ erfüllt wird.

    Schreibweise für \glqq{}$\alpha$ ist wahr unter $\cM$\grqq{}:
    $\Mmodels \alpha$.

   \item
    $\alpha$ ist \emph{falsch} unter $\cM$,
    falls $\alpha$ von keinem $s\in\Sigma_{\cM}$ erfüllt wird.

   \item $\cM$ heißt \emph{Modell} einer Formel $\alpha$,
         falls $\alpha$ unter $\cM$ wahr ist.

         $\cM$ heißt \emph{Modell} für Formelmenge $\Gamma$,
         falls $\cM$ Modell jeder Formel in $\Gamma$ ist.
  \end{itemize}
\end{defini}

\begin{bsp}
Die Formel $\alpha_0$ aus dem letzten Beispiel
ist unter der angegebenen Interpretation $\cM_0$ weder
wahr noch falsch,
da es eine Variablenbelegung gibt, die $\alpha_0$ erfüllt,
und eine andere Variablenbelegung, die $\alpha_0$ nicht erfüllt.

Unter einer Interpretation $\cM_1$ mit Grundmenge $\N$ und
$(A^1_2)^{\cM_1}=\N$ ist die Formel $\alpha_0$ wahr.
Also ist $\cM_1$ ein Modell für $\alpha_0$.

Unter einer Interpretation $\cM_2$ mit Grundmenge $\N$ und
$(A^1_2)^{\cM_2}=\emptyset$ ist die Formel $\alpha_0$ falsch.
Also ist $\cM_1$ ein Modell für $\alpha_0$.

Unter einer Interpretation $\cM_3$ mit Grundmenge $\N$,
$(A^1_2)^{\cM_3}=\{(a,b)\in\N^2\colon b=0 \vee b \text{ teilt } a\}$
und $(f^2_1)^{\cM_3} = ((a,b) \mapsto a+b)$
ist $\alpha_0$ wahr.
\end{bsp}

Wichtige Eigenschaften von Formeln
in Bezug auf die Begriffe wahr und falsch (ohne Beweise):
\begin{itemize}[(E1)]
 \item $\alpha$ ist wahr unter $\cM$ \gdw $\neg \alpha$ ist falsch unter $\cM$.

 \item Es gilt höchstens eins von $\Mmodels \alpha$ und $\Mmodels\neg\alpha$.

 \item Aus $\Mmodels\alpha$ und $\Mmodels \alpha\rightarrow\beta$
  folgt $\Mmodels\beta$.

 \item $\alpha\rightarrow\beta$ ist falsch unter $\cM$ \gdw \\
  $\alpha$ ist wahr unter $\cM$ und $\beta$ ist falsch unter $\cM$.

 \item $s$ erfüllt $\alpha\wedge\beta$ \gdw
  $s$ erfüllt $\alpha$ und $s$ erfüllt $\beta$. \\
  $s$ erfüllt $\alpha\vee\beta$ \gdw
  $s$ erfüllt $\alpha$ oder $s$ erfüllt $\beta$. \\
  $s$ erfüllt $\alpha\leftrightarrow\beta$ \gdw
  $s$ erfüllt $\alpha\rightarrow\beta$ und $s$ erfüllt $\beta\rightarrow\alpha$. \\
  $s$ erfüllt $(\exists x_j\quantsep \beta)$ \gdw\\
  \rule{4mm}{0mm}
  es gibt $s'\in\Sigma_{\cM}$ mit $s'(x_i)=s(x_i)$ für alle $i\ne j$
  und $s'$ erfüllt $\beta$.

 \item $\Mmodels \alpha$ \gdw $\Mmodels (\forall x_i\quantsep \alpha)$.

             (Für den Abschluss $\beta$ von $\alpha$ gilt also:
                     $\Mmodels \beta$ \gdw $\Mmodels \alpha$.)

 \item Eine Instanz einer Tautologie erhält man,
             indem man die Aussagevariablen einer Tautologie durch
             Formeln ersetzt (gleiche Aussagevariablen
             durch gleiche Formeln).

             Es gilt: Jede Instanz einer Tautologie ist wahr unter jeder Interpretation.

 \item Sei $V$ eine Menge von Variablen, die alle freien Variablen von $\alpha$
  enthält.
  $s$ und $s'$ seien Variablenbelegungen in $\Sigma_{\cM}$.

  Wenn $s(x_i)=s'(x_i)$ für alle $x_i\in V$, dann gilt:
  \begin{center}
    $s$ erfüllt $\alpha$ \gdw $s'$ erfüllt $\alpha$.
  \end{center}

 \item Für jede geschlossene Formel $\alpha$ und jede Interpretation $\cM$ gilt:
  \begin{gather*}
    \Mmodels \alpha \text{~oder~} \Mmodels \neg \alpha
  \end{gather*}

 \item Sei $t$ frei für $x_i$ in $\alpha$.
  Dann gilt für alle $\cM$:
  \begin{gather*}
    \Mmodels (\forall x_i\quantsep \alpha ) \rightarrow \alpha[x_i/t].
  \end{gather*}

 \item Wenn $x_i$ in $\alpha$ nicht frei vorkommt, dann gilt für alle $\cM$
  \begin{gather*}
    \Mmodels (\forall x_i\quantsep \alpha\rightarrow\beta) \rightarrow
       (\alpha \rightarrow (\forall x_i\quantsep \beta)).
  \end{gather*}
\end{itemize}

\begin{defini}[erfüllbare und gültige Formeln]
  \begin{itemize}
   \item
    Eine Formel $\alpha$ heißt \emph{gültig},
    falls
    $\Mmodels \alpha$ für jede Interpretation $\cM$ gilt.

    Schreibweise: $\models \alpha$.

   \item
    $\alpha$ heißt \emph{erfüllbar},
    falls es eine Interpretation $\cM$ und eine Variablenbelegung $s\in\Sigma_{\cM}$
    gibt, die $\alpha$ erfüllt.
  \end{itemize}
\end{defini}

Offensichtlich gilt:
\begin{itemize}
 \item $\alpha$ ist gültig \gdw $\neg\alpha$ ist nicht erfüllbar.

 \item $\alpha$ ist erfüllbar \gdw $\neg\alpha$ ist nicht gültig.
\end{itemize}



\section{Theorien 1.~Ordnung}

\begin{defini}[Theorie 1.~Ordnung]\label{def:theo1.ord}
  Eine \emph{Theorie 1.~Ordnung} $\mathrm{K}$ besteht aus
  \begin{enumerate}[1.]
   \item \textit{Formeln}

    Die Definition der Formeln ist gemäß \autoref{def:formeln}.
    Theorien können sich durch die zugelassenen Variablen-, Konstanten-,
     Funktions- und Prädikatensymbole unterscheiden.

   \item \textit{logischen Axiomen}

    Sie entstehen aus den Axiomenschemata (A1)--(A5)
    durch Einsetzen von beliebigen Formeln für $\alpha$, $\beta$ und $\gamma$.
    \begin{enumerate}[({A}1)]
     \item $\alpha \rightarrow (\beta \rightarrow \alpha)$

     \item $\left(\alpha \rightarrow (\beta \rightarrow \gamma)\right) \rightarrow
      \left(\left(\alpha\rightarrow \beta\right) \rightarrow \left(\alpha \rightarrow \gamma\right) \right)$

     \item $\left( \neg\beta \rightarrow \neg\alpha\right) \rightarrow
      \left( \left( \neg\beta \rightarrow \alpha\right) \rightarrow \beta\right)$

     \item $(\forall x_i\quantsep\alpha) \rightarrow \alpha[x_i/t]$,
      wobei $t$ ein Term ist, der frei für $x_i$ in $\alpha$ ist.

     \item $(\forall x_i\quantsep \alpha\rightarrow\beta) \rightarrow
      (\alpha \rightarrow (\forall x_i\quantsep \beta))$,
      falls $x_i$ in $\alpha$ nicht frei vorkommt.
    \end{enumerate}
      Die Axiomenschemata sind also die drei bereits aus der Aussagenlogik bekannten
      und zwei weitere zur Beschreibung von Eigenschaften des Allquantors.

   \item \textit{zusätzlichen Axiomen}

      Die Menge der zusätzlichen Axiome kann leer sein.
      Eine Theorie 1.~Ordnung ohne zusätzliche Axiome wird
        \emph{Prädikatenkalkül 1.~Ordnung} genannt.
      In \autoref{chapter-zahlentheorie} werden wir eine Theorie betrachten,
      die zusätzliche Axiome zur Beschreibung von Eigenschaften der natürlichen
      Zahlen besitzt.

   \item \textit{Ableitungsregeln}

    \begin{mdescription}
     \item[(MP)] modus ponens:
      $\displaystyle\frac{\alpha, \alpha\rightarrow\gamma}{\gamma}$
     \item[(Gen)] Generalisierung:
      $\displaystyle\frac{\alpha}{(\forall x_{i}\quantsep \alpha)}$
      für ein beliebiges Variablensymbol $x_i$
    \end{mdescription}
  \end{enumerate}
\end{defini}

Jede Theorie 1.~Ordnung ist eine formale Theorie.
Damit sind auch die Begriffe Beweis und Theorem definiert.
Ein \emph[indexrand=Modell einer Theorie 1.~Ordnung]{Modell einer Theorie
$\mathrm{K}$ 1.~Ordnung}
ist ein Modell für die Menge aller (logischen und zusätzlichen) Axiome von $\mathrm{K}$.
Aus (E3) und (E6) folgt, dass
jedes Modell von $\mathrm{K}$ auch ein Modell
aller Theoreme von $\mathrm{K}$ ist.


\begin{bsp}
  Ein Beweis für
  $\alpha, (\forall x_1 \quantsep\alpha)\rightarrow \beta \vdash (\forall x_1\quantsep \beta)$.
  \begin{align*}
    (1)\quad & \alpha & \text{Hypothese}\\
    (2)\quad & (\forall x_1\quantsep \alpha) & \text{Gen (1)}\\
    (3)\quad & (\forall x_1\quantsep \alpha)\rightarrow \beta & \text{Hypothese}\\
    (4)\quad & \beta & \text{MP (2), (3)} \\
    (5)\quad & (\forall x_1\quantsep \beta) & \text{Gen (4)}
  \end{align*}
\end{bsp}

An diesem Beispiel sehen wir, dass sich das Deduktionstheorem
nicht direkt auf Theorien 1.~Ordnung übertragen lässt.
Im obigen Beispiel finden beide Anwendungen von (Gen) statt auf Formeln,
die aus $\alpha$ abgeleitet wurden.
Deshalb gilt \textit{nicht}:
$(\forall x_1\quantsep \alpha)\rightarrow \beta \vdash \alpha \rightarrow
(\forall x_1\quantsep \beta)$.



\section{Eigenschaften von Theorien 1.~Ordnung}


% 31.5.06

Ohne zusätzliche Axiome können ausschließlich gültige Formeln bewiesen werden.

\begin{satz}[Korrektheit des Prädikatenkalküls 1.~Ordnung]\label{satz-korrektheit-theorien-1.ordnung}
  Für jeden Prädikatenkalkül 1.~Ordnung $K$ und jede Formel $\alpha$
  gilt:
  \begin{center}
    Wenn $\xvdash{K} \alpha$, dann ist $\alpha$ gültig.
  \end{center}

\begin{proof}
  Alle Axiome sind gültig (E7 für A1--A3, E10 für A4 und E11 für A5).
  Der modus ponens und die Generalisierung erhalten die Gültigkeit (E3
  und E6).
\end{proof}
\end{satz}


Das alte Deduktionstheorem gilt \textit{nicht} für Theorien 1.~Ordnung.
Betrachte dazu folgenden Beweis.
%
\begin{align*}
  (1)\quad & A^1_1(x_1)                   & \text{Hypothese}\\
  (2)\quad &( \forall x_{1}\quantsep A^1_1(x_1) ) & \text{Gen (1)}
\end{align*}
Mit dem alten Deduktionstheorem folgt:
$\vdash A^1_1(x_1) \rightarrow(\forall x_{1}\quantsep A^1_1(x_1))$.
Diese Formel ist aber nicht gültig!
(Man nehme eine Interpretation $\cM$ mit Grundmenge $\N$
und $(A^1_1)^{\cM}=\{a\in\N \colon a \text{ ist ungerade} \}$.)
Ihre Beweisbarkeit widerspräche \autoref{satz-korrektheit-theorien-1.ordnung}.
Das Problem liegt hier in der Anwendung der Generalisierung
auf eine Variable, die in der Hypothese frei vorkommt.

Um ein Deduktionstheorem für Theorien 1.~Ordnung zu formulieren,
brauchen wir eine Eigenschaft von Beweisen.
Sei $\alpha\in\Gamma$ und $\beta_{1},\dotsc,\beta_{k}$ sei eine
Herleitung aus $\Gamma$. $\beta_{i}$ \emph[indexrand=hängt\ldots{} ab]
{hängt} von $\alpha$ ab, falls
\begin{itemize}
 \item $\beta_{i}=\alpha$ oder
 \item $\beta_{i}$ entsteht durch Anwendung einer Ableitungsregel auf
  (mindestens) eine Formel, die von $\alpha$ abhängt.
\end{itemize}

\begin{lemma}
  Sei $\alpha\notin\Gamma$ und $\Gamma,\alpha \vdash\beta$. Wenn $\beta$
  aus $\Gamma\cup\{\alpha\}$ hergeleitet werden kann, so dass $\beta$
  nicht von $\alpha$ abhängt, dann gilt $\Gamma\vdash\beta$.
\end{lemma}


\begin{satz}[Deduktionstheorem für Theorien 1.~Ordnung]\label{Deduktionstheorem2}
  Sei $\alpha\notin\Gamma$ und $\Gamma,\alpha\vdash\beta$,
  wobei $\beta_{1},\dotsc,\beta_{k}$ eine
  Herleitung von $\beta$ aus $\Gamma\cup\{\alpha\}$ mit folgender
  Eigenschaft:
\begin{quote}
wenn $\beta_{i}=(\forall x_{j}\quantsep \beta_{q})$ durch Anwendung
  der Generalisierungsregel auf $\beta_{q}$ entsteht, dann gilt (1)
  $\beta_{q}$ hängt nicht von $\alpha$ ab oder (2) $x_{j}$ kommt nicht
  frei in $\alpha$ vor.
\end{quote}
  Dann gilt $\Gamma \vdash \alpha\rightarrow\beta$.

\begin{proof}
  Induktion über die Länge $i$ der Herleitung.
  \begin{mdescription}
   \item[IA] $i=1$, $\beta_{i}$ ist ein Axiom oder aus
    $\Gamma\cup\{\alpha\}$ (analog zum Beweis des Deduktionstheorems in der
    Aussagenlogik, \autoref{al-Deduktionstheorem}).

   \item[IS]~
    \begin{faelle}
     \item $\beta_{i+1}$ ist ein Axiom, aus $\Gamma\cup\{\alpha\}$ oder
      entsteht durch modus ponens (analog zum Beweis des Deduktionstheorems in der
      Aussagenlogik)

     \item $\beta_{i+1}$ entsteht durch Generalisierung, d.\,h.
      $\beta_{i+1}=(\forall x_{j}\quantsep \beta_{q})$.

      \begin{faelle}
       \item $\beta_{q}$ hängt nicht von $\alpha$ ab: dann gilt
        \begin{align*}
          \Gamma &\vdash \beta_{q}\\
          \Gamma &\vdash (\forall x_{j}\quantsep \beta_{q}) &\text{Gen}\\
          \Gamma &\vdash (\forall x_{j}\quantsep \beta_{q}) \rightarrow
             (\alpha\rightarrow (\forall x_{j}\quantsep \beta_{q})) &\text{A1}\\
          \Gamma &\vdash \alpha \rightarrow (\forall x_{j}\quantsep \beta_{q})
             &\text{MP}
        \end{align*}

       \item $x_{j}$ kommt nicht frei in $\alpha$ vor: dann gilt
        \begin{align*}
          \Gamma &\vdash \alpha \rightarrow \beta_{q} &\text{IV}\\
          \Gamma &\vdash (\forall x_{j}\quantsep \alpha \rightarrow \beta_{q})
             &\text{Gen}\\
          \Gamma &\vdash (\forall x_{j}\quantsep \alpha \rightarrow \beta_{q})
             \rightarrow (\alpha \rightarrow (\forall x_{j}\quantsep \beta_{q}))
             &\text{A5} \\
          \Gamma & \alpha \rightarrow (\forall x_{j}\quantsep \beta_{q})
             &\text{MP}
        \end{align*}
      \end{faelle}
    \end{faelle}
  \end{mdescription}
\end{proof}
\end{satz}

\begin{bsp}
  Als Beispiel für das Deduktionstheorem für Theorien 1.~Ordnung beweisen wir
  die Formel
  $(\forall x_1 \quantsep(\forall x_2\quantsep\alpha) )\rightarrow
  (\forall x_2 \quantsep(\forall x_1\quantsep\alpha) )$.
  Dafür zeigen wir zuerst
  $(\forall x_1 \quantsep(\forall x_2\quantsep\alpha) )\vdash
  (\forall x_2 \quantsep(\forall x_1\quantsep\alpha) )$:
  \begin{align*}
    (1)\quad & \forall x_1 \quantsep(\forall x_2\quantsep \alpha)
       & \text{Hypothese}\\
    (2)\quad & (\forall x_1\quantsep (\forall x_2\quantsep\alpha) )
       \rightarrow (\forall x_2\quantsep\alpha) &
       \text{(A4) mit $t=x_1$}%
       \footnote{Bem.: $(\forall x_2\quantsep\alpha)[x_1/x_1]=(\forall
       x_2\quantsep\alpha))$}\\
    (3)\quad & (\forall x_2\quantsep\alpha) & \text{MP 1,2} \\
    (4)\quad &  (\forall x_2\quantsep\alpha) \rightarrow \alpha
       & \text{(A4) mit $t=x_2$} \\
    (5)\quad & \alpha & \text{MP 3,4} \\
    (6)\quad &  (\forall x_1\quantsep\alpha) & \text{Gen 5} \\
    (7)\quad &  (\forall x_2 \quantsep(\forall x_1\quantsep\alpha)) & \text{Gen 6} \\
  \end{align*}

  Da durch die Generalisierung im Schritt~6 und 7 die Variablen $x_1$ und
  $x_2$ gebunden wurden und beide nicht frei in $(\forall x_1
  \quantsep(\forall x_2\quantsep\alpha) )$ vorkommen,
  kann das Deduktionstheorem angewendet werden.
  Damit folgt
    $\vdash (\forall x_1\quantsep(\forall x_2\quantsep\alpha) )
            \rightarrow(\forall x_2\quantsep(\forall x_1\quantsep\alpha) ) $.
\end{bsp}

Folgendes Korollar nennt zwei einfache Bedingungen,
unter denen das Deduktionstheorem angewendet werden kann.

\begin{korol}
  \begin{itemize}
   \item Wenn $\alpha$ keine freien Variablen enthält, dann gilt: aus
    $\Gamma,\alpha\vdash\beta$ folgt $\Gamma\vdash\alpha\rightarrow
    \beta$.

   \item Wenn im Beweis von $\Gamma,\alpha\vdash\beta$ nur
    Generalisierungen auf Variablen, die in $\alpha$ nicht frei
    vorkommen, statt finden, dann gilt: aus $\Gamma,\alpha\vdash\beta$
    folgt $\Gamma\vdash\alpha\rightarrow\beta$.
  \end{itemize}
\end{korol}


\subsection{Schreibweisen, die Beweise vereinfachen}

Zwei neue Regeln, die die Schreibweise vereinfachen. Die Nummern sind in
Anlehnung an ihren Ursprung:
\begin{mdescription}
 \item[(RA4)] $(\forall x\quantsep \alpha)\vdash \alpha[x/t]$, falls $t$ frei für $x$
  in $\alpha$ ist.

 \item[(RE4)] $\alpha[x/t] \vdash (\exists x\quantsep \alpha)$, falls $t$ frei für $x$
  in $\alpha$ ist.
\end{mdescription}
(Auf die Beweise der Korrektheit der Regeln wird aus Platzgründen verzichtet \ldots{})

\begin{bsp}
  Zeige $\vdash (\forall x\quantsep \alpha) \rightarrow (\exists x\quantsep \alpha)$.
  \begin{align*}
    (1)\quad & (\forall x\quantsep \alpha) &\text{Hypothese}\\
    (2)\quad &  \alpha[x/t] &\text{mit RA4}\\
    (3)\quad & (\exists x\quantsep \alpha) &\text{mit RE4}
  \end{align*}
  Mit dem Deduktionstheorem folgt $\vdash (\forall x\quantsep \alpha)
  \rightarrow (\exists x\quantsep \alpha)$.
\end{bsp}

Weitere Regeln (ohne Korrektheits-Beweise):
\begin{mdescription}
 \item[Negation:] $\neg\neg\alpha\vdash\alpha$ und
  $\alpha\vdash\neg\neg\alpha$

 \item[Konjunktion:] $\alpha\wedge\beta\vdash\alpha$ und
  $\alpha\wedge\beta\vdash\beta$ dann $\neg(\alpha\wedge\beta)\vdash
  \neg\alpha \vee \neg\beta$ und $\alpha,\beta\vdash\alpha\wedge\beta$

 \item[Disjunktion:] $\alpha\vee\beta,\alpha\rightarrow\gamma,
  \beta\rightarrow\gamma \vdash \gamma$ dann $\neg (\alpha\vee\beta)
  \vdash\neg\alpha\wedge\neg\beta$ (de Morgan), $\alpha\vee\beta,
  \neg\alpha\vdash\beta$ und $\alpha\vee\beta, \neg\beta\vdash\alpha$;
  $\alpha\vdash\alpha\vee\beta$ und $\beta\vdash\alpha\vee\beta$

 \item[Implikation:] $\alpha\rightarrow\beta,\neg\beta\vdash\neg\alpha$

  $\neg(\alpha\rightarrow\beta) \vdash\alpha$ und
  $\neg(\alpha\rightarrow\beta) \vdash\neg\beta$

 \item[Äquivalenz:] $\alpha \leftrightarrow \beta,\alpha\vdash\beta$
  $\alpha \leftrightarrow \beta, \beta\vdash\alpha$

  $\alpha\leftrightarrow\beta, \neg\alpha\vdash\neg\beta$ und
  $\alpha\leftrightarrow\beta, \neg\beta\vdash\neg\alpha$

  $\alpha \leftrightarrow\beta \vdash\alpha\rightarrow\beta$ und $\alpha
  \leftrightarrow\beta \vdash\beta\rightarrow\alpha$

  $\alpha\rightarrow\beta, \beta\rightarrow\alpha \vdash\alpha
  \leftrightarrow\beta$

 \item[Widerspruchsbeweis:] Sei $\Gamma,\neg\alpha \vdash
  \beta\wedge\neg\beta$ beweisbar ohne Verwendung der Generalisierung auf
  eine freie Variable in $\alpha$. Dann gilt $\Gamma\vdash\alpha$.
\end{mdescription}

\begin{bsp}
  Wir zeigen $\vdash (\forall x\quantsep \alpha\leftrightarrow\beta) \rightarrow (
  (\forall x\quantsep\alpha) \leftrightarrow (\forall x\quantsep\beta))$
  \begin{align*}
    (1)\quad &(\forall x\quantsep \alpha\leftrightarrow \beta) &\text{Hypothese}\\
    (2)\quad &(\forall x\quantsep \alpha) &\text{Hypothese}\\
    (3)\quad & \alpha\leftrightarrow\beta &\text{RA4,1}\\
    (4)\quad & \alpha &\text{RA4, 2}\\
    (5)\quad & \beta &\text{Äquivalenzregel mit 3,4}\\
    (6)\quad &\forall x\quantsep\beta&\text{Gen 5}
  \end{align*}
  Mit dem Deduktionstheorem folgt dann $(\forall x\quantsep \alpha\leftrightarrow\beta)
  \vdash ((\forall x\quantsep \alpha) \rightarrow (\forall x\quantsep \beta))$.

  Analog: $(\forall x\quantsep \alpha\leftrightarrow\beta) \vdash ((\forall
  x\quantsep \beta) \rightarrow (\forall x\quantsep \alpha))$. Mit Äquivalenzregel  folgt
  $(\forall x\quantsep \alpha\leftrightarrow\beta) \vdash (\forall x\quantsep \alpha)
  \leftrightarrow (\forall x\quantsep\beta)$. Mit Deduktionstheorem:
  $\vdash(\forall x\quantsep \alpha\leftrightarrow\beta) \rightarrow ((\forall
  x\quantsep \alpha) \leftrightarrow (\forall x\quantsep \beta))$
\end{bsp}

\begin{satz}[Ersetzbarkeitstheorem]\label{Ersetzbarkeitstheorem}
  Sei $\beta$ eine Teilformel von $\alpha$,
  und $\alpha'$ sei eine Formel, die
  aus $\alpha$ entsteht, indem in $\alpha$ beliebig viele Vorkommen von $\beta$ durch
  $\gamma$ ersetzt werden. Dabei enthält $y_{1}, y_{2}, \dotsc, y_{k}$ alle
  freien Variablen von $\beta$ oder $\gamma$, die in $\alpha$ gebunden
  vorkommen.

  Dann gilt:
  \begin{enumerate}
   \item $(\forall y_{1} \dotso (\forall y_{k}\quantsep
    \beta\leftrightarrow\gamma)\dotso) \rightarrow
    (\alpha\leftrightarrow\alpha')$

   \item Aus $\vdash\beta\leftrightarrow\gamma$ folgt $\vdash\alpha
    \leftrightarrow \alpha'$

   \item Aus $\vdash\beta \leftrightarrow\gamma$ und $\vdash\alpha$
    folgt $\vdash\alpha'$
  \end{enumerate}
\end{satz}


\subsection{Regel~C (choice)}

Betrachte zuerst folgenden umgangssprachlichen Beweis für
die Aussage
\begin{center}
  Das Quadrat einer geraden Zahl ist ebenfalls gerade.
\end{center}

Beweis:
\begin{enumerate}
 \item Sei $m$ eine gerade Zahl.
 \item Das heißt $\exists x\in\N\quantsep (m=2\cdot x)$.
 \item Sei $c$ diese Zahl.
 \item Also gilt $m^2 = 4 \cdot c^2 = 2 \cdot ( 2\cdot c^2)$.
 \item Folglich gilt $\exists x\in\N\quantsep (m^2 = 2\cdot x)$.
 \item Das heißt $m^2$ ist gerade.
\end{enumerate}

Im Beweis wird für die durch den Existenzquantor gebundene Variable $x$
zunächst die natürliche Zahl $c$ eingesetzt.
Dann wird mit $n$ herumgerechnet. Und schlielich
wird der Term $2\cdot c^2$ wieder generalisiert.

Dieses Vorgehen soll auch in formalen Beweisen benutzt werden können. Es wird
\emph{Regel~C} genannt.
\begin{mdescription}
 \item[Regel~C:] $(\exists x\quantsep \alpha) \vdash \alpha[x/c]$ für ein
  neues Konstantensymbol $c$.
\end{mdescription}

Im folgenden Beispiel wird eine korrekte Benutzung der Regel~C vorgestellt.
Man muss jedoch ein paar Einschränkungen beachten, die im Anschluss
diskutiert werden.
\autoref{satz-regel-c} gibt dann die korrekte Benutzung von Regel~C an.
\begin{bsp}
  Wir beweisen $\vdash
  \big( (\exists x\quantsep A(x)) \wedge (\exists x\quantsep B(x)) \big) \rightarrow
  (\exists x\quantsep A(x) \rightarrow B(x))$.
  \begin{align*}
    (1)\quad & (\exists x\quantsep A(x)) \wedge(\exists x\quantsep B(x)) &\text{Hypothese}\\
    (2)\quad &(\exists x\quantsep B(x)) &\text{Konj.Regel, 1}\\
    (3)\quad & B(c) &\text{Regel C, 2}\\
    (4)\quad & B(c) \rightarrow (A(c) \rightarrow B(c)) &\text{A1}\\
    (5)\quad & A(c) \rightarrow B(c) &\text{MP 3,4}\\
    (6)\quad & (\exists x\quantsep A(x)\rightarrow B(x)) &\text{RE4, 5}
  \end{align*}
  Mit dem Deduktionstheorem folgt das Theorem.
\end{bsp}

Die Verwendung der Regel~C unterliegt den folgenden Einschränkungen.

\begin{enumerate}
 \item Bei jeder Verwendung muss ein neues Konstantensymbol $c$ eingeführt werden,
  das bisher im Beweis nicht vorkam.

  {\footnotesize Wird kein neues Konstantensymbol eingeführt, können nicht gültige Formeln
  bewiesen werden.

  $
  \begin{array}{cll}
    (1) & \exists x_1 ~ A^2_1(x_1, a_1) & \text{Hypothese} \\
    (2) & A^2_1(a_1, a_1) &
    \text{falsche Anwendung von Regel C: $a_1$ ist kein neues Konst.symbol} \\
    (3) & \exists x_1 ~ A^2_1(x_1, x_1) &\text{Regel RE4}
  \end{array}
  $

  Mit Deduktionstheorem könnte
  $(\exists x_1 ~ A^2_1(x_1, a_1)) \rightarrow (\exists x_1 ~ A^2_1(x_1, x_1))$
  bewiesen werden, was offensichtlich nicht gültig ist.}

 \item Die Generalisierung darf nicht angewendet werden auf eine Variable,
  die frei in einer Formel vorkommt, die durch Regel~C entstanden ist.

  {\footnotesize Bei Nichtbeachtung dieser Einschränkung können
  nicht gültige Formeln bewiesen werden.

  $
  \begin{array}{cll}
    (1) & (\forall x_1 ~ (\exists x_2 ~ A^2_1(x_1, x_2))) & \text{Hypothese} \\
    (2) & (\exists x_2 ~ A^2_1(x_1, x_2)) & \text{RA4, 1} \\
    (3) & A^2_1(x_1,a_1) & \text{Regel C (korrekte Anwendung), 2} \\
    (4) & (\forall x_1 ~ A^2_1(x_1,a_1)) &
    \text{Gen, 3 (Anwendung auf freie Var. aus 3, die durch Regel C entstanden ist)} \\
    (5) & (\exists x_2 ~ (\forall x_1 ~ A^2_1(x_1,a_1))) & \text{RE4, 4}
  \end{array}
  $

  Mit Deduktionstheorem könnte
  $\vdash (\forall x_1 ~ (\exists x_2 ~ A^2_1(x_1, x_2))) \rightarrow
  (\exists x_2 ~ (\forall x_1 ~ A^2_1(x_1,a_1)))$ bewiesen werden,
  was offensichtlich nicht gültig ist.
  }
 \item In der bewiesenen Formel kommt kein Konstantensymbol vor, das
  durch Regel~C eingeführt wurde.

  {\footnotesize Sonst könnte $(\exists x_1 A^1_1(x_1)) \rightarrow A^1_1(a_1)$
  bewiesen werden, was offensichtlich nicht gültig ist.
  }
\end{enumerate}

% 2006-06-07

\begin{satz}[Regel C]\label{satz-regel-c}
  Sei $\alpha$ eine Formel und $\Gamma$ eine Menge von Hypothesen. Falls
  $\alpha$ aus $\Gamma$ mit Benutzung der Regel~C unter Berücksichtigung der
  drei Einschränkungen beweisbar ist, dann ist $\alpha$ auch ohne
  Benutzung von Regel~C aus $\Gamma$ beweisbar. ($\Gamma\vdash\alpha$)
\end{satz}

\section{Vollständigkeit des Prädikatenkalküls
  1.~Ordnung}

Wir wollen zeigen, dass in jedem \emph{Prädikatenkalkül 1.~Ordnung}
alle gültigen Formeln beweisbar sind
(d.\,h. aus $\models \alpha$ folgt $\vdash\alpha$).
Diese Eigenschaft des Prädikatenkalküls nennt man
\emph[index=Vollständigkeit!des Prädikatenk. 1.~Ord.]{Vollständigkeit}.
Wir zeigen äquivalent,
dass jede nicht beweisbare Formel auch nicht gültig ist.
Dazu müssen wir für jede nicht beweisbare Formel $\alpha$
eine Interpretation finden, unter der $\alpha$ falsch ist.
Die Konstruktion dieser Interpretation basiert auf einer
Erweiterung des Prädikatenkalküls durch zusätzliche Axiome.
Im ersten Schritt werden Axiome hinzugenommen, so dass
für jede geschlossene Formel $\alpha$
entweder $\alpha$ oder $\neg \alpha$ beweisbar ist.
Eine Theorie mit dieser Eigenschaft heißt
\emph[index=abgeschlossene Theorie]{abgeschlossen}.
Da die zusätzlichen Axiome nicht notwendigerweise gültig sind,
sind nicht alle Modelle des Prädikatenkalküls auch Modelle
dieser Erweiterung. Wichtig ist jedoch nur, dass am Ende
(mindestens) ein Modell übrig bleibt.
Im zweiten Schritt werden Axiome hinzugenommen,
die die einfache Konstruktion eines Modells für die Theorie ermöglichen.
Diese Axiome machen die Theorie \emph{T-produktiv}.
Die Vollständigkeit jedes Prädikatenkalküls 1.~Ordnung
basiert also darauf, dass man ihn zu einer abgeschlossenen
und T-produktiven Theorie erweitern kann, die ein Modell besitzt
(\autoref{lemma-abz-modelle}).


Die Auswahl der zusätzlichen Axiome basiert darauf,
dass man die Menge aller Formeln abzählen kann.


\subsection{Abzählbarkeit von Formelmengen}
\label{sec-abzaehlbarkeit}

\begin{defini}
  Eine unendliche Menge $A$ heißt \emph{abzählbar unendlich}, falls es
  eine bijektive Funktion $f\colon A\rightarrow \N$ gibt.
\end{defini}

\begin{bsp}
  Die Menge $\N$ ist trivialer Weise abzählbar mit $f=\operatorname{id}$.

  Die Menge $\Z$ ist abzählbar, da die Funktion $f\colon \Z\rightarrow\N$
  eine Bijektion ist.
  \begin{gather*}
    f(m) = \begin{cases}2m-1 & m > 0\\ 2m & m\leq 0\end{cases}
  \end{gather*}

  Die Menge $\N\times\N$ ist abzählbar mittesl der folgenden bijektiven Funktion
  $bp\colon \N\times\N \rightarrow \N$.
  \begin{gather*}
    bp(a,b) = \Big(\sum_{d=0}^{a+b} d\Big)+b
  \end{gather*}

  Die Menge der reellen Zahlen $\R$
  und die Potenzmenge der natürlichen Zahlen $\mathfrak{P}(\N)$ sind nicht
  abzählbar.
\end{bsp}

\begin{lemma}
  Wenn $f\colon A\rightarrow\N$ injektiv ist, dann ist $A$ \emph{abzählbar
  unendlich}.

  Wenn $A\subseteq B$ und $B$ ist abzählbar, dann ist $A$ abzählbar.
\end{lemma}

\begin{satz}
  Die Menge aller Formeln einer Theorie 1.~Ordnung ist abzählbar.

  \begin{proof}
    Wir definieren eine Funktion $g^{\ast}$, die die Menge aller Formeln
    injektiv auf $\N$ abbildet.
    Dazu definieren wir zuerst eine Funktion $g$, die jedes Symbol,
    das in einer Formel vorkommen kann, durch eine natürliche Zahl kodiert.
    Formeln bestehen aus folgenden Symbolen:
    \begin{description}
     \item[Variablensymbole:] $x_{1}, x_{2}, x_{3},\dotsc$ (abzählbar
      viele)
     \item[Konstantensymbole:] $a_{1},a_{2},a_{3},\dotsc$ (abzählbar
      viele)
     \item[Funktionssymbole:] $f_{1}^{1}, f_{2}^{1},\dotsc, f_{1}^{2},
      f_{2}^{2}$ (abzählbar viele)
     \item[Prädikatensymbole:] $A_{1}^{1}, A_{2}^{1},\dotsc,A_{1}^{2},
      A_{2}^{2}$ (abzählbar viele)
     \item[sonstige Zeichen:] $(, ), \forall, \neg, \rightarrow, ,$ (Komma)
    \end{description}

    Die Funktion $g\colon \text{Menge aller
    Symbole}\rightarrow\N$ ist wie folgt definiert:

    \begin{tabular}{r|*{6}{|c}|}
      $u$ & $($ & $)$ & $,$ & $\neg$ & $\rightarrow$ & $\forall$ \\ \hline
      $g(u)$ & 1 & 2 & 3 & 4 & 5 & 6
    \end{tabular}

    \begin{tabular}{r|*{4}{|c}|}
      $u$ & $x_{i}$ & $a_{i}$ & $f_{i}^{j}$ & $A_{i}^{j}$\\ \hline
      $g(u)$ & $3+4i$ & $4+4i$ & $9+4\cdot bp(j-1,i-1)$
         & $10+ 4\cdot bp(j-1,i-1)$
    \end{tabular}

    Die Funktion $g$ ist injektiv (man kann aus einer Zahl $g(u)$ eindeutig
    das Symbol $u$ bestimmen), aber nicht surjektiv (ist auch nicht nötig).
    Folgende Tabbelle zeigt die Kodierung einiger Symbole.

    \begin{tabular}{c*{9}{|c}}
      $u$ & $x_{1}$ & $a_{1}$ & $f_{1}^{1}$ & $A_{1}^{1}$ & $x_{2}$ &
         $a_{2}$ & $f_{1}^{2}$ & $A_{1}^{2}$ & \ldots{}\\ \hline
      $g(u)$ & 7 & 8 & 9 & 10 & 11 & 12 & 13 & 14 & \ldots{}
    \end{tabular}

    Die Funktion
    \begin{gather*}
      g^{\ast}\colon\text{Menge aller Formeln}\rightarrow\N
    \end{gather*}
    ist definiert durch
    \begin{gather*}
      g^{\ast}(u_{1}u_{2}\dotso
            u_{k}) = 2^{g(u_{1})}\cdot 3^{g(u_{2})}\cdot 5^{g(u_{3})}\dotsm
             p_{k}^{g(u_{k})} ,
    \end{gather*}
    wobei $p_{k}$ die $k$-te Primzahl ist ($p_1=2$).

    Da verschiedene Formeln aus verschiedenen Folgen von Symbolen bestehen
    und jede natürliche Zahl $\geq 1$ eindeutig als Produkt von Primzahlen
    dargestellt werden kann, ist $g^{\ast}$ eine injektive Funktion.
    Der Wertebereich von $g^{\ast}$ ist $\N$.
    Also ist der Definitionsbereich von $g^{\ast}$ -- das ist die Menge
    aller Formeln -- abzählbar.
  \end{proof}
\end{satz}

    Bsp.:
    \begin{gather*}
      g^{\ast}(A_{1}^{1}(x_{1})\rightarrow A_{2}^{1}(f_{1}^{1}(a_{2}))) =
         2^{10}\cdot 3^{1}\cdot 5^{7}\cdot 7^{2}\cdot 11^{5}\cdot 13^{5}
    \end{gather*}
    $g^{\ast}$ ist nicht surjektiv, da z.\,B. die Zahl $2^3\cdot 3^4$
    für die Symbolfolge "`$,\neg$"' steht, die aber keine Formel ist.
    $g^{\ast}$ definiert auf natürliche Weise eine Ordnung auf den Formeln.
    Wir sagen $\alpha<\beta$, falls $g^{\ast}(\alpha)<g^{\ast}(\beta)$.
    Damit können wir eine Funktion
    \begin{gather*}
        f\colon\N\rightarrow\text{Menge aller Formeln}
    \end{gather*}
    definieren, die die Menge aller Formeln geordnet aufzählt, d.\,h.
    \begin{gather*}
      \{f(i) \mid i\in \N\} = \text{Menge aller Formeln und $f(i)<f(i+1)$}.
    \end{gather*}
    $f$ kann wie folgt definiert werden:
    \begin{align*}
       f(0) & = \text{die kleinste Formel} \\
       f(n+1) & = \text{die kleinste Formel, die nicht in $\{f(0),\dotsc,f(n)\}$ ist}
    \end{align*}
Jede Menge von Formeln oder Termen einer Theorie 1.~Ordnung kann ebenfalls
geordnet aufgezählt werden.
Von den folgenden Mengen werden wir diese Eigenschaft noch nutzen.
\begin{itemize}
 \item die Menge aller geschlossenen Formeln
 \item die Menge aller variablenfreien Terme
 \item die Menge aller T-produktiven Formeln
\end{itemize}


\subsection{Konsistente und abgeschlossene Erweiterungen Theorien}

Eine Theorie dient dazu, Formeln in beweisbare Formeln (Theoreme)
und nicht beweisbare Formeln zu teilen.
Eine Theorie, in der sowohl eine Formel $\alpha$
als auch ihre Negation $\neg \alpha$ bewiesen werden kann,
ist insofern sinnlos, da in dieser Theorie alle Formeln Theoreme sind
(siehe \autoref{bemerk-nichtkonsistenz}).
Die \glqq{}nicht sinnlosen\grqq{} Theorien heißen \textit{konsistent}
(siehe \autoref{defini-konsistent}).
In diesem Abschnitt geht es darum,
wie man eine konsistente Theorie erweitern kann (durch zusätzliche Axiome),
so dass sie konsistent bleibt und die zusätzliche Eigenschaft
der Abgeschlossenheit erhält
(Lindenbaums Lemma (\autoref{lemma-lindenbaum})).
Eine Theorie heißt abgeschlossen (siehe \autoref{defini-abgeschlossene-Theorie}),
falls für jede geschlossene Formel $\alpha$ entweder $\alpha$
oder $\neg \alpha$ beweisbar ist.
In einer konsistenten und abgeschlossenen Theorie
ist die Menge der Theoreme maximal:
nimmt man zu ihr eine nicht beweisbare Formel als Axiom hinzu,
dann wird die Theorie nicht konsistent.
(Siehe \autoref{figure-abgeschlossene-Erweiterung}.)


\begin{figure}[t]
  \centering
  \includegraphics{resolution.11}
  \caption{Die Theoreme eines Prädikatenkalküls (dunkel gefärbter Bereich),
  die Theoreme einer konsistenten und abgeschlossenen Erweiterung davon
  (dunkel und weniger dunkel gefärbte Bereiche) und
  die in der abgeschlossenen Erweiterung unbeweisbaren Formeln (weißer Hintergrund)}
  \label{figure-abgeschlossene-Erweiterung}
\end{figure}

\begin{defini}[konsistente Theorie]\label{defini-konsistent}
  Eine Theorie $K$ heißt \emph{konsistent}, falls es keine
  Formel $\alpha$ gibt mit $\xvdash{K}\alpha$ und $\xvdash{K}\neg\alpha$.
\end{defini}

\begin{lemma}\label{lemma-KonsistenzPK}
  Jeder Prädikatenkalkül 1.~Ordnung ist konsistent.

  \begin{proof}
    Aus $\xvdash{K}\alpha$ folgt $\models\alpha$
    (\autoref{satz-korrektheit-theorien-1.ordnung}). Da höchstens eine der
    Formeln $\alpha$ und $\neg\alpha$ gültig ist, muss $K$ konsistent sein.
  \end{proof}
\end{lemma}

\begin{bemerk}\label{bemerk-nichtkonsistenz}
  Wenn $K$ eine nicht konsistente Theorie ist, dann kann man jede
  beliebige Formel $\alpha$ beweisen: $\xvdash{K}\alpha$.

  \begin{proof}
    Sei $K$ eine nicht konsistente Theorie. Dann gibt es eine Formel
    $\beta$ mit $\xvdash{K}\beta$ und $\xvdash{K}\neg\beta$. Mit der
    Instanz der Tautologie $\xvdash{K}\beta \rightarrow (\neg\beta
    \rightarrow\alpha)$ und zweimal modus ponens folgt $\xvdash{K}\alpha$.
  \end{proof}
\end{bemerk}

Wenn eine Theorie ein Modell besitzt, muss sie also konsistent sein:
keine Interpretation kann gleichzeitig $\alpha$ und $\neg\alpha$ erfüllen.
Wir werden sehen, dass jede konsistente Theorie
auch ein Modell besitzt.
Dazu müssen wir uns zunächst mit dem konsistenten Erweitern von Theorien beschäftigen.

Wenn $\alpha$ gültig ist, dann ist $\neg \alpha$
nicht gültig und nicht beweisbar in $K$.
Die Nichtbeweisbarkeit von $\neg \alpha$ reicht aus,
um die Konsistenz der um Axiom $\alpha$ erweiterten Theorie zu beweisen.


\begin{lemma}\label{lemma-kons-erweiterung}
  Sei $K$ eine konsistente Theorie,
  und $\alpha$ sei eine geschlossene Formel.
  $K'$ sei die Theorie, die aus $K$ durch Hinzufügen des
  zusätzlichen Axioms $\alpha$ entsteht.
  Dann gilt:

  \centering{%
  wenn $\neg \alpha$ in $K$ nicht beweisbar ist (d.\,h. $\not\xvdash{K} \neg \alpha$),
  dann ist $K'$ konsistent.
  }
\end{lemma}

\begin{proof}
  Wir beweisen das Lemma, indem wir zeigen:
  wenn $K'$ nicht konsistent ist, dann gilt $\xvdash{K} \neg \alpha$.

  Sei also $K'$ nicht konsistent.
  Dann gibt es eine Formel $\beta$
  mit $\xvdash{K'} \beta$ und $\xvdash{K'} \neg\beta$.
  Die Formel $\beta\rightarrow(\neg \beta \rightarrow \neg \alpha)$
  ist Instanz einer Tautologie und deshalb in $K'$ beweisbar.
  Durch Anwendung von modus ponens erhält man
  aus den letzten drei Formeln
  $\xvdash{K'} \neg \alpha$.

  Da das zusätzliche Axiom $\alpha$ der einzige Unterschied
  zwischen $K$ und $K'$ ist,
  ist der Beweis für $\neg \alpha$ in $K'$
  auch ein Beweis in $K$ mit Hypothese $\alpha$,
  d.\,h. $\alpha \xvdash{K} \neg \alpha$.
  Da $\alpha$ geschlossen ist,
  kann das Deduktionstheorem angewendet werden,
  und man erhält $\xvdash{K} \alpha \rightarrow \neg \alpha$.
  Die Formel $(\alpha \rightarrow \neg \alpha) \rightarrow \neg \alpha$
  ist Instanz einer Tautologie
  und deshalb in $K$ beweisbar.
  Mit modus ponens folgt aus den letzten beiden Formeln
  $\xvdash{K} \neg \alpha$.
\end{proof}

Die Menge aller Theoreme in $K'$ ist eine
Obermenge der Menge aller Theoreme in $K$,
da jedes Axiom von $K$ ebenfalls ein Axiom von $K'$ ist.

\begin{defini}
  Eine Theorie $K'$ ist eine \emph{Erweiterung} von $K$,
  falls jedes Theorem von $K$ ebenfalls ein Theorem von $K'$ ist
  (d.\,h. aus $\xvdash{K} \alpha$ folgt $\xvdash{K'} \alpha$).
\end{defini}

Wenn -- wie oben -- $K'$ aus $K$ durch Hinzunahme
des zusätzlichen Axioms $\alpha$ entsteht,
dann schreiben wir $K' = K + \{\alpha\}$.

Wenn weder $\alpha$ noch $\neg \alpha$ gültig ist,
dann bleibt eine konsistente Theorie $K$ nach Hinzunahme von Axiom $\alpha$
konsistent.
Also kann von jeder abgeschlossenen Formel $\alpha$
stets eine der beiden Formeln $\alpha$ und $\neg \alpha$
ein Axiom sein.
Falls eine der beiden Formeln beweisbar ist, muss man
natürlich die beweisbare Formel auswählen.

\begin{defini}[abgeschlossene Theorie]\label{defini-abgeschlossene-Theorie}
  Eine Theorie $K$ heißt \emph{abgeschlossen},
  falls für jede geschlossene Formel $\alpha$ (von $K$)
  gilt: $\xvdash{K} \alpha$ oder $\xvdash{K} \neg \alpha$.
\end{defini}

In einer konsistenten und abgeschlossenen Theorie
gilt dann für jede geschlossene Formel $\alpha$:
entweder $\vdash \alpha$ oder $\vdash \neg \alpha$ (aber nicht beides).
Solche Theorien gibt es,
und jede konsistente Theorie lässt sich dazu erweitern.

\begin{satz}[Lindenbaums Lemma]\label{lemma-lindenbaum}
  Für jede konsistente Theorie $K$
  gibt es eine konsistente und abgeschlossene Erweiterung $K'$.
  (Dabei haben $K$ und $K'$ die gleichen Formeln.)
\end{satz}

\begin{proof}
  Sei $K$ eine konsistente Theorie.
  $\beta_1, \beta_2, \dotsc$ sei eine
  Aufzählung aller geschlossenen Formeln von $K$.
  Wir definieren induktiv Theorien $J_0, J_1, J_2, \dotsc$,
  die Erweiterungen von $K$ sind.
  \begin{enumerate}
   \item $J_0=K$
   \item $J_{i+1} = \begin{cases}
     J_i, & \text{falls $\xvdash{J_i} \neg \beta_{i+1}$} \\
     J_i + \{\beta_{i+1}\}, &\text{falls $\not\xvdash{J_i} \neg \beta_{i+1}$}
   \end{cases}
    $
  \end{enumerate}
  Für $J_i$ gilt also:
  $\xvdash{J_i} \neg \beta_i$ (da $\xvdash{J_{i-1}} \neg \beta_{i}$)
  oder
  $\xvdash{J_i} \beta_i$ (da $\not\xvdash{J_{i-1}} \neg \beta_{i}$
  und $\beta_i$ Axiom von $J_i$ ist).

  Nach \autoref{lemma-kons-erweiterung} ist jedes $J_i$ konsistent.

  Definiere $K'$ als die Theorie, die alle Axiome aller $J_i$ enthält.
  Also ist $K'$ eine Erweiterung aller $J_i$
  und damit auch eine Erweiterung von $K=J_0$.

  Jeder Beweis in $K'$ ist endlich
  und kann deshalb nur eine endliche Anzahl von Axiomen enthalten.
  Also kann jeder Beweis auch in einer \glqq{}Untertheorie\grqq{} $J_i$
  geführt werden.
  Da alle $J_i$ konsistent sind, muss $K'$ ebenfalls konsistent sein.

  $K'$ ist abgeschlossen:
  sei $\alpha$ eine geschlossene Formel.
  Dann gibt es ein $i$ mit $\alpha=\beta_i$.
  Nach obiger Bemerkung gilt $\xvdash{J_i} \neg \beta_i$
  oder $\xvdash{J_i} \beta_i$.
  Da $K'$ eine Erweiterung von $J_i$ ist,
  folgt $\xvdash{K} \neg \beta_i$ oder $\xvdash{K} \beta_i$.
\end{proof}


% 2006-06-14

\subsection{Modelle für konsistente Theorien}

In einer konsistenten und abgeschlossenen Theorie können
Formeln bewiesen werden, die nicht gültig sind.
Solche Formeln sind nicht in jeder Interpretation wahr.
Deshalb stellt sich die Frage, ob solche Theorien
überhaupt noch Modelle\footnote{Ein Modell für eine Theorie ist eine Interpretation,
unter der alle Axiome der Theorie wahr sind.
Daraus folgt, dass unter dieser Interpretation ebenfalls
alle beweisbaren Formeln wahr sind.}
besitzen.
Um möglichst einfach ein Modell konstruieren zu können,
erweitern wir die Theorie um zusätzliche Axiome,
die zusätzliche Konstantensymbole enthalten,
und halten die Theorie konsistent
(siehe \autoref{figure-Tproduktive-Erweiterung}).
Die zusätzlichen Konstantensymbole spielen die entscheidende Rolle
bei der Konstruktion eines Modells.
In \autoref{lemma-abz-modelle} wird gezeigt,
dass jede konsistente und abgeschlossene Theorie ein Modell besitzt.
Interessant ist auch, dass dieses Modell eine
abzählbare Grundmenge hat (Satz von Löwenheim und Skolem, \autoref{satz-löwe-skolem}).

\begin{figure}[t]
  \centering
  \includegraphics{resolution.12}
  \caption{Die Formeln eines Prädikatenkalküls (innerhalb des Ovals)
  und die Formeln einer Erweiterung davon durch Einführung neuer Konstantensymbole (Rechteck).
  Da die Erweiterung abgeschlossen ist, sind alle Formeln im eingefärbten Bereich Theoreme
  der Erweiterung.
  Die Theoreme des ursprünglichen Prädikatenkalküls sind im dunkel
  eingefärbten Bereich.}
  \label{figure-Tproduktive-Erweiterung}
\end{figure}


\begin{defini}[T-produktive Theorie]
  Eine Theorie $K$ heißt \emph{T-produktiv} (\glqq{}scape goat\grqq{}, engl. Sündenbock),
  falls für jede Formel $\alpha$ mit genau einer freien Variablen $x$ ein
  variablenfreier Term $t$ existiert mit
  \begin{gather*}
    \xvdash{K} (\exists x ~ \neg\alpha) \rightarrow \neg\alpha[x/t]
  \end{gather*}
\end{defini}

\begin{lemma}\label{lem:8}
  Jede konsistente Theorie $K$ hat eine konsistente Erweiterung $K'$, die
  T-produktiv ist und die Menge aller Terme in $K'$ ist abzählbar.

  \begin{proof}
    $K'$ entsteht aus $K$ durch Hinzufügen von neuen Konstantensymbolen
    $\{c_{1},c_{2},\dotsc\}$ und durch Hinzufügen neuer zusätzlicher
    Axiome wie folgt. Sei $\alpha_{1},\alpha_{2},\dotsc$ eine Aufzählung
    aller Formeln in $K'$ mit genau einer freien Variablen; $\alpha_{i}$
    enthalte die Variablen $x_{j_{i}}$ frei. Sei $b_{1},b_{2},\dotsc$
    eine Aufzählung einer Teilmenge von $\{c_{1},c_{2},\dotsc\}$ so, dass
    $b_{i}$ weder in $\alpha_{1},\dotsc,\alpha_{i-1}$ nicht in
    $b_{1},\dotsc,b_{i-1}$ vorkommt.

    Definiere $\sigma_{k}=(\exists x_{j_{k}} ~ \neg\alpha)
    \rightarrow\neg\alpha[x_{j_{k}}/b_{k}]$. $K'$ hat zusätzliche Axiome
    $\sigma_{1},\sigma_{2},\dotsc$.

    Um zu zeigen, dass $K'$ konsistent ist, betrachten wir die Teiltheorien
    $K_{0},K_{1},K_{2},\dotsc$ mit
    \begin{align*}
      K_{0} &= K \text{~erweitert um die neuen Konstantensmbole~}
         \{c_{1},c_{2},\dotsc\}\\
      K_{i+1} &= K_{i} \text{~erweitert um zusätzliches Axiom~} \sigma_{i+1}
    \end{align*}
    ($K_{j}$ hat die zusätzlichen Axiome $\sigma_{1},\sigma_{2},\dotsc,
    \sigma_{j}$).

    Wenn $K_{0},K_{1},K_{2},\dotsc$ konsistent sind, dann ist auch $K'$
    konsistent.
    \begin{itemize}
     \item $K_{0}$ ist konsistent, da $K$ konsistent ist.
     \item Sei angenommen, dass $K_{n}$ nicht konsistent ist.
      Dann gilt $\xvdash{K_{n}}\neg\sigma_{n}$.
      Also folgt $\sigma_{n} \xvdash{K_{n-1}}\neg\sigma_{n}$.
      Mit dem Deduktionstheorem folgt
      $\xvdash{K_{n-1}}\sigma_{n}\rightarrow\neg\sigma_{n}$ und mit der
      Tautologie $(\sigma_{n}\rightarrow\neg\sigma_{n})\rightarrow
      \neg\sigma_{n}$ folgt $\xvdash{K_{n-1}}\neg\sigma_{n}$, d.\,h.
      \begin{gather*}
        \xvdash{K_{n-1}}\neg(\exists x_{j_{n}} ~ \neg\alpha)
           \rightarrow \neg\alpha[x_{j_{n}}/b_{n}]
      \end{gather*}

      Mit der Implikationsregel folgt
      \begin{gather*}
        \xvdash{K_{n-1}} (\exists x_{j_{n}} ~
           \neg\alpha)\quad\text{und}\quad
           \xvdash{K_{n-1}} \neg\neg\alpha[x_{j_{n}}/b_{n}] ,
      \end{gather*}
      und mit der Negationsregel $\xvdash{K_{n-1}} \alpha[x_{j_{n}}/b_{n}]$.

      Das $b_{n}$ kommt in keinem zusätzlichen Axiom von $K_{n-1}$ vor.
      Deshalb kann es im Beweis von $\xvdash{K_{n-1}}
      \alpha[x_{j_{n}}/b_{n}]$ durch eine Variable $x'$ ersetzt werden,
      die im Beweis sonst nicht vorkommt, und wir erhalten
      $\xvdash{K_{n-1}}\alpha[x_{j_{n}}/x']$.

      Nach der Aufgabe 3 auf \hyperref[sec:uebung8]{Blatt~\ref*{sec:uebung8}} gilt
      $\xvdash{K_{n-1}}(\forall x_{j_{n}} ~ \alpha) \leftrightarrow
      (\forall x' ~ \alpha[x_{j_{n}}/x']$). Aus $\xvdash{K_{n-1}}
      \alpha[x_{j_{n}}/x']$ folgt mit Generalisierung $\xvdash{K_{n-1}}
      (\forall x' ~ \alpha[x_{j_{n}}/x'])$.

      Mit Äquivalenzregel folgt $\xvdash{K_{n-1}}(\forall x_{j_{n}} ~
      \alpha)$. Aus $\xvdash{K_{n-1}} (\exists x_{j_{n}} ~
      \neg\alpha)$ folgt $\xvdash{K_{n-1}} \neg(\forall x_{j_{n}} ~
      \alpha)$. Also ist $K_{n-1}$ nicht konsistent.
    \end{itemize}
  \end{proof}
\end{lemma}

\begin{satz}[Abzählbare Modelle]\label{lemma-abz-modelle}
  Jede konsistente, abgeschlossene und T-produktive Theorie $J$ besitzt
  ein Modell $\mathcal{M}$, dessen Grundmenge die Menge aller
  variablenfreien Terme von $J$ ist.

  \begin{proof}
    Definiere $\cM$ wie folgt.
    \begin{itemize}
     \item Die Grundmenge $D$ besteht aus allen variablenfreien Termen,
      die in $J$ gebildet werden können.
     \item Konstanten- und Funktionssymbole werden \glqq{}durch sich selbst\grqq{}
      interpretiert:
      \begin{align*}
        (a_i)^{\cM} & = a_i \\
        (f^n_i)^{\cM}(t_1,\dotsc,t_n) & = f^n_i(t_1,\dotsc,t_n)
      \end{align*}
     \item Prädikatensymbole werden durch Beweisbarkeit interpretiert:
      \begin{gather*}
        (A^n_i)^{\cM}  =  \big\{(t_1,\dotsc,t_n)\in D^n \bigm|
           ~ \xvdash{J} A^n_i(t_1,\dotsc,t_n)\big\} \\
      \end{gather*}
    \end{itemize}
    Wir zeigen, dass $\cM$ ein Modell von $J$ ist.
    Dazu zeigen wir, dass für jede \textit{geschlossene} Formel $\alpha$ gilt:
    aus $\Mmodels \alpha$ folgt $\xvdash{J} \alpha$.
    (Eine nicht geschlossene Formel $\beta$ und deren Abschluss $\beta'$
     haben die gleichen Eigenschaften in Bezug auf Gültigkeit und Beweisbarkeit.
     Für jede Formel $\beta$ und deren Abschluss $\beta'$ gilt
    (1) $\Mmodels \beta$ gdw. $\Mmodels \beta'$ (wg. (E6)) und
    (2) $\xvdash{J} \beta$ gdw. $\xvdash{J} \beta'$ (wg. Gen und (RA4).)
    Der Beweis wird mittels Induktion über den Formelaufbau geführt,
    d.\,h. über die Anzahl der in der Formel vorkommenden Verknüpfungszeichen.

    Im Induktionsanfang betrachten wir geschlossene atomare Formeln $\alpha$
    ohne Verknüpfungszeichen -- also ohne Quantoren.
    Diese Formeln enthalten keine Variablensymbole.
    Es folgt direkt aus der Definition der Interpretation der
    Prädikatensymbole, dass $\Mmodels \alpha$ gdw. $\xvdash{J} \alpha$.

    Die Induktionsvoraussetzung lautet, dass die Behauptung für alle geschlossenen Formeln
    bis zu einer bestimmten Größe gilt.

    Im Induktionsschritt betrachten wir die drei Möglichkeiten,
    aus zwei Formeln $\alpha$ und $\beta$ eine Formel $\gamma$ mit einem zusätzlichen
    Verknüpfungszeichen zu konstruieren:
    (1) $\gamma = (\neg \alpha)$, (2) $\gamma=(\alpha\rightarrow\beta)$
    und (3) $\gamma = (\forall y~ \alpha)$.

    \textbf{Fall (1): $\gamma = (\neg \alpha)$.}

    Es gilt
    \begin{gather*}
      \Mmodels \gamma ~ \Leftrightarrow_{(1)} ~
         \not\Mmodels \alpha
         ~ \Leftrightarrow_{(2)} ~
         \not\xvdash{J} \alpha
         ~ \Leftrightarrow_{(3)} ~
         \xvdash{J} (\neg \alpha)
         ~ \Leftrightarrow_{(4)} ~
         \xvdash{J} \gamma
    \end{gather*}
    Äquivalenz (1) folgt aus $\gamma = (\neg \alpha)$,
    (2) folgt aus der Induktionsvoraussetzung,
    (3) folgt aus der Abgeschlossenheit von $J$,
    und (4) folgt wiederum aus $\gamma = (\neg \alpha)$.

    \textbf{Fall (2): $\gamma = (\alpha\rightarrow \beta)$.}

    Es gilt
    \begin{gather*}
      \not\Mmodels \gamma
         ~ \Leftrightarrow_{(1)} ~
         \Mmodels \alpha \text{~und~} \not\Mmodels \beta
         ~ \Leftrightarrow_{(2)} ~
         \xvdash{J} \alpha \text{~und~} \not\xvdash{J} \beta
         ~ \Leftrightarrow_{(3)} ~
         \xvdash{J} (\neg \gamma)
         ~ \Leftrightarrow_{(4)} ~
         \not\xvdash{J} \gamma
    \end{gather*}

    Die Äquivalenzen (1), (2) und (4) sind einfach.
    (1) ist Eigenschaft (E4) der grundlegenden Eigenschaften
    von Formeln und Interpretationen,
    (2) folgt aus der Induktionsvoraussetzung,
    und (4)  folgt aus der Abgeschlossenheit von $J$.

    Für Äquivalenz (3) betrachten wir beide Richtungen getrennt.
    Aus ~$\xvdash{J} \alpha \text{~und~} \not\xvdash{J} \beta$~
    folgt zuerst $\xvdash{J} \neg\beta$ aus der Abgeschlossenheit von $J$.
    Mit der Tautologie $\alpha\rightarrow(\neg \beta \rightarrow\neg(\alpha\rightarrow\beta))$
    und modus ponens ergibt sich $\xvdash{J} \neg(\alpha\rightarrow\beta)$,
    also $\xvdash{J} (\neg \gamma)$.

    Die andere Implikation  ~
    $\xvdash{J} \neg(\alpha\rightarrow\beta) \Rightarrow
    \xvdash{J} \alpha \text{~und~} \not\xvdash{J} \beta$
    ~
    folgt direkt aus der Implikationsregel.

    \textbf{Fall (3): $\gamma = (\forall y ~\alpha)$.}

    Das ist der etwas schwierigere Fall.

    Zuerst betrachten wir den Fall, dass $\alpha$ geschlossen ist.
    Dann gilt
    \begin{gather*}
      \Mmodels (\forall y~\alpha)
         ~ \Leftrightarrow_{(1)} ~
         \Mmodels \alpha
         ~ \Leftrightarrow_{(2)} ~
         \xvdash{J} \alpha
         ~ \Leftrightarrow_{(3)} ~
         \xvdash{J} (\forall y ~\alpha)
    \end{gather*}
    Äquivalenz (1) ist die grundlegende Eigenschaft (E6) von Formeln
    und Interpretationen.
    Äquivalenz (2) folgt aus der Induktionsvoraussetzung,
    da $\alpha$ eine geschlossene Formel ist.
    Äquivalenz (3) folgt aus der Generalisierung bzw. Axiom (A4),
    da $\alpha[y/t]=\alpha$ ($y$ kommt in $\alpha$ nicht frei vor).

    Nun zum Fall, dass $\alpha$ keine geschlossene Formel ist.
    Dann ist $y$ die einzige freie Variable in $\alpha$.
    Also ist $\neg(\forall y~\alpha) \rightarrow \neg\alpha[y/b_i]$
    ein Axiom von $J$.
    Es gelten folgende Äquivalenzen.
    \begin{align*}
      \Mmodels (\forall y ~ \alpha)
      & \Leftrightarrow_{(1)}
      \text{für jede Variablenbelegung $s\in\Sigma_{\cM}$ gilt: $s$ erfüllt $\alpha$} \\
      & \Leftrightarrow_{(2)}
      \text{für jeden variablenfreien Term $t$ gilt:~} \Mmodels \alpha[y/t] \\
      & \Leftrightarrow_{(3)}
      \text{für jeden variablenfreien Term $t$ gilt:~} \xvdash{J} \alpha[y/t]
    \end{align*}
    Äquivalenz (3) folgt aus der Induktionsvoraussetzung.
    Äquivalenz (1) folgt aus der semantischen Definition des Allquantors.
    Äquivalenz (2) folgt aus der Definition von $\cM$.
    Für Variablenbelegung $s$ ist $s(y)\in D$.
    Da variablenfreie Terme durch sich selbst interpretiert werden,
    gilt: $s$ erfüllt $\alpha$ genau dann, wenn $\Mmodels \alpha[y/s(y)]$.
    Da $\{ s(y) \mid s\in\Sigma_{\cM} \} = D$
    und $D$ die Menge aller variablenfreien Treme ist, folgt (2).

    Es bleibt noch folgende Äquivalenz ($\star$) zu zeigen:
    \begin{gather*}
      \text{für jeden variablenfreien Term $t$ gilt~} \xvdash{J} \alpha[y/t]
         ~ ~ \Leftrightarrow ~ ~
         \xvdash{J} (\forall y ~ \alpha)
    \end{gather*}
    Wir zeigen die beiden Implikationsrichtungen von ($\star$) getrennt.

    Aus $\xvdash{J} (\forall y~ \alpha)$ folgt
    $\xvdash{J} \alpha[y/t]$ für jeden variablenfreien Term $t$
    mittels Axiom A4 und modus ponens.

    Die andere Implikationsrichtung zerlegen wir in folgende Teile.

    $
    \begin{array}{cclc}
      \multicolumn{3}{l}{\text{für jeden variablenfreien Term $t$ gilt:~} \xvdash{J} \alpha[y/t]} & (1) \\
      \rule{20mm}{0mm} & \Rightarrow &
      \text{für jeden variablenfreien Term $t$ gilt:~} \not\xvdash{J} \neg\alpha[y/t] & (2) \\
      & \Rightarrow &
      \text{für jedes Konstantensymbol $a_j$ gilt:~} \not\xvdash{J} \neg\alpha[y/a_j] & (3) \\
      & \Rightarrow & \not\xvdash{J} \neg(\forall y ~ \alpha) & (4) \\
      & \Rightarrow & \xvdash{J} (\forall y ~ \alpha) & (5)
    \end{array}
    $

    Aus (1) folgt (2) wg.~der Konsistenz von $J$.
    Aus (2) folgt (3), da jedes Konstantensymbol ein variablenfreier Term ist.
    Aus dem Axiom
    $\neg(\forall y~\alpha) \rightarrow \neg\alpha[y/a_i]$
    und $\xvdash{J} \neg(\forall y ~ \alpha)$ folgt $\xvdash{J} \neg\alpha[y/a_i]$.
    Also folgt die Negation von (3) aus der Negation von (4).
    Damit folgt (4) aus (3).
    Die Abgeschlossenheit von $J$ führt schließlich zu (5).

    Damit ist ($\star$) bewiesen und der Beweis des Lemmas abgeschlossen.
  \end{proof}
\end{satz}

Aus \autoref{lemma-abz-modelle} folgt sofort:
\begin{satz}[Satz von Löwenheim und Skolem]\label{satz-löwe-skolem}
Jede Theorie, die ein Modell besitzt, besitzt ein
Modell mit einer abzählbaren Grundmenge.
\end{satz}

\subsection{Der Vollständigkeitssatz von Gödel}

Aus den Lemmata und Sätzen der letzten Abschnitte folgt,
dass alle gültigen Formeln in einem  Prädikatenkalkül 1.~Ordnung
auch tatsächlich bewiesen werden können.

\begin{satz}[Vollständigkeitssatz von Gödel]\label{satz-vollstPK}
  Sei $K$ ein Prädikatenkalkül 1.~Ordnung. Dann ist jede gültige Formel
  in $K$ beweisbar, d.\,h. für jede Formel $\alpha$ von $K$ gilt: aus
  $\models\alpha$ folgt $\xvdash{K}\alpha$.

  \begin{proof}
    Sei $\beta$ eine Formel, die nicht in $K$ beweisbar ist
    ($\not\xvdash{K}\beta$).
    $\beta$ ist beweisbar in $K$ genau dann, wenn der Abschluss von $\beta$
     in $K$ beweisbar ist.
    Sei $\alpha$ der Abschluss von $\beta$.
    Erweitere $K$ zu $K'$ durch Hinzunehmen von $\neg\alpha$ als
    zusätzliches Axiom. Da $K$ konsistent ist (\autoref{lemma-KonsistenzPK}),
    ist $K'$ ebenfalls konsistent (\autoref{lemma-kons-erweiterung}).
    $K$ kann nach \autoref{lem:8} zu einer T-produktiven
    Theorie $K_{T}'$ erweitert werden, die konsistent ist.
    $K_{T}'$ kann zu einer abgeschlossenen Theorie $K^{\ast}$ erweitert werden, die
    konsistent und T-produktiv ist (\autoref{lemma-lindenbaum}).
    $K^{\ast}$ hat ein Modell $\mathcal{M}$ (\autoref{lemma-abz-modelle}).

    Da alle Axiome von $K'$ ebenfalls in $K^{\ast}$
    enhalten sind, ist $\mathcal{M}$ auch ein Modell von $K'$.
    $\neg\alpha$ ist ein Axiom von $K'$. Also gilt $\Mmodels\neg\alpha$.
    Daraus folgt $\not\Mmodels\alpha$, und gemäß (E6) $\not\Mmodels\beta$.
    Folglich gibt es eine Interpretation,
    die kein Modell von $\beta$ ist, d.\,h. $\beta$ ist nicht gültig,
    also $\not\models\beta$.

    Damit haben wir gezeigt: aus $\not\xvdash{K}\beta$ folgt $\not\models\beta$.
  \end{proof}
\end{satz}

Zum Abschluss dieses Kapitels fassen wir
\autoref{satz-vollstPK} und \autoref{satz-korrektheit-theorien-1.ordnung} zusammen.

\begin{korol}[Korrektheit und Vollständigkeit des Prädikatenkalküls 1.~Ordnung]
Sei $K$ ein Prädikatenkalkül 1.~Ordnung.
Dann gilt für jede Formel $\alpha$ von $K$:

{\centering

$\alpha$ ist gültig genau dann, wenn $\alpha$ in $K$ beweisbar ist.

}
\end{korol}

Diese Korrektheit und Vollständigkeit ist genau das, was man
als \glqq{}natürlich\grqq{} annimmt.
Man formuliert ja gerade Axiome und Ableitungsregeln, damit
man Beweise führen kann.
Und man will natürlich alles beweisen können, was wahr ist.
Im nächsten Kapitel werden wir sehen,
dass Vollständigkeit nur in recht \glqq{}kleinen\grqq{} Theorien
garantiert werden kann.
Wir werden eine Erweiterung des Prädikatenkalküls betrachten,
in der man mit natürlichen Zahlen rechnen kann.
Also so etwas wie elementare Zahlentheorie.
Von dieser Theorie kann man zeigen,
dass sie nicht vollständig ist
(Unvollständigkeitssatz von Gödel, \autoref{satz-unvollst}).
Das liegt letztlich daran, dass man in der von der Theorie zur Verfügung gestellten
Sprache Aussagen über die Theorie machen kann.
Jede Erweiterung der elementaren Zahlentheorie
ist ebenfalls nicht vollständig (solange entscheidbar bleibt,
was die Axiome der Theorie sind\footnote{\glqq{}entscheidbar\grqq{}
heißt hier im intuitiven Sinne, dass man von jeder Formel nach endlicher
Zeit zum Überlegen sagen kann, ob sie ein Axiom ist oder nicht}).
Die Welt, in der wir leben, besitzt also keine entscheidbare
Menge von Axiomen, aus der alle Wahrheiten abgeleitet werden können.



% 2006-06-21

\chapter{Formale Zahlentheorie}
\label{chapter-zahlentheorie}

Wir begeben uns nun auf die Zielgerade mit dem Blick auf Gödels
Unvollständigkeitssatz. Im \href{cha:prlogik}{\ref*{cha:prlogik}.~Kapitel} haben
wir uns die Hilfsmittel für die Formalisierung der Zahlentheorie geschaffen.
\todo{weiterschreiben, was kommt denn nun alles?}

Die \emph{Zahlentheorie} befasst sich mit Eigenschaften natürlicher Zahlen.
Die wohl am Häufigsten gebrauchte Beschreibung der natürlichen Zahlen sind die
fünf \emph{Peano-Axiome}:
\begin{enumerate}[(P1)]
 \item $0$ ist eine natürliche Zahl.
 \item Jede natürliche Zahl~$z$ hat genau einen Nachfolger~$z'$, der ebenfalls
  eine natürliche Zahl ist. % ($z'$ steht für $z+1$)
 \item Die Zahl~$0$ ist kein Nachfolger einer natürlichen Zahl;
  $\forall z\in \N\quantsep z'\ne0$.
 \item Jede natürliche Zahl ist Nachfolger höchstens einer natürlichen Zahl;
  $\forall x,y\in\N\quantsep x'=y' \Rightarrow x=y$.
 \item Sei $Q$ eine Eigenschaft von natürlichen Zahlen.
  Wenn
  \begin{enumerate}[1.]
   \item $0$ die Eigenschaft $Q$ besitzt, und
   \item für alle Zahlen~$z$ aus \glqq{}$z$ hat die Eigenschaft $Q$\grqq{}
    folgt \glqq{}$z'$ hat Eigenschaft $Q$\grqq{},
  \end{enumerate}
  dann besitzen alle natürlichen Zahlen die Eigenschaft $Q$. Dieses Prinzip
  wird \emph[index=Induktionsprinzip]{Induktion} genannt;
  $(Q(0)\wedge(\forall z\in\N\quantsep Q(z)\rightarrow Q(z')))\rightarrow
  (\forall z\in\N\quantsep Q(z))$
\end{enumerate}
Man beachte, dass an dieser Stelle die Gleichheitsrelation bereits als bekannt
vorausgesetzt wird.

Die Peano-Axiome vermitteln zwar ein intuitives Verständnis von den
natürlichen Zahlen, dennoch möchte man gerne Axiome formulieren, auf deren
Grundlage man die Sätze der Zahlentheorie formal beweisen kann.

\section{Die Theorie \texorpdfstring{$\ThS$}{S}}

Ausgehend von dem, wie die Peano-Axiomen die natürlichen Zahlen definieren,
wollen wir Axiome einer formalen Theorie 1.~Ordnung für die Zahlentheorie
aufstellen. Diese Theorie nennen wir $\ThS$.

Zu den Axiomen, die von der Theorien 1.~Ordnung (\autoref{def:theo1.ord})
übernommen werden, ergänzen wir in $\ThS$ noch folgende Axiome, wobei $a_{1}$
das einzige Konstantensymbol, $A_{1}^{2}$ das einzige Prädikatensymbol und
$f_{1}^{1}, f_{1}^{2}$ und $f_{2}^{2}$ drei Funktionensybole sind -- auf ihre
Bedeutungen \help{wäre an der Stelle Interpretationen richtig?} kommen wir
gleich zu sprechen. Alle übrigen Symbole -- Variablensymbole $x_1, x_2, \dotsc$,
logische Verknüpfungszeichen, Klammern -- werden ohne Einschränkung übernommen.
\begin{enumerate}[(S1)]
 \item $A_{1}^{2}(x_1, x_2) \rightarrow (A_{1}^{2}(x_1,x_3) \rightarrow
  A_{1}^{2}(x_2,x_3))$
 \item $A_{1}^{2}(x_1, x_2) \rightarrow
  A_{1}^{2}(f_{1}^{1}(x_1), f_{1}^{1}(x_2))$
 \item $\neg A_{1}^{2}(a_{1}, f_{1}^{1}(x_1))$
 \item $A_{1}^{2}(f_{1}^{1}(x_1), f_{1}^{1}(x_2)) \rightarrow A_{1}^{2}(x_1, x_2)$
 \item $A_{1}^{2}(f_{1}^{2}(x_1, a_{1}), x_1)$
 \item $A_{1}^{2}(f_{1}^{2}(x_1, f_{1}^{1}(x_2)),
  f_{1}^{1}(f_{1}^{2}(x_1,x_2)))$
 \item $A_{1}^{2}(f_{2}^{2}(x_1, a_{1}), a_{1})$
 \item $A_{1}^{2}(f_{2}^{2}(x_1, f_{1}^{1}(x_2)),
  f_{1}^{2}(f_{2}^{2}(x_1, x_2), x_1))$
 \item Sei $\alpha$ eine Formel mit freier Variable $x$. $\alpha(a_{1})$
  bezeichne $\alpha[x/a_{1}]$, $\alpha(x)$ bezeichne $\alpha$, und
  $\alpha(f_{1}^{1}(x))$ bezeichne $\alpha[x/f_{1}^{1}(x)]$.
  Dann ist folgende Formel ein Axiom:
  \begin{gather*}
    \alpha(a_{1}) \rightarrow \Big((\forall x\quantsep \alpha(x) \rightarrow
       \alpha(f_{1}^{1}(x))\big) \rightarrow \big(\forall x\quantsep
       \alpha(x)\big)\Big)
  \end{gather*}
\end{enumerate}
\help{Woher wissen wir eigentlich, dass diese Axiome insich nicht
  widersprüchlich sind?}

Um die Bedeutung der Axiome etwas eingängiger darzustellen, verwenden wir die
üblichen Schreibweisen aus der Mathematik:
\begin{itemize}
 \item statt dem Konstantensymbol~$a_1$ verwenden wir das Symbol $0$,
 \item statt dem Prädikatensymbol~$A^2_1(s,t)$ verwenden wir $s=t$ und
 \item für die drei Funktionssymbole schreiben wir
  \begin{enumerate}
   \item $t'$ (Nachfolger von $t$) statt $f^1_1(t)$,
   \item $s+t$ statt $f^2_1(s,t)$ und
   \item $s\cdot t$ statt $f^2_2(s,t)$.
  \end{enumerate}
\end{itemize}

Damit ist die Bedeutung der einzelnen Axiome auch leichter erkennbar:
\begin{itemize}
 \item Die Axiome (S1) und (S2) benötigen wir zur Beschreibung der
  Gleichheitsrelation, welche bei den Peano-Axiomen bereits vorrausgesetzt
  wurde. Das Axiom~(S1) beschreibt die Gleichheitsbeziehung zwischen drei
  Elementen und mit Axiom~(S2) ist die Fortsetzung der Gleichheit -- zwei
  Zahlen sind gleich, wenn ihre Vorgänger gleich sind.

 \item Das Axiom~(S3) entspricht dem Peano-Axiom~(P3), Axiom~(S4) entspricht
  dem Peano-Axiom~(P4) und das Axiom~(S9) entspricht dem Peano-Axiom~(P5).

 \item Die Axiome~S(5)--(S8) beschreiben grundlegende Eigenschaften der
  Addition ($f_{1}^{2}$) und der Multiplikation ($f_{2}^{2}$).
  \help{Kann man diese nicht auch aus den anderen Axiomen ableiten? Nachfolger
    $\rightarrow$ Addition $\rightarrow$ Multiplikation}
\end{itemize}

Die beiden ersten Peano-Axiome~(P1) und (P2) sind durch die Festlegung von
$a_{1}$ als Konstantensymbol bzw. $f_{1}^{1}$ als die Nachfolgerfunktion
umgesetzt. Damit haben wir eine formale Theorie 1.~Ordnung für die
Zahlentheorie bestimmt.

Hier noch einmal die Axiome mit der eingängigeren Schreibweise:
\begin{enumerate}[(S1)]
 \item $x_1= x_2 \rightarrow (x_1=x_3 \rightarrow x_2=x_3)$
 \item $x_1= x_2 \rightarrow x_1'= x_2'$
 \item $\neg(0=x_{1}')$ oder abkürzend dafür $0\ne x_1'$
 \item $x_1'= x_2' \rightarrow x_1= x_2$
 \item $x_1+0 = x_1$
 \item $x_1+(x_2') = (x_1+x_2)'$
 \item $x_1\cdot 0 = 0$
 \item $x_1\cdot (x_2') = (x_1\cdot x_2) + x_1$
 \item Sei $\alpha$ eine Formel mit freier Variable $x$. $\alpha(0)$ bezeichne
  $\alpha[x/0]$, $\alpha(x)$ bezeichne $\alpha$, und $\alpha(x')$ bezeichne
  $\alpha[x/x']$. Dann ist folgende Formel ein Axiom:
  \begin{gather*}
    \alpha(0) \rightarrow \Big((\forall x\quantsep \alpha(x) \rightarrow \alpha(x')\big)
       \rightarrow \big(\forall x\quantsep \alpha(x)\big)\Big)
  \end{gather*}
\end{enumerate}

\begin{lemma}
  Alle Formeln, die aus Axiomen mittels Ersetzen von Variablen
  durch Terme entstehen, sind in der Theorie~$\ThS$ beweisbar.

  \help{Wieso haben wir eigentlich die Axiome mit Variablen formuliert? Alle
    anderen Axiome sind doch auch mit Formeln $\alpha,\beta$ formuliert, warum
    diese nicht?}

  \todo{klären: Was ist mit S9? Funktioniert da Generalisierung?}

  \begin{proof}
    Da in den Axiomen (S1)--(S8) alle Variablen frei vorkommen, kann man
    schrittweise für jede Variable die Generalisierung und die Regel~RA4
    anwenden.

    Beispielhaft wollen wir den Beweis für das Axiom~(S1) führen. Das
    entstehenden Axiomenschema bezeichnen wir mit (S1').

    (S1'): für alle Terme $r,s,t$ gilt
    $\Svdash r=s \rightarrow (r=t \rightarrow s=t)$.

    \begin{align*}
      (1)\quad & x_1= x_2 \rightarrow (x_1=x_3 \rightarrow x_2=x_3)
         & \text{(S1)}\\
      (2)\quad & (\forall x_1\quantsep x_1= x_2 \rightarrow (x_1=x_3 \rightarrow x_2=x_3))
         & \text{Gen, 1}\\
      (3)\quad & r = x_2 \rightarrow (r=x_3 \rightarrow x_2=x_3)
         & \text{RA4, 2}\displaybreak[0]\\
      (4)\quad & (\forall x_2\quantsep r= x_2 \rightarrow (r=x_3 \rightarrow x_2=x_3))
         & \text{Gen, 3}\\
      (5)\quad & r = s \rightarrow (r=x_3 \rightarrow s=x_3)
         & \text{RA4, 4}\displaybreak[0]\\
      (6)\quad & (\forall x_3\quantsep r = s \rightarrow (r=x_3 \rightarrow s=x_3))
         & \text{Gen, 5}\\
      (7)\quad &  r = s \rightarrow (r=t \rightarrow s=t)
         & \text{RA4, 6}
    \end{align*}
  \end{proof}
\end{lemma}

%%%%%%%%%%%%%

Folgende grundlegende Eigenschaften der Gleichheitsrelation -- Reflexivität,
Symmetrie, Transitivität -- sowie der Addition -- Kommutativität,
Assoziativität -- können wir auch in der Theorie~$\ThS$ beweisen.

\begin{lemma}\label{lemma-zahlen-elem}
  Für alle Terme $r$, $s$ und $t$ sind folgende Formeln
  Theoreme von $\ThS$.

  \begin{minipage}[t]{.5\linewidth}
    \centering
    \begin{enumerate}[(a)]
     \item $t=t$
     \item $t=r \rightarrow r=t$
     \item $t=r \rightarrow (r=s \rightarrow t=s)$
     \item $r=t \rightarrow (s=t \rightarrow r=s)$
     \item $t=r \rightarrow t+s=r+s$
     \item $t = 0+t$
     \item $t'+r = (t+r)'$
     \item $t+r = r+t$
    \end{enumerate}
  \end{minipage}%
  \begin{minipage}[t]{.5\linewidth}
    \centering
    \begin{enumerate}[(a)]\setcounter{enumi}{8}
     \item $t=r \rightarrow s+t=s+r$
     \item $(t+r)+s = t+ (r+s)$
     \item $t=r \rightarrow t\cdot s= r\cdot s$
     \item $0\cdot t = 0$
     \item $t'\cdot r = t\cdot r + r$
     \item $t \cdot r = r\cdot t$
     \item $t=r \rightarrow s\cdot t=s\cdot r$
    \end{enumerate}
  \end{minipage}

  \begin{proof}
    Wir führen nur ein einige Beweise auf, die auch als Beispiel
    für die fehlenden Beweise gesehen werden können.

    Ein Beweis der Formel (a)
    \begin{align*}
      (1)\quad & t+0=t & \text{(S5')}\\
      (2)\quad & (t+0=t) \rightarrow ((t+0=t)\rightarrow(t=t)) & \text{(S1')}\\
      (3)\quad & (t+0=t)\rightarrow(t=t) & \text{MP~ 1,2}\\
      (4)\quad & t=t & \text{MP 1,3}
    \end{align*}

    Für die Formel (b) kann man $t=r\Svdash r=t$ beweisen woraus mit Hilfe des
    Deduktionstheorems die eigentliche Formel folgt.
    \begin{align*}
      (1)\quad & (t=r) \rightarrow((t=t) \rightarrow(r=t)) & \text{(S1')}\\
      (2)\quad & t=r & \text{Hypothese} \\
      (3)\quad & (t=t) \rightarrow (r=t) & \text{MP 2,1}\\
      (4)\quad & t=t & \text{Teil (a)}\\
      (5)\quad & r=t & \text{MP 5,4}
    \end{align*}

    Die Formel (e) $\Svdash x_{1}=x_{2} \rightarrow x_{1}+x_{3}=x_{2}+x_{3}$
    beweisen wir mittels Induktion über $x_{3}$.
    \help{Die Formel $\Svdash t=r \rightarrow t+s=r+s$ ist aber mit Termen und
      nicht mit Variablen. Arbeiten wir hier mit (S9) oder (S9')}
    \begin{enumerate}
     \item Für den Induktionsanfang $\alpha(0)$ müssen wir $x_{1}=x_{2}
      \rightarrow x_{1}+0 = x_{2}+0$ zeigen
      \begin{align*}
        (1)\quad& x_{1}+0 =x_{1} &\text{S5}\\
        (2)\quad& x_{2}+0 = x_{2} &\text{S5}\\
        (3)\quad& x_{1} = x_{2} &\text{Hypothese}\\
        (4)\quad& x_{1}+0 = x_{1} \rightarrow (x_{1} = x_{2} \rightarrow
           x_{1}+0=x_{2}) &\text{(c) mit $t=x_{1}+0$}\\
        (5)\quad& x_{1}+0 = x_{2} &\text{MP 1,3,4}\\
        (6)\quad& x_{2}+0 = x_{2} \rightarrow x_{2}=x_{2}+0 &\text{(b)}\\
        (7)\quad& x_{2} = x_{2}+0 &\text{MP 2,6}\\
        (8)\quad& x_{1}+0 = x_{2} \rightarrow (x_{2}=x_{2}+0 \rightarrow
           x_{1}+0 = x_{2}+0) &\text{(c)}\\
        (9)\quad& x_{1} + 0 = x_{2}+0 &\text{MP 5,7,8}
      \end{align*}
      Mit dem Deduktionstheorem folgt $x_{1}=x_{2} \rightarrow x_{1}+0 =
      x_{2}+0$. Damit ist der Induktionsanfang $\alpha(0)$ bewiesen.

     \item Für den Induktionsschritt $\alpha(x_{3})\rightarrow\alpha(x_{3}')$
      zeigen wir
      \begin{gather*}
        (x_{1}=x_{2} \rightarrow x_{1}+x_{3} = x_{2}+x_{3}) \rightarrow
           (x_{1}=x_{2} \rightarrow x_{1}+x_{3}' = x_{2}+x_{3}')
      \end{gather*}
      \begin{align*}
        (1)\quad& x_{1}=x_{2} \rightarrow x_{1}+x_{3} = x_{2}+x_{3}
           &\text{Hypothese}\\
        (2)\quad& x_{1} = x_{2} &\text{Hypothese}\\
        (3)\quad& x_{1}+x_{3} = x_{2}+x_{3} &\text{MP 1,2}\\
        (4)\quad& x_{1}+x_{3} = x_{2}+x_{3} \rightarrow (x_{1}+x_{3})' =
           (x_{2}+x_{3})' &\text{S2}\\
        (5)\quad& (x_{1}+x_{3})' = (x_{2}+x_{3})' &\text{MP 3,4}\\
        (6)\quad& x_{1} +x_{3}' = (x_{1}+x_{3})' &\text{S6 und (b)}\\
        (7)\quad& x_{1}+x_{3}' = (x_{2}+x_{3})' &\text{(c), MP 5,6}\\
        (8)\quad& x_{2}+x_{3}' = (x_{2}+x_{3}) &\text{S6}\\
        (9)\quad& x_{2}+x_{3}' = (x_{2}+x_{3})' \rightarrow (x_{2}+x_{3})'
           = x_{2} +x_{3}' &\text{(b)}\\
        (10)\quad& (x_{2}+x_{3})' = x_{2}+x_{3}' &\text{MP 8,9}\\
        (11)\quad& x_{1}+x_{3}' = x_{2}+x_{3}' &\text{(c), MP 7,10}
      \end{align*}
      Damit ist bewiesen:
      \begin{gather*}
        x_{1}=x_{2}, x_{1}=x_{2} \rightarrow x_{1}+x_{3} = x_{2}+x_{3}
            \Svdash x_{1}+x_{3}' = x_{2} + x_{3}'
      \end{gather*}
      Mit zweimaliger Anwendung des Deduktionstheorems folgt
      \begin{gather*}
        \Svdash \left(x_{1}=x_{2} \rightarrow x_{1}+x_{3} = x_{2}+x_{3}\right)
                    \rightarrow
                 \left(x_{1}=x_{2} \rightarrow x_{1}+x_{3}' = x_{2} + x_{3}'\right)
      \end{gather*}
      \help{Was ist mit mit $x_{1}=x_{2}$ passiert? Wie soll dann das mit der
        Generalisierung von statten gehen?}
      Darauf wenden wir noch einmal die Generalisierung an und bekommen
      \begin{gather*}
        \Svdash \forall x_3\quantsep
          \underbrace{\left(x_{1}=x_{2} \rightarrow x_{1}+x_{3} = x_{2}+x_{3}\right)}_{\alpha(x_3)}
                    \rightarrow
          \underbrace{\left(x_{1}=x_{2} \rightarrow x_{1}+x_{3}' = x_{2} + x_{3}'\right)}_{\alpha(x_3')}
      \end{gather*}
    \end{enumerate}

    Bis jetzt haben wir $\Svdash\alpha(0)$ und $\Svdash (\forall
    x_{3}\quantsep \alpha(x_{3}) \rightarrow \alpha(x_{3}'))$ gezeigt.
    \begin{align*}
      &\Svdash \alpha(0) \rightarrow ((\forall x_{3}\quantsep
         \alpha(x_{3}) \rightarrow \alpha(x_{3}')) \rightarrow (\forall
         x_{3}\quantsep \alpha(x_{3}))) & \text{S9}\\
      &\Svdash (\forall x_{3}\quantsep
         \alpha(x_{3}) \rightarrow \alpha(x_{3}')) \rightarrow (\forall
         x_{3}\quantsep \alpha(x_{3})) & \text{MP aus S9 und $\alpha(0)$}\\
      &\Svdash \forall x_{3}\quantsep \alpha(x_{3})
         &\text{MP aus $(\forall x_3\quantsep\alpha(x_3)\rightarrow\alpha(x_3'))$} \\
      &\Svdash \alpha(x_{3}) & \text{RA4}
    \end{align*}
    Sollte bei RA4 im letzten Schritt nicht ein Termsymbol entstehen?
  \end{proof}
\end{lemma}

Die Beweise in der Zahlentheorie laufen also wie gewohnt, aber wie es nicht
anders zu erwarten war, werden die Beweise schnell lang.

In der Theorie $\ThS$ -- wie auch bei den Peano-Axiomen -- gibt es keine
Symbole für natürliche Zahlen außer der $0$. Der Nachfolger von $0$ ist $0'$,
und das ist im intuitiven Verständnis die $1$. Wir führen die abkürzende
Schreibweise $\overline{1}$ für $0'$, $\overline{2}$ für $0''$, \dots{} und
entsprechend $\overline{m}$ für $0\overbrace{'\raisebox{.7ex}{$\cdots$}'}
^{\text{$m$-mal}}$ ein. Der Einheitlichkeit halber soll auch $\overline{0}=0$
sein.
\help{Hätte man nicht besser von Anfang an die Null mit $\overline{0}$
  bezeichnet?}

Den Strich über den Zahlen setzen wir, um die Symbole für die Elemente unserer
Theorie~$\ThS$ von den natürlichen Zahlen abzuheben. Denn bereits der Strich
$'$ war eine Abkürzung für $f_{1}^{1}$.
\begin{gather*}
  \overline{2} = \overline{1} + \overline{1} \quad\text{ist}\quad
     0'' = 0' + 0' \quad\text{ist}\quad
     A_{1}^{2}\Bigl(f_{1}^{1}\bigl(f_{1}^{1}(a_{1})\bigr),
     f_{1}^{2}\bigl(f_{1}^{1}(a_{1}), f_{1}^{1}(a_{1})\bigr)\Bigr)
\end{gather*}

\begin{lemma}\label{lemma-eins}
  Sei $t$ ein Term. Dann gilt
  \begin{enumerate}[(a)]
   \item $\Svdash t + \overline{1} = t'$
   \item $\Svdash t\cdot\overline{1} = t$
  \end{enumerate}

  \begin{proof}
    Der Beweis für die Addition mit 1:
    \begin{align*}
      (1)\quad & t+0 = t & \text{S5'}\\
      (2)\quad & t+0 = t \rightarrow (t+0)' = t'& \text{(S9')}\\
      (3)\quad & (t+0)' = t' & \text{MP, 1,2}\\
      (4)\quad & t+0'=(t+0)' & \text{(S6')}\\
      (5)\quad & t+0' = t'   & \text{\autoref{lemma-zahlen-elem}~(c) Trans. von $=$ mit 4,3}
    \end{align*}

    Der Beweis für die Multiplikation mit 1:
    \begin{align*}
      (1)\quad & t\cdot 0 = 0 & \text{S7'}\\
      (2)\quad & t\cdot0 = 0 \rightarrow t\cdot0+t = 0+t&
         \text{\autoref{lemma-zahlen-elem}~(e)}\\
      (3)\quad & t\cdot 0 + t = 0+t & \text{MP 1,2}\\
      (4)\quad & t\cdot 0' = t\cdot 0 + t & \text{S8'}\\
      (5)\quad & t\cdot 0' = 0+t & \text{Trans. von $=$ mit 4,3}\\
      (6)\quad & t = 0+t& \text{\autoref{lemma-zahlen-elem}~(f)}\\
      (7)\quad & t\cdot0' = 0+t \rightarrow (t=0+t \rightarrow t\cdot 0'=t)
         &\text{\autoref{lemma-zahlen-elem}~(d)}\\
      (8)\quad & t\cdot 0' = t & \text{MP 5,6,7}
    \end{align*}
  \end{proof}
\end{lemma}


\begin{lemma}\label{lemma-numerale1}
  Seien $m$ und $n$ natürliche Zahlen.
  \begin{enumerate}[(a)]
   \item
    Falls $m=n$,
    dann gilt $\Svdash \overline{m}=\overline{n}$.
   \item
    Falls $m\ne n$,
    dann gilt $\Svdash \neg(\overline{m}=\overline{n})$.
   \item
    $\Svdash \overline{n+m} = \overline{n} + \overline{m}$
  \end{enumerate}
  \begin{proof}
    \begin{enumerate}[(a)]
     \item Folgt aus \autoref{lemma-zahlen-elem}~(a).

     \item Für den Beweis benötigen wir das Theorem $\Svdash \neg(t=s)
      \rightarrow\neg(t'=s')$, welches sich leicht durch den modus ponens aus
      Axiom~(S4) ($t'=s'\rightarrow t=s$) und \autoref{lem:5} ($\Svdash
      (\alpha\rightarrow\beta)\rightarrow(\neg\beta\rightarrow\neg\alpha)$)
      herleiten lässt.
      \help{Ist der Einsatz von \autoref{lem:5} hier in Ordnung?}

      \begin{faelle}
        \item Wenn $n>m$, dann ist $n-m-1\geq0$ und kann daher als
        $\overline{n-m-1}$ geschrieben werden.
        \begin{align*}
          (1)\quad& 0\ne\overline{n-m-1}'& \text{S4}\\
          (2)\quad& 0\ne\overline{n-m} \rightarrow 0'\ne\overline{n-m}'&
             \text{Vorbem.}\\
          (3)\quad& \overline{1} \ne \overline{n-m}'& \text{MP 1,2}\\
          (4)\quad& \overline{1}\ne\overline{n-m+1} \rightarrow
             \overline{1}'\ne\overline{n-m+1}'& \text{Vorbem.}\\
          (5)\quad& \overline{2}\ne \overline{n-m+2}& \text{MP, 3,4}\\
          \vdots\qquad& \quad\vdots& \vdots\quad\\
          (2m)\quad& \overline{m-1}\ne\overline{n-1} \rightarrow
             \overline{m-1}' \ne\overline{n-1}'& \text{Vorbem.}\\
          (2m+1)\quad& \overline{m}\ne\overline{n}& \text{MP $2m-1$,$2m$}
        \end{align*}

       \item Wenn $m>n$, dann ist $\overline{m-n-1}$ zulässig. Mit dem
        Beweis im Fall~1 erhalten wir nach $2n+1$~Schritten das Ergebnis
        $\overline{n}\ne\overline{m}$.

        Wir können aber leicht mit \autoref{lem:5} und
        \autoref{lemma-zahlen-elem}~(b) die Symmetrie des
        Ungleichheitszeichens ($\Svdash t\ne r\rightarrow r\ne t$) zeigen und
        damit unter Einsatz des modus ponens' das Theorem
        $\overline{m}\ne\overline{n}$ herleiten.
      \end{faelle}

     \item Zuvor ein kurzer Beweis für $\Svdash t'+r = t+r'$
      \begin{align*}
        (1)\quad& t'+r = (t+r)'& \text{\autoref{lemma-zahlen-elem}~(g)}\\
        (2)\quad& t+r' = (t+r)'& \text{(S6')}\\
        (3)\quad& t'+r = (t+r)' \rightarrow (t+r' = (t+r)' \rightarrow t'+r =
           t+r')& \text{\autoref{lemma-zahlen-elem}~(d)}\\
        (4)\quad& t'+r = t+r'& \text{MP 1,2,3}
      \end{align*}

      Damit können wir nun den eigentlichen Beweis antreten:
      \begin{align*}
        (1)\quad& \overline{n+m} = \overline{n+m-1}'& \text{nach Def. von
           $\overline{n}$}\\
        (2)\quad& \overline{n+m-1} + \overline{1} = \overline{n+m-1}'&
           \text{\autoref{lemma-eins}~(a)}\\
        (3)\quad& \overline{n+m} = \overline{n+m-1} + \overline{1}&
           \text{MP 1,2,\autoref{lemma-zahlen-elem}~(d)}\\
        (4)\quad& \underbrace{\overline{n+m-2}'}_{=\overline{n+m-1}}
           + \overline{1} = \overline{n+m-2} +
           \underbrace{\overline{1}'}_{=\overline{2}}& \text{nach Vorbem.}\\
        (5)\quad& \overline{n+m} = \overline{n+m-2} + \overline{2}&
           \text{MP 3,4,\autoref{lemma-zahlen-elem}~(c)}\\
        (6)\quad& \underbrace{\overline{n+m-3}'}_{=\overline{n+m-2}}
           + \overline{2} = \overline{n+m-3} +
           \underbrace{\overline{2}'}_{=\overline{3}}& \text{nach Vorbem.}\\
        (7)\quad& \overline{n+m} = \overline{n+m-3} + \overline{3}&
           \text{MP 5,6,\autoref{lemma-zahlen-elem}~(c)}\\
        \vdots\quad& \quad\vdots& \vdots\quad\\
        (2m-1)\quad& \overline{n+m} = \overline{n+m-(m-1)} + \overline{m-1}\\
           % &\text{MP $2m-3$,$2m-2$,\autoref{lemma-zahlen-elem}~(c)}\\
        (2m)\quad& \overline{n+m-m}' + \overline{m-1} = \overline{n+m-m} +
           \overline{m-1}'\\ %& \text{nach Vorbem.}\\
        (2m+1)\quad& \overline{n+m} = \overline{n} + \overline{m}
           % &\text{MP $2m-1$,$2m$,\autoref{lemma-zahlen-elem}~(c)}
      \end{align*}
      \help{Ist der Beweis in Ordnung?}
    \end{enumerate}
  \end{proof}
\end{lemma}

Weitere abkürzende Schreibweisen:\\
\begin{tabular}{r@{~\ldots{}~}l}
  $t<s$ & für $(\exists w\quantsep w\ne0 \wedge t+w=s)$\\
  $t\leq s$ & für $t<s \vee t=s$\\
  $t>s$ & für $s<t$\\
  $t\geq s$ & für $s\leq t$\\
  $t\not< s$ & für $\neg t<s$
\end{tabular}




Das Standardmodell für $\ThS$ besteht
aus den natürlichen Zahlen als Grundmenge
und der \glqq{}intuitiven\grqq{} Interpretation der übrigen Symbole.

\begin{itemize}
 \item Grundmenge: die natürlichen Zahlen
 \item das Konstantensymbol $0$ wird durch die nat.\,Zahl $0$ interpretiert
 \item $f^1_1$ ($'$) wird durch Addition mit $1$ interpretiert
 \item $f^2_1$ und $f^2_2$ werden durch Addition und Multiplikation interpretiert
 \item $A^2_1$ wird durch die Gleichheitsrelation interpretiert
\end{itemize}

\glqq{}Offensichtlich\grqq{} sind die Axiome von $\ThS$ wahr
im Standardmodell.
Damit folgt auch, dass alle beweisbaren Formeln wahr sind.

Das Standardmodell ist jedoch nicht das einzige Modell für $\ThS$.
Es gibt auch Modelle für $\ThS$ mit
überabzählbarer Grundmenge \ldots{}
\help{Wieso? Worauf fußt diese Behauptung?}

Versuche ein Modell $\cM$ für $\ThS$ zu finden, das nicht
die natürlichen Zahlen als Grundmenge hat. Erweitern wir die Grundmenge
um die Elemente $p_{0}, p_{1}, p_{2},\dotsc$, wobei $p_{1}$ Nachfolger von
$p_{0}$ und $p_{2}$ Nachfolger von $p_{1}$ ist usw. Eine mögliche
Interpretation von $+$ wäre dann:
\begin{gather*}
  (f_{1}^{2})^{\mathcal{M}}(a,b) =
     \begin{cases}
       a+b & \text{falls}~a,b\in\N\\
       p_{i+j} & \text{falls}~a=p_{i}, b=p_{j}\\
       p_{a+i} & \text{falls}~a\in\N, b=p_{i}\\
       p_{i+b} & \text{falls}~a=p_{i}, b\in\N
     \end{cases}
\end{gather*}

Da $(p_{k})' = p_{k+1} = p_{k}+p_{1}$, muss $p_{1}=1$ sein, damit jedes
Element nur Nachfolger genau eines Elements ist. Aber dann haben wir die
natürlichen Zahlen. Versuch gescheitert.

% 2006-06-27

\begin{satz}[Endlichkeitssatz -- Compactness Theorem]
  Sei $\mathcal{S}$ eine unendliche Menge von Formeln. $\mathcal{S}$ hat
  ein Modell genau dann, wenn jede endliche Teilmenge von $\mathcal{S}$
  ein Modell hat.

  (In der Aussagenlogik: Sei $T$ eine unendliche Menge aussagenlogischer
  Formeln. Es gibt eine Belegung, die alle Formeln in $T$ erfüllt, genau
  dann, wenn jede endliche Teilmenge von $T$ eine erfüllende Belegung
  besitzt.)

  Wir benötigen die Größerrelation $x>y\colon (\exists z\in\N \quantsep
  z\ne0 \wedge x=y+z)$. Für die unendliche Formelmenge $\mathcal{C}=
  \{c>0, c>1, c>2, c>3, \dotsc\}$ gibt es für jede Teilmenge ein Modell
  $\mathcal{M}$ mit der Interpretation $c^{\mathcal{M}} = c+1$.

  Modell $\mathcal{M}$ für $\mathcal{C}$ kann $c$ nicht durch ein Element
  von $\N$ interpretieren.
\end{satz}

Unser Ziel ist es, eine Formel der Zahlentheorie anzugeben,
die wahr ist und die man nicht beweisen kann.
In der Prädikatenlogik gibt es eine solche Formel nicht,
aber in der Zahlentheorie gibt es sie.
Grundidee dieser Formel ist eine Paradoxie
wie \glqq{}Dieser Satz ist falsch\grqq{}.
In einer formalen Theorie kann man nicht über wahr und falsch
sprechen, dafür aber über beweisbar und nicht beweisbar.
Die zu formulierende Aussage geht dann in die
Richtung \glqq{}Formel $\phi$ ist nicht beweisbar\grqq{}
(für eine feste Formel $\phi$).
Wäre diese Aussage beweisbar,
dann wäre eine falsche Aussage beweisbar
(Widerspruch zur Korrektheit der Zahlentheorie).
Also muss sie nicht beweisbar sein, womit sie auch
eine wahre Aussage ist.

Das Problem liegt nun darin, eine solche Aussage in
der Zahlentheorie zu formulieren.
Dort kann man über natürliche Zahlen und deren Eigenschaften sprechen.
Also muss man eine Übersetzung (Kodierung) von Formeln, Beweisen usw.~in
die natürlichen Zahlen finden.
Soetwas haben wir schonmal bei der Betrachtung der
Abzählbarkeit von Formeln (\autoref{sec-abzaehlbarkeit}) gemacht
und werden es jetzt noch viel ausführlicher auswalzen.
In diesem Zusammenhang heißt diese Übersetzung Arithmetisierung von Formeln.

Eigenschaften von Formeln lassen sich dann durch Eigenschaften
von natürlichen Zahlen ausdrücken.
Eine Formel $\alpha$ mit einer freien Variablen $x_1$
kann als Darstellung der Menge
$\{n\in\N \mid \Svdash \alpha[x_1/\overline{n}]\}$ aufgefasst werden.
Also lassen sich Eigenschaften von Formeln
durch Formeln darstellen.
Was für Eigenschaften (Relationen) geht, geht auch für Funktionen
auf den natürlichen Zahlen.
Wir werden den Begriff der Repräsentierbarkeit von Relationen und
Funktionen in $\mathrm{S}$ kennenlernen.

Wir wissen, dass es abzählbar viele Formeln
und überabzählbar viele Eigenschaften von Formeln gibt.
Kann man die Eigenschaft der Beweisbarkeit
-- also die Menge
$\{ n\in\N\mid n\mbox{ ist Kodierung einer in $\mathrm{S}$ beweisbaren Formel}\}$
-- durch eine Formel in $\mathrm{S}$ darstellen?
Die Darstellung von Mengen in $\mathrm{S}$ ist auf den ersten
Blick recht kompliziert.
Aber es gibt ein sehr schönes Werkzeug dafür:
die (primitiv-)rekursiven Funktionen.

Die hier angerissenen Begriffe werden nun in umgekehrter
Reihenfolge betrachtet.
Wir beginnen mit den (primitiv-)rekursiven Funktionen,
zeigen dann die Verbindung zwischen diesen Funktionen
und $\mathrm{S}$
und kommen schließlich zur Arithmetisierung und in $\mathrm{S}$
repräsentierbaren Eigenschaften von Formeln.


\section{Primitiv-rekursive Funktionen}
\label{sec-prFunktionen}


Primitiv-rekursive Funktionen lassen sich mittels
Komposition und Rekursion auf einfache Basisfunktionen zurückführen.
Die Basisfunktionen sind
%
\begin{itemize}
 \item die (konstante) \emph{Nullfunktion} $Z\colon\emptyset\rightarrow\N$ mit
  $Z(\,)=0$
 \item die \emph{Nachfolgerfunktion} $N\colon\N\rightarrow\N$ mit $N(n)=n+1$
 \item die \emph[rand=Projektionsfunkt.]{Projektionsfunktionen}
  $U^{(k)}_i\colon\N^k\rightarrow\N$ mit $U^{(k)}_i(x_1,\dotsc,x_k)=x_i$
  wobei $k\in\N^+$ und $1\leq i\leq k$.
\end{itemize}
%

\begin{defini}[Komposition]
  Seien $f\colon\N^k\rightarrow\N$
  und $g_1,\dotsc,g_k\colon\N^l\rightarrow\N$
  Funktionen auf den natürlichen Zahlen.
  Die Funktion $h\colon\N^l\rightarrow\N$ mit
  \begin{gather*}
    h(x_1,\dotsc,x_l) = f\big(g_1(x_1,\dotsc,x_l),\dotsc,g_k(x_1,\dotsc,x_l)\big)
  \end{gather*}
  entsteht aus $f$ und $g_1,\dotsc,g_k$ durch \emph{Komposition}.
\end{defini}

\begin{bsp}\label{bsp:3}
  Die Funktion $h\colon\N\rightarrow\N$ mit $h(x)=2\cdot x$ entsteht aus
  $f\colon\N^2\rightarrow\N$ mit $f(x,y)=x+y$ und $g_1, g_{2}\colon\N
  \rightarrow\N$ mit $g_1(x) = g_2(x)=x$ durch Komposition. Es gilt $h(x)
  = f\big(g_1(x), g_2(x)\big)$.
\end{bsp}

Die Komposition der Funktionen
$f\colon\N^3\rightarrow\N$ mit $f(x,y,z)=x+y+z$ und
$g_1,g_2,g_3\colon\N^2\rightarrow\N$
mit $g_1(x,y)=x^2$, $g_2(x,y)=h(x)$ und $g_3(x,y)=y^2$
liefert die Funktion
$h'\colon\N^2\rightarrow\N$ mit $h'(x,y)=x^2+2x+y^2$.

\begin{defini}[totale Funktion]
  Eine Funktion $f\colon\Gamma\rightarrow\Omega$ heißt
  \emph[indexrand=totale Funktion]{total} falls für alle $x\in\Gamma$ ein
  $y\in\Omega$ existiert, so dass $f(x) = y$. Mit anderen Worten: Die
  Funktion $f$ ist auf ganz $\Omega$ definiert.
\end{defini}

\begin{defini}
  Sei $k\in\N$ und $g\colon\N^2\rightarrow\N$ eine totale Funktion.
  Dann entsteht die Funktion $h\colon\N\rightarrow\N$ mit
  $h(0) = k$ und $h(n+1) = g(n,h(n))$ aus $k$ und $g$ mittels \emph{Rekursion}.
\end{defini}


Die Rekursion ist stets endlich.
Wenn $h$ durch Rekursion aus $g$ und $k$ entsteht,
dann gilt zum Beispiel
% \begin{gather*}
%   h(5)=g(4,\underbrace{g(3,\overbrace{g(2,\underbrace{g(1,\overbrace{g(0,\underbrace{k}_{h(0)})}^{h(1)})}_{h(2)})}^{h(3)})}_{h(4)}) \ \ .
% \end{gather*}
\begin{align*}
  h(5) &= g\big(4, h(4)\big) = g\big(4, g(3, h(3))\big)
     = g\big(4, g\big(3, g(2, h(2))\big)\big)\\
  &= g\Big(4, g\big(3, g\big(2, g(1, h(1))\big)\big)\Big)\\
  &= g\Big(4, g\Big(3, g\big(2, g\big(1, g(0, h(0))\big)\big)\Big)\Big)\\
  &= g\Big(4, g\Big(3, g\big(2, g\big(1, g(0, k)\big)\big)\Big)\Big)
\end{align*}
Sei $h$ definiert durch Rekursion aus $k=0$ und $g(x,y)=x+y$.
Das heißt
\begin{alignat*}{3}
  h(0) & = k && = 0 &\quad \text{und} \\
  h(n+1) & = g(n,h(n)) && = n + h(n)
\end{alignat*}

Dann gilt
\begin{gather*}
  h(n)=\sum_{i=0}^{n-1} i
\end{gather*}

Die obige Definition der Rekursion diente
der Veranschaulichung der wesentlichen Eigenschaften.
Rekursion ist natürlich auch für mehrstellige Funktionen definiert.
Dabei dient eines der Argumente für die Rekursion.
Die anderen Argumente werden nur "`mitgeschleift"'.

\begin{defini}
  Seien $f\colon\N^k\rightarrow \N$ und $g\colon\N^{k+2}\rightarrow\N$.
  Die Funktion $h\colon\N^{k+1}\rightarrow\N$ entsteht mittels
  \emph{Rekursion} aus $f$ und $g$, falls
  \begin{align*}
    h(x_1,\dotsc,x_k,0) & = f(x_1,\dotsc,x_k) \text{\quad und} \\
    h(x_1,\dotsc,x_k,n+1) & = g\big(n,h(x_1,\dotsc,x_k,n),x_1,\dotsc,x_k\big) .
  \end{align*}
\end{defini}


\begin{defini}[primitiv-rekursive Funktion]
  Eine Funktion heißt \emph{primitiv-rekursiv}, wenn sie
  \begin{itemize}
   \item die Nullfunktion, die Nachfolgerfunktion,
    oder eine Projektionsfunktion ist,
    oder
   \item durch Komposition oder Rekursion aus primitiv-rekursiven
    Funktionen entsteht.
  \end{itemize}

  Ein Prädikat $R\subseteq \N^k$ heißt \emph{primitiv-rekursiv},
  falls die zu $R$ gehörende charakteristische Funktion $\chi_R\colon\N^k\rightarrow\N$ mit
  \begin{gather*}
    \chi_R(x_1,\dotsc,x_k) =
       \begin{cases}
         0, & \text{falls $(x_1,\dotsc,x_k)\notin R$} \\
         1, & \text{falls $(x_1,\dotsc,x_k)\in R$}
       \end{cases}
  \end{gather*}
  primitiv-rekursiv ist.
  Anstelle von $\chi_R$ schreiben wir der Einfachheit halber auch $R$.
\end{defini}


\subsubsection*{Einige wichtige primitiv-rekursive Funktionen und Prädikate}

\begin{lemma}
  Die Additionsfunktion $f_{add}\colon\N^2\rightarrow\N$ mit
  $f_{add}(x,y)=x+y$ ist primitiv-rekursiv.

  \begin{proof}
    Zuerst überlegen wir informell, wie man
    die Additionsfunktion rekursiv über $y$ definieren kann.
    Es gilt
    \begin{align*}
      x+0 & = x\\
      x+(y+1) & = (x+y) +1
    \end{align*}
    Formal ist das
    \begin{align*}
      f_{add}(x,0) & = U^{(1)}_1(x) \\
      f_{add}(x,y+1) & = N(U^{(3)}_2(y,f_{add}(x,y),x))
    \end{align*}

    $f_{add}$ entsteht durch Rekursion aus der Projektionsfunktion
    $U^{(1)}_1$ und der dreistelligen Funktion $g\colon\N^3\rightarrow\N$
    mit $g(y,z,x) = N(U^{(3)}_2(y,z,x))$. Da $g$ durch Komposition aus
    der Nachfolgerfunktion $N$ und der Projektionsfunktion $U^{(3)}_2$
    entsteht, ist $g$ und damit auch $f_{add}$ primitiv-rekursiv.
  \end{proof}
\end{lemma}

\begin{bsp}
  Die Funktion $h(x) = 2\cdot x$ aus \autoref{bsp:3} ist mit $f=f_{add}$
  und $g_{1} = g_{2} = U_{1}^{(1)}$ somit auch primitiv-rekursiv. Es gilt
  $f(x) = f_{add}\big(U_{1}^{(1)}(x), U_{1}^{(1)}(x)\big)$.
\end{bsp}

\begin{simplelist}
 \item
  Die Multiplikationsfunktion $f_{mul}\colon\N^2\rightarrow\N$ mit $f_{mul}(x,y)=x\cdot y$.
  Zuerst schreiben wir die Rekursion wieder informell auf.
  \vspace{1ex}

  \begin{align*}
    x\cdot 0 & = 0\\
    x\cdot(y+1) & = (x\cdot y) +x
  \end{align*}

  Formal ist das
  \begin{align*}
    f_{mul}(x,0) & = N^{(1)}(x) \\
    f_{mul}(x,y+1) & = f_{add}\big(U^{(3)}_2(y,f_{mul}(x,y),x),U^{(3)}_3(y,f_{mul}(x,y),x)\big)
  \end{align*}

  Die Funktionen, aus denen $f_{mul}$ mittels Rekursion entsteht,
  sind primitiv-rekursiv.
  Also ist $f_{mul}$ ebenfalls primitiv-rekursiv.

 \item
  Die Fakultätsfunktion $h_2\colon\N\rightarrow\N$ mit $h_2(x)=x!$.
  Es gilt
  \begin{align*}
    0! & = 1\\
    (y+1)! & = y! \cdot (y+1)
  \end{align*}

  Formal ist das
  \begin{align*}
    h_2(0) & = N(Z(\,)) \\
    h_2(y+1) & = f_{mul}\big(N(U^{(2)}_1(y,h_2(y)),U^{(2)}_2(y,h_2(y)))\big)
  \end{align*}

 \item Die konstanten Nullfunktionen bel. Stelligkeit
       $Z^{(k)}\colon\N^k\rightarrow \N$ mit $Z^{(k)}(x_1\dotsc,x_k)=0$.

       Offensichtlich ist $Z^{(0)}=Z$.
       Wir definieren $Z^{(k+1)}$ induktiv aus $Z^{(k)}$.
       \begin{align*}
         Z^{(k+1)}(x_1,\dotsc,x_k,0) & = Z^{(k)}(x_1,\dotsc,x_k) & ( = 0 ) \\
         Z^{(k+1)}(x_1,\dotsc,x_k,n+1) & =
              U^{(k+2)}_{2}(n,Z^{(k+1)}(x_1,\dotsc,x_k,n),x_1,\dotsc,x_k)
                  & ( = 0 )
       \end{align*}



 \item
  Die Potenzfunktion $f_{pot}\colon\N^2\rightarrow\N$ mit $f_{pot}(x,y)=x^y$.
  Es gilt
  \begin{align*}
    x^0 & = 1\\
    x^{(y+1)} & = (x^y) \cdot x
  \end{align*}

  Formal
  \begin{align*}
    f_{pot}(x,0) & = N(Z^{(1)}(x)) \\
    f_{pot}(x,y+1) & = f_{mul}(U^{(3)}_2(y,f_{pot}(x,y),x),U^{(3)}_3(y,f_{pot}(x,y),x))
  \end{align*}

 \item
  Die Dekrementfunktion $h_4\colon\N\rightarrow\N$ mit $h_4(x)=x\dminus 1$.
  Es gilt
  \begin{align*}
    0\dminus 1 & = 0   \\
    (x+1)\dminus 1 & = x
  \end{align*}
  und damit
  \begin{align*}
    h_4(0) & = Z(\, ) \\
    h_4(x+1) & = U^{(2)}_1(x,h_4(x))
  \end{align*}

 \item
  Die Subtraktionsfunktion $h_5\colon\N^2\rightarrow\N$ mit $h_5(x,y)=x\dminus y$.
  Es gilt
  \begin{align*}
    x\dminus 0 & = x  \\
    x\dminus (y+1) & = (x\dminus y) \dminus 1
  \end{align*}
  und damit
  \begin{align*}
    h_5(x,0) & = U^{(1)}_1(x) \\
    h_5(x,y+1) & = h_4(U^{(3)}_2(y,h_5(x,y),x))
  \end{align*}

 \item
  Die Differenzfunktion $h_6\colon\N^2\rightarrow\N$ mit $h_6(x,y)=\abs{x-y}$.
  Es gilt
  \begin{gather*}
    |x-y| = (x\dminus y)+(y\dminus x).
  \end{gather*}

  Also ist $h_6(x,y)=f_{add}(h_5(x,y),h_5(U^{(2)}_2(x,y),U^{(2)}_1(x,y)))$.

 \item
  Das Gleichnullprädikat ist $\alpha\colon\N\rightarrow\{0,1\}$ mit
  \begin{gather*}
    \alpha(x)=
       \begin{cases}
         1, & \text{falls $x=0$} \\
         0, & \text{sonst}
    \end{cases}
  \end{gather*}
  Diese Funktion kann man gleich formal aufschreiben.
  \begin{align*}
    \alpha(0) & = N(Z^{(0)}(~)) \\
    \alpha(x+1) & = Z^{(2)}(x,\alpha(x))
  \end{align*}

 \item
  Das Ungleichnullprädikat ist $\overline{\alpha}\colon\N\rightarrow\{0,1\}$ mit
  \begin{gather*}
    \alpha(x)=
       \begin{cases}
         0, & \text{falls $x=0$} \\
         1, & \text{sonst}
       \end{cases}
  \end{gather*}
  ist $\overline{\alpha}(x)=1\dminus\alpha(x)$.

 \item
  Das Gleichheitsprädikat $x=y$:
  es gilt $x=y$ genau dann, wenn $|x-y|=0$.
  Also ist
  \begin{gather*}
    (x=y) = \alpha(|x-y|)
  \end{gather*}
  (formal $\alpha(h_6(x,y))$).

 \item
  Das Kleinergleichprädikat $x\leq y$: es gilt
  $x\leq y$ genau dann, wenn $x\dminus y = 0$.
  Also ist
  \begin{gather*}
    (x\leq y) = \alpha(x\dminus y)\ \ .
  \end{gather*}
\end{simplelist}


\subsection{Allgemeinere Konstruktoren für primitiv-rekursive Funktionen}

In der Definition primitiv-rekursiver Funktionen gibt es nur
die Konstruktoren Komposition und Rekursion.
Wir betrachten jetzt weitere Konstruktoren für Funktionen,
die das formale Aufschreiben von Funktionen erleichtern.
Mit Ausnahme des (unbeschränkten) Minimum-Konstruktors
kann man mit diesen Konstruktoren aus primitiv-rekursiven Funktionen
auch nur primitiv-rekursive Funktionen erzeugen.

Die üblichen logischen Verknüpfungen von Prädikaten können durch
primitiv-rekursive arithmetische Operationen dargestellt werden.

\begin{satz}
  Seien $P$ und $Q$ primitiv-rekursive Prädikate.
  Dann sind die Prädikate $\neg P$, $P\wedge Q$ und $P\vee Q$
  primitiv-rekursiv.
\end{satz}

\begin{proof}
  Es ist leicht zu sehen, dass $\chi_{\neg P}(x) = \alpha(\chi_{P}(x))$,
  $\chi_{P\wedge Q}(x) = \chi_P(x) \cdot \chi_Q(x)$
  und
  $\chi_{P\vee Q}(x) = \chi_{\neg(\neg P \wedge \neg Q)}
  = \alpha(\alpha(\chi_P(x))\cdot \alpha(\chi_Q(x)))$.
\end{proof}


Prädikate werden zum Beispiel in Funktionen benutzt,
die durch Fallunterscheidung beschrieben werden.
Dieses Mittel kann man auch für primitiv-rekursive Funktionen verwenden.

\begin{satz}(Fallunterscheidung)
  Seien $g\colon\N^k\rightarrow\N$ und $h\colon\N^k\rightarrow\N$
  primitiv-rekursive Funktionen,
  und $P\subseteq \N^k$ sei ein primitiv-rekursives Prädikat.
  Dann ist auch die Funktion $f\colon\N^k\rightarrow\N$ mit
  \begin{gather*}
    f(x_1,\dotsc,x_k) =
       \begin{cases}
         g(x_1,\dotsc,x_k), & \text{falls $(x_1,\dotsc,x_k)\in P$} \\
         h(x_1,\dotsc,x_k), & \text{sonst}
    \end{cases}
  \end{gather*}
  primitiv-rekursiv.
\end{satz}

\begin{proof}
  Offensichtlich gilt
  \begin{gather*}
    f(x_1,\dotsc,x_k) = g(x_1,\dotsc,x_k) \cdot \chi_P(x_1,\dotsc,x_k)
       + h(x_1,\dotsc,x_k) \cdot \alpha\big(\chi_P(x_1,\dotsc,x_k)\big)\ \ .
  \end{gather*}
  Also ist $f$ primitiv-rekursiv.
\end{proof}

Fallunterscheidungen mit mehr als zwei Fällen, die durch
primitiv-rekursive Prädikate entschieden werden, sind ebenfalls
primitiv-rekursiv (Beweis entsprechend).

Als erstes Beispiel für eine rekursive Funktion hatten
wir die Summe der ersten $n$ natürlichen Zahlen betrachtet.
Die Summe der Werte einer primitiv-rekursiven Funktion,
bei der ein Argument hochgezählt wird,
ist ebenfalls primitiv-rekursiv.
Gleiches gilt für das Produkt.


\begin{satz}
  Sei $f\colon\N^{k+1}\rightarrow\N$ primitiv-rekursiv.
  Dann sind auch die folgenden Funktionen $g,h\colon\N^{k+1}\rightarrow\N$
  primitiv-rekursiv.
  \begin{align*}
    g(x_1,\dotsc,x_k,y) & = \sum_{t=0}^{y} f(x_1,\dotsc,x_k,t) \\
    h(x_1,\dotsc,x_k,y) & = \prod_{t=0}^{y} f(x_1,\dotsc,x_k,t)
  \end{align*}
\end{satz}

\begin{proof}
  Sei $f\colon\N^{k+1}\rightarrow\N$ primitiv-rekursiv.
  Definiere $f'\colon\N^{k}\rightarrow\N$
  mit
  \begin{align*}
    f'(x_1,\dotsc,x_k) & = f(x_1,\dotsc,x_k,0) \\
    & = f\left(U^{(k)}_1\left(x_1,\dotsc,x_k\right),\dotsc,
    U^{(k)}_k\left(x_1,\dotsc,x_k\right),Z^{(k)}\left(x_1,\dotsc,x_k\right)\right)\ \ .
  \end{align*}
  $f'$ ensteht also durch Komposition aus
  den primitiv-rekursiven Funktionen $f$, $U^{(k)}_1$, \ldots{}, $U^{(k)}_k$ und $Z^{(k)}$.
  Also ist $f'$ primitiv-rekursiv.
  Nun kann $g$ mittels Rekursion definiert werden.
  %
  \begin{align*}
    g(x_1,\dotsc,x_k,0) & = f'(x_1,\dotsc,x_k) \\
    g(x_1,\dotsc,x_k,y+1) & =
    \underbrace{g(x_1,\dotsc,x_k,y)}_{=\sum\limits_{t=0}^{y} f(x_1,\dotsc,x_k,t)}
    + f(x_1,\dotsc,x_k,N(y))
  \end{align*}

  Für die Funktion $h$ wird entsprechend vorgegangen.
  \begin{align*}
    h(x_1,\dotsc,x_k,0) & = f'(x_1,\dotsc,x_k) \\
    h(x_1,\dotsc,x_k,y+1) & =
    \underbrace{h(x_1,\dotsc,x_k,y)}_{=\prod\limits_{t=0}^{y} f(x_1,\dotsc,x_k,t)}
    \cdot f(x_1,\dotsc,x_k,N(y))
  \end{align*}
\end{proof}

Man muss die Summe nicht unbedingt bei Index $0$ beginnen.
\begin{satz}
  Sei $f\colon\N^{k+1}\rightarrow\N$ primitiv-rekursiv.
  Dann sind auch die folgenden Funktionen primitiv-rekursiv.
  \begin{align*}
    g(x_1,\dotsc,x_k,y) & = \sum_{t=1}^y f(x_1,\dotsc,x_k,t) \\
    h(x_1,\dotsc,x_k,y) & = \prod_{t=1}^y f(x_1,\dotsc,x_k,t)
  \end{align*}
\end{satz}

\begin{proof}
  Mit
  \begin{gather*}
    \sum_{t=1}^y f(x_1,\dotsc,x_k,t) =
       \big(\sum_{t=0}^y f(x_1,\dotsc,x_k,t)\big) \dminus f(x_1,\dotsc,x_k,0)
  \end{gather*}
  folgt dieser Satz direkt aus dem letzten Satz.
  Für das Produkt muss der Spezialfall
  $f(x_1,\dotsc,x_k,0)=0$ getrennt betrachtet werden.
\end{proof}

Die Argumente von Prädikaten lassen sich quantifizieren.
Wir benutzen \textit{beschränkte} Quantoren,
die nur über einen Anfangsabschnitt der natürlichen Zahlen definiert sind.
Sei $P$ ein $(k+1)$-stelliges Prädikat.
Das ebenfalls $(k+1)$-stellige Prädikat $E$ mit
\begin{gather*}
  E(x_1,\dotsc,x_k,y) = (\exists t)_{\leq y} P(x_1,\dotsc,x_k,t)
\end{gather*}
ist wahr genau dann, wenn es (mindestens) ein $t\leq y$ gibt,
für das $P(x_1,\dotsc,x_k,t)$ gilt.
Entsprechend ist
\begin{gather*}
  A(x_1,\dotsc,x_k,y) = (\forall t)_{\leq y} P(x_1,\dotsc,x_k,t)
\end{gather*}
wahr genau dann, wenn $P(x_1,\dotsc,x_k,t)$ für alle $t\leq y$ wahr ist.
Diese beschränkten Quantoren können durch primitiv-rekursive Konstrukte
beschrieben werden.

\begin{satz}
  Sei $P\colon\N^{k+1}\rightarrow\N$ ein primitiv-rekursives
  Prädikat.
  Dann sind auch die folgenden mit beschränkten Quantoren definierten
  Prädikate primitiv-rekursiv.
  \begin{gather*}
    (\exists t)_{\leq y} P(x_1,\dotsc,x_k,t)
       \qquad\text{und}\qquad
       (\forall t)_{\leq y} P(x_1,\dotsc,x_k,t)\ \ .
  \end{gather*}
\end{satz}

\begin{proof}
  Beim Summieren aller Werte $P(x_1,\dotsc,x_k,t)$ für alle $t=0,1,2,\dotsc,k$
  erhält man einen Wert größer $0$ genau dann, wenn es ein $t\leq y$ mit $P(x_1,\dotsc,x_k,t)$
  gibt.
  Also gilt
  \begin{align*}
    (\exists t)_{\leq y} P(x_1,\dotsc,x_k,t)
    & = \bigg( \Big[\sum_{t=0}^y P(x_1,\dotsc,x_k,t)\Big] \ne 0 \bigg) \\
    & = 1 \dminus \alpha \Big(\sum_{t=0}^y P(x_1,\dotsc,x_k,t)\Big)
  \end{align*}

  Entsprechend ist das Produkt aller Werte $P(x_1,\dotsc,x_k,t)$ für alle $t=0,1,2,\dotsc,k$
  gleich $1$ genau dann, wenn $P(x_1,\dotsc,x_k,t)$ für alle $t=0,1,2,\dotsc,k$ gilt.
  Also gilt
  \begin{align*}
    (\forall t)_{\leq y} P(x_1,\dotsc,x_k,t)
    & = \bigg(\Big[\prod_{t=0}^y P(x_1,\dotsc,x_k,t)\Big] = 1 \bigg) \\
    & = \prod_{t=0}^y P(x_1,\dotsc,x_k,t)
  \end{align*}
\end{proof}

Als Beispiel betrachten wird das Teilbarkeitsprädikat $y|x$ ("`$y$ teilt $x$"').
$y|x$ ist wahr genau dann, wenn es ein $t\leq x$ gibt, so dass $t\cdot y=x$.
Das dreistellige Prädikat  $P$ mit
\begin{gather*}
  P(x,y,t)= (t\cdot y=x)
\end{gather*}
ist primitiv-rekursiv.
Nach obigem Satz ist dann auch das Prädikat
\begin{gather*}
  Q(x,y,z) = (\exists t)_{\leq z} P(x,y,t)
\end{gather*}
primitiv-rekursiv.
Das Teilbarkeitsprädikat $T(x,y)= (y|x)$
lässt sich informell beschreiben als
\begin{gather*}
  T(x,y)=Q(x,y,y)\ \ .
\end{gather*}
Formal entsteht es durch Komposition aus $Q$ und Projektionsfunktionen
\begin{gather*}
  T(x,y) = Q\big(U^{(2)}_1(x,y),U^{(2)}_2(x,y),U^{(2)}_2(x,y)\big) \ \ \ .
\end{gather*}

Der beschränkte Allquantor kann zur Beschreibung der Primzahleigenschaft
benutzt werden.
Das Prädikat $\prim(x)$ ist wahr genau dann, wenn $x$ eine Primzahl ist.
$x$ ist eine Primzahl genau dann, wenn jeder Teiler von $x$ entweder $1$
oder $x$ ist. Da $x$ keinen größeren Teiler als sich selbst besitzen kann,
folgt
\begin{gather*}
  \prim(x) =  x>1 \wedge
  (\forall t)_{\leq x} \big(t=1 \vee t=x \vee \neg(t|x)\big) \ \ \ .
\end{gather*}


\subsection{Beschränkte Minimierung}

Der Existenzquantor liefert nur eine Antwort darauf,
ob eine Zahl mit einer bestimmten Eigenschaft existiert.
Oft will man eine solche Zahl auch benutzen.
Sie wird vom $\min$-Konstruktor geliefert,
der wie folgt definiert ist.
Sei $P\colon\N^{k+1}\rightarrow\N$
ein $(k+1)$-stelliges Prädikat.
Dann ist $\min P\colon\N^k\rightarrow\N$ eine Funktion mit
\begin{gather*}
  \min_{t\leq y} P(x_1,\dotsc,x_k,t) =
     \begin{cases}
       t, & \begin{minipage}[t]{100mm}
         falls es ein $t\leq y$ gibt mit \\$P(x_1,\dotsc,x_k,t)$
         und $\neg P(x_1,\dotsc,x_k,s)$ für $s=0,\dotsc,t-1$
       \end{minipage} \\[0.5ex]
       0, & \mbox{sonst}
     \end{cases}
\end{gather*}

Der $\min$-Konstruktor kann zum Beispiel zur Beschreibung der ganzzahligen
Division
\begin{gather*}
  \left\lfloor \frac{x}{y} \right\rfloor\ \ = \ \ 
     \text{die größte ganze Zahl kleiner oder gleich\  \ } \frac{x}{y}
\end{gather*}
benutzt werden.
Es gilt
\begin{gather*}
  \left\lfloor \frac{x}{y} \right\rfloor \cdot y \leq x <
     \left(\left\lfloor \frac{x}{y} \right\rfloor +1\right)\cdot y \ \ .
\end{gather*}
Also ist $\lfloor \frac{x}{y} \rfloor$ die kleinste natürliche Zahl $t$
mit $(t+1)\cdot y > x$.
Formaler aufgeschrieben gilt
\begin{gather*}
  \left\lfloor \frac{x}{y} \right\rfloor =
     \min\limits_{t\leq x}\left[(t+1)\cdot y > x \right] \ \ \ .
\end{gather*}
Damit lässt sich nun auch die mod-Operation einfach darstellen.
\begin{gather*}
  x \bmod y \ \ =\ \  x \dminus \left( y\cdot\left\lfloor\frac{x}{y}\right\rfloor \right)
\end{gather*}

Die beschränkte Minimierung lässt sich mit den
Mitteln primitiv-rekursiver Funktionen beschreiben.

\begin{satz}
  Sei $P\colon\N^{k+1}\rightarrow\N$ ein primitiv-rekursives
  Prädikat und $f\colon\N^{k+1}\rightarrow\N$ sei definiert als
  \begin{gather*}
    f(y,x_1,\dotsc,x_k) = \min\limits_{t\leq y} P(x_1,\dotsc,x_k,t)\ .
  \end{gather*}
  Dann ist $f$ primitiv-rekursiv.
\end{satz}


\begin{proof}
  Zuerst betrachten wir den Fall, dass $P(x_1,\dotsc,x_k,t)$ für ein $t\leq y$ gilt,
  und sei $t_0 = \min\limits_{t\leq y} P(x_1,\dotsc,x_k,t)$.
  Dann ist $P(x_1,\dotsc,x_k,u)=0$ für $u=0,1,2,\dotsc,t_0-1$.
  Damit folgt für alle $s=0,1,2,\dotsc,t_0-1$
  \begin{gather*}
    \sum_{u=0}^{s} P(x_1,\dotsc,x_k,u) \ \ =\ \  0 \ \ .
  \end{gather*}
  Wegen $P(x_1,\dotsc,x_k,t_0)=1$ folgt für alle $s=t_0,t_0+1,\dotsc,y$
  \begin{gather*}
    \sum_{u=0}^{s} P(x_1,\dotsc,x_k,s) \ \ \geq\ \  1 \ \ .
  \end{gather*}
  Also gilt
  \begin{align*}
    t_0 & = \text{Anzahl aller $s\leq y$ mit\ }
       \sum_{u=0}^s P(x_1,\dotsc,x_k,u) = 0 \\
    & = \sum_{s=0}^y\  \alpha\Big(\sum_{u=0}^s P(x_1,\dotsc,x_k,u)\Big)
  \end{align*}



  Das schreiben wir als
  Funktion $g\colon\N^{k+1}\rightarrow\N$ auf.
  Definiere
  \begin{gather*}
    g(y,x_1,\dotsc,x_k) = \sum_{s=0}^y
       \alpha\Big(\sum_{u=0}^s P(x_1,\dotsc,x_k,u)\Big) \ \ .
  \end{gather*}
  Da $P$ primitiv-rekursiv ist, ist $g$ ebenfalls primitiv-rekursiv.
  Durch Fallunterscheidung kann jetzt noch der Fall abgefangen werden,
  dass das gesuchte Minimum nicht existiert.
  Damit ergibt sich
  \begin{gather*}
    f(y,x_1,\dotsc,x_k) =
       \begin{cases}
         g(y,x_1,\dotsc,x_k), &
         \text{falls $(\exists t)_{\leq y} P(x_1,\dotsc,x_k,t)$} \\
         0, & \sonst
    \end{cases}
  \end{gather*}
  Also ist $f$ primitiv-rekursiv.
\end{proof}

Als weiteres Beispiel für die Benutzung des $\min$-Operators
zeigen wir, dass die Funktion $p\colon\N\rightarrow \N$ mit
\begin{gather*}
  p(n)\ \ =\ \ \mbox{die $n$-te Primzahl}
\end{gather*}
primitiv-rekursiv ist.
Die unendliche Folge von Primzahlen beginnt mit $2,3,5,7,11,13$.
Die erste Primzahl ist also $2$, d.\,h.~$p(1)=2$.
Da es keine $0$te Primzahl gibt, die Funktion $p$ aber
trotzdem auf $\N$ -- also auch für $0$ -- definiert sein soll,
setzen wir einfach $p(0)=0$ fest.
Aus dem (oder besser: einem) Beweis des Satzes,
dass es unendlich viele Primzahlen gibt, folgt
$p(n+1)\leq p(n)!+1$.
Damit ist schon mal eine Schranke gefunden, bis zu der
nach der nächsten Primzahl gesucht werden muss.
Dann ist $p(n+1)$ die kleinste Zahl $t\leq p(n)!+1$,
die größer als $p(n)$ und eine Primzahl ist.
Als einen ersten informellen Ansatz beschreiben wir die Funktion $p$ damit wie folgt.
\begin{align*}
  p(0) & = 0 \\
  p(n+1) & = \min_{t\leq p(n)!+1}
     \left[ \prim(t) \wedge t> p(n) \right]
\end{align*}

Formaler definieren wir zunächst eine primitiv-rekursive Funktion $h$ mit
\begin{gather*}
  h(y,z) = \min_{t\leq z} \left[ \prim(t) \wedge t>y\right]
\end{gather*}
und darüber die Funktion $q$ mit
\begin{gather*}
  q(y,m) = h(m, m!+1) \ \ .
\end{gather*}
Damit gilt schließlich
\begin{align*}
  p(0) & = 0 \\
  p(n+1) & = q(n,p(n)) \ \ \ .
\end{align*}


% 2006-07-11

\subsection{Kodieren und Dekodieren von Folgen von natürlichen Zahlen}

Primzahlen können zur Kodierung von Folgen von natürlichen Zahlen
durch natürliche Zahlen verwendet werden.
Die Folge $a_{0}, a_{1},\dotsc,a_{n}$ mit $a_{n}\ne 0$ wird kodiert als
$2^{a_{0}}\cdot 3^{a_{1}}\cdot 5^{a_{2}}\dotsm p_{n}^{a_{n}}$, wobei
$p_{i}$ die $i$-te Primzahl ist ($p_{0}=2$).
Da die Zerlegung von natürlichen Zahlen in Primfaktoren eindeutig ist,
lassen sich die einzelnen Elemente der Folge dekodieren.
Die Funktion zur Dekodierung ist primitiv-rekursiv.
\begin{gather*}
  dek(m,i) = \text{~die Potenz von $p_{i}$ in der
     Primfaktorenzerlegung von $m$~} = \min_{i\leq m} \neg (
     (p_{i})^{i+1} | m)\\
  dek(36,2) = 0\\
  dek(42,3 = 1
\end{gather*}
Für $dek(m,i)$ benutzen wir als vereinfachende Schreibweise $(m)_{i}$.

Die Länge einer kodierten Folge lässt sich primitiv-rekursiv berechnen.
\begin{gather*}
  lh(m) = \text{~der größte Index $i$ in einer Primzahl $p_{i}$ in der
     Primfaktorenzerlegung von $m$}\\
  lh(2^{3}\cdot 3^{7}\cdot 11^{8}) = 4\\
  lh(m) = \sum_{j=1}^{m} \big( \underbrace{(\exists i)_{\leq m}
     (p_{i}| m\wedge i\geq j)}_{=1, \text{falls $m$ Primfaktor $p_{i}$
     mit $i>j$}, =0 \text{sonst}} \big)
\end{gather*}

Die \emph{Konkatenation} von zwei kodierten Folgen $m = 2^{a_{0}}\cdot
3^{a_{1}}\dotsm p_{k}^{a_{k}}$ und $q = 2^{b_{0}} \cdot 3^{b_{1}} \dotsm
p_{l}^{b_{l}}$ ist $m\ast q = 2^{a_{0}}\cdot 3^{a_{1}}\dotsm
p_{k}^{a_{k}}\cdot p_{k+1}^{b_{0}} \cdot p_{k+2}^{b_{1}} \dotsm
p_{k+l+1}^{b_{l}}$.
\begin{gather*}
  m\ast q = m\cdot \prod_{i=0}^{lh(q)} (p_{lh(m)+i+1})^{(q)_{i}}
\end{gather*}
Offensichtlich ist die Konkatenation assoziativ: $(m\ast q)\ast r = m\ast
(q\ast r)$.

\begin{defini}
  Um später die allgemeine Rekursion einzuführen definieren wir
  \begin{gather*}
    f\#(y) = 2^{f(0)} \cdot 3^{f(1)}\dotsm p_{y-1}^{f(y-1)} =
       \prod_{i=0}^{y-1} p_{i}^{f(i)}
  \end{gather*}
  für eine beliebige Funktion $f\colon\N\rightarrow\N$.
\end{defini}

Sei $h$ eine primitiv-rekursive Funktion, so dass $f(n) = h(n, f\#(n))$,
dann ist $f$ primitiv-rekursiv. (Intention: Man kann bei der Rekursion auf
beliebige Vorgängerwerte zurückgreifen)

\begin{lemma}
   $f\#$ ist primitiv-rekursiv.

  \begin{proof}
    $f$ sei eine beliebige Funktion auf den natürlichen Zahlen.
    \begin{align*}
      f\#(0) &= 1 &\text{(leeres Produkt)}\\
      f\#(n+1) & = f\#(n) \cdot p_{n}^{f(n)} = f\#(n) \cdot p_{n}^{h(n,
         f\#(n))}
    \end{align*}
    Also ist $f\#$ primitiv-rekursiv.
  \end{proof}
\end{lemma}

Da $f(n) = h(n, f\#(n))$, ist $f$ ebenfalls primitiv-rekursiv.


\subsection{Exkurs: Unbeschränkte Minimierung und rekursive Funktionen}

Verzichtet man auf die obere Schranke für das gesuchte Minimum,
dann kann der Funktionswert von $\min P$ undefiniert sein.
\begin{gather*}
  \min\limits_{y} P(x_1,\dotsc,x_k,y) =
     \begin{cases}
       \min\{t\mid P(x_1,\dotsc,x_k,t)\}, &
         \exists t\in\N\colon P(x_1,\dotsc,x_k,t) \wedge\\
       & \forall s<t, s\in\N\colon\neg P(x_1,\dotsc,x_k,s)\\
       \uparrow, & \text{sonst}
     \end{cases}
\end{gather*}
Die Funktion $g$ mit
\begin{gather*}
  g(x_1,\dotsc,x_k) = \min\limits_y P(x_1,\dotsc,x_k,y)
\end{gather*}
entsteht aus $P$ durch (unbeschränkte) Minimierung.

Die Subtraktionsfunktion auf den ganzen Zahlen
liefert für $x-y<0$ keinen Funktionswert und kann
auf den natürlichen Zahlen an diesen Stellen als undefiniert aufgefasst werden.
Formal kann das ausgedrückt werden durch
\begin{gather*}
  x-y = \min\limits_z\big[ x=y+z \big] \ \ .
\end{gather*}
Nimmt man Minimierung als zusätzlichen Konstruktor zu den
für primitiv-rekursive Funktionen benutzten Konstruktoren,
dann wird eine
neue Klasse von Funktionen definiert.

\begin{defini}[rekursive Funktion]
  Eine Funktion heißt \emph{rekursiv}, falls sie
  \begin{enumerate}
   \item die Nullfunktion, die Nachfolgerfunktion, oder
    eine Projektionsfunktion ist, oder
   \item mittels Komposition, Rekursion oder
    Minimierung aus rekursiven Funktionen entsteht.
  \end{enumerate}
\end{defini}

Offensichtlich ist jede primitiv-rekursive Funktion auch rekursiv.
Es gibt jedoch rekursive Funktionen, die nicht primitiv-rekursiv sind.
Die überall undefinierte Funktion $\omega\colon\N\rightarrow\N$
ist rekursiv, da sie wie folgt definiert werden kann.
\begin{gather*}
  \omega(n) = \min\limits_t[t+1=0]
\end{gather*}
Alle primitiv-rekursiven Funktionen sind total.
Also ist $\omega$ nicht primitiv-rekursiv.
Es gibt aber auch totale rekursive Funktionen, die
nicht primitiv-rekursiv sind.
Ein bekanntes Beispiel ist die Ackermann-Funktion
$A\colon\N^2\rightarrow\N$.
Sie wächst stärker als jede primitiv-rekursive Funktion.
Allerdings ist es auch nicht ganz leicht zu zeigen,
dass die Ackermann-Funktion rekursiv ist.
\vspace{1ex}

\hspace{15mm}\begin{tabular}{rcll}
  $A(0,y)$ & $=$ & $1$ & für jedes $y\geq 0$ \\
  $A(1,0)$ & $=$ & $2$ & \\
  $A(x,0)$ & $=$ & $x+2$ & für $x\geq 2$ \\
  $A(x+1,y+1)$ & $=$ & $A(A(x,y+1),y)$ & für $x\geq 0$ und $y\geq 0$
\end{tabular}


% 2006-06-28

\section{Repräsentierbarkeit von Relationen und Funktionen in
  \texorpdfstring{$\mathrm{S}$}{S}}


Eine $k$-stellige Relation auf den natürlichen Zahlen
ist eine Menge $R\subseteq\N^k$.
Eine $k$-stellige Funktion auf den natürlichen Zahlen
ist eine Funktion $f\colon\N^k\rightarrow \N$.

\begin{defini}[Repräsentierbarkeit in $\mathrm{S}$]
  Eine $k$-stellige Relation $R$ auf den natürlichen Zahlen
  heißt \emph{repräsentierbar} in $\mathrm{S}$,
  falls es eine Formel $\alpha$ in $\mathrm{S}$
  mit folgenden Eigenschaften gibt.
  \begin{enumerate}
   \item $\alpha$ hat die freien Variablen $x_1,\dotsc,x_k$, und
   \item für alle $n_1,\dotsc,n_k\in\N$ gilt:
    \begin{itemize}
     \item[(1)] falls $(n_1,\dotsc,n_k)\in R$,
      dann $\Svdash \alpha[x_1/\overline{n_1},\dotsc,x_k/\overline{n_k}]$
     \item[(2)] falls $(n_1,\dotsc,n_k)\notin R$,
      dann $\Svdash \neg \alpha[x_1/\overline{n_1},\dotsc,x_k/\overline{n_k}]$
    \end{itemize}
  \end{enumerate}
\end{defini}

\begin{bsp}
  Die Gleichheitsrelation $=$ ist repräsentierbar in $\mathrm{S}$.
  Sie wird repräsentiert durch die Formel $x_1=x_2$ (nennen wir $\alpha_{=}$).
  Wir haben bereits gesehen, dass folgende Eigenschaften
  für alle natürlichen Zahlen $n$ und $m$ gelten.
  \begin{itemize}
   \item[(1)] falls $n=m$, dann gilt $\Svdash\overline{n}=\overline{m}$
    (also $\Svdash \alpha_{=}[x_1/\overline{n}, x_2/\overline{m}]$)
   \item[(2)] falls $n\ne m$, dann gilt $\Svdash\neg(\overline{n}=\overline{m})$
    (also $\Svdash \neg \alpha_{=}[x_1/\overline{n}, x_2/\overline{m}]$)
  \end{itemize}

  Die Kleinerrelation $<$ ist repräsentierbar in $\mathrm{S}$ durch $x_{1} < x_{2}$
  (steht für   $(\exists z ~ z\ne0\wedge x_{1}+z=x_{2})$).

  Seien $n_{1},n_{2}\in\N$.
  \begin{faelle}
   \item $n_{1}<n_{2}$. Dann gibt es ein $b\in\N$ mit $n_1+b=n_2$.
    Es ist $\Svdash \exists z ~ z\ne0 \wedge\overline{n_{1}}+z=\overline{n_{2}}$
    zu beweisen
    \begin{align*}
      (1)\quad &\overline{n_{1}} + \overline{b} = \overline{n_{1}}
         &  \text{\autoref{lemma-numerale1}}\\
      (2)\quad &\overline{b} \ne 0 &    \text{Axiom}\\
      (3)\quad &\overline{b} \ne 0 \wedge
         \overline{n_{1}} + \overline{b} = \overline{n_{1}}  &
         \text{Konjunktionsregel}\\
      (4)\quad & \exists z ~ z\ne 0 \wedge \overline{n_{1}} + z = \overline{n_{1}}  &
         \text{RE4}\\
    \end{align*}

   \item $n_{1}\not< n_{2}$. Es ist $\Svdash \neg(\exists z ~ z\ne 0
    \wedge \overline{n_{1}} + z = \overline{n_{2}})$ zu beweisen.
    \begin{enumerate}
     \item $n_{1}=n_{2}$
      \begin{align*}
        (1)\quad & \overline{n_{1}} = \overline{n_{2}} &\text{Lemma}\\
        (2)\quad & \overline{n_{2}} < \overline{n_{1}} \vee
           \overline{n_{1}} = \overline{n_{2}} & \text{Disjunktionsregel}
      \end{align*}

     \item $n_{2}<n_{1}$
      \begin{align*}
        (1)\quad &\overline{n_{2}} < \overline{n_{1}} &\text{wie oben}\\
        (2)\quad &\overline{n_{2}} < \overline{n_{1}} \vee
           \overline{n_{1}} = \overline{n_{2}} & \text{Disjunktionsregel}
      \end{align*}
    \end{enumerate}

    Also gilt: Wenn $n_{1}\not< n_{2}$, dann $\Svdash \overline{n_{2}}<
    \overline{n_{1}}\vee \overline{n_{1}}=\overline{n_{2}}$. Daraus folgt
    (mit einigem Aufwand) $\Svdash\neg (\overline{n_{1}} <
    \overline{n_{2}})$
  \end{faelle}
\end{bsp}

\begin{defini}
  Eine $k$-stellige Funktion $f$ auf den natürlichen Zahlen
  heißt \emph{repräsentierbar} in $\mathrm{S}$,
  falls es eine Formel $\alpha$ in $\mathrm{S}$
  mit folgenden Eigenschaften gibt.
  \begin{enumerate}
   \item $\alpha$ hat die freien Variablen $x_1,\dotsc,x_k,x_{k+1}$, und
   \item für alle $n_1,\dotsc,n_k,m\in\N$ gilt:
    \begin{itemize}
     \item[(1)] falls $f(n_1,\dotsc,n_k)=m$,
      dann $\Svdash \alpha[x_1/\overline{n_1},\dotsc,x_k/\overline{n_k},x_{k+1}/\overline{m}]$, und
     \item[(2)] $\Svdash (\exists_1 x_{k+1}~ \alpha[x_1/\overline{n_1},\dotsc,x_k/\overline{n_k}])$

      $(\exists_1 x ~ \alpha)$ ist abkürzende Schreibweise für
      $(\exists x~\alpha) \wedge (\forall x~ \forall y ~ (\alpha\wedge\alpha[x/y])\rightarrow x=y)$.
      Es wird ausgedrückt, dass \textit{genau ein $x$} existiert, das die in $\alpha$ beschriebenen
      Eigenschaften besitzt.
    \end{itemize}
  \end{enumerate}
  $f$ heißt \emph{streng repräsentierbar}, falls Eigenschaft (2)
  durch die folgende Eigenschaft ersetzt werden kann:
  \begin{itemize}
   \item[(2')] $\Svdash (\exists_1 x_{k+1}~ \alpha)$
  \end{itemize}
\end{defini}


\begin{bsp}
  Die Additionsfunktion $f\colon\N^2\rightarrow\N$ mit $f(a,b) = a +b$
  ist streng repräsentierbar in $\mathrm{S}$.
  $f$ wird repräsentiert durch die Formel $\alpha$:
  \begin{gather*}
    x_{1} + x_{2} = x_{3} ~ ~ .
  \end{gather*}
  \begin{enumerate}
  \item Für alle $n_1,n_2\in\N$ gilt
      $\Svdash \alpha\left[x_1/\overline{n_1}, x_2/\overline{n_2}, x_3/\overline{f(n_1,n_2)}\right]$,
      d.\,h. $\Svdash \overline{n_1} + \overline{n_2} = \overline{n_1+n_2}$

   \item[2'.] zu zeigen: $\Svdash \exists_{1} x_{3}~ x_{1}+x_{2}=x_{3}$,
    d.\,h. $\Svdash (\exists x_{3} ~ x_{1}+x_{2}=x_{3}) \wedge
    (\forall x_{3} \forall x_{4} ~ x_{1}+x_{2}=x_{3}\wedge
    x_{1}+x_{2}=x_{4} \rightarrow x_{3}=x_{4})$.

    Erster Term:
    \begin{align*}
      (1)\quad & x_{1}+x_{2}= x_{1}+x_{2} &\text{Lemma}\\
      (2)\quad & \exists x_{3} ~ x_{1}+x_{2}=x_{3} &\text{RE4}
    \end{align*}

    Der zweite Term folgt aus der Symmetrie und der Transitivität der
    Gleichheitsrelation.
  \end{enumerate}

  Die Dekrementfunktion $f\colon\N\rightarrow\N$ mit
  \begin{gather*}
    f(n) =
       \begin{cases}
         0 &\text{falls~} n=0\\
         n-1 &\text{sonst}
       \end{cases}
  \end{gather*}
  ist repräsentierbar durch $(x_{1}=0\wedge x_{2}=0) \vee x_{1}=x_{2}'$.

  \begin{enumerate}
   \item
    \begin{enumerate}
     \item $n=0$:
      $\begin{array}[t]{lll}
        (1) & 0=0 & \text{Lemma}\\
        (2) & 0=0 \wedge 0=0 & \text{(1), Konjunktionsregel}\\
        (3) & (0=0\wedge 0=0) \vee 0\ne0 &\text{(2), Disjunktionsregel}
      \end{array}$

     \item $n>0$:
      $\begin{array}[t]{lll}
        (1) & \overline{n} = \overline{n+1} & \text{Lemma}\\
        (2) & (\overline{n}+0 \wedge \overline{n}=0) \vee
           \overline{n} = \overline{n}' &\text{Disjunktionsregel}
      \end{array}$
    \end{enumerate}

   \item zu zeigen ist noch  $\Svdash\exists_{1}
    x_{2} ~ (x_{1}=0\wedge x_{2}=0) \vee x_{1}=x_{2}'$
  \end{enumerate}
\end{bsp}

Die Nullfunktion, die Nachfolgerfunktion und die Projektionsfunktionen
bilden die Basisfunktionen der primitiv-rekursiven Funktionen.
Wir zeigen, dass diese Funktionen repräsentierbar sind.


Die konstante Nullfunktion $Z\colon\emptyset\rightarrow\N$ mit
$Z(\,)=0$ für alle $n\in\N$
ist streng repräsentierbar in $\mathrm{S}$.
$Z$ wird repräsentiert durch die Formel
$x_1=0$.
Für $Z(\,)=m$ gilt $m=0$,
und $\Svdash 0=0$
folgt aus \autoref{lemma-zahlen-elem}(a).
Es bleibt noch $\Svdash (\exists_1 x_{1}~ x_1=0)$
zu zeigen, also
$(\exists x_1~ x_1=0) \wedge (\forall x_1 ~ \forall y ~
(x_1=0 \wedge y=0) \rightarrow x_1=y)$.
Der erste Teil $(\exists x_1~ x_1=0)$
folgt aus $\Svdash 0=0$ (\autoref{lemma-zahlen-elem}(a)) und Regel RE4.
Für den zweiten Teil führen wir folgenden Beweis.
$
\begin{array}[t]{cll}
  (1) & x_1=0 \wedge y=0 & \text{Hypothese} \\
  (2) & x_1=0 & \text{(1), Konjunktionsregel} \\
  (3) & y=0   & \text{(1), Konjunktionsregel} \\
  (4) & x_1=y & \text{(2), (3), Trans. und Symm. von $=$} \\
\end{array}
$

Daraus folgt mittels Deduktionstheorem und Generalisierung der zweite Teil.
Mittels Konjunktionsregel fügen sich die beiden Teile
zur gewünschten Formel zusammen.

Die Nachfolgerfunktion $N\colon\N\rightarrow\N$ mit $N(n) = n+1$ ist repräsentierbar
\begin{gather*}
  \alpha_{N}\colon x_{2}= x_{1}'
\end{gather*}

Die Projektionsfunktion $U_{i}^{(k)}\colon \N^{k}\rightarrow\N$ mit
$U_{i}^{(k)}(n_{1},\dotsc,n_{k})=n_{i}$ ist repräsentierbar
\begin{gather*}
  \alpha_{U_{i}^{(k)}}\colon x_{1}=x_{1}\wedge \dotsb x_{k}=x_{k} \wedge
     x_{k+1}=x_{i}
\end{gather*}

Fügt man repräsentierbare Funktionen mittels Komposition zusammen,
dann erhält man wiederum repräsentierbare Funktionen.

Die Komposition von Funktionen: Seien $g\colon \N^{k} \rightarrow \N$
und $h_{1},\dotsc,h_{m}\colon \N^{k}\rightarrow\N$ repräsentierbar
durch $\alpha, \beta_{1},\dotsc,\beta_{m}$. Definiere $f\colon
\N^{k}\rightarrow\N$ durch
\begin{gather*}
  f(n_{1},\dotsc,n_{k}) = g(h_{1}(n_{1},\dotsc,n_{k}),
     h(n_{1},\dotsc,n_{k}))
\end{gather*}
Dann ist $f$ repräsentierbar durch
\begin{gather*}
  \exists y_{1} \dotso \exists y_{n} ~
     \beta_{1}(x_{1},\dotsc,x_{k},y_{1}) \wedge \dotsb \wedge
     \beta_{n}(x_{1},\dotsc,x_{k},y_{n}) \wedge
     \alpha(y_{1},\dotsc,y_{n}, y_{k+1})
\end{gather*}




% 2006-07-04
%
%\section{Primitiv-rekursive Funktionen sind in S repräsentierbar}

Wir haben bereits gesehen, dass
die Nullfunktionen, die Nachfolgerfunktion und die
Projektionsfunktionen in $\mathrm{S}$ repräsentierbar sind.
Außerdem haben wir gesehen, dass jede Funktion, die durch Komposition aus
in $\mathrm{S}$ repräsentierbaren Funktionen entsteht,
ebenfalls in $\mathrm{S}$ repräsentierbar ist.
Es bleibt also noch zu zeigen,
dass auch mittels Rekursion entstandene Funktionen diese Eigenschaft haben.
Der \glqq{}Trick\grqq{} liegt hier in der
Kodierung der Zwischenergebnisse, die bei der Berechnung
einer rekursiv definierten Funktion anfallen.

Dazu verwenden wir eine Folgerung aus dem Chinesischen Restsatz.

\begin{korol}[Folgerung aus dem Chinesischen Restsatz]\label{korol-chin-restsatz}
  Seien $x_1,\dotsc,x_k$ paarweise teilerfremde natürliche Zahlen,
  und $y_1,\dotsc,y_k$ seien natürliche Zahlen mit $y_i<x_i$.
  Dann gibt es eine natürliche Zahl $z<x_1\cdot x_2 \dotsm x_k$, so dass
  für alle $i=1,2,\dotsc,k$ gilt:
  $y_i = z \bmod x_i$.
\end{korol}

\autoref{korol-chin-restsatz} kann wie folgt zur Kodierung
einer Folge $k_0,k_1,\dotsc,k_m$ von natürlichen Zahlen verwendet werden.

\begin{enumerate}
 \item bestimme $j=\max(m,k_0,k_1,\dotsc,k_m)+1$
 \item die Zahlen $u_0,u_1,\dotsc,u_m$ mit $u_i=(i+1)\cdot j! +1$
  sind paarweise teilerfremd, und es gilt $k_i<u_i$
  \begin{quote}
    \small Sei angenommen, dass $u_i$ und $u_k$ nicht teilerfremd sind (für $i<k$).
    Dann gibt es eine Primzahl $p$, die sowohl $u_i$ als auch $u_k$ teilt.
    Dann ist $p$ auch Teiler von $u_k-u_i=(k-i)\cdot j!$.
    $p$ ist kein Teiler von $j!$, da $p$ dann sowohl ein Teiler
    von $(i+1)\cdot j!$ als auch von $u_i=(i+1)\cdot j!+1$ wäre, woraus $p=1$ folgte.
    $p$ ist auch kein Teiler von $k-i$, da $k-i<j$ und deshalb jeder Teiler von $k-i$
    ebenfalls ein Teiler von $j!$ ist.
    Da $p$ eine Primzahl ist, kann $p$ also kein Teiler von $(k-i)\cdot j!$ sein:
    Widerspruch.
  \end{quote}
 \item durchlaufe für $z$ die Zahlen $1,2,\dotsc,k_0\cdot k_1\dotsm k_m$,
  bis ein $z$ mit $k_i = z \bmod u_i$ gefunden wurde
\end{enumerate}

Der Chinesische Restsatz garantiert, dass das gesuchte $z$ auch
tatsächlich existiert.

\begin{bsp}
  Es soll die Folge $2,1,1$ kodiert werden.

  Zuerst wird $j=\max(2,2,1,1)+1=3$ bestimmt.
  Damit ergibt sich $u_0=1\cdot j!+1=7$,
  $u_1=2\cdot j!+1=13$ und $u_2=3\cdot j!+1=19$.
  Für $z$ erhalten wir dann den Wert $z=989$.
  Es gilt $989 \bmod 7=2$, $989 \bmod 13 = 1$ und $989 \bmod 19 = 1$.
\end{bsp}

Zur Dekodierung dient Gödels $\beta$-Funktion
$\beta\colon\N^3\rightarrow \N$ mit
\begin{gather*}
  \beta(z,c,i) ~ = ~ z \bmod \left(\left(i+1\right)\cdot c +1\right) \ \ .
\end{gather*}
Für die nach obiger Methode kodierten $k_i$ gilt $k_i=\beta(z,j!,i)$.
Die $\beta$-Funktion ist repräsentierbar in $\mathrm{S}$.
Dazu schauen wir uns die Definition der $\beta$-Funktion nochmal an.
Für gegebenes $z$, $c$ und $i$ gibt es (genau) ein $w\in\N$ mit
\begin{gather*}
  z ~=~ w \cdot \left(\left(i+1\right)\cdot c +1\right)  + \beta(z,c,i) \ \ .
\end{gather*}
Außerdem gilt $\beta(z,c,i) \leq \left(i+1\right)\cdot c +1$.
Damit haben wir die Bestandteile der folgenden Formel
$Bt(x_1,x_2,x_3,x_4)$, die die $\beta$-Funktion
repräesentiert.
\begin{gather*}
  (\exists w ~ x_1=w\cdot(x_3'\cdot x_2)'+x_4)~ \wedge~ x_4<(x_3'\cdot x_2)'  \ \ .
\end{gather*}
Wir werden nun die Repräsentation der $\beta$-Funktion benutzen,
um durch Rekursion entstandene Funktionen zu repräsentieren.

Sei $f\colon\N^{k+1}\rightarrow\N$ aus $g\colon\N^k\rightarrow \N$ und
$h\colon\N^{k+2}\rightarrow \N$ mittels Rekursion entstanden.
\begin{align*}
  f(x_1,\dotsc,x_n,0) & = g(x_1,\dotsc,x_n) \\
  f(x_1,\dotsc,x_n,y+1) & = h(y,f(x_1,\dotsc,x_n,y), (x_1,\dotsc,x_n))
\end{align*}
$g$ und $h$ seien durch $\gamma(x_1,\dotsc,x_{n+1})$ und
$\delta(x_1,\dotsc,x_{n+3})$ repräsentierbar.
Man kann sich die Berechnung von $f(k_1,\dotsc,k_n,m)$
mittels folgendem \glqq{}Programm\grqq{} vorstellen.

\begin{quote}
  $v_0 := g(k_1,\dotsc,k_n)$ \\
  für $i:=1,2,\dotsc,m$ wiederhole\\
  $\{$ \\
  \rule{10mm}{0mm} $v_i:=h(i-1,v_{i-1},k_1,\dotsc,k_n)$ \\
  $\}$
\end{quote}
Dann ist $f(k_1,\dotsc,k_n,m)=v_m$.

Wir betrachten die vom Programm berechnete
Zahlenfolge $v_0,v_1,\dotsc,v_m$
kodiert als Zahl $z$ mit $v_i=\beta(z,c,i)$.
Dann gilt (umgangssprachlich ausgedrückt)
\begin{gather*}
  \beta(z,c,0)=g(k_1,\dotsc,k_n) ~ \wedge ~
     (\forall i  ~ i<m \rightarrow \beta(z,c,i+1)=h(i,\beta(z,c,i),k_1,\dotsc,k_n))
\end{gather*}
Daraus entwickeln wir nun die Formel, die die
Funktion $f$ repräsentiert.

$\beta(z,c,0)=g(k_1,\dotsc,k_n)$ wird ausgedrückt durch
$(\exists w ~ Bt(z,c,0,w) \wedge \gamma(x_1,\dotsc,x_n,w)$.
Dabei sind $z$ und $c$ Variablensymbole, die
genau die durch die Kodierung intendierten Werte annehmen sollen.

$\beta(z,c,i+1)=h(i,\beta(z,c,i),k_1,\dotsc,k_n)$ wird ausgedrückt durch
$(\exists u ~ \exists v ~ Bt(z,c,i,u) \wedge Bt(z,c,i',v) \wedge \delta(i,u,x_1,\dotsc,x_n,v))$.

Schließlich muss noch ausgedrückt werden,
dass $f(k_1,\dotsc,k_n,m)=\beta(z,c,m)$ ist.
Das geschieht durch $Bt(z,c,x_{n+1},x_{n+2})$.

Insgesamt erhalten wir folgende Formel zur Repräsentation von $f$.

$
\begin{array}{rcl}
  \exists z ~ \exists c & & (\exists w ~ Bt(z,c,0,w) \wedge \gamma(x_1,\dotsc,x_n,w)) \\
  & \wedge &
  (\forall i ~ i<m \rightarrow
  (\exists u ~ \exists v ~ Bt(z,c,i,u) \wedge Bt(z,c,i',v) \wedge \delta(i,u,x_1,\dotsc,x_n,v))) \\
  & \wedge & Bt(z,c,x_{n+1},x_{n+2})
\end{array}
$


\begin{satz}[Repräsentierbarkeit primitiv-rekursiver Funktionen in $\mathrm{S}$]
  Jede primitiv-rekursive Funktion ist in $\mathrm{S}$ repräsentierbar.
\end{satz}

(Den Beweis, dass oben angeführte Formel tatsächlich die betrachtete Funktion
repräsentiert, sparen wir uns hier.)

\begin{korol}
  Jedes primitiv-rekursive Prädikat ist in $\mathrm{S}$ repräsentierbar.
\end{korol}


% 2006-07-12

\section{Arithmetisierung}

In der Sprache der Theorie $\mathrm{S}$
können Aussagen über Zahlen gemacht werden.
Im Abschnitt über Abzählbarkeit haben wir gesehen,
dass Formeln auch durch Zahlen kodiert werden können.
Über diesen \glqq{}Umweg\grqq{} lassen sich in $\mathrm{S}$
also auch Aussagen über Formeln und Eigenschaften von Formeln ausdrücken.
In $\mathrm{S}$ können wir die primitiv-rekursiven Funktionen
dazu benutzen, und das werden wir jetzt tun.
Wir beginnen mit der Kodierung von Symbolen,
Ausdrücken und Folgen von Ausdrücken durch natürliche Zahlen
und drücken anschließend Eigenschaften von Formeln
durch primitiv-rekursive Relationen und Funktionen aus.
Ziel ist der Nachweis,
dass das Überprüfen eines Beweises auf Korrektheit primitiv-rekursiv ist.
Das erlaubt einem schließlich,
eine Aussage der Art \glqq{}Formel $\alpha$ ist in $\mathrm{S}$ nicht beweisbar\grqq{}
in $\mathrm{S}$ zu formulieren.


\subsection{Gödelisierung}

Funktion $g$ bildet
\begin{itemize}
\item Symbole,
\item endliche Folgen von Symbolen (=Ausdrücke), und
\item endliche Folgen von Ausdrücken
\end{itemize}
wie folgt injektiv auf $\N$ ab.
\vspace{1ex}

Symbole ($n,k\geq 1$):
\begin{gather*}
  \begin{array}{r|*{10}{|c}}
    u    & ( & ) & , & \neg & \rightarrow & \forall & a_k        & x_k & f^n_k & A^n_k\\[.5mm] \hline
    \rule{0mm}{4mm}
    g(u) & 3 & 5 & 7 &  9   &     11      &   13    & 7+8\cdot k & 13+ 8\cdot k
    & 1+8\cdot(2^n\cdot 3^k) & 3+8\cdot(2^n\cdot 3^k)
  \end{array}
\end{gather*}

$g(u)$ heißt \emph{Gödelnummer} von $u$.

Wenn $u$ ein Symbol ist, dann ist $g(u)$ ungerade.

Für $u\geq 15$ gibt $g(u) \bmod 8$ gibt an, welche
Art von Symbol $u$ ist.


Sei $u_0 u_1 \dotso u_n$ eine endliche Folge von Symbolen.
Dann ist
\begin{gather*}
  g(u_0 u_1 \dotso u_n) = 2^{g(u_0)} \cdot 3^{g(u_1)} \dotsm p_n^{g(u_n)}
      = \prod_{i=0}^{n} p_i^{g(u_i)}
\end{gather*}
wobei $p_i$ die $i$-te Primzahl ist ($p_0=2$).
\vspace{1ex}

Bsp.:\ \  \ $g(\forall x_1~ A_2^1(x_1)) = 2^{13} \cdot 3^{21} \cdot 5^{138}
          \cdot 7^3 \cdot 11^{21} \cdot 13^{5}$
\vspace{1ex}


Das \textit{Symbol} $x_1$ hat GN $g(x_1)=21$ (ist ungerade).


Der \textit{Ausdruck} $x_1$ hat GN $g(x_1)=2^{21}$ (ist gerade).
\vspace{2ex}

Sei $e_0, e_1, \dotsc, e_n$ eine endliche Folge von Ausdrücken.
Dann ist
\begin{gather*}
  g(e_0, e_1, \dotsc, e_n) = 2^{g(e_0)} \cdot 3^{g(e_1)} \dotsm p_n^{g(e_n)}
     = \prod_{i=0}^{n} p_i^{g(e_i)}
\end{gather*}
wobei $p_i$ die $i$-te Primzahl ist ($p_0=2$).
\vspace{2ex}

Bsp.:\ \  \ $g(\forall x_1~ A_2^1(x_1), x_1)
= 2^{(2^{13} \cdot 3^{21} \cdot 5^{138} \cdot 7^3 \cdot 11^{21} \cdot 13^{5})}
  \ \cdot 3^{(2^{21})}$
\vspace{3ex}


Der \textit{Ausdruck} $x_1$ hat GN $g(x_1)=2^{21}$ (ungerade Zweierpotenz).
\vspace{0.5ex}

Die \textit{Folge von Ausdrücken} $x_1$ hat GN
$g(x_1)=2^{2^{21}}$ (gerade Zweierpotenz).


\subsection{Erkennen von Eigenschaften von Symbolen}

Die folgenden Relationen stellen dar, dass
eine Zahl ein Symbol einer bestimmten Art darstellt
(Konstanten-, Variablen-, Funktions- oder Prädikatensymbol)
oder ein Ausdruck aus genau einem solchen Symbol ist.
Für die in $\mathrm{S}$ zugelassenen Symbole sind
diese Relationen primitiv-rekursiv.

\begin{itemize}
\item $IC = \{ n \mid n\mbox{ ist GN eines Konstantensymbols} \}$
\vspace{1ex}

$IC(n)\ = \ (n\geq 15) \wedge (n \bmod 8 = 7)$
\vspace{1ex}

\item $Vb = \{ n \mid n\mbox{ ist GN eines Variablensymbols} \}$
\vspace{1ex}

$Vb(n)\ = \ (n\geq 15) \wedge (n \bmod 8 = 5)$
\vspace{1ex}

\item $FL = \{ n \mid n\mbox{ ist GN eines Funktionssymbols} \}$
\vspace{1ex}

$FL(n)\ = \ (n\geq 15) \wedge (n \bmod 8 = 1)$
\vspace{1ex}

\item $PL = \{ n \mid n\mbox{ ist GN eines Prädikatensymbols} \}$
\vspace{1ex}

$PL(n)\ = \ (n\geq 15) \wedge (n \bmod 8 = 3)$

\item $EIC = \{ n \mid n\mbox{ ist GN eines Ausdrucks, der aus einem Konstantensymbol besteht} \}$
\vspace{0.5ex}

$EIC(n)\ = \ (\exists z)_{\leq n}~ (IC(z) \wedge n=2^z)$
\vspace{1ex}

\item $EVb = \{ n \mid n\mbox{ ist GN eines Ausdrucks,
der aus einem Variablensymbol besteht} \}$
\vspace{0.5ex}

$EVb(n)\ = \ (\exists z)_{\leq n} ~ (Vb(z) \wedge n=2^z)$
\vspace{1ex}

\item $EFL = \{ n \mid n\mbox{ ist GN eines Ausdrucks,
         der aus einem Funktionssymbol besteht} \}$
\vspace{0.5ex}

$EFL(n)\ = \ (\exists z)_{\leq n} ~ (FL(z) \wedge n=2^z)$
\vspace{1ex}

\item $EPL = \{ n \mid n\mbox{ ist GN eines Ausdrucks,
           der aus einem Prädikatensymbol besteht} \}$
\vspace{0.5ex}

$EPL(n)\ = \ (\exists z)_{\leq n}~(PL(z) \wedge n=2^z)$

\end{itemize}

Bei Funktions- und Prädikatensymbolen muss die Stelligkeit
festgestellt werden können.
Dafür definieren wir die folgenden Funktionen,
die in $\mathrm{S}$ primitiv-rekursiv sind.

\begin{itemize}
\item $Arg_T(x)=n$, falls $x$ GN von $f^n_j$ ist

  \begin{gather*}
    Arg_T(x) = \left(\left\lfloor\frac{x\dminus 1}{8}\right\rfloor\right)_0
  \end{gather*}
\item $Arg_P(x)=n$, falls $x$ GN von $A^n_j$ ist

  \begin{gather*}
    Arg_P(x) = \left(\left\lfloor\frac{x\dminus 3}{8}\right\rfloor\right)_0
  \end{gather*}
\end{itemize}


\subsection{Erkennen von Formeln}

Wir wollen nun zeigen,
dass die Menge aller Kodierungen von Formeln
primitiv-rekursiv ist.
Das heißt es gibt eine primitiv-rekursive Funktion $h$,
deren Funktionswert $h(n)=1$ is, falls $n$ die Kodierung
einer Formel ist, und anderenfalls ist der Funktionswert $0$.

Formeln werden aus atomaren Formeln zusammengesetzt,
und atomare Formeln haben Terme als Bestandteile.
Wir wollen eine primitiv-rekursive Funktion angeben,
die entscheidet, ob ein Zahl die Gödelnummer eines Termes ist.
Diese Funktion ist die charakteristishe Funktion der Menge
\begin{gather*}
  Trm=\{ n \mid \text{ $n$ ist GN eines Termes}\}
\end{gather*}
Terme sind induktiv aufgebaut.
Die einfachsten Terme sind Konstanten- und Variablensymbole.
Zum Erkennen dieser Terme können wir $EIC$ und $EVb$ benutzen.
Die übrigen Terme sind aus einem Funktionssymbol
und weiteren Termen zusammengesetzte Ausdrücke.
Zum Beispiel ist der Term
$t=f^3_5(x_1, f_2^2(a_3,x_1), f^1_3(f^2_2(a_1,a_2),x_1,a_{13}))$
zusammengesetzt aus dem Funktionssymbol $f^3_5$ und
den drei Termen $x_1$, $f_2^2(a_3,x_1)$ und $f^1_3(f^2_2(a_1,a_2),x_1,a_{13})$.
Diese drei Terme bezeichnen wir als die Zerlegung von $t$.
Da die Zerlegung eine Folge von Termen ist,
kann sie mit der Funktion $g$ kodiert werden.
In diesem Beispiel ist
\begin{gather*}
  g(x_1, f_2^2(a_3,x_1), f^1_3(f^2_2(a_1,a_2),x_1,a_{13}))
     = 2^{g(x_1)} \cdot 3^{g(f_2^2(a_3,x_1))} \cdot 5^{g(f^1_3(f^2_2(a_1,a_2),x_1,a_{13}))}
     ~ ~ .
\end{gather*}
Sei $m=g(x_1, f_2^2(a_3,x_1), f^1_3(f^2_2(a_1,a_2),x_1,a_{13}))$
die Kodierung der Zerlegung von $t$.
Daraus lässt sich die Kodierung $c$ von $t$ gewinnen.
Die Kodierung des Funktionssymbols von $t$ ist $(c)_0 (=g(f^3_5)$.
Die Kodierung des ersten Termes der Zerlegung von $t$ ist $(m)_0 (=g(x_1))$,
die Kodierungen des zweiten und dritten Termes der Zerlegung von $t$ sind
$(m)_1 (=g(f_2^2(a_3,x_1)))$ und $(m)_2 (=g(f^1_3(f^2_2(a_1,a_2),x_1,a_{13})))$.
Also gilt
\begin{gather*}
  t = (c)_0 * 2^3 * (m)_0 * 2^7 * (m)_1 * 2^7 * (m)_2 * 2^5 ~ ~ .
\end{gather*}
Formal drücken wir die Zerlegung eines Termes durch folgendes Prädikat aus.
\vspace{1ex}

$Zerl_T\ = \ \{ (x,w)\mid$\begin{tabular}[t]{ll}
                       $x$ ist GN eines Termes $f^n_i(t_1,\dotsc,t_k)$ \\
         und $w=2^{g(t_1)} \cdot 3^{g(t_2)} \dotsm p_{n-1}^{g(t_n)}$ & $\}$
               \end{tabular}

Dieses Prädikat ist primitiv-rekursiv.
\begin{gather*}
  Zerl_T(x,w) =
     \big( x = (x)_0 * 2^3 *
     \left(\prod_{i=0}^{Arg_T((x)_0)-2} \left(\left(w\right)_i * 2^7\right) \right)
     * (w)_{Arg_T((x)_0)-1} * 2^5 \big)
\end{gather*}

Atomare Formeln können entsprechend in ihre Terme zerlegt werden.
Dafür benutzen wir $Zerl_A(x,w)$.

$Zerl_A\ = \ \{ (x,w)\mid$\begin{tabular}[t]{ll}
                       $x$ ist GN einer atomaren Formel $A^n_i(t_1,\dotsc,t_k)$ \\
             und $w=2^{g(t_1)} \cdot 3^{g(t_2)} \dotsm p_{n-1}^{g(t_n)}$ & $\}$
               \end{tabular}

Dieses Prädikat ist primitiv-rekursiv.
\begin{gather*}
  Zerl_A(x,w) =
     \big( x = (x)_0 * 2^3 *
     \left(\prod_{i=0}^{Arg_P((x)_0)-2} \left(\left(w\right)_i * 2^7\right) \right)
     * (w)_{Arg_P((x)_0)-1} * 2^5 \big)
\end{gather*}

Mit diesen Prädikaten können wir
einfach testen, ob eine Kodierung einen Term bzw. eine atomare Formel kodiert.
Die folgenden Relationen sind primitiv-rekursiv.

\begin{itemize}
\item $Trm=\{ n \mid \mbox{ $n$ ist GN eines Termes}\}$

  \begin{multline*}
    Trm(n) = EIC(n) ~\vee~ EVb(n) ~\vee~ \\
    \big( EFL((n)_0) ~\wedge~
       (\exists w)_{<(p_n)^{n^2}} ( Zerl_T(n,w) \wedge
       (\forall i)_{\leq lh(w)} Trm((w)_i) ) \big) ~ ~ .
  \end{multline*}

\item $Atmfml=\{ n \mid \mbox{ $n$ ist GN einer atomaren Formel}\}$

  \begin{gather*}
    Atmfml(n) \ = \ EPL((n)_0) ~\wedge~
       (\exists w)_{<(p_n)^{n^2}} ( Zerl_A(n,w) \wedge
       (\forall i)_{\leq lh(w)} Trm((w)_i) ) ) ~ ~ .
  \end{gather*}
\end{itemize}

Formeln sind atomare Formeln oder werden aus Teilformeln zusammengesetzt.
Funktionen, die aus Kodierungen von Teilformeln
die Kodierung einer daraus zusammengesetzten Formel ergeben,
sind primitiv-rekursiv.

\begin{itemize}
\item $NegFml(x)=$ die GN der Formel $(\neg \alpha)$,
falls $x$ die GN von Formel $\alpha$ ist
  \begin{gather*}
    NegFml(x) \ = \ 2^3 * 2^9 * x * 2^5
  \end{gather*}

\item $CondFml(x,y)=$ die GN der Formel $(\alpha\rightarrow \beta)$,
falls $x$ und $y$ die GNn von $\alpha$ und $\beta$ sind
  \begin{gather*}
    CondFml(x,y) \ = \ 2^3 * x * 2^{11} * y * 2^5
  \end{gather*}

\item $GenFml(u,v)=$ die GN der Formel $(\forall x ~\alpha)$,
falls $u$ und $v$ die GNn von $\alpha$ und $x$ sind
  \begin{gather*}
    GenFml(u,v) \ = \ 2^3 * 2^{13} * 2^{v} * u * 2^5
  \end{gather*}

\end{itemize}

Daraus können wir die Repräsentation der Relation
\begin{gather*}
  Fml \ = \ \{ x \mid x \mbox{ ist GN einer Formel} \}
\end{gather*}
zusammensetzen.

$
\begin{array}{llll}
Fml(x) \ = & \multicolumn{3}{l}{Atmfml(x) ~ \vee} \\
& (\exists z)_{<x} \big[ & (Fml(z)~ \wedge ~ x=NegFml(z)) ~ \vee \\
& & ( Fml((z)_0) ~ \wedge ~ Fml((z)_1) ~ \wedge ~ x=CondFml((z)_0,(z)_1)) ~\vee \\
& & ( Fml((z)_0) ~ \wedge ~ Vb((z)_1) ~ \wedge ~ x=GenFml((z)_0,(z)_1)
          & \big] \\
\end{array}
$

\subsection{Die Diagonalfunktion}

Die Diagonalfunktion ist recht technisch
und ein wesentlicher Bestandteil für \autoref{satz-gamma0-nicht-beweisbar}
und den Unvollständigkeitssatz von Gödel (\autoref{satz-unvollst}).

Die Formel $\alpha[x/t]$ entsteht aus der Formel $\alpha$
durch Ersetzen aller freien Vorkommen der Variablen $x$ durch den Term $t$.
Wir wollen die Kodierung von $\alpha[x/t]$
berechnen aus den Kodierungen von $\alpha$, $x$ und $t$.
Dazu beginnen wir bei den Termen, in denen die Ersetzungen
tatsächlich stattfinden.

$TrmSubst\ = \ \{ (x,y,u,v)\mid$\begin{tabular}[t]{p{0.6\textwidth}l}
                       wenn im Term mit GN $y$ der Term mit GN $v$
                       für alle Vorkommen der Variablen mit GN $u$ eingesetzt wird,
                       dann entsteht der Term mit GN $x$ \\[-3ex] & $ \}$
               \end{tabular}

Hier entspricht $y$ der Kodierung des Termes $\alpha$,
$u$ der Kodierung der Variablen $x_i$ und $v$ der Kodierung des Termes $t$.
$x$ ist dann die Kodierung des Termes $\alpha[x_i/t]$.
Wir betrachten zuerst die zu unterscheidenden Fälle.
\begin{enumerate}
\item wenn $\alpha$ ein Konstantensymbol ist, dann ist $\alpha[x_i/t]=\alpha$
\item wenn $\alpha=x_i$ die zu ersetzende Variable ist,
         dann ist $\alpha[x_i/t]=t$
\item wenn $\alpha=x_j$ eine Variable ungleich $x_i$ ist,
         dann ist $\alpha[x_i/t]=\alpha$
\item wenn $\alpha=f^m_j(t_1,\dotsc,t_m)$ ist,
dann ist $\alpha[x_i/t] = f^m_j(t_1[x_i/t],\dotsc,t_m[x_i/t])$.
Die Ersetzungen werden also induktiv im zusammengesetzten Term vorgenommen.
\end{enumerate}
Die folgende Formel drückt genau diese Fallunterscheidung aus.
Der letzte Fall -- $\alpha$ ist ein zusammengesetzter Term --
führt wieder dazu, dass der Term zerlegt wird
und die Ersetzungen auf die Terme der Zerlegung einzeln angewendet werden.
\vspace{1ex}

$
\begin{array}{p{10mm}lll}
\multicolumn{3}{l}{TrmSubst(x,y,u,v) ~ = } \\
& \multicolumn{3}{l}{Trm(x) ~\wedge~ Trm(y)  ~\wedge~ Vb(u) ~\wedge~ Trm(v) ~\wedge~} \\
 & \big( & (y=2^u ~\wedge~ x=v) ~\vee \\
 &       & (EVb(y) ~\wedge~ y\ne2^u ~\wedge~ x=y) ~\vee \\
 &       & (EIC(y) \wedge x=y) ~\vee \\
 &      & \begin{array}[t]{ll}
        (\exists w)_{<(p_y)^{y^2}} (\exists z)_{<(p_x)^{x^2}} & Zerl_T(y,w) ~\wedge~ Zerl_T(x,z) ~\wedge \\
                    & (\forall i)_{<Arg_T((y)_0)} TrmSubst((z)_i,(w)_i,u,v)~ \wedge \\
                    & (x)_0=(y)_0
        \end{array} & \\[-3ex]
 &      & & \big)
\end{array}
$
\vspace{2ex}

Ersetzungen in atomaren Formeln laufen entsprechend.
\vspace{1ex}

$AtmfmlSubst\ = \ \{ (x,y,u,v)\mid$\begin{tabular}[t]{p{0.5\textwidth}l}
                       wenn in der at.Fml. mit GN $y$ der Term mit GN $v$
                       für alle Vorkommen der Variablen mit GN $u$ eingesetzt wird,
                       dann entsteht die at.Fml. mit GN $x$ \\[-3ex] & $ \}$
               \end{tabular}

\vspace{1ex}

$
\begin{array}{p{10mm}lll}
\multicolumn{3}{l}{AtmfmlSubst(x,y,u,v) \ = } \\
& \multicolumn{3}{l}{Atmfml(x) ~\wedge~ Atmfml(y)  ~\wedge~ Vb(u) ~\wedge~ Trm(v) ~\wedge~} \\
& \big( & \begin{array}[t]{ll}
        (\exists w)_{<(p_y)^{y^2}} (\exists z)_{<(p_x)^{x^2}} & Zerl_A(y,w) ~\wedge~ Zerl_A(x,z) ~\wedge \\
                    & (\forall i)_{<Arg_P((y)_0)} TrmSubst((z)_i,(w)_i,u,v)~ \wedge \\
                    & (x)_0=(y)_0
        \end{array} & \\[-3ex]
&      & & \big)
\end{array}
$
\vspace{1ex}

Von den Ersetzungen in den atomaren Formeln
kommen wir nun zu Ersetzungen in beliebigen Formeln.
Dazu definieren wir eine Funktion,
die die Kodierung der durch Ersetzung entstandenen Formel bestimmt.

\vspace{1ex}

$Subst(y,u,v)\ = \ x$\begin{tabular}[t]{p{0.7\textwidth}l}
                       für die GN $x$ der Formel, die entsteht,
                       wenn in der Formel mit GN $y$ der Term mit GN $v$
                       für alle freien Vorkommen der Variablen mit GN $u$ eingesetzt wird
               \end{tabular}

\vspace{1ex}

Hier ist folgende Fallunterscheidung nötig.
\begin{enumerate}
\item wenn $\alpha$ eine atomare Formel ist,
dann findet die Ersetzung mittels $\mathit{AtmfmlSubst}$ statt
\item wenn $\alpha=(\neg \beta)$,
dann gilt $\alpha[x_i/t] = (\neg \beta[x_i/t])$
\item wenn $\alpha=(\beta\rightarrow\gamma)$,
dann gilt $\alpha[x_i/t] = (\beta[x_i/t]\rightarrow\gamma[x_i/t])$
\item wenn $\alpha=(\forall x_i ~ \beta)$,
dann gilt $\alpha[x_i/t] = \alpha$
\item wenn $\alpha=(\forall x_j ~ \beta)$ für $x_i\ne x_j$,
dann gilt $\alpha[x_i/t] = (\forall x_j ~ \beta[x_i/t])$
\end{enumerate}
Diese Fallunterscheidung findet sich in folgender Formel wieder,
die zeigt, dass $Subst$ primitiv-rekursiv ist.
Da durch Ersetzung stets eine Formel entsteht,
hat der min-Operator auch ein Ergebnis.
\todo{Schranke für den min-Operator in der Formel}

\begin{multline*}
  Subst(y,u,v) = \min_{x} \mathit{AtmfmlSubst}(x,y,u,v) \vee \\
  \shoveleft{\hspace{5mm} (\exists w)_{<y}(\exists z)_{<y} \Big[}
    \big( Fml(z) \wedge y=NegFml(z) \wedge
      x=NegFml(Subst(z,u,v)) \big) \vee \\
    \big( Fml(w) \wedge Fml(z) \wedge y=CondFml(w,z) \wedge\\
      \hspace{2cm} x=CondFml(Subst(w,u,v),Subst(z,u,v)) \big) \vee \\
    \big( u=w \wedge y=GenFml(z,w) \wedge x=y \big) \vee \\
    \big( u\ne v \wedge Vb(w) \wedge y=GenFml(z,w) \wedge
      x=GenFml(Subst(z,u,v),w) \big)
  \Big]
\end{multline*}

Mit der Funktion $Subst$ lässt sich feststellen,
ob eine Formel ein freies Vorkommen einer Variablen enthält.

\begin{itemize}
\item
$Fr\ = \ \{ (y,u)\mid$\begin{tabular}[t]{p{0.5\textwidth}l}
                       in der Formel mit GN $y$ kommt Variable mit GN $u$ frei vor
                       \\[-3ex] & $ \}$
               \end{tabular}

  \begin{gather*}
    Fr(y,u) =
       Fml(y) \wedge Vb(u) \wedge \neg (y=Subst(y,u,2^{13+8\cdot y}))
  \end{gather*}
\end{itemize}

Damit kommen wir zur Diagonalfunktion.
Sei $\alpha$ eine Formel mit freier Variablen $x_1$.
Sei $c_{\alpha}$ die Kodierung von $\alpha$.
Die Diagonalfunktion berechnet aus der Kodierung von $\alpha$
die Kodierung von $\alpha[x_1/\overline{c_{\alpha}}]$.
Im ersten Schritt brauchen wir dazu noch eine Funktion,
die aus der Zahl $m$ die Kodierung des Termes $\overline{m}$ berechnet.

\begin{itemize}
\item
$\mathit{Num}(m)=$ die GN von $\overline{m}$

$
\begin{array}{rcl}
\mathit{Num}(0) & = & 2^{15} (=2^{g(a_1)}) \\
\mathit{Num}(m+1) & = & 2^{49} * 2^3 * \mathit{Num}(m) * 2^5  ( = f^1_1(\overline{m}) )
\end{array}
$

\item $D(u)=$ die GN von $\alpha[x_1/\overline{u}]$, falls $u$ die GN von $\alpha$ ist
\vspace{1ex}

$D(u) ~=~ Subst(u,21,\mathit{Num}(u))$ \ \ .
\item $D_2(u)=$ die GN von $\alpha[x_2/\overline{u}]$, falls $u$ die GN von $\alpha$ ist
\vspace{1ex}

$D_2(u) ~=~ Subst(u,29,\mathit{Num}(u))$ \ \ .
\end{itemize}

Die Funktionen $D$ und $D_2$ heißen \emph{Diagonalfunktion}
und sind primitiv-rekursiv.



\subsection{Das Beweisprädikat}

Zum Abschluss kommen wir noch zur Kodierung von Beweisen.
Beweise sind Folgen von Formeln,
die Axiome sind oder aus Ableitungsregeln (modus ponens, Generalisierung)
aus zuvor im Beweis vorkommenden Formeln entstehen.
Die Kodierungen von Formeln,
die durch Ableitungsregeln aus anderen Formeln entstehen,
sind primitiv-rekursiv.

\begin{itemize}
\item $\mathit{MP}=\{(x,y,z)\mid$\begin{tabular}[t]{ll}
                             Ausdruck mit GN $z$ entsteht aus \\
                            Ausdrücken mit GNn $x$ und $y$ durch modus ponens & $\}$
                        \end{tabular}

$
\mathit{MP}(x,y,z) \ = \ ( y= 2^3 * x * 2^{11} * z * 2^5) \wedge Fml(x) \wedge Fml(z)
$

\item $Gen=\{(x,y)\mid $\begin{tabular}[t]{ll} Ausdruck mit GN $y$ entsteht\\
               aus Ausdruck mit GN $x$ durch Generalisierung & $\}$
                        \end{tabular}

$
Gen(x,y) \ = \ (\exists v)_{<y}~(EVb(v) \wedge y=2^3*2^{13}*v*x*2^5) \wedge Fml(x)
$
\end{itemize}

Die Relation
\begin{gather*}
  Ax = \{ x \mid \text{$x$ ist GN eines Axioms} \}
\end{gather*}
ist primitiv-rekursiv für die Axiome von $\mathrm{S}$.
Damit ergibt sich, dass auch Kodierungen von Beweisen primitiv-rekursiv sind.

$\mathit{Prf} \ = \ \{ y \mid \mbox{$y$ ist GN eines Beweises} \}$

Dazu betrachten wir folgende induktive Definition von Beweisen.

Eine Folge $\alpha_1,\alpha_2,\dotsc,\alpha_n$ ist ein Beweis, falls
\begin{enumerate}
\item $n=1$ und $\alpha_1$ ein Axiom ist, oder
\item $\alpha_n$ ein Axiom ist, oder
\item $\alpha_1,\alpha_2,\dotsc,\alpha_{n-1}$ ein Beweis ist
      und $\alpha_n$ mittels Generalisierung aus $\alpha_i$ mit $i<n$ entsteht.
\item $\alpha_1,\alpha_2,\dotsc,\alpha_{n-1}$ ein Beweis ist
      und $\alpha_n$ mittels modus ponens aus $\alpha_i$ und $\alpha_j$
      mit $i,j<n$ entsteht, oder
\end{enumerate}
Folgender Ausdruck zeigt, dass
$\mathit{Prf}$ eine primitiv-rekursive Relation ist
(für jede Theorie, in der $Ax$ primitiv-rekursiv ist.

\begin{multline*}
  \mathit{Prf}(y) = (\exists u)_{<y}(\exists v)_{<y}(\exists w)_{<y}(\exists z)_{<y}
  \big( y=2^w \wedge Ax(w) \big) \vee \\
  \big( \mathit{Prf}(u) \wedge y=u*2^v \wedge Ax(v) \big) \vee \\
  \big( (\mathit{Prf}(u) \wedge Fml((u)_w) \wedge y = u*2^v \wedge Gen((u)_w,v)\big) \vee \\
  \big( \mathit{Prf}(u) \wedge Fml((u)_z \wedge Fml((u)_w)) \wedge y = u*2^v
       \wedge \mathit{MP}((u)_z,(u)_w,v) \big)
\end{multline*}

% 2006-07-18

\section{Der Unvollständigkeitssatz von Gödel}

Jeder Prädikatenkalkül ist vollständig in dem Sinne,
dass jede gültige Formel auch bewiesen werden kann (\autoref{satz-vollstPK}).
Diese Eigenschaft hat die formale Zahlentheorie nicht.
Das heißt, es gibt Formeln,
die in der Zahlentheorie \glqq{}gültig\grqq{} sind\footnote{%
Eine Formel ist \glqq{}gültig in S\grqq{},
falls jedes Modell von S auch Modell der Formel ist.},
für die es aber keinen Beweis gibt.
Der Unvollständigkeitssatz von Gödel macht eine allgemeinere
Aussage, für welche Theorien es solche \glqq{}gültigen\grqq{}
und unbeweisbaren Formeln gibt.
Die Idee zum Beweis des Unvollständigkeitssatzes
basiert auf der sog.~Paradoxie
\glqq{}Dieser Satz ist falsch\grqq{}.
Dieser Satz kann weder wahr noch falsch sein,
also ist er keine Aussage.
Über Wahrheit kann man innerhalb der Theorie S keine Aussagen machen.
Man kann jedoch über Beweisbarkeit sprechen.
Das Prädikat $\mathit{Pf}$ mit
%
\begin{gather*}
  \mathit{Pf} = \{ (x_{1},x_{2})\colon \text{$x_{1}$ ist Gödelnummer eines Beweises
     der Formel mit Gödelnummer $x_{2}$} \}
\end{gather*}
%
primitiv-rekursiv.
Folglich gibt es eine Formel $\phi_{Pf}$ in S,
die $\mathit{Pf}$ repräsentiert.
Wenn eine Formel $\alpha$ mit Gödelnummer $u$ in S nicht beweisbar ist,
dann ist die Formel $\forall x_1 ~ \neg \phi_{Pf}[x_2/\overline{u}]$
wahr (im Standardmodell).
Analog zu \glqq{}Dieser Satz ist falsch\grqq{}
könnte man nun versuchen, eine Formel zu konstruieren,
die der Aussage \glqq{}Diese Aussage ist nicht beweisbar.\grqq{} entspricht.
Man könnte eine Zahl $u$ suchen,
so dass $u$ genau die Gödelnummer von
$\forall x_1 ~ \neg \phi_{Pf}[x_2/\overline{u}]$ ist.
Mit der hier betrachteten Kodierung von Formeln und Termen in Zahlen
geht das nicht.
Muss man dazu nun eine geschicktere Kodierung wählen?
Eine kodierungsunabhängige Antwort liefert das Diagonalisierungslemma (\autoref{satz:6}).
Dort wird gezeigt, dass es
eine Formel $\gamma_0$ gibt,
deren Äquivalenz zur Aussage \glqq{}$\gamma_0$ ist nicht beweisbar\grqq{}
bewiesen werden kann.
D.\,h. für
die Gödelnummer $g$ von $\gamma_0$ gilt
$\Svdash \gamma_0 \leftrightarrow (\forall x_1 ~ \neg \phi_{Pf}[x_2/\overline{g}])$.
Diese Formel $\gamma_0$ ist in der Tat nicht in S beweisbar
(\autoref{satz-gamma0-nicht-beweisbar}).
Also ist $\forall x_1 ~ \neg \phi_{Pf}[x_2/\overline{g}]$ wahr (im Standardmodell),
und da $\gamma_0$ beweisbar äquivalent dazu ist,
ist $\gamma_0$ ebenfalls eine wahre Formel.
Die Konstruktion von $\gamma_0$ wird möglich
im wesentlichen durch die Repräsentierbarkeit des
Beweisüberprüfungsprädikats $\mathit{Pf}$ in S.
Diese wiederum basiert auf der Repräsentierbarkeit
der Menge der Axiome von S und der primitiv-rekursiven Funktionen in S.
Im Unvollständigkeitssatz von Gödel (\autoref{satz-unvollst})
wird schließlich festgestellt, dass
es in jeder konsistenten Theorie mit diesen Eigenschaften
wahre und nicht beweisbare Formel gibt.


Das geht indirekt über die Konstruktion
einer zu einer solchen Aussage äquivalenten Aussage.
Grundlage dafür ist das folgende
(recht technisch aussehende)
Diagonalisierungslemma.

Für Formel $\alpha$ mit Gödelnummer $u$
bezeichnet $\ucorner{\alpha}$ den Term $\overline{u}$.

\begin{satz}[Diagonalisierungslemma]\label{satz:6}
  Sei $\alpha$ eine Formel in $\mathrm{S}$ mit $x_{2}$ als einziger
  freien Variablen. Dann gibt es eine geschlossene Formel $\gamma$
  mit $\Svdash\gamma \leftrightarrow \alpha[x_{2}/\ucorner{\gamma}]$.

  \begin{proof}
    Die Repräsentierbarkeit der Diagonalfunktion $D_2$ hatten wir bereits betrachtet.
    %
    \begin{gather*}
      D_2(u) = \text{die Gödelnummer von $\alpha[x_{2}/\overline{u}]$, wenn
                         $\alpha$ die Gödelnummer $u$ hat}
    \end{gather*}
    %
    Sei $\phi_{D_2}$ eine Formel in $\mathrm{S}$, die die
    Diagonalfunktion $D_2$ repräsentiert. Wir definieren die
    Formeln $\alpha_{2} := (\forall x_{2} ~ \phi_{D_2}\rightarrow
    \alpha)$ und $\gamma := (\forall x_{2} ~
    \phi_{D_2}[x_{1}/\ucorner{\alpha_{2}}] \rightarrow \alpha)$.
    Es gilt $\Svdash\phi_{D} [x_{1}/\ucorner{\alpha_{2}},
    x_{2}/\ucorner{\gamma}]$, da $D_2(\text{Gödelnummer von
    $\alpha_{2}$}) = \text{Gödelnummer von $\gamma$}$
    und $D_2$ von $\phi_{D_2}$ repräsentiert wird.
    Diese Eigenschaft nennen wir hier $(\star)$.

    Wir zeigen $\Svdash\gamma \leftrightarrow \alpha[x_{2}/\ucorner{\gamma}]$:
    \begin{enumerate}
     \item $\Svdash\gamma \rightarrow \alpha[x_{2}/\ucorner{\gamma}]$:
      \begin{align*}
        (1)\quad& (\forall x_{2}~ \phi_{D_2}[x_{1}/\ucorner{\alpha_{2}}]
           \rightarrow \alpha) & \text{Hypothese $\gamma$}\\
        (2)\quad& \phi_{D_2}[x_{1}/\ucorner{\alpha_{2}}, x_{2}/\ucorner{\gamma}]
           \rightarrow \alpha[x_{2}/\ucorner{\gamma}] & \text{(1), RA 4}\\
        (3)\quad& \phi_{D_2}[x_{1}/\ucorner{\alpha_{2}}, x_{2}/\ucorner{\gamma}]
           &\text{$(\star)$} \\
        (4)\quad& \alpha[x_{2}/\ucorner{\gamma}] &\text{MP (2), (3)}
      \end{align*}
      Mit dem Deduktionstheorem folgt
        $\Svdash\gamma \rightarrow \alpha[x_{2}/\ucorner{\gamma}]$.

     \item $\Svdash \alpha[x_{2}/\ucorner{\gamma}] \rightarrow \gamma$:
      \begin{align*}
        (1)\quad& \alpha[x_{2}/\ucorner{\gamma}] & \text{Hypothese}\\
        (2)\quad& \phi_{D_2}[x_{1}/\ucorner{\alpha_{2}}] &\text{Hypothese}\\
        (3)\quad& \exists_{1} x_{2} ~ \phi_{D_2}[x_{1}/\ucorner{\alpha_{2}}]
           &\text{da $\phi_{D_2}$ $D_2$ streng repräsentiert}\\
        (4)\quad& \phi_{D_2}[x_{1}/\ucorner{\alpha_{2}}, x_{2}/\ucorner{\gamma}]
           &\text{$(\star)$}\\
        (5)\quad& x_{2}= \ucorner{\gamma} &\text{Eigenschaft von $=$, (3), (4)}\\
        (6)\quad& \alpha & \text{(1), (5), Eigenschaft von $=$}
      \end{align*}

      Damit ist gezeigt: $\alpha[x_{2}/\ucorner{\gamma}],
      \phi_{D_2}[x_{1}/\ucorner{\alpha_{2}}]\Svdash \alpha$.

      Mit dem Deduktionstheorem folgt: $\alpha[x_{2}/\ucorner{\gamma}] \Svdash
      \phi_{D_2}[x_{1}/\ucorner{\alpha_{2}}] \rightarrow \alpha$.

      Mit Generalisierung: $\alpha[x_{2}/\ucorner{\gamma}] \Svdash
      \underbrace{\forall x_{2} ~ \phi_{D_2}[x_{1}/\ucorner{\alpha_{2}}] \rightarrow
      \alpha}_{\gamma}$.

      Mit Deduktionstheorem: $\Svdash\alpha [x_{2}/\ucorner{\gamma}]\rightarrow
      \gamma$.
    \end{enumerate}
  \end{proof}
\end{satz}



Ein Beweis einer Formel $\alpha$ ist eine
Folge von Formeln, die ein Beweis ist und mit $\alpha$ endet.
Das primitiv-rekursive Prädikat $\mathit{Prf}$
erkennt Formelfolgen, die korrekte Bweise sind.
Es ist einfach zu testen, ob eine Formelfolge mit einer bestimmten Formel endet.
Deshalb ist folgendes Prädikat $\mathit{Pf}$ primitiv-rekursiv
und folglich repräsentierbar.
%
\begin{gather*}
  \mathit{Pf} = \{ (x_{1},x_{2})\colon \text{$x_{1}$ ist Gödelnummer eines Beweises
     der Formel mit Gödelnummer $x_{2}$} \}
\end{gather*}
%
$\phi_{Pf}$ sei eine Formel in $\mathrm{S}$, die $\mathit{Pf}$ repräsentiert.
$\phi_{Pf}$ hat die freien Variablen $x_{1}$ und $x_{2}$. $(\forall
x_{1} ~ \neg\phi_{Pf})$ ist eine Formel in $\mathrm{S}$ mit $x_{2}$
als einziger freien Variable. Mit dem Diagonalisierungslemma
(\autoref{satz:6}) folgt:
es gibt eine Formel $\gamma_0$ mit
\begin{gather*}
  \Svdash \gamma_{0} \leftrightarrow (\forall x_{1} ~ \neg\phi_{Pf}
     [x_{2}/\ucorner{\gamma_{0}}])
\end{gather*}
$\gamma_{0}$ ist also (beweisbar) äquivalent zu der Formel
für die Aussage \glqq{}Keine Zahl ist die Gödelnummer eines
Beweises der Formel mit Gödelnummer $\gamma_{0}$.\grqq{}
oder etwas kompakter \glqq{}$\gamma_0$ ist nicht beweisbar.\grqq{}.
Wir zeigen, dass das eine wahre Aussage ist.

\begin{satz}\label{satz-gamma0-nicht-beweisbar}
  $\gamma_{0}$ ist in $\mathrm{S}$ nicht beweisbar, d.\,h. $\not\Svdash\gamma_{0}$.

  \begin{proof}
    $\mathrm{S}$ ist konsistent, d.\,h. es existiert keine Formel
    $\alpha$, für die $\Svdash \alpha$ und $\Svdash\neg\alpha$ gilt.

    Annahme: Es gelte $\Svdash\gamma_{0}$.
    Sei $r$ die Gödelnummer eines Beweises von $\gamma_{0}$ in $\mathrm{S}$.
    Dann folgt $\Svdash \phi_{Pf}[x_{2}/\ucorner{\gamma_{0}}, x_{1}/\overline{r}]$.
    Aufgrund der Konstruktion von $\gamma_0$ mit dem
    Diagonalisierungslemma (\autoref{satz:6}) gilt
    $\Svdash\gamma_{0} \leftrightarrow
         (\forall x_{2} ~ \neg\phi_{Pf}[x_{2}/\ucorner{\gamma_{0}}])$.
    Nach Äquivalenzregel folgt
    $\Svdash (\forall  x_{1} ~ \neg\phi_{Pf}[x_{2}/\ucorner{\gamma_{0}}])$.
    Mit RA~4 folgt
    $\Svdash\neg\phi_{Pf}[x_{2}/\ucorner{\gamma_{0}}, x_{1}/\overline{r}]$.
    Also ist $\mathrm{S}$ nicht konsistent.
  \end{proof}
\end{satz}

Wir führen jetzt noch einen stärkeren Begriff der Konsistenz ein,
der sich stärker auf die Standardinterpretation der Zahlentheorie
mit den natürlichen Zahlen als Grundmenge bezieht.

\begin{defini}[$\omega$-Konsistenz]\label{defi-omega-Konsistenz}
  Sei $K$ eine Theorie mit dem Konstantensymbol $0$
  und dem Funktionssymbol $f_{1}^{1}$ (Nachfolgerfunktion).
  $K$ heißt \emph{$\omega$-konsistent}, falls für jede Formel $\alpha$ in $K$ gilt:
  \begin{gather*}
    \text{falls für jede natürliche Zahl $n$ gilt $\xvdash{K} \neg\alpha[x/\overline{n}]$,
           dann
       $\not\xvdash{K}(\exists x ~ \alpha)$}
  \end{gather*}
\end{defini}

$\mathrm{S}$ ist $\omega$-konsistent, da die Standardinterpretation
(mit der Grundmenge $\N$) ein Modell für $\mathrm{S}$ ist.

\begin{lemma}
  Wenn eine Theorie $K$ $\omega$-konsistent ist, dann ist $K$ auch
  konsistent.

  \begin{proof}
    Wenn $K$ nicht konsistent ist, dann lässt sich in $K$ alles beweisen,
    da aus den logischen Axiomen folgt: wenn $\xvdash{K} \alpha$ und
    $\xvdash{K} \neg\alpha$, dann folgt für jede Formel $\beta$:
    $\xvdash{K} \beta$ (wegen der Tautologie $\xvdash{K} \alpha \rightarrow
    (\neg\alpha \rightarrow \beta)$).

    Also reicht es aus, eine Formel $\beta$ aus $K$ zu finden, die nicht
    beweisbar ist. Sei $\beta$ eine beliebige Formel und $\alpha$ sei
    $\beta\wedge\neg\beta$. Dann ist $\neg\alpha$ eine gültige Formel und
    $\neg \alpha[x/\overline{u}]$ ist Instanz einer Tautologie. Also gilt
    $\xvdash{K} \neg\alpha[x/\overline{u}]$ für jedes $n\in\N$.

    Da $K$ $\omega$-konsistent ist, folgt $\not\xvdash{K} (\exists x ~ \alpha)$.
  \end{proof}
\end{lemma}

\begin{bemerk}
  Es gibt Theorien, die konsistent aber nicht $\omega$-konsistent sind.
\end{bemerk}

\begin{satz}
  Man kann $\neg\gamma_{0}$ in $\mathrm{S}$ nicht beweisen,
  d.\,h. $\not\xvdash{S}\neg\gamma_{0}$.

  \begin{proof}
    Nehmen wir an, dass wir $\neg\gamma_{0}$ in $\mathrm{S}$ beweisen können.
    Aufgrund der Konstruktion von $\gamma_0$ aus dem Diagonalisierungslemma
    (\autoref{satz:6}) gilt
    $\Svdash\gamma_{0} \leftrightarrow
          (\forall x_{1} ~ \neg\phi_{Pf}[x_{2}/\ucorner{\gamma_{0}}])$.
    Mit der Äquivalenzregel folgt
    $\Svdash\neg(\forall x_{1} ~ \neg\phi_{Pf}[x_{2}/\ucorner{\gamma_{0}}])$,
    d.\,h. $\Svdash (\exists x_{1} ~ \phi_{Pf}[x_{2}/\ucorner{\gamma_{0}}])$.

    Wir wissen: $\not\Svdash \gamma_{0}$ (\autoref{satz-gamma0-nicht-beweisbar}).
    Also ist $\mathit{Pf}(r, u)$ ($u$ ist die Gödelnummer von $\gamma_{0}$)
    falsch für jedes $r\in\N$.
    Folglich gilt $\Svdash\neg\phi_{Pf}[x_{2}/\ucorner{\gamma_{0}}, x_{1}/\overline{r}]$
    für jedes $r\in\N$.
    Dann folgt aus der $\omega$-Konsistenz von
    $\mathrm{S}$: $\not\Svdash (\exists x_{1} ~  \phi_{Pf}[x_{2}/\ucorner{\gamma_{0}}])$.
    Das ist ein Widerspruch zur Konsistenz von $\mathrm{S}$.
  \end{proof}
\end{satz}

Da in $\mathrm{S}$
weder $\gamma_0$ noch $\neg\gamma_0$ beweisbar,
kann man $\mathrm{S}$ durch Hinzunahme von $\gamma_0$ als
zusätzliches Axiom konsistent zu einer Theorie $\mathrm{S}'$ erweitern
(\autoref{lemma-kons-erweiterung}).
In $\mathrm{S}'$ ist $\gamma_0$ beweisbar (da es ein Axiom ist).
Das Diagonalisierungslemma gilt aber auch für $\mathrm{S}'$,
da $D_2$ in $\mathrm{S}'$ die gleiche Repräsentation besitzt wie in $\mathrm{S}$.
Das Beweisüberprüfungsprädikat $\mathit{Pf}$ für $\mathrm{S}'$
ist -- wegen des zusätzlichen Axioms -- ein anderes als das für $\mathrm{S}$.
Aber es ist in $\mathrm{S}'$ repräsentierbar.
Deshalb gilt \autoref{satz-gamma0-nicht-beweisbar} entsprechend für $\mathrm{S}'$.
Also gibt es auch für $\mathrm{S}'$
eine wahre und nicht in $\mathrm{S}'$ beweisbare Formel.
Die Konstruktion einer solchen Formel
geht für jede Theorie $K$ mit den folgenden Eigenschaften:
\begin{enumerate}
 \item Die Menge aller Axiome von $K$ ist repräsentierbar;

       d.\,h. das Prädikat $\{m ~\colon \text{$m$
  ist Gödelnummer eines Axioms von $K$}\}$ ist repräsentierbar in $K$.

 \item $\xvdash{K} 0\ne\overline{1}$.

 \item Jede primitiv-rekursive Funktion ist repräsentierbar in $K$.
\end{enumerate}

\begin{satz}[Unvollständigkeitssatz von Gödel]\label{satz-unvollst}
  Sei $K$ eine Theorie mit den Eigenschaften (1)--(3). Dann gibt es eine
  wahre Formel $\gamma$ mit:
  \begin{enumerate}
   \item Wenn $K$ konsistent ist, dann ist $\gamma$ in $K$
    nicht beweisbar, d.\,h. $\not\xvdash{K} \gamma$.
   \item Wenn $K$ $\omega$-konsistent ist, dann ist $\neg\gamma$ in
    $K$ nicht beweisbar, d.\,h. $\not\xvdash{K} \neg\gamma$.
  \end{enumerate}
\end{satz}

Der Beweis des Satzes geht analog zu den Beweisen der vorherigen Sätze.


\begin{bemerk}
  Paris und Huntington haben zahlentheoretisch Formeln hergeleitet, die
  wahr und unbeweisbar sind.

  Rosser hat gezeigt, dass man die $\omega$-Konsistenz nicht benötigt.
  Dadurch werden die unbeweisbaren Formeln schwieriger.

  Die Konsistenz einer Theorie $K$ lässt sich nicht "`innerhalb"' von $K$
  zeigen. ($\mathrm{S}$ ist konsistent bedeutet "`$0=\overline{1}$"' ist
  nicht beweisbar; $\forall x_{1}~ \neg\phi_{Pf}[x_{2}/\text{\glqq{}$0=\overline{1}$\grqq{}}]$).

  Daraus hat sich die Berechenbarkeitstheorie mit den (primitiv-)rekursiven
  Funktionen entwickelt.
\end{bemerk}

\clearpage
\appendix

\chapter{Übungsaufgaben}

\section{Blatt 1}
\subsection*{Aufgabe 1}
Zeigen Sie folgende Äquivalenzen durch Umformen:
\begin{enumerate}
 \item $A\rightarrow (B \rightarrow C) \equiv (A\wedge B) \rightarrow C$
 \item $(A\rightarrow B) \rightarrow A \equiv A$
 \item $\neg\big(\neg(A\wedge \wedge \neg(B\vee A)) \rightarrow (A
  \rightarrow (\neg B\wedge A)) \big) \equiv A\wedge B$
 \item $A\leftrightarrow B \equiv (A\rightarrow B) \wedge (B\rightarrow A)$
 \item $(A\rightarrow B) \rightarrow C \not\equiv
  A\rightarrow(B\rightarrow C)$
\end{enumerate}
\subsection*{Aufgabe 2}
Sind die folgenden Argumentationen logisch korrekt?
\begin{enumerate}
 \item Wenn es regnet, dann ist die Straße nass. Die Straße ist nass,
  also regnet es.

 \item Wenn eine Zahl $x$ auf 0 endet, dann ist sie durch 5 teilbar.
  \begin{enumerate}
   \item $x$ endet nicht mit 0, also ist $x$ nicht durch 5 teilbar.
   \item $x$ ist nicht durch 5 teilbar, also endet $x$ nicht auf 0.
  \end{enumerate}

 \item Wenn $a=0$ oder $b=0$, dann ist $a\cdot b=0$. Es gilt $a\cdot
  b\ne0$, also ist $a\ne0$ und $b\ne0$.
\end{enumerate}

\section{Blatt 2}

\begin{enumerate}[(1)]
 \item $\Lvdash (\neg \alpha \rightarrow\alpha) \rightarrow\alpha$

  \begin{align*}
    (1)\quad & \neg \alpha \rightarrow \neg \alpha
       &\text{\autoref{bsp:1}}\\
    (2)\quad & (\neg \alpha \rightarrow \neg \alpha) \rightarrow \big(
       (\neg\alpha \rightarrow \alpha) \rightarrow \alpha\big)
       &\text{A3}\\
    (3)\quad & (\neg\alpha \rightarrow \alpha) \rightarrow \alpha
       &\text{MP 1,2}
  \end{align*}

 \item $\alpha\rightarrow(\beta\rightarrow\gamma) \Lvdash \beta
  \rightarrow(\alpha\rightarrow\gamma)$

  \begin{align*}
    (1)\quad & \alpha \rightarrow (\beta \rightarrow \gamma)
       &\text{Hypothese}\\
    (2)\quad & \beta &\text{Hypothese}\\
    (3)\quad & \big( \alpha \rightarrow (\beta \rightarrow \gamma) \big)
       \rightarrow \big( (\alpha \rightarrow \beta) \rightarrow
       (\alpha\rightarrow\gamma)\big) &\text{A2}\\
    (4)\quad & (\alpha \rightarrow \beta) \rightarrow
       (\alpha\rightarrow\gamma) &\text{MP 1,3}\\
    (5)\quad & \beta \rightarrow (\alpha \rightarrow\beta)
       &\text{A1}\\
    (6)\quad & \beta \vdash \alpha\rightarrow\beta &\text{DT 5}\\
    (7)\quad & \alpha\rightarrow\beta &\text{2,6}\\
    (8)\quad & \alpha\rightarrow\gamma &\text{MP 7,4}
  \end{align*}
  Mit Deduktionstheorem wird aus $\alpha \rightarrow
  (\beta\rightarrow\gamma), \beta \vdash \alpha\rightarrow\gamma$.

 \item $\Lvdash (\neg\beta\rightarrow\neg\alpha) \rightarrow
  (\alpha\rightarrow\beta)$ \label{enu:1}

  2x DT: $\neg\beta \rightarrow \neg\alpha, \alpha \Lvdash
  \beta$ zu beweisen
  \begin{align*}
    (1)\quad & \neg\beta \rightarrow \neg\alpha &\text{Hypothese}\\
    (2)\quad & \alpha &\text{Hypothese}\\
    (3)\quad & (\neg\beta\rightarrow\neg\alpha) \rightarrow ((\neg\beta
       \rightarrow \alpha) \rightarrow \beta) &\text{A3}\\
    (4)\quad & (\neg\beta\rightarrow\alpha) \rightarrow \beta &\text{MP
       1,3}\\
    (5)\quad & \alpha \rightarrow (\neg\beta\rightarrow\alpha)
       &\text{A1}\\
    (6)\quad & \neg\beta \rightarrow \alpha &\text{MP 2,5}\\
    (7)\quad & \beta &\text{MP 6,1}
  \end{align*}
  2x DT: $\Lvdash (\neg\beta\rightarrow\neg\alpha) \rightarrow
  (\alpha\rightarrow\beta)$

 \item Theorie $\mathrm{L}$ ist konsistent, d.\,h. wenn $\alpha$ eine Theorem von
  $\mathrm{L}$ ist, dann ist $\neg\alpha$ kein Theorem von $\mathrm{L}$,
  und wenn $\Lvdash
  \neg\alpha$, dann nicht $\Lvdash \alpha$.

  Wenn $\Lvdash\alpha$ ein Theorem ist, dann ist $\alpha$
  eine Tautologie (\autoref{satz:1}). Dann ist $\neg\alpha$ keine
  Tautologie. Folglich gilt nicht $\Lvdash\neg\alpha$.

  Aus der Negation von \glqq{}Wenn $\Lvdash\alpha$ ein Theorem
  ist, dann ist $\alpha$ eine Tautologie\grqq{} folgt: Wenn $\alpha$ keine
  Tautologie ist, dann gilt nicht $\Lvdash\alpha$. Wenn
  $\neg\alpha$ also kein Theorem ist, dann ist $\alpha$ kein Theorem

  Wenn $\Lvdash \neg\alpha$, dann ist $\neg\alpha$ eine
  Tautologie. Dann ist $\neg\neg\alpha$ keine Tautologie. Es gilt
  $\neg\neg=\alpha$. Also ist $\alpha$ keine Tautologie, folglich gilt
  nicht $\Lvdash \alpha$.

 \item $\alpha,\neg\alpha \Lvdash \beta$ gilt für beliebige Formeln
  $\alpha$ und $\beta$.

  \begin{align*}
    (1)\quad & \alpha &\text{Hypothese}\\
    (2)\quad & \neg\alpha & \text{Hypothese}\\
    (3)\quad & \alpha \rightarrow (\neg\beta\rightarrow\alpha)
       &\text{A1}\\
    (4)\quad & \neg\alpha \rightarrow (\neg\beta \rightarrow\neg\alpha)
       &\text{A1}\\
    (5)\quad & \neg\beta \rightarrow \alpha &\text{MP 1,3}\\
    (6)\quad & \neg\beta \rightarrow \neg\alpha &\text{MP 2,4}\\
    (7)\quad & (\neg\beta \rightarrow \neg\alpha) \rightarrow ((\neg\beta
       \rightarrow\alpha) \rightarrow \beta) &\text{A3}\\
    (8)\quad & (\neg\beta \rightarrow \alpha) \rightarrow \beta &\text{MP
       6,7}\\
    (9)\quad & \beta & \text{MP 5,8}
  \end{align*}
\end{enumerate}

\section{Blatt 3}
\subsection*{Aufgabe 1}

In wievielen Beweisschritten ist eine Tautologie in $\mathrm{L}$ beweisbar?
(Abschätzung nach Anzahl von Verknüpfungszeichen und Anzahl der Variablen in der Formel.)

Aus dem Beweis von \autoref{satz:2} folgt:
Jede Formel baut sich induktiv aus ihren Teilformeln auf
(siehe z.\,B. \autoref{fig-formelaufbau}).
Jede Teilformel einer Tautologie $\alpha$ fügt höchstens $3$ Beweisschritte
zum Beweis von $\cA \Lvdash \alpha$ hinzu
(siehe Beweis von \autoref{satz:2} und Beispiel in \autoref{fig-beweisaufbau}).
Also hat der Beweis für $\cA \Lvdash \alpha$
höchstens $3\cdot\text{Anzahl Teilformeln von $\alpha$}$ Schritte.
Sei $\abs{\alpha}$ die Anzahl der Teilformeln von $\alpha$.

Für eine Tautologie mit $n$ Variablen gibt es $2^n$
Belegungen dieser Variablen, aus denen die Tautologie bewiesen werden kann.
Nach dem Beweis von \autoref{satz:3}
werden diese $2^n$ Beweise mit insgesamt $\leq 2^n\cdot 3\cdot \abs{alpha}$
Beweisschritten induktiv in $2^n-1$ Schritten
zu einem Beweis für $\Lvdash \alpha$ zusammengefasst.
In jedem dieser weiteren Schritte wird
$2$ mal das Deduktionstheorem verwendet
und mit den so erhaltenen Formeln
$2$ mal modus ponens auf eine Tautologie angewendet.
Rechnet man die Schritte zum Beweis der jeweiligen Tautologie nicht mit,
dann ergeben sich daraus $4\cdot(2^n-1)$ weitere Beweisschritte.



\subsection*{Aufgabe 2}

Sei $\mathrm{L}'$ die Theorie, die aus $\mathrm{L}$ entsteht, indem
Axiom A3 ersetzt wird durch Axiom A3': $(\neg \alpha
\rightarrow \neg\beta) \rightarrow(\beta\rightarrow\alpha)$.

Zeigen Sie, dass $\mathrm{L}'$ korrekt und vollständig ist, das heißt,
$\phi$ ist Tautologie \gdw $\xvdash{\mathrm{L}'} \phi$.

Da (jede Instanz von) A3' eine Tautologie ist,
kann der Beweis von \autoref{satz:1} übernommen werden und folglich
ist $\mathrm{L}'$ korrekt.

Wir zeigen, dass sich aus den Axiomen A1, A2 und A3' und dem modus ponens
das Axiom A3 beweisen lässt.
Damit sind alle Beweise, die wir bisher geführt haben und die A3 verwenden,
auch mit A3' herleitbar.

$\mathrm{L}'$ vollständig (d.\,h. für jede Tautologie $\phi$ gilt:
$\xvdash{\mathrm{L}'} \phi$): hinreichend ist $\xvdash{\mathrm{L}'} A3$.

\begin{align*}
  (1)\quad &\neg\beta \rightarrow \neg\alpha &\text{Hypothese}\\
  (2)\quad &\neg\beta \rightarrow \alpha &\text{Hypothese}\\
  (3)\quad &(\neg\beta\rightarrow\neg\alpha) \rightarrow
     (\alpha\rightarrow\beta) & \text{A3'}\\
  (4)\quad &\alpha\rightarrow\beta &\text{MP 1,3}\\
  (5)\quad &\text{\help{wie weiter?}}
\end{align*}


\section{Blatt 4}

\subsection*{Aufgabe 1}

Zeigen Sie mittels Resolution, dass die folgende Instanz des Axioms A2
eine Tautologie ist.
\begin{gather*}
  (A\rightarrow (B\rightarrow C)) \rightarrow ((A\rightarrow
     B)\rightarrow(A\rightarrow C))
\end{gather*}

Wenn A2 eine Tautologie ist, dann ist die Negation davon eine
Kontradiktion (d.\,h. eine Formel, die unter jeder Belegung falsch ist).
Die konjunktive Normalform ist
also die UND"=Verknüpfung der Negation aller passenden Belegungen:
\begin{gather*}
  (\neg A\vee \neg B\vee\neg C) \wedge (\neg A\vee \neg B\vee C) \wedge
     (\neg A\vee B\vee\neg C) \wedge \dotsb \wedge (A \vee \neg B\vee C)
     \wedge (A\vee B \vee\neg C) \wedge (A\vee B\vee C)
\end{gather*}
Daraus erhalten wir folgende resolutionsherleitung der leeren Klausel.

\includegraphics{resolution.9}

\subsection*{Aufgabe 2}

Zeigen Sie mittels Resolution, dass folgende Formel $\alpha$ eine
Tautologie ist.
\begin{gather*}
  \big( (A\vee B\vee \neg C) \wedge (\neg A\vee B\vee D) \wedge (C\vee D)
     \wedge (\neg A \vee \neg D) \wedge (A\vee C \vee \neg D) \big)
     \rightarrow (B\vee C)
\end{gather*}

Wir zeigen, dass die Negation $\neg \alpha$ von $\alpha$ eine Kontradiktion ist.
Da $\alpha$ die Form $\beta\rightarrow \gamma$ hat,
hat $\neg\alpha$ die Form $\beta \wedge \neg\gamma$.
Also ist $\neg \alpha$ folgende Formel.
\begin{gather*}
  (A\vee B\vee \neg C) \wedge (\neg A\vee B\vee D) \wedge (C\vee D)
     \wedge (\neg A \vee \neg D) \wedge (A\vee C \vee \neg D) \big)
     \wedge \neg B \wedge \neg C
\end{gather*}

Daraus erhalten wir folgende Resolutionsherleitung der leeren Klausel.

\includegraphics{resolution.10}


\subsection*{Aufgabe 3}
Wie lang kann ein Resolutionsbeweis höchstens sein?

Aus $n$ Variablen können höchstens $2^{2n}$ Klauseln gebildet werden.

Bei Klauselmengen mit Variablen $A_{1},A_{2},\dotsc,A_{n}$ ist jede
Klausel eine Teilmenge von $\underbrace{\{A_{1},\dotsc,A_{n}, \neg A_{1},\dotsc,\neg
A_{n}\}}_{2n\ \text{Elemente}}$. Eine Menge mit $2n$ Elementen hat
$2^{2n}$ Teilmengen.

Also ist $2^{2n}$ die obere Schranke für die Länge eines
Resolutionsbeweises für eine Klauselmenge mit $n$ Variablen.


\section{Blatt 5}

\subsection*{Aufgabe 1}
Was bedeuten die Formeln und den angegebenene Interpretationen?
\begin{enumerate}
 \item $(\exists n A_{1}^{2}(f_{1}^{2}(x,u), y) \wedge (\exists v
  A_{1}^{2}(f_{1}^{2}(x,v),z))$ auf der Grundmenge $\N$ und $A_{1}^{2}$
  ist die Gleichheit \glqq{}$=$\grqq{} und $f_{1}^{2}$ die Multiplikation
  ($u,v,x,y,z$ sind Variablensymbole)

  $(\exists u\in\N  x\cdot u=y) \wedge (\exists v\in\N  x\cdot
  v=z)$. Das entspricht der Aussage \glqq{}$x$ ist gemeinsamer Teiler von $y$
  und $z$\grqq{}.

 \item $\forall y( (\exists z A_{1}^{2}(f_{1}^{2}(y,z),x)) \rightarrow
  (A_{1}^{2}(y,a) \wedge A_{1}^{2}(y,x)))$, Interpretation wie oben und
  $a=1$

  $\forall y\in\N ~ (\exists z\in\N ~ y\cdot z=x \rightarrow)
  \rightarrow (y=1 \vee y=x)$. Das bedeutet \glqq{}$y$ ist Teiler von $x$
  $\rightarrow$ $(y=1 \vee y=x)$.\grqq{} Dies wiederum bedeutet \glqq{}$x$ ist eine
  Primzahl.\grqq{}
\end{enumerate}

\subsection*{Aufgabe 2}
Geben Sie eine Formel mit Interpretation mit der Grundmenge $\N$ an, die
folgende Bedeutung hat.
\begin{enumerate}
 \item $x=ggT(y,z)$

  \begin{gather*}
    T(x, a) \wedge T(x,b) \wedge (\forall y ~ T(y,a) \wedge T(y, b)
       \wedge y\leq x)
  \end{gather*}
  mit $T(\alpha,\beta)$ als \glqq$\alpha$ teilt $\beta$\grqq{}.

 \item Es gibt unendlich viele Primzahlen.

  \begin{gather*}
    \neg \big( \exists u ~ P(u) \wedge (\forall x ~ P(x) \wedge x
       < u) \big)
  \end{gather*}
  mit $P(\alpha)$ als \glqq$\alpha$ ist prim\grqq{}.

  oder: $P(2) \wedge \forall x \exists y (P(y) \wedge A_{1}^{2}(x,y))$
  mit $P(\alpha)$ als $\alpha$ ist prim und $A_{1}^{2}(\alpha,\beta)$ als
  $\alpha < \beta$.
\end{enumerate}


\section{Blatt 6}

\subsection*{Aufgabe 1}
Welche der folgenden Formeln sind gültig?
\begin{enumerate}
 \item $\neg (\exists x ~(\forall y ~ A^2_1(x,y) \leftrightarrow \neg
  A^2_1(x,x) ) )$

  Der Teil $A^{2}_{1}(x,y) \leftrightarrow \neg A_{1}^{2}(x,x)$ soll für
  alle $y$ gelten, also auch für $y=x$. Dann ist die Äquivalenzrelation
  $A_{1}^{2}(x,x) \leftrightarrow A_{1}^{2}(x,x)$ falsch und damit auch
  die Allaussage. Durch den Existenzquantor bleibt die Formel falsch und
  damit ist die Gesamtaussage wahr.

 \item $[(\exists x ~A^1_1(x))\rightarrow(\exists x~A^1_2(x))] \rightarrow
  (\exists x ~A^1_1(x) \rightarrow A^1_2(x)) $

  Der zweite Teil der Implikation ist falsch, wenn $\neg (\exists x A(x)
  \rightarrow B(x)) \equiv (\forall x A(x) \wedge \neg B(x))$. Also muss
  $(A)^{\mathcal{M}}$ die Grundmenge sein (d.\,h. immer wahr) und
  $B(x)=\emptyset)$. $\exists A(x) \rightarrow B(x)$ ist falsch nur dann,
  wenn $\mathcal{M}$ die Implikation von $A$ und $B$ enthält. $(\exists
  A(x)) \rightarrow (\exists x B(x))$ ist falsch unter jeder solchen
  Interpretation. Also ist die gesamte Formel unter jeder Interpretation
  wahr. Das heißt die Formel ist gültig.

 \item
  \begin{align*}
    (\exists x &A^1_1(x) \rightarrow (\forall x~A^1_1(x))) \\[2ex]
    &\equiv \exists x \neg A(x) \vee (\forall x A(x))\\
    &\equiv (\exists x \neg A(x)) \vee (\exists x (\forall x A(x)))\\
    &\equiv \neg(\forall x A(x)) \vee (\forall x A(x))
  \end{align*}
  Die Formel ist immer gültig, da sie eine Instanz von $B\vee\neg B$ ist.

  Der Umformung von der zweiten in die dritte Zeile $\exists x (\forall x
  A(x)) \equiv \forall x A(x)$ liegt zugrunde, dass Quantoren nur freie
  Vorkommen von Variablen binden. $x$ ist aber bereits durch den
  Allquantor gebunden und daher kann der Existenzquantor weggelassen
  werden.

 \item $(\forall x ~A^1_1(x) \vee A^1_2(x)) \rightarrow
  ((\forall x~A^1_1(x)) \vee (\exists x~A^1_2(x)))$

  $\mathcal{M}$ sei eine Interpretation, unter der $\forall x
  A_{1}^{1}(x)\vee A_{2}^{1}(x)$ wahr ist.
  \begin{faelle}
   \item Sei $\forall x A^{1}_{1}(x)$ falsch, dann ist $\forall x
    A_{1}^{2}(x)$ wahr, also auch $\exists x A_{1}^{2}(x)$ wahr und die
    Implikation $(\forall x A^1_1(x)) \vee (\exists x A^1_2(x))$ und
    damit die gesamte Formel.

   \item Sei $\forall x A_{1}^{1}(x)$ wahr, dann ist die Implikation
    immer wahr.
  \end{faelle}

  Für die Interpretation $\mathcal{M}'$, unter der $\forall x
  A_{1}^{1}(x)\vee A_{2}^{1}(x)$ falsch ist, gilt die Implikation immer.
\end{enumerate}

\subsection*{Aufgabe 2}
Finden Sie eine erfüllbare geschlossene Formel, die falsch ist unter
jeder Interpretation mit einer Grundmenge aus einem (zwei, drei)
Elementen.

Für einelementige Grundmengen ist die Formel $\exists x A(x) \wedge
\exists x \neg A(x)$ immer falsch. Mit einer Grundmenge mit mindestens
zwei Elementen ist die Formel jedoch wahr.

Für zweielementige Grundmengen ist die Formel $(\exists x \neg A(x)
\wedge \neg B(x)) \wedge (\exists x A(x) \wedge \neg B(x)) \wedge
(\exists x \neg A(x) \wedge B(x))$ falsch. Für die Grundmenge
$D=\{1,2,3\}$ macht die Interpretation $(A)^{\mathcal{M}} =\{2\},
(B)^{\mathcal{M}}=\{3\}$ die Formel wahr.

\subsection*{Aufgabe 3}
Zeigen Sie: ~~$\xvdash~ \alpha[x_i/t] \rightarrow (\exists x_i ~\alpha)$,
wobei $t$ frei für $x_i$ in $\alpha$ ist.

Bsp.: $\alpha = A_{1}^{2}(x,y) \wedge (\exists y \neg A_{1}^{2}(y,x))$\\
$\alpha[x/f_{1}^{2}(x,z)] = A_{1}^{2}(f_{1}^{2}(x,z), y)\wedge(\exists y
\neg A_{1}^{2}(y, f_{1}^{2}(x,z))$\\
$\alpha[y/x] = A_{1}^{2}(x,x) \wedge (\exists y \neg A_{1}^{2}(y,x))$\\
$\alpha[x/y] = A_{1}^{2}(y,y) \wedge (\exists y \neg A_{1}^{2}(y,y))$ ist
falsch. Da $y$ im zweiten Teil gebunden ist, darf $x$ nicht durch $y$
ersetzt werden.

\begin{align*}
  (1)\quad& (\forall x_{i} \neg\alpha) \rightarrow \neg\alpha[x_{i}/t] & \text{A4}\\
  (2)\quad& \big((\forall x_{i} \neg\alpha) \rightarrow
     \neg\alpha[x_{i}/t]\big) \rightarrow (\alpha[x_{i}/t] \rightarrow
     \neg(\forall x_{i} \neg\alpha)) &\text{Instanz einer auss.log. Tautologie}\\
  (3)\quad& \alpha[x_{i}/t] \rightarrow \neg (\forall x_{i} \neg\alpha)
     &\text{MP 1,2}\\
  (4)\quad& \alpha[x_{i}/t] \rightarrow (\exists x_{i}~ \alpha)
                & \text{abk. Schreibweise mit $\exists$}
\end{align*}

\subsection*{Aufgabe 4}
Zeigen Sie: ~~$\vdash~ (\forall x_i ~\alpha) \rightarrow (\exists x_i ~\alpha)$.

\begin{align*}
  (1)\quad & (\forall x_i ~ \alpha) \rightarrow \alpha[x_i/t] &\text{A4}\\
  (2)\quad & \alpha[x_{i}/t] \rightarrow (\exists x_{i} ~ \alpha)
     &\text{Aufgabe 3}\\
  (3)\quad & (\forall x_{i}~ \alpha) \rightarrow (\exists x_{i}~ \alpha)
     &\text{Transitivität von $\rightarrow$ auf 1,2}
\end{align*}

\section{Blatt 7}

Sei $\alpha$ eine Formel, in der $x$ nicht frei vorkommt.
Zeigen Sie, dass dann gilt:
\begin{enumerate}
 \item $\vdash \alpha \leftrightarrow (\forall x~\alpha)$

  Beweisen wir die Aussage in zwei Teilen:
  \begin{faelle}
   \item zu zeigen: $\vdash \alpha \rightarrow (\forall x~ \alpha)$
    \begin{align*}
      (1)\quad & \alpha &\text{Hypothese}\\
      (2)\quad& (\forall x~ \alpha) &\text{Gen 1}
    \end{align*}
    Damit ist gezeigt, dass $\alpha\vdash (\forall x ~ \alpha)$. Da $x$ nicht
    frei in $\alpha$ vorkommt, können wir das Deduktionstheorem anwenden
    und erhalten $\vdash \alpha \rightarrow (\forall x~ \alpha)$.

   \item zu zeigen: $\vdash (\forall x~ \alpha) \rightarrow \alpha$
    \begin{align*}
      (1)\quad & (\forall x~ \alpha) \rightarrow
         \underbrace{\alpha[x/t]}_{=\alpha} &\text{A4}
    \end{align*}
  Da $x$ in $\alpha$ nicht frei vorkommt, gilt $\alpha[x/t]=\alpha$.
  \end{faelle}
  Mit der Äquivalenzregel $\alpha\rightarrow\beta,
  \beta\rightarrow\alpha\vdash \alpha\leftrightarrow\beta$ folgt aus den
  beiden Fällen: $\vdash\alpha \leftrightarrow (\forall x~ \alpha)$

 \item $\vdash \alpha \leftrightarrow (\exists x ~ \alpha)$

  Zerlegen wir die Aussage wieder in zwei Teile:
  \begin{faelle}
   \item zu zeigen: $\vdash\alpha\rightarrow(\exists x ~ \alpha)$
    \begin{align*}
      (1)\quad& \alpha &\text{Hypothese}\\
      (2)\quad& (\exists x ~ \alpha) &\text{aus 1 mit RE4 (da $\alpha[x/t]=\alpha$)}
    \end{align*}
    Mit dem Deduktionstheorem ergibt sich $\vdash \alpha
    \rightarrow(\exists x ~ \alpha)$

   \item zu zeigen: $\vdash(\exists x ~ \alpha)\rightarrow\alpha$
    \begin{align*}
      (1)\quad& (\exists x ~ \alpha) &\text{Hypothese}\\
      (2)\quad& \underbrace{\alpha[x/c]}_{=\alpha} &\text{aus 1  mit Regel C}
    \end{align*}
    Die Regel~C darf im zweiten Schritt angewendet werden, weil die
    Konstante~$c$ bisher nicht in $\alpha$ vorkommt, und da
    $\alpha[x/c]=\alpha$ kommt $c$ auch nicht in der zu beweisenden
    Formel vor.
  \end{faelle}
  Die beiden Aussagen können wieder zur Gesamtaussage mittels der Äquivalenzregel
  $\alpha\rightarrow\beta,\beta\rightarrow\alpha\vdash \alpha\leftrightarrow\beta$
  gebracht werden.

 \item $\vdash \alpha \leftrightarrow (\alpha \rightarrow (\forall
  x ~ \beta)) \leftrightarrow (\forall x ~ \alpha \rightarrow\beta)$

  Wieder zwei Teil, wie zuvor:
  \begin{faelle}
   \item zu zeigen: $\vdash(\alpha\rightarrow(\forall x ~ \beta))
    \rightarrow (\forall x ~ \alpha\rightarrow\beta)$
    \begin{align*}
      (1)\quad& (\exists x ~ \alpha \wedge \neg\beta) &\text{Hypothese}\\
      (2)\quad& \underbrace{(\alpha \wedge \neg\beta)[x/c]}_{=\alpha
         \wedge \neg\beta[c/t]} &\text{aus 1 mit Regel C}\\
      (3)\quad& \alpha & \text{aus 2 mit Konjunktionsregel}\\
      (4)\quad& \neg\beta[x/c] &\text{aus 2 mit Konjunktionsregel}\\
      (5)\quad& (\exists x ~ \neg\beta) &\text{aus 4 mit RE4}\\
      (6)\quad& \underbrace{\alpha \wedge (\exists x ~ \neg\beta)}_{\alpha
         \wedge \neg(\forall x\beta) = \neg(\alpha \rightarrow (\forall
         x ~ \beta))} & \text{aus 3 und 5 mit Konjunktionsregel}
    \end{align*}
    Damit ist gezeigt: $\neg(\forall x ~ \alpha\rightarrow\beta) \vdash
    \neg(\alpha \rightarrow (\forall x ~ \beta))$. Mit Deduktionstheorem
    folgt: $\vdash\neg(\forall x ~ \alpha\rightarrow\beta) \rightarrow
    \neg(\alpha \rightarrow (\forall x ~ \beta))$. Verwenden wir folgende
    Instanz der Tautologie $(\neg\gamma\rightarrow\neg \delta)\rightarrow
    (\delta\rightarrow\gamma)$: $\vdash\big(\neg(\forall x ~ \alpha\rightarrow
    \beta) \rightarrow \neg(\alpha \rightarrow (\forall x ~ \beta)) \big)
    \rightarrow \big( (\alpha \rightarrow (\forall x ~ \beta)) \rightarrow
    (\forall x ~ \alpha\rightarrow\beta)\big)$, dann folgt mittels
    modus ponens $(\alpha \rightarrow (\forall x ~ \beta)) \rightarrow
    (\forall x ~ \alpha\rightarrow\beta)$.

   \item zu zeigen: $\vdash (\forall x ~ \alpha\rightarrow\beta)
    \rightarrow (\alpha \rightarrow \forall x ~ \beta)$
    \begin{align*}
      (1)\quad& (\forall x ~ \alpha\rightarrow\beta)
    \rightarrow (\alpha \rightarrow \forall x ~ \beta) &\text{A5}
    \end{align*}
  \end{faelle}

 \item $\vdash \alpha \leftrightarrow ((\exists x
  ~ \beta)\rightarrow\alpha) \leftrightarrow (\exists x ~ \beta \rightarrow
  \alpha)$

  Zeigen wir die Aussage wieder in zwei Schritten:
  \begin{faelle}
   \item dazu zeigen wir zuerst: $\neg(\exists x ~ \beta\rightarrow\alpha)
    \rightarrow \neg((\exists x ~ \beta) \rightarrow \alpha)$
    \begin{align*}
      (1)\quad& \underbrace{\neg(\exists x ~ \beta\rightarrow\alpha)}
         _{=(\forall x ~  \beta\wedge \neg\alpha)} &\text{Hypothese}\\
      (2)\quad& \beta[x/b] \wedge \neg \alpha &\text{aus 1 mit RA4}\\
      (3)\quad& \beta[x/b] &\text{aus 2 mit Konjunktionsregel}\\
      (4)\quad& \neg\alpha &\text{aus 2 mit Konjunktionsregel}\\
      (5)\quad& (\exists x ~ \beta) &\text{aus 3 mit RE4}\\
      (6)\quad& (\exists x ~ \beta) \wedge \neg\alpha
         &\text{Konjunktionsregel}
    \end{align*}
    Mit Deduktionstheorem folgt $\vdash\neg(\exists x ~\beta\rightarrow
    \alpha) \rightarrow \neg((\exists x~\beta) \rightarrow \alpha)$

    Analog zur vorherigen Aufgabe folgt die Teilaussage.

   \item analog zum ersten Fall.
  \end{faelle}
\end{enumerate}

\section{Blatt 8}\label{sec:uebung8}

\subsection*{Aufgabe 1}
Zeigen Sie
\begin{gather*}
  \vdash (\exists x~(\forall y ~\alpha)) \rightarrow (\forall y ~(\exists x~ \alpha))
\end{gather*}

    \begin{align*}
      (1)\quad & (\exists x~(\forall y ~\alpha)) & \text{Hypothese} \\
      (2)\quad & (\forall y ~ \alpha[x/c])   & \text{Regel C, 1} \\
      (3)\quad & \underbrace{(\alpha[x/c])[y/y]}_{=\alpha[x/c]}   & \text{RA4, 2} \\
      (4)\quad & (\exists x ~ \alpha) & \text{RE4, 3} \\
      (5)\quad & (\forall y ~ (\exists x ~ \alpha))   & \text{Gen, 3} \\
    \end{align*}
Die Generalisierung in Schritt (5) betrifft eine
Variable, die in der durch Regel C in Schritt (3) erhaltenen Formel
nicht frei vorkommt und ebenfalls in der Hypothese nicht frei vorkommt.
Deshalb war die Anwendung von Regel C korrekt
und das Deduktionstheorem kann angewendet werden.
\vspace{1ex}

Zeigen Sie, dass die folgende Formel nicht gültig ist:
\begin{gather*}
  (\forall y~ (\exists x ~A(x,y))) \rightarrow (\exists x~ (\forall y ~A(x,y)))
\end{gather*}

Die Interpretation $\cM$ mit Grundmenge $\N$
und $(A)^{\cM}=\{(x,y) \mid x>y\}$ ist kein Modell der Formel.
\vspace{1ex}

Warum funktioniert obiger Beweis bei letzterer Formel nicht?

Weil die Generalisierung eine Variable betrifft,
die in der durch Regel C erzeugten Formel frei vorkommt.
Deshalb wäre die Anwendung von Regel C nicht korrekt.


\subsection*{Aufgabe 2}
\begin{gather*}
  \vdash (\exists x ~\alpha\rightarrow\beta) \rightarrow
        ((\forall x ~\alpha) \rightarrow (\exists x ~\beta))
\end{gather*}


    \begin{align*}
      (1)\quad &  (\exists x ~\alpha\rightarrow\beta) & \text{Hypothese} \\
      (2)\quad &   \underbrace{(\alpha\rightarrow\beta)[x/c]}_{=\alpha[x/c] \rightarrow \beta[x/c]} & \text{Regel C, 1} \\
      (3)\quad &  (\forall x ~\alpha)  & \text{Hypothese} \\
      (4)\quad &  \alpha[x/c]  & \text{RA4, 3} \\
      (5)\quad &  \beta[x/c]   & \text{MP 4,2} \\
      (6)\quad &  (\exists x ~ \beta)   & \text{RE4, 5}
    \end{align*}
Hier ist wichtig, dass Schritt (2) vor Schritt (4) kommt.
Die durch Regel C eingeführte Konstante
kann durch Regel RA4 in Schritt (4) wiederverwendet werden.
Da im Beweis keine Generalisierungen vorkommen,
kann das Deduktionstheorem angewendet werden.


\subsection*{Aufgabe 3}
Gebundene Umbenennung von Variablen.

Bsp.: in einer Formel können quantifizierte Variable
umbenannt werden, ohne dass die Aussage der Formel geändert wird.
Als Beispiel betrachten wir die Definition der $O$-Notation.
Eine Funktion $f\colon\N\rightarrow\N$ ist in $O(g)$, falls
\begin{gather*}
\exists c\in\N ~ \exists n_{0}\in\N ~
\forall n\in\N ~ (n\geq n_{0}) \rightarrow (f(n)\leq c\cdot g(n)+c) .
\end{gather*}
Durch gebundene Umbenennung von $n_0$ zu $m$ erhalten wir die äquivalente Formel
\begin{gather*}
\exists c\in\N ~ \exists m\in\N ~
\forall n\in\N ~ (n\geq m) \rightarrow (f(n)\leq c\cdot g(n)+c).
\end{gather*}
Bei der gebundenen Umbenennung wird also die Variable hinter dem Quantor
und alle durch diesen Quantor gebundenen Vorkommen der Variablen umbenannt.


Formal: Sei $\alpha$ eine Formel mit freier Variablen $x$ ohne freies
Vorkommen von $y$ und mit $y$ frei für $x$ in $\alpha$. Dann gilt:
$\vdash (\forall x ~\alpha) \leftrightarrow (\forall y ~\alpha[x/y])$.

Wir zeigen zuerst $\vdash (\forall x ~\alpha) \rightarrow (\forall y ~\alpha[x/y])$.
    \begin{align*}
      (1)\quad & (\forall x ~\alpha) & \text{Hypothese} \\
      (2)\quad & \alpha[x/y] & \text{RA4, 1} \\
      (3)\quad & (\forall y ~\alpha[x/y]) & \text{Gen, 2}
    \end{align*}
Schritt (2) ist korrekt, da $y$ frei für $x$ in $\alpha$ ist.
Nun zeigen wir $\vdash (\forall y ~\alpha[x/y] \rightarrow (\forall x ~\alpha)$.
    \begin{align*}
      (1)\quad & (\forall y ~\alpha[x/y]) & \text{Hypothese} \\
      (2)\quad & \underbrace{(\alpha[x/y])[y/x]}_{=\alpha} & \text{RA4, 1} \\
      (3)\quad & (\forall x ~\alpha) & \text{Gen, 2}
    \end{align*}
Schritt (2) ist korrekt, da $y$ in $\alpha$ nicht frei vorkommt.
Alle freien Vorkommen von $y$ in $\alpha[x/y]$ sind also solche,
die freie Vorkommen von $x$ in $\alpha$ ersetzt haben.

Aus  $\vdash (\forall x ~\alpha) \rightarrow (\forall y ~\alpha[x/y])$
und $\vdash (\forall y ~\alpha[x/y] \rightarrow (\forall x ~\alpha)$
folgt $\vdash (\forall x ~\alpha) \leftrightarrow (\forall y ~\alpha[x/y])$
mit der Äquivalenzregel.


\section{Blatt 9}

\subsection*{Aufgabe 1}

Sei $K$ eine konsistente und abgeschlossene Theorie,
und $\alpha$ seine eine Formel von $K$, die nicht beweisbar ist.
Zeigen Sie: dann ist $K+\{\alpha\}$ nicht konsistent.

Wenn $\alpha$ eine geschlossene Formel ist,
dann sind in $K+\{\alpha\}$ sowohl $\alpha$ als auch $\neg\alpha$ beweisbar.
Also ist $K+\{\alpha\}$ nicht konsistent.

Wenn $\alpha$ nicht geschlossen ist,
dann ist der Abschluss $\alpha^{*}$ von $\alpha$ in $K$ nicht beweisbar.
Deshalb ist $\neg\alpha^{*}$ in $K$ beweisbar,
und ebenso in $K+\{\alpha\}$.
In $K+\{\alpha\}$ ist $\alpha^{*}$ beweisbar (mittels Gen).
Also ist $K+\{\alpha\}$ nicht konsistent.


\subsection*{Aufgabe 2}

Sei $\alpha$ eine Formel ohne Quantoren und $\vdash\alpha$ im
Prädikatenkalkül 1.~Ordnung. Zeigen Sie: $\alpha$ ist Instanz einer
Tautologie. (Hinweis: falls nicht, dann gibt es eine Interpretation mit
der Menge aller Terme von $\alpha$ als Grundmenge, unter der $\alpha$
falsch ist.)

Formel ohne Quantoren:
\begin{gather*}
  A_{1}^{2}(x_{5}, f_{1}^{2}(x_{1},x_{3})) \rightarrow A_{1}^{1}\big(
     f_{1}^{1}( f_{2}^{2}(x_{1},x_{5}))\big)
\end{gather*}
Menge aller Terme: $\{a_{5}, x_{1},x_{3},x_{5},f_{1}^{2}(x_{1}, x_{3}),
f_{2}^{2}(x_{1},x_{5}), f_{1}^{1}\big(f_{2}^{2}(x_{1},x_{5})\big) \}$.

$A_{1}^{2}\rightarrow A_{1}^{1}$ wird falsch unter $\{A_{1}^{2}, \neg
A_{1}^{1}\}$. Dieses dann auf den Inhalt anwenden.

% ---

Annahme: $\not\Mmodels\alpha$, d.\,h. es gibt eine Interpretation
$\mathcal{M}$ und eine Variablenbelegung $s\in\Sigma_{\mathcal{M}}$, so
dass gilt: $s$ erfüllt $\alpha$ nicht. Mit dem Vollständigkeitssatz
(\autoref{satz-vollstPK}) folgt $\not\vdash\alpha$.

Beweis der Annahme: $\alpha$ ist Formel ohne Quantoren und $\alpha$ ist
keine Instanz einer Tautologie. $\alpha$ könnte beispielsweise so aussehen
$\neg A(y)\wedge \big(A(x)\vee
(B(x) \rightarrow \neg A(x))\big) \leadsto A_{3}\wedge (A_{1}\vee
(A_{2}\rightarrow \neg A_{1}))$.

$\beta$ entsteht aus $\alpha$ durch Ersetzen atomarer Formeln durch
Variablen (gleiche atomare Formeln durch gleich Variablen). $\beta$ ist
keine Tautologie, dann hat $\beta$ eine Belegung $B$ unter der $\beta$
falsch ist. [$B=\{A_{1}, \neg A_{2}, A_{3}\}$.]

Konstruktion einer Interpretation $\mathcal{M}$ und einer
Variablenbelegung $s$: Grundmenge sei die Menge aller Terme aus
Bestandteilen von $\alpha$
\begin{gather*}
  \{x, y, f(x), f(y), f(f(x)), f(f(y)), \dotsc\}
\end{gather*}
und $(f)^{\mathcal{M}}(t) = f(t)$ für jedes $t$ in der Grundmenge.

\glqq{}Terme werden durch sich selbst interpretiert.\grqq{}

[$(A)^{\mathcal{M}} = \{x,y\}, (B)^{\mathcal{M}} = \emptyset$.]
Prädikatensymbole werden entsprechend der Belegung der aussagenlogischen
Variablen interpretiert.

Variablenbelegung von $s$:\hspace{1cm}
\begin{tabular}[t]{c|cc}
  $z$ & $x$ & $y$\\
  \hline
  $s(z)$ & $x$ & $y$
\end{tabular}

Jedes Variablensymbol wird in $s$ durch sich selbst interpretiert. Nun
gilt: $s$ erfüllt $\alpha$ \gdw $\beta$ ist wahr unter $B$. Weil $\beta$
falsch ist unter $B$, ist $\mathcal{M}$ kein Modell von $\alpha$. Also
ist $\alpha$ nicht gültigt und folglich gilt $\not\vdash\alpha$.

\section{Blatt 10}

Beweisen Sie das Theorem (f): $\Svdash t=0+t$

Wir zeigen $\Svdash x=0+x$ mittels Induktion über $x$
\begin{mdescription}
 \item[IA:]
  \begin{align*}
    (1)\quad& 0+0 = 0&\text{(S5')}\\
    (2)\quad& 0+0 = 0 \rightarrow 0=0+0&\text{(b)}\\
    (3)\quad& 0=0+0 &\text{MP 1,2}
  \end{align*}
  Damit ist $\Svdash x=0+x$ bewiesen.

 \item[IS:] $x=0+x \rightarrow x'=0+x'$
  \begin{align*}
    (1)\quad& x=0+x & \text{Hypothese}\\
    (2)\quad& x=0+x \rightarrow x' = (0+x)' &\text{(S2')}\\
    (3)\quad& x' = (0+x)' &\text{MP 1,2}\\
    (4)\quad& 0+x' = (0+x)' &\text{(S6')}\\
    (5)\quad& x'=(0+x)' \rightarrow (0+x' = (0+x)' \rightarrow x' = 0+x')
       &\text{(d)}\\
    (6)\quad& 0+x' = (0+x)' \rightarrow x'=0+x' &\text{MP 3,5}\\
    (7)\quad& x' = 0+x' &\text{MP 4,6}
  \end{align*}
  Damit ist $x=0+x \Svdash x'=0+x'$ gezeigt. Mit dem Deduktionstheorem
  folgt $\Svdash x=0+x \rightarrow x'=0+x'$. Mit Generalisierung folgt
  $\Svdash \forall x ~ x=0+x \rightarrow x'=0+x'$.

  Aus dem Induktionsanfang und Induktionsschluss folgt mit Axiom~S9 $\Svdash
  (\forall x ~ x=0+x)$. Mit der Regel~RA4 ergibt sich $\Svdash t=0+t$.
\end{mdescription}

\section{Blatt 11}
\subsection*{Aufgabe 1}
Beweisen Sie, dass die Nullfunktion (streng) repräsentierbar ist.
\begin{gather*}
  Z\colon\N^{k} \rightarrow \N\quad\text{mit}\quad
     Z(n_{1},\dotsc,n_{k})=0 \qquad\text{für alle~} n_{1},\dotsc,n_{k}\in\N
\end{gather*}

Rerpäsentation ist:
\begin{gather*}
  x_{1} = x_{1} \wedge \dotsb \wedge x_{k}=x_{k} \wedge x_{k+1}=0
\end{gather*}

\begin{enumerate}[(1)]
 \item
  Für $Z(n_{1},\dotsc,n_{k})=m=0$ gilt $\Svdash \overline{n_{1}} =
  \overline{n_{2}}\wedge \overline{n_{2}}=\overline{n_{2}}\wedge \dotsb
  \wedge \overline{n_{k}}=\overline{n_{k}}\wedge 0=0$.
  \begin{align*}
    (1)\quad & \overline{n_{1}} = \overline{n_{1}} & \text{\autoref{lemma-zahlen-elem}}\\
    \vdots\quad & \vdots\\
    (k)\quad & \overline{n_{k}} = \overline{n_{k}}\\
    (k+1)\quad & \overline{0} = \overline{0}\\
    (k+2)\quad & \overline{n_{1}} = \overline{n_{2}}\wedge
       \overline{n_{2}}=\overline{n_{2}}\wedge \dotsb
       \wedge \overline{n_{k}}=\overline{n_{k}}\wedge 0=0
       &\text{Konjunktionsregel}
  \end{align*}

 \item $\Svdash \exists_{1} x_{k+1} ~ \overline{n_{1}} \ne
  \overline{n_{2}}\wedge \overline{n_{2}}\ne\overline{n_{2}}\wedge \dotsb
  \wedge \overline{n_{k}}\ne\overline{n_{k}}\wedge x_{k+1}\ne0$

  einfacher: $\Svdash \exists_{1}x_{k+1} ~ x_{k+1}=0$ d.\,h.
  \begin{gather*}
    \Svdash (\exists x_{k+1} ~ x_{k+1} =0) \wedge (\forall x_{k+1}
       \dotso \forall y ~ (x_{k+1} = 0\wedge y=0) \rightarrow x_{+1}
       = y)
  \end{gather*}

  $(\exists x_{k+1} ~ x_{k+1} =0)$
  \begin{align*}
    (1)\quad & 0=0 & \text{Lemma}\\
    (2)\quad & \exists x_{1} ~ x_{k+1}=0 &\text{RE 4}
  \end{align*}

  $(\forall x_{k+1} \dotso \forall y ~ (x_{k+1} = 0\wedge y=0)
  \rightarrow x_{+1} = y)$
  \begin{align*}
    (1)\quad & x_{k+1} = 0\wedge y=0 &\text{Hypothese}\\
    (2)\quad & x_{k+1} = 0 &\text{Konjunktionsregel}\\
    (3)\quad & y=0&\text{Konjunktionsregel}\\
    (4)\quad & x_{k+1} = y &\text{Transitiv. und Symm. von $=$}
  \end{align*}
\end{enumerate}

\subsection*{Aufgabe 2}
Beweisen Sie, dass die Konstantenfunktion $C_{i}\colon\N\rightarrow\N$
mit $C_{i}(n) =i$ (streng) repräsentierbar ist.
\begin{gather*}
  x_{1} = x_{1} \wedge \dotsb \wedge x_{k}=x_{k} \wedge x_{k+1} = \overline{m}
\end{gather*}

\begin{enumerate}[(1)]
 \item Für $C_{m}^{k}(n_{1},\dotsc,n_{k})= m$ gilt
  $\Svdash (m_{1}=n_{1}\wedge\dotsb \wedge n_{k}=n_{k} \wedge
  \overline{m}=\overline{m})$
 \item $\Svdash(\exists_{1} x_{k+1} ~
  \overline{n_{1}}=\overline{n_{1}} \wedge\dotsb\wedge
  \overline{n_{k}}=\overline{n_{k}} \wedge x_{k+1}=\overline{m}$
\end{enumerate}

\subsection*{Aufgabe 3}
Geben Sie Formeln zur Repräsentation der folgenden Funktionen an.
\begin{gather*}
  f(n) = \left\lfloor \frac{n}{2} \right\rfloor \\
     f(n) = \begin{cases}
              n-1 & \text{falls $n$ ungerade}\\
              n+1 & \text{sonst}
            \end{cases}
\end{gather*}

\begin{gather*}
  \overline{2}\cdot x_{2} = x_{1} \vee \overline{2}\cdot
     x_{2}+\overline{1} = x_{1}\\[1ex]
  \big((x_{2} + \overline{1} = x_{1}) \wedge (\exists z ~ x_{1}
     = \overline{2}\cdot z+\overline{1})\big) \vee \big((x_{2} = x_{1} +
     \overline{1}) \wedge (\exists z ~ x_{1} = \overline{2}\cdot
     z)\big)
\end{gather*}

\section{Blatt 12}

\subsection*{Aufgabe 1}
Zeigen Sie, dass $x^y$ primitiv-rekursiv ist.
\begin{align*}
  f_{pot}(a,0) &= 1 &&= N(Z^{(1)}(a))\\
  f_{pot}(a,b+1) &= f_{pot}(a,b)\cdot a &&= h(b, f_{pot}(a,b), a)
\end{align*}
mit $h=(p,q,r) = f_{mul}(U_{2}^{(3)}(p,q,r), U_{1}^{(3)}(p,q,r))$. Da
$f_{mul}$ primitiv-rekursiv ist und $h$ durch Komposition aus
primitv-rekursiven Funktionen entsteht ist auch $f_{pot}$
primitiv-rekursiv.

\subsection*{Aufgabe 2}
Zeigen Sie, dass die Fibonacci-Funktion primitiv-rekursiv ist.
\begin{align*}
  fib(0) &= 0 \qquad fib(1) =1\\
  fib(n+2) &=fib(n+1)+fib(n)
\end{align*}

Das Problem ist, dass zur Berechnung von $fib(n)$
sowohl auf $fib(n-1)$ als auch auf $fib(n-2)$ zurückgegriffen wird.
Das erlaubt das Schema der Rekursion nicht direkt.
Deswegen definieren wir zuerst eine Funktion,
die zwei Zahlen zu einer Zahl kodiert,
und die entsprechenden Dekodierungsfunktionen.
Die Kodierungsfunktion $k$ ist primitiv-rekursiv.
\begin{gather*}
k(a,b) = 2^a \cdot 3^b
\end{gather*}
$k$ ist injektiv, also
gibt es die Dekodierungsfunktionen.
\begin{align*}
  d_0(n) &= a &\text{falls~}n=k(a,b)\\
  d_1(n)&= b &\text{falls~}n=k(a,b)
\end{align*}
Falls $n$ nicht im Wertebereich von $k$ liegt,
sind uns die Werte $d_0(n)$ und $d_1(n)$ egal.
Die beiden Dekodierungsfunktionen sind ebenfalls primitiv-rekursiv.
\begin{align*}
  d_0(n) &= \min_{i\leq n} \neg(2^{i+1} | n)\\
  d_1(n) &= \min_{i\leq n} \neg(3^{i+1} | n)
\end{align*}
Der Einfachheit halber schreiben wir $(n)_0$ für $d_0(n)$,
und $(n)_1$ für $d_1(n)$.

Nun definieren wir eine Hilfsfunktion $f(n) = k(fib(n),fib(n+1))$,
die zwei aufeinanderfolgende Fibonacci-Zahlen kodiert.
\begin{align*}
  f(0) &= 3  &&= N(N(N(Z^{(0)})))\\
  f(n+1) &= k(fib(n+1),fib(n+2)) = k((f(n))_{1},(f(n))_{0} + (f(n))_{1} = h(n, f(n))\\
  h(a,b) &= f_{mult}\Big(f_{pow}(N(N(Z^{(2)}(a,b))), ( U_{2}^{(2)}(a,b)
     )_{1}), f_{pow}(N(N(N(Z^{(2)}(a,b)))),
     f_{add} ( (U_{2}^{(2)}(a,b))_{0}, (U_{2}^{(2)}(a,b))_{1} ) ) \Big)
\end{align*}
Also ist $f$ primitiv-rekursiv.
Zum Abschluss müssen wir noch sagen,
wie die Fibonacci-Funktion definiert ist:
\begin{gather*}
  fin(n) = (f(n))_{0}
\end{gather*}

\clearpage
\pdfbookmark[0]{Index}{index}
\printindex

\end{document}
