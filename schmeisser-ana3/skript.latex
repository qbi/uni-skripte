% Einige zusätzliche Informationen für rubber
% rubber: clean Fundamental-waerme.pdf $base.thm
% rubber: watch $base.thm
% rubber: makeidx.tool xindy
% rubber: makeidx.language  german-din
% rubber: makeidx.modules indexstyle.xdy

\documentclass[halfparskip*,german,draft,twoside]{scrreprt}

\usepackage{ifthen}
\usepackage{makeidx}
\usepackage[final]{graphicx}
\usepackage{color}
\usepackage[draft=false,colorlinks,bookmarksnumbered,linkcolor=blue,breaklinks]{hyperref}

\usepackage[latin1]{inputenc}
\usepackage{ngerman}
% \usepackage{tabularx}

\usepackage{times}		% Times

% Schrift, die für serifenlose Schrift (\textsf{}) verwendet wird
\usepackage{helvet}

% T1-Schriften verwenden -- notwendig für PDFs
\usepackage[T1]{fontenc}

\usepackage{esint}       % für den Pfeil am oint
% esint muss vor amsmath geladen werden, da es die ganzen Integrale
% umdefiniert und so die Ausrichtung der Grenzen (Option intlimits bei
% amsmath) zerstört. Da amsmath aber die folgenden Befehle neu definiert,
% müssen wir sie nach dem Laden wieder löschen.
\makeatletter
\let\iint\relax
\let\iiint\relax
\let\iiiint\relax
\makeatother

\usepackage[intlimits,leqno]{amsmath}
\usepackage{amssymb}     % wird für \R, \C,... gebraucht
\usepackage[thmmarks,hyperref,amsmath]{ntheorem} % für die Theorem-Umgebungen
                                         % (satz, defini, bemerk)
\usepackage{xspace}      % wird weiter unten gebraucht
\usepackage{slashbox}    % für schräge Striche im links oben in der
                         % Tabelle; s. texdoc slashbox

\usepackage{paralist}    % besseres enumerate und itemize und neue
                         % compactenum/compactitem; s. texdoc paralist

\usepackage{svn}         % Zum Auswerten und ordentlichen Darstellen der
                         % SVN-Schlüsselwörter (s. vor \begin{document})
                         % dafür muss in SVN noch das Flag svn:keywords
                         % auf "LastChangedRevision LastChangedDate"
                         % gesetzt werden
\usepackage{nicefrac}    % kleine Brüche besser aussehen lassen
\usepackage{ifpdf}       % Erkennung, ob PDF generiert wird; nützlich zur
                         % Unterscheidung bei Grafiken
                         % \input{XYZ.pdf_t}
\usepackage{xkeyval}     % für die Auswertung von Argumentenlisten; s.
                         % Neudefinition von \emph
\usepackage[all,warning]{onlyamsmath}
\usepackage[l2tabu]{nag}
\usepackage{fixmath}



% Damit auch die Zeichen im Mathemode in Überschriften fett sind
% <news:lzfyyvx3pt.fsf@tfkp12.physik.uni-erlangen.de>
\addtokomafont{sectioning}{\boldmath}

\setdefaultenum{(1)}{(a)}{i.}{A.}

\makeatletter
\def\@thmcountersep{/}
% Anpassung, damit ntheorem in der Satzübersicht genügend Platz für die
% Satznummer und den Namen lässt; einfach aus ntheorem.sty kopiert und
% den dritten Parameter von \@dottedtocline vergrößert
\def\thm@@thmline@name#1#2#3#4#5{%
     \ifx\\#5\\%
         \@dottedtocline{-2}{0em}{3.5em}%
             {#1 \protect\numberline{#2}#3}%
             {#4}
     \else
         \ifHy@linktocpage\relax\relax
             \@dottedtocline{-2}{0em}{3.8em}%
                 {#1 \protect\numberline{#2}#3}%
                 {\hyper@linkstart{link}{#5}{#4}\hyper@linkend}%
         \else
             \@dottedtocline{-2}{0em}{3.8em}%
                 {\hyper@linkstart{link}{#5}%
                   {#1 \protect\numberline{#2}#3}\hyper@linkend}%
                 {#4}%
         \fi
     \fi}
% Damit \autoref den richtigen Namen findet
% <news:slrnd8s9ce.403.joerg@alea.gnuu.de>
\newcommand*{\saved@gather}{}
\let\saved@gather\gather
\def\gather{\@hyper@itemfalse\saved@gather}
\makeatother

% nach dem Theoremkopf wird ein Zeilenumbruch eingefügt, die Schrift des
% Körpers ist normal und der Kopf wird fett gesetzt
\theoremstyle{break}
\theorembodyfont{\normalfont}
\theoremheaderfont{\normalfont\bfseries}
\theoremnumbering{arabic}

% Die folgenden Umgebungen werden einzeln nummeriert und am Ende jedes
% Kapitels zurückgesetzt
\newtheorem{satz}{Satz}[subsection]
\newtheorem{bemerk}{Bemerkung}[subsection]
\newtheorem{defini}{Definition}[subsection]
\newtheorem{bsp}{Beispiel}[subsection]
\newtheorem{folger}{Folgerung}[subsection]
\newtheorem{lemma}{Lemma}[subsection]

\makeatletter
% \autoref unterscheidet die Umgebungen, die angesprochen werden, anhand
% ihres Zählernamens. Da sich aber alle Umgebungen einen Zähler mit satz
% teilen sollen, bezeichnet \autoref alles mit "`Satz"'. Daher bekommt
% jede Umgebung einen eigenen Zähler, der in Wirklichkeit ein Alias zu
% satz ist
% <news:m3wvitk0o9.fsf@sgifford.tir.com>
\renewcommand*{\c@bemerk}{\c@satz}
\renewcommand*{\p@bemerk}{\p@satz}
\renewcommand*{\thebemerk}{\thesatz}
\renewcommand*{\c@defini}{\c@satz}
\renewcommand*{\p@defini}{\p@satz}
\renewcommand*{\thedefini}{\thesatz}
\renewcommand*{\c@bsp}{\c@satz}
\renewcommand*{\p@bsp}{\p@satz}
\renewcommand*{\thebsp}{\thesatz}
\renewcommand*{\c@folger}{\c@satz}
\renewcommand*{\p@folger}{\p@satz}
\renewcommand*{\thefolger}{\thesatz}
\renewcommand*{\c@lemma}{\c@satz}
\renewcommand*{\p@lemma}{\p@satz}
\renewcommand*{\thelemma}{\thesatz}
\makeatother

% Die folgenden Theoremumgebungen bekommen keine Nummer
\theoremstyle{nonumberbreak}

\theoremheaderfont{\scshape}
\theorembodyfont{\normalfont}
% Das Zeichen am Ende eines Beweises
\theoremsymbol{\ensuremath{_\blacksquare}}
% \theoremsymbol{q.\,e.\,d.}
\newtheorem{proof}{Beweis:}

% Hier die Definition, wie \autoref die Umgebungen nennen soll, die mit
% newtheorem definiert wurden
\newcommand*{\satzautorefname}{Satz}
\newcommand*{\lemmaautorefname}{Lemma}
\newcommand*{\bemerkautorefname}{Bemerkung}
\newcommand*{\definiautorefname}{Definition}
\newcommand*{\bspautorefname}{Beispiel}
\newcommand*{\folgerautorefname}{Folgerung}
\newcommand*{\proofautorefname}{Beweis}
% Zwischen Unter- und Unterunterabschnitten sollte nicht unterschieden
% werden.
\renewcommand*{\subsectionautorefname}{Abschnitt}
\renewcommand*{\subsubsectionautorefname}{Abschnitt}

\pagestyle{headings}

\newcommand*{\R}{\mathbb{R}}      % reelle Zahlen
\newcommand*{\C}{\mathbb{C}}      % komplexe Zahlen
\newcommand*{\N}{\mathbb{N}}      % natürliche Zahlen
\newcommand*{\Z}{\mathbb{Z}}      % ganze Zahlen

% Wenn irgendwo Unklarheiten zum Inhalt im Skript auftreten, können sie
% einfach mit \help{Ich verstehe das nicht} hervorgehoben werden. Dies
% macht es leichter sie alle zu finden und auch ganz einfach
% auszublenden, indem man den Befehl einfach leer definiert
\newcommand*{\help}[1]{\textcolor{green}{help: #1}}

% \todo ist das gleiche wie \help nur für offene Aufgaben
\newcommand*{\todo}[1]{\textcolor{red}{todo: #1}}

% Um wichtige Begriffe im Text überall gleich vorzuheben (gleiches
% Markup), sollte dieser Befehl verwendet werden. Das Argument wird
% automatisch als Indexeintrag verwendet und am Rand wiederholt. Da unter
% Umständen der Eintrag im Index oder am Rand anders lauten soll --
% z.\,B. Oberbegriff!Unterbegriff für den Index --, akzeptiert der Befehl
% ein optionales Argument in Form einer Liste, die mit
% index=<Indexeintrag> und rand=<Randeintrag> die jeweiligen Felder
% anders belegt.
\makeatletter
\define@key{local}{index}{\def\local@index{#1}}
\define@key{local}{rand}{\def\local@rand{#1}}

\renewcommand*{\emph}[2][]{%
  \begingroup%
    \setkeys{local}{index={#2},rand={#2}}\setkeys{local}{#1}%
    \textit{#2}%
    \if\@empty\local@index\relax\else\index{\local@index}\fi%
    \if\@empty\local@rand\relax\else%
      \marginpar{\raggedright\small\itshape\local@rand}%
    \fi%
  \endgroup%
}
\makeatother

% Definition für Xindy für die Trennung der einzelnen Abschnitte im
% Index. siehe auch die Datei indexstyle.xdy
\newcommand*{\indexsection}{\minisec}

% Für Leute, die nicht gern o.\,B.\,d.\,A. jedesmal eintippen wollen
\newcommand*{\obda}{o.\,B.\,d.\,A.\xspace}

% Diese Befehle sind dafür gedacht, dass die Symbole für "genau dann wenn"
% im ganzen Dokument gleich aussehen. Außerdem erlaubt es eine schnelle
% Veränderung aller Stellen, falls der Prof. doch nicht mehr gdw nimmt,
% sondern \Leftrightarrow.
\newcommand*{\gdw}{\ifthenelse{\boolean{mmode}}%
			       {\Leftrightarrow}%
			       {$\gdw$\xspace}}
\newcommand*{\gdwdef}{\ifthenelse{\boolean{mmode}}%
			       {:\Leftrightarrow}%
			       {$\gdwdef$\xspace}}

% Um sicherzustellen, dass jeder Betrag-/jede Norm links und rechts die
% Striche bekommt, sind diese Befehle da. Damit kann man nicht die
% rechten Striche vergessen und es wird etwas übersichtlicher. (Vorschlag
% ist aus amsldoc) \abs[\big]{\abs{a}-\abs{b}} \leq \abs{a+b}
\newcommand*{\abs}[2][]{#1\lvert#2%
  \ifthenelse{\equal{\protect #1}{\protect \left}}{\right}{#1}\rvert}
\newcommand*{\norm}[2][]{#1\lVert#2%
  \ifthenelse{\equal{\protect #1}{\protect \left}}{\right}{#1}\rVert}
\newcommand*{\sprod}[3][]{#1\langle #2,#3%
  \ifthenelse{\equal{\protect #1}{\protect \left}}{\right}{#1}\rangle}

% Das original Epsilon sieht nicht so toll aus
\renewcommand*{\epsilon}{\varepsilon}
% ... und mancheinem gefällt auch das Phi nicht
\renewcommand*{\phi}{\varphi}

% In der Vorlesung war an dem Kurvenintegral ein kleiner Pfeil. Da das
% Kurvenintegral ohne Pfeil nie genutzt wurde, definieren wir es einfach
% um. Mithilfe von \ilimits@ aus amsmath wird in abgesetzten Formeln die
% Grenzen drüber und drunter und in Textformeln daneben gestellt.
\makeatletter
\def\oint{\varointctrclockwise\ilimits@}
\makeatother

% Befehl zur Vergabe von Gleichungsnummern, an Stellen, an denen sonst
% keine Nummer erstellt werden würde (in gather* z.B.)
% <news:1326938.k4GxBACWuN@ID-107054.user.dfncis.de>
\newcommand*{\taglabel}[1]{%
  \refstepcounter{equation}\tag{\theequation}\label{#1}%
}

% Manchmal möchte man Begriffe erklären oder etwas aufzählen, das aber
% nicht fett gedruckt werden soll. Dazu diese Umdefinition einer
% description mit normaler Schrift
\newenvironment*{mdescription}%
               {\renewcommand*{\descriptionlabel}[1]%
			      {\hspace\labelsep\normalfont ##1}%
		 \begin{description}}%
		 {\end{description}}

\newcounter{fall}
\newenvironment*{faelle}%
               {\begin{list}{\textit{\arabic{fall}.\,Fall:}}%
                      {\usecounter{fall}%
                        \settowidth{\labelwidth}{\textit{\underline{9.\,Fall:}}}%
                        \setlength{\leftmargin}{1.3cm}%
                        \setlength{\itemindent}{3mm}%
                        \addtolength{\itemindent}{\labelwidth}%
                        \addtolength{\itemindent}{-\leftmargin}%
                      }}%
               {\end{list}}

\DeclareMathOperator{\Div}{div}		% Differgent
\DeclareMathOperator{\grad}{grad}	% Gradient
\DeclareMathOperator{\rot}{rot}		% Rotation
\DeclareMathOperator{\supp}{supp}	% Träger
\DeclareMathOperator{\Res}{Res}         % Residuum

\makeindex

\SVN $LastChangedRevision$
\SVN $LastChangedDate$

\begin{document}

\title{Analysis 3}
\author{Prof.\,Dr.\,Hans-Jürgen Schmeißer}
\date{Semester: WS 2005/06}
\maketitle

\clearpage
\chapter*{Vorwort}
{\itshape

  Dieses Skript ist im Rahmen des
  \href{http://www.minet.uni-jena.de/~joergs/skripte/}{Projekts
  "`Vorlesungsskripte der Fakultät für Mathematik und Informatik"'}
  entstanden und wird im Rahmen dieses Projekts weiter betreut. Das
  Skript ist nach bestem Wissen und Gewissen entstanden. Denoch
  garantiert weder der auf der Titelseite genannte Dozent, noch die
  Mitglieder des Projekts für dessen Fehlerfreiheit. Für etwaige Fehler
  und dessen Folgen wird von keiner der genannten Personen eine Haftung
  übernommen. Es steht jeder Person frei, dieses Skript zu lesen, zu
  verändern oder auf anderen Medien verfügbar zu machen, solange ein
  Verweis die Internetadresse
  \url{http://www.minet.uni-jena.de/~joergs/skripte/} des Projekts
  enthalten ist.

  Diese Ausgabe trägt die Versionsnummer~\SVNLastChangedRevision\ und ist
  vom \SVNDate. Eine (mögliche) aktuellere Ausgabe ist im Verzeichnis
  \href{http://www.minet.uni-jena.de/~joergs/skripte/pdf/}{PDF} verfügbar.

  Jeder ist dazu aufgerufen Verbesserungen, Erweiterungen und
  Fehlerkorrekturen für das Skript einzureichen bzw. zu melden oder selbst
  einzupflegen -- einfach eine eMail an die
  \href{mailto:skripte@listserv.uni-jena.de}{Mailingliste
  \texttt{<skripte@listserv.uni-jena.de>}} senden. Weitere Informationen
  sind unter der oben genannten Internetadresse des Projekts verfügbar.

  Hiermit möchten wir allen Personen, die an diesem Skript mitgewirkt
  haben, vielmals danken:
  \begin{itemize}
   \item \href{mailto:joerg@alea.gnuu.de}{Jörg Sommer
    \texttt{<joerg@alea.gnuu.de>}} (2005--2006)
   \item \href{mailto:jens@kubieziel.de}{Jens Kubieziel \texttt{<jens@kubieziel.de>}} (2005--2006)
   \item Peter Schindler (2005)
   \item Fabian Stutzki (2005--2006)
  \end{itemize}
}

\clearpage
\pdfbookmark[0]{Inhaltsverzeichnis}{inhaltsverzeichnis}
\tableofcontents
\clearpage

\clearpage
\pdfbookmark[0]{Auflistung der Sätze}{theoremlist}
\chapter*{Auflistung der Theoreme}

\pdfbookmark[1]{Sätze}{satzlist}
\section*{Sätze}
\theoremlisttype{optname}
\listtheorems{satz}

\pdfbookmark[1]{Definitionen und Festlegungen}{definilist}
\section*{Definitionen und Festlegungen}
% \theoremlisttype{all}
\listtheorems{defini,festl}

\clearpage
\pdfbookmark[0]{Literaturverzeichnis}{literaturverzeichnis}
\begin{thebibliography}{99}
 \bibitem{Jost} I. Jost: Partielle Differentialgleichungen, Springer 1998
 \bibitem{Wuest} R. Wüst: Höhere Mathematik für Physiker, Teil 2, de
  Gruyter 1995
 \bibitem{Evans} L. Evans: Partial differential equations, AMS 1998
 \bibitem{Fischer+Lieb} W.\,Fischer, I.\,Lieb: Funktionentheorie, Vieweg
  2003 (8.\,Auflage)
 \bibitem{Remmert} R.\,Remmert: Funktionentheorie I+II, Springer 1184/91
 \bibitem{Fischer+Kaul} H.\,Fischer, H.\,Kaul: Mathematik für Physiker 1,
  Teubener 1990 (Kapitel VII)
 \bibitem{Stein+Shakarchi} E.\,M.\,Stein, R.\,Shakarchi: Complex
  Analysis, Princeton University Press 2003
\end{thebibliography}

\setcounter{chapter}{7}

\chapter{Vektoranalysis, Integralsätze}
\section{Vektorfelder}
\subsection{Differentialoperatoren-Rechenregeln}

\begin{defini}
  Sei $\Omega\subseteq\R^{n}$ offen, $x=(x_{1},\ldots,x_{n})\in\Omega$,
  $\{\vec{e_{1}}, \ldots,\vec{e_{n}} \}$ kanonische Basis,
  $u\colon\Omega\rightarrow\R$ ist einmal stetig differenzierbar ($u\in
  C^{1}(\Omega)$), $u$ ist ein \emph{vskalares Feld}\footnote{Ein
  skalares Feld ist eine Abbildung von $\R^{n}$ nach $\R$. Man sagt,
  jedem Punkt im Raum wird eine reelle Zahl zugeordnet.}, $\vec{v}(x) = v_{1}
  (x) \vec{e_{1}} + \ldots+ v_{n} (x) \vec{e_{n}} =
  (v_{1}(x), \ldots, v_{n}(x))$ oder als Spaltenvektor
  $\begin{bmatrix}v_{1}(x)\\\vdots\\v_{n}(x)\end{bmatrix}, v_{j}\in
  C^{1}(\Omega)$ ein $C^{1}$-Vektorfeld (für  $=1,\ldots,n$). Dann gilt:

  \begin{enumerate}
   \item Als den \emph[rand={Gradient, Nabla}]{Gradient} oder \emph[rand=]{Nabla} einer
    Funktion $u$ bezeichnet man
    \begin{align*}
      \grad u &= \nabla u = \partial_{1}u\vec{e_{1}}
         +\ldots+\partial_{n}u\vec{e_{n}}&\text{wobei }\partial_{j} =
         \frac{\partial}{\partial x_{j}}\\
      &= \begin{bmatrix}\partial_{1}u\\\vdots\\\partial_{n}u\end{bmatrix}
    \end{align*}
   \item Als \emph{Divergenz} eines Vektorfeldes $\vec{v}$
    bezeichnet man
    \begin{gather*}
      \Div \vec{v} := \partial_{1}v_{1} +
         \partial_{2}v_{2}+\ldots+\partial_{n}v_{n} (=\nabla \vec{v})
    \end{gather*}
   \item Die \emph{Rotation} eines Vektorfeldes $\vec{v}$ im $R^{3}$ ist
    definiert als
    \begin{align*}
      \rot \vec{v} &= (\partial_{2}v_{3}-\partial_{3}v_{2})\vec{e_{1}} +
         (\partial_{3}v_{1}-\partial_{1}v_{3})\vec{e_{2}} +
         (\partial_{1}v_{2}-\partial_{2}v_{1})\vec{e_{3}}\\
      \left(&= \nabla \times \vec{v} =
         \begin{vmatrix}
           \vec{e_{1}}&\partial_{1}& v_{1}\\
           \vec{e_{2}}&\partial_{2}& v_{2}\\
           \vec{e_{3}}&\partial_{3}& v_{3}
           \end{vmatrix}\right)
    \end{align*}
    Letzteres kann man als Eselsbrücke ansehen.
  \end{enumerate}
\end{defini}

\begin{bemerk}
  Gilt  $\Div \vec{v} = 0$ für $\vec{v}$ auf $\Omega$, dann nennt man
  $\vec{v}$ ein \emph[rand=quellenfreies V.,
  index=Vektorfeld!quellenfreies]{quellenfreies Vektorfeld}. Ist $\rot
  \vec{v}=0$ auf $\Omega$, so nennt man es ein \emph[rand=wirbelfreies
  V.,index=Vektorfeld!wirbelfreies]{wirbelfreies Vektorfeld}.
\end{bemerk}

\begin{defini}\label{def:1}
  Für $u\in C^{2}(\Omega)$ und $\vec{v}$ ein $C^{2}$-Vektorfeld auf
  $\Omega\subseteq\R^{3}$ bezeichnet
  \begin{enumerate}
   \item
    \begin{gather*}
      \Delta u := \sum_{j=1}^{n}\partial_{j}^{2}u = \sum_{j=1}^{n}
         \frac{\partial^{2}u}{\partial u_{j}^{2}}
    \end{gather*}
    den \emph{Laplace-Operator}\footnote{Als Eselsbrücke kann man sich
    $\Delta= \nabla^{2}$ merken.}.
   \item $\Delta\vec{v} := \Delta v_{1}\vec{e_{1}} + \Delta
    v_{2}\vec{e_{2}} + \Delta v_{3} \vec{e_{3}}$
  \end{enumerate}
\end{defini}

\begin{satz}
  Sei $\Omega\subseteq\R^{n}$ offen, $u\in C^{2}(\Omega)$ und
  $\vec{v}$ ein $C^{2}$-Vektorfeld. Dann gilt:
  \begin{enumerate}
   \item $\rot(\grad u) = 0$
   \item $\Div(\rot \vec{v}) = 0$
   \item $\Div(\grad u) = \Delta u$
   \item $\rot(\rot \vec{v}) = \grad(\Div \vec{v})-\Delta \vec{v}$
  \end{enumerate}

  \begin{proof}
    \begin{mdescription}
      \item[(1)--(3)] durch elementare Rechnung unter Anwendung des Satz
      von Schwarz
      \item[(4)] durch Einsetzen der Definition der Operatoren
      (\autoref{def:1}) und Anwendung des Satzes von Schwarz
      \begin{align*}
        \grad(\Div\vec{v}) &=
           \begin{bmatrix}
             \partial_{1} (\partial_{1} v_{1} +\partial_{2} v_{2}
             +\partial_{3}v_{3})\\
             \partial_{2}(\partial_{1} v_{1} +\partial_{2} v_{2}
             +\partial_{3}v_{3})\\
             \partial_{3}(\partial_{1} v_{1} +\partial_{2} v_{2}
             +\partial_{3}v_{3})
           \end{bmatrix} =
           \begin{bmatrix}
             \partial_{1}^{2} v_{1} +\partial_{1}\partial_{2} v_{2}
             +\partial_{1}\partial_{3}v_{3}\\
             \partial_{1}\partial_{2} v_{1} +\partial_{2}^{2} v_{2}
             +\partial_{2}\partial_{3}v_{3}\\
             \partial_{1}\partial_{3} v_{1} +\partial_{2}\partial_{3} v_{2}
             +\partial_{3}^{2}v_{3}
           \end{bmatrix}\\
        \Delta \vec{v} &=
           \begin{bmatrix}
             \Delta v_{1}\\
             \Delta v_{2}\\
             \Delta v_{3}
           \end{bmatrix} =
           \begin{bmatrix}
             \partial_{1}^{2} v_{1} + \partial_{2}^{2}v_{1}
             +\partial_{3}^{2}v_{1}\\
             \partial_{1}^{2} v_{2} + \partial_{2}^{2}v_{2}
             +\partial_{3}^{2}v_{2}\\
             \partial_{1}^{2} v_{3} + \partial_{2}^{2}v_{3}
             +\partial_{3}^{2}v_{3}
           \end{bmatrix}\\
        \grad(\Div\vec{v}) - \Delta \vec{v} &=
           \begin{bmatrix}
             \partial_{1}^{2} v_{1} +\partial_{1}\partial_{2} v_{2}
             +\partial_{1}\partial_{3}v_{3}
             -\partial_{1}^{2} v_{1} - \partial_{2}^{2}v_{1}
             -\partial_{3}^{2}v_{1}\\
             \partial_{1}\partial_{2} v_{1} +\partial_{2}^{2} v_{2}
             +\partial_{2}\partial_{3}v_{3}
             -\partial_{1}^{2} v_{2} - \partial_{2}^{2}v_{2}
             -\partial_{3}^{2}v_{2}\\
             \partial_{1}\partial_{3} v_{1} +\partial_{2}\partial_{3} v_{2}
             +\partial_{3}^{2}v_{3}
             -\partial_{1}^{2} v_{3} - \partial_{2}^{2}v_{3}
             -\partial_{3}^{2}v_{3}
           \end{bmatrix}\\
        &= \begin{bmatrix}
             \partial_{1}\partial_{2} v_{2}
             +\partial_{1}\partial_{3}v_{3}
             - \partial_{2}^{2}v_{1}
             -\partial_{3}^{2}v_{1}\\
             -\partial_{1}^{2} v_{2}
             +\partial_{1}\partial_{2} v_{1}
             +\partial_{2}\partial_{3}v_{3}
             -\partial_{3}^{2}v_{2}\\
             -\partial_{1}^{2} v_{3} +\partial_{1}\partial_{3} v_{1}
             - \partial_{2}^{2}v_{3}
             +\partial_{2}\partial_{3} v_{2}
           \end{bmatrix}\\
        &= \begin{bmatrix}
             \partial_{2}(\partial_{1}v_{2}-\partial_{2}v_{1})
             -\partial_{3}(\partial_{3}v_{1}-\partial_{1}v_{3})\\
             \partial_{3}(\partial_{2}v_{3}-\partial_{3}v_{2})
             -\partial_{1}(\partial_{1}v_{2}-\partial_{2}v_{1})\\
             \partial_{1}(\partial_{3}v_{1}-\partial_{1}v_{3})
             -\partial_{2}(\partial_{2}v_{3}-\partial_{3}v_{2})
           \end{bmatrix}
           = \rot (\rot\vec{v})
      \end{align*}
    \end{mdescription}
  \end{proof}
\end{satz}

\begin{satz}[Rechenregeln für Differentialoperatoren]
  Sei $f,g \in C^{1}(\Omega)$ und $\vec{H}, \vec{K}$ seien $C^{1}$-Vektorfelder.
  \begin{enumerate}
   \item $\Div, \grad, \rot$ sind linear
   \item $\grad(f\cdot g) = g(\grad f) + f(\grad g)$
   \item $\Div(f\cdot \vec{H}) = f\Div\vec{H} + (\grad f)\cdot\vec{H}$
   \item $\Div(\vec{H}\times \vec{K}) = (\rot\vec{H}) \cdot \vec{K} -
    \vec{H}\cdot (\rot\vec{K})$
   \item $\rot (f\cdot\vec{H}) = f(\rot\vec{H})+(\grad f)\times \vec{H}$
  \end{enumerate}

  \begin{proof}
    (4) und (5) \todo{ergänzen aus Übung 29/1}, zu (3):
    \begin{align*}
      \Div(f\vec{H}) &= \partial_{1}(f H_{1}) + \partial_{2}(f H_{2}) +
         \partial_{3}(f H_{3})\\
      &= f(\partial_{1}H_{1} + \partial_{2}H_{2}+\partial_{3}H_{3}) +
         (\partial_{1}f) H_{1} + (\partial_{2}f)H_{2} +
         (\partial_{3}f)H_{3} &\text{mit Produktregel}\\
      &= f\Div \vec{H} + (\grad f)\cdot \vec{H}
    \end{align*}
    Den Beweis zu (2) kann man analog zu (3) führen.
  \end{proof}
\end{satz}

\subsection{Hauptsatz für Kurvenintegrale und skalare Potentiale}
\label{sec:8.1.2}

Eine kurze Wiederholung aus Abschnitt\,7.2
\begin{itemize}
 \item $(\Gamma, \phi)$ bezeichnet eine \emph{glatte Jordankurve}
  \gdwdef $\phi\colon [a,b] \rightarrow \R^{n}$ stetig differenzierbar,
  $\Gamma=\{\phi(t)\colon t\in[a,b]\}$, $\phi$ ist injektiv auf $(a,b)$,
  der \emph{Tangentenvektor} $\dot{\phi}(t) \ne0$ für $t\in(a,b)$
  \help{warum?}

  $(\Gamma, \phi)$ heißt \emph{geschlossen} \gdwdef $\phi(a) = \phi(b)$
 \item $\Omega\subseteq\R^{n}$ offen, $(\Gamma, \phi)$ \emph{glatte
  Jordankurve}, $\Gamma\subseteq\Omega$, $\vec{v}\colon \Omega\rightarrow\R^n$
  stetiges Vektorfeld
  \begin{gather*}
    \int_{\Gamma} \vec{v}\cdot\vec{dx} := \int_{a}^{b}
       \vec{v}(\phi(t))\cdot \dot{\phi}(t)\,dt
  \end{gather*}
  Anmerkung: Die Physik definiert dieses Integral "`Arbeit"'
\end{itemize}

\begin{defini}
  Man bezeichnet $(\Gamma, \phi)$ als \emph{stückweise glatte Kurve} oder kurz
  \emph{Kurve} \gdwdef:
  \begin{compactitem}
   \item $\phi\colon[a,b]\rightarrow\R^{n}$ stetig
   \item $\Gamma=\{\phi(t)\colon t\in[a,b]\}$
   \item es existieren endlich viele Teilungspunkte $a=t_{0}<t_{1}<\ldots
  <t_{n}=b$
   \item für jedes $j=1,\ldots,n$ ist $(\Gamma_{j},
    \phi\big|_{[t_{j-1},t_{j}]})$ eine glatte Jordankurve, wobei
    $\Gamma_{j} = \{\phi(t)\colon [t_{j-1}, t_{j}]\}$
  \end{compactitem}

  Auch solche Kurven nennen wir \emph{geschlossen}, wenn Anfangs- und Endpunkt
  zusammenfallen: $\phi(a) =\phi(b)$.
\end{defini}

\begin{bsp}[Polygonzug]
  Einer Folge $x^{0},x^{1},\ldots,x^{n}\in\R^{n}$, wobei
  $x^{j-1}\neq x^{j}$, wird ein \emph{Polygonzug}
  \begin{align*}
    \phi_{j}(t) &= x^{j-1}+t(x^{j}-x^{j-1}) &t\in[0,1]
  \end{align*}
  zugeordnet. $[x^{0} x^{1}\ldots x^{n}]$. Dies ist ein Beispiel für
  eine stückweise stetige Kurve.
\end{bsp}

\begin{defini}
  Sei $(\Gamma, \phi)$ Kurve und $\vec{v}$ stetiges Vektorfeld auf
  $\Omega\subseteq \R^{n}$. Dann gilt:
  \begin{gather*}
    \int_{\Gamma} \vec{v}\cdot\vec{dx} := \sum_{j=1}^{N}
       \int_{\Gamma_{j}} \vec{v}\cdot \vec{dx}
  \end{gather*}
\end{defini}

% 26.10.05

\begin{bsp}
  \begin{align*}
    x^{0} &= (0,0,0)\\
    x^{1} &= (1,0,0)\\
    x^{2} &= (1,1,0)\\
    x^{3} &= (1,1,1)\\
    \vec{v}(x) &= \begin{bmatrix}x_{1}\\x_{1}x_{2}\\x_{1}x_{2}x_{3}\end{bmatrix}
  \end{align*}

  \begin{align*}
    \int_{\Gamma} \vec{v}\cdot\vec{dx}
       &= \int_{0}^{1} \begin{bmatrix}x_{1}\\0\\0\end{bmatrix}\cdot
       \begin{bmatrix}1\\0\\0\end{bmatrix}\,dx_{1}
       + \int_{0}^{1} \begin{bmatrix}1\\x_{2}\\0\end{bmatrix} \cdot
       \begin{bmatrix}0\\1\\0\end{bmatrix}\,dx_{2} + \int_{0}^{1}
       \begin{bmatrix}1\\1\\x_{3}\end{bmatrix}\cdot
       \begin{bmatrix}0\\0\\1\end{bmatrix}\,dx_{3}\\
    &= 3\int_{0}^{1} x_{1}\,dx_{1} = \frac{3}{2}
  \end{align*}
\end{bsp}

\begin{satz}[Hauptsatz für Kurvenintegrale]\label{satz:8.1.2/5}
  (vergleiche mit Satz 7.2.2/7 aus Analysis II) Sei
  Sei $\Omega\subseteq\R^{n}$ offen, $(\Gamma,
  \phi)$ eine Kurve in $\Omega$, $u\colon\Omega\rightarrow\R$ stetig
  differenzierbar ($u\in C^{1}(\Omega)$), $\vec{v} = \grad u$ und $x^{0} =
  \phi(a)$ der Anfangspunktsowie $x^{1}=\phi(b)$ der Endpunkt von $\Gamma$.
  Dann ist
  \begin{gather*}
    \int_{\Gamma} \vec{v}\cdot\vec{dx} = u(x^{1})-u(x^{0})
  \end{gather*}

  \begin{proof}
    Wir betrachten zunächst das Integral über dem $j$-ten Abschnitt
    der Kurve $\Gamma$ und wenden die Erkenntnisse dann auf die
    gesamte Kurve an.
    \begin{align*}
      \int_{\Gamma_{j}} \vec{v}\cdot\vec{dx} &= \int_{t_{j-1}}^{t_{j}}
         \vec{v}(\phi(t))\cdot\dot{\phi}(t)\,dt = \int_{t_{j-1}}^{t_{j}} \bigg(
         \sum_{k=1}^{n} v_{k}(\phi(t))\cdot\dot{\phi}_{k}(t) \bigg)\,dt\\
      &= \int_{t_{j-1}}^{t_{j}} \underbrace{\sum_{k=1}^{n} \frac{\partial u}{\partial
         x_{k}}\big(\phi(t)\big)\cdot\dot{\phi}_{k}(t)\,dt}
         _{\frac{d}{dt}\big(u(\phi(t))\big) \text{ Kettenregel}} &&v_{k}=\frac{\partial
         u}{\partial x_{k}} \text{ nach Voraussetzung}\\
      &= u(\phi(t))\big|_{t_{j-1}}^{t_{j}} = u(\phi(t_{j}))
         -u(\phi(t_{j-1}))\\
      \int_{\Gamma} \vec{v}\vec{dx} &= \sum_{j=1}^{N} \int_{\Gamma_{j}}
         \vec{v}\vec{dx} = \sum_{j=1}^{N} \big(
         u(\phi(t_{j}))-u(\phi(t_{j-1})) \big)\\
      &= u(\phi(b)) - u(\phi(a)) = u(x^{1}) - u(x^{0})
    \end{align*}
  \end{proof}
\end{satz}

\begin{bemerk}
  Sei $\vec{v} = \grad u$. Dann ist $\int_{\Gamma}\vec{v}\vec{dx}$
  "`\emph{wegunabhängig}"', nur von Anfangs- und Endpunkt abhängig und
  es gilt, $\int_{\Gamma}\vec{v}\vec{dx}=0$ für alle \emph{geschlossenen
  Kurven} in $\Omega$.
\end{bemerk}

\begin{defini}
  Sei $\Omega\subseteq\R^{n}$ offen und $\vec{v}$ stetiges Vektorfeld auf
  $\Omega$. Dann heißt $\vec{v}$ \emph{konservativ} \gdwdef $\forall
  x^{0},x^{1}\in\Omega$ und für alle Kurven $\Gamma_{1}$ und $\Gamma_{2}$
  von $x^{0}$ nach $x^{1}$ gilt:
  \begin{gather*}
    \int_{\Gamma_{1}} \vec{v}\vec{dx} = \int_{\Gamma_{2}}\vec{v}\vec{dx}
  \end{gather*}
\end{defini}

\begin{bemerk}
  \begin{enumerate}
   \item äquivalent:
    \begin{gather*}
      \int_{\Gamma} \vec{v}\vec{dx}=0\quad\text{für alle geschlossenen
         Kurven}
    \end{gather*}
   \item $\vec{v}=\grad u$ $\Rightarrow$ $\vec{v}$ konservativ
    (\autoref{satz:8.1.2/5})
   \item Gilt auch die Umkehrung von (2)? \todo{Antwort einfügen}
  \end{enumerate}
\end{bemerk}

\begin{defini}
  Eine offene Menge $\Omega\subseteq\R^{n}$ heißt \emph{zusammenhängend}
  \gdwdef für je zwei Punkte $x^{0}$ und $x^{1}$ aus $\Omega$ existiert
  ein Polygonzug \textit{in $\Omega$} von $x^{0}$ nach $x^{1}$.

  Eine offene zusammenhängende Menge bezeichnet man als \emph{Gebiet}.
  \todo{Abbildung zu Gebieten einfügen}
\end{defini}

\begin{satz}\label{satz:8.1.2/10}
  Für ein Gebiet $\Omega\subseteq\R^{n}$ und ein stetiges Vektorfeld
  $\vec{v}\colon\Omega\rightarrow\R^{n}$ gilt:
  \begin{enumerate}
   \item Für ein konservatives Vektorfeld $\vec{v}$ existiert eine
    $C^{1}(\Omega)$-Abbildung $u$, sodass $\vec{v} = \grad u$.

    Konservative Vektorfelder besitzen ein \emph{Potential}.
   \item Die Abbildung $u$ ist für ein konservatives Vektorfeld $\vec{v}$
    bis auf eine additive Konstante bestimmt.
    \begin{gather*}
      \grad u = \grad \tilde{u} \Rightarrow u=\tilde{u}+const
    \end{gather*}
  \end{enumerate}

  In der Physik heißt $-u$ \emph{Potential} des Vektorfelds $\vec{v}$.

  \begin{proof}
    \begin{enumerate}
     \item Wir halten $x^{0}\in\Omega$ fest und wählen $x\in\Omega$
      beliebig. Da $\Omega$ ein Gebiet ist, findet man eine Kurve von
      $x^{0}$ nach $x$. Sei $\Gamma$ eine solche Kurve. Wir definieren $u$
      als
      \begin{gather*}
	u(x) := \int_{\Gamma}\vec{v}\cdot\vec{dx}
      \end{gather*}
      Dies ist sinnvoll, da $u$ unabhängig von $\Gamma$ ist. Denn
      $\vec{v}$ ist konservativ. Für alle $x\in\Omega$ gibt es eine
      Kugel $K_{\delta}(x)\subseteq\Omega$ und für $\abs{t}<\delta$
      und $t\neq 0$ gilt
      \begin{align*}
	\frac{1}{t} (u(x+t\vec{e_{j}})-u(x)) &= \frac{1}{t} \int_{0}^{t}
         \vec{v}\underbrace{(x+\tau \vec{e_{j}{)}_{\phi(t)}\cdot
	   \underbrace{\vec{e_{j}}}_{\dot{\phi(t)}}\,d\tau\\
	&= \frac{1}{t} \int_{0}^{t} v_{j} (x+ \tau \vec{e_{j}})\,d\tau\\
	&= v_{j}(x+se_{j}) &&\text{nach MWS der Int., wobei $s\in(0,t)$}\\
	&\xrightarrow{t\rightarrow0} v_{j}(x)
      \end{align*}
      Das heißt, $\frac{\partial u}{\partial x_{j}}(x) = v_{j}(x)$.
     \item hierzu die folgende Annahme: $\grad \tilde{u} = \grad u
      =\vec{v}$. Dann:
    \begin{gather*}
      u(x) = \int_{\Gamma}\vec{v}\,dx =^{\text{nach \autoref{satz:8.1.2/5}}}
         \tilde{u}(x)-\tilde{u}(x^{0})\quad \forall x
    \end{gather*}
    $\Rightarrow\tilde{u}(x)-u(x) = -\tilde{u}(x^{0}) = \text{const}$.
  \end{proof}
\end{satz}

\begin{folger}\label{fol:8.1.2/11}
  Teil (1) aus \autoref{satz:8.1.2/10} gilt auch für beliebige offene
  Mengen $\Omega\subseteq\R^{n}$.

  \begin{proof}
    Sei $\Omega=\bigcup_{k=1}^{\infty}\Omega_{k}$. Dann sind $\Omega_{k}$ die
    \emph[rand=Zu\-sam\-men\-hangs\-kom\-po\-nen\-ten]{Zusammenhangskomponenten} von $\Omega$ und damit
    $\Omega_{k}\cap\Omega_{j}=\emptyset$ für $j\neq k$. $\Omega_{k}$ ist
    ein Gebiet und man kann \autoref{satz:8.1.2/10} auf $\Omega_{k}$
    anwenden.
  \end{proof}
\end{folger}

\begin{lemma}\label{lem:8.1.2/11}
  Sei $\vec{v}\colon\Omega\rightarrow\R^{n}$ ein $C^{1}$-Vektorfeld und $\Omega$
  offen, $\vec{v}$ sei konservativ. Dann gilt
  \begin{gather*}
    \partial_{j} v_{k} = \partial_{k} v_{j} \quad \forall j,k=1,\ldots,n
  \end{gather*}

  Für $n=3$ bedeutet das:
  \begin{gather}\label{eq:1}
    \rot \vec{v}=0
  \end{gather}

  \begin{proof}
    \autoref{satz:8.1.2/10} + \autoref{fol:8.1.2/11} $\Rightarrow$
    $\vec{v}=\grad u$, d.\,h. $\frac{\partial u}{\partial x_{j}}$ für
    $j=1,\ldots,n$. Es gilt $u\in C^{2}(\Omega)$, wegen der Definition des
    Gradienten.

    Nach dem Satz von Schwarz gilt
    \begin{gather*}
      \frac{\partial v_{j}}{\partial x_{k}} = \frac{\partial}{\partial
         x_{k}}\bigg(\frac{\partial u}{\partial x_{j}}\bigg) =
         \frac{\partial}{\partial x_{j}}\big(\frac{\partial u}{\partial
         x_{k}}\big) = \frac{\partial v_{k}}{\partial x_{j}}
    \end{gather*}
  \end{proof}
\end{lemma}

Die Umkehrung von \autoref{lem:8.1.2/11} gilt im allgemeinen \textit{nicht}.
\begin{bsp}
  $n=2$. $\Omega=\R^{2}\setminus\{0\}$ ist ein Gebiet. Betrachten wir
  \begin{gather*}
    \vec{v}(x,y) = \frac{1}{x^{2}+y^{2}} \begin{bmatrix}-y\\x\end{bmatrix}
  \end{gather*}

  \begin{align*}
   \Rightarrow \partial_{1}v_{2} &= \frac{\partial}{\partial x}
       \big(\frac{x}{x^{2}+y^{2}}\big) =
       \frac{x^{2}+y^{2}-2x}{(x^{2}+y^{2})^{2}} =
       \frac{y^{2}-x^{2}}{(x^{2}-y^{2})^{2}}\\
    \partial_{2} v_{1} &= \frac{\partial}{\partial
       y}\big(\frac{-y}{x^{2}+y^{2}}\big) = -\frac{\partial}{\partial y}
       \big(\frac{y}{x^{2}+y^{2}}\big) =
       \frac{y^{2}-x^{2}}{(x^{2}-y^{2})^{2}}
  \end{align*}
  Das heißt, es gilt \autoref{eq:1}. Aber $\Gamma$ Einheitskreis: $x=\cos
  t, y=\sin t, t\in[0,2\pi]$
  \begin{gather*}
    \int_{\Gamma}\vec{v}\vec{dx} = \int_{0}^{2\pi}
       \begin{bmatrix}-\sin t\\\cos t\end{bmatrix}
       \begin{bmatrix}-\sin t\\\cos t\end{bmatrix}\,dt = 2\pi \ne 0
  \end{gather*}
\end{bsp}

\begin{satz}
\label{satz:VFaequi}
  Sei $\Omega\subseteq \R^n$ offen und sternförmig, d.\,h. $\exists x^0\in
  \Omega\,\forall x\in \Omega\,\forall t\in (0,1)\colon x^0+t(x-x^0)\in\Omega$.
  Weiter sei $\vec{v}$ ein $C^1$-Vektorfeld über $\Omega$. Dann sind folgende
  Aussagen äquivalent:
  \begin{enumerate}
    \item $\vec{v}$ ist konservativ.
    \item Es gibt ein Potential $u$, so dass $\vec{v}=\grad u$ gilt.
    \item Für alle $j,k$ auf $\Omega$ gilt: $\partial_j v_k= \partial_k v_j$
    \item $\rot \vec{v}=0\Leftrightarrow n=3$
  \end{enumerate}
  \begin{proof}
    Es reicht zu zeigen, dass aus dem dritten Punkt der zweite folgt. Alle
    anderen wurden bereits in den vorangegangen Beweisen gezeigt.
    \begin{align*}
      u(x) &:= \int_{[x^0x]} \vec{v}\vec{dx} = \int_0^1 \vec{v} (x^0 + t(x-x^0))
      (x-x^0)dt\\
      \Rightarrow \frac{\partial u}{\partial x_j} &= \int_0^1
      \frac{\partial}{\partial x_j} \left[ \vec{v} (x^0+t(x-x^0))(x-x^0)\right]
      dt
    \end{align*}
    Im Kapitel~\autoref{sec:8.1.2} findet sich eine Erklärung,
    warum hier das Gleichheitszeichen gesetzt werden kann. Es gilt nun:
    \begin{align*}
      \frac{\partial}{\partial x_j} &\left[ \vec{v}
        (x^0+t(x-x^0))(x-x^0)\right]\\
      &= \frac{\partial}{\partial x_j} \sum_{k=1}^n v_k (x^0+t(x-x^0))(x-x^0)\\
      &= v_j(x^0+t(x-x^0)) + \sum_{k=1}^n (x_k-x_k^0) \sum_{l=1}^n
      \frac{\partial v_k}{\partial x_l} (x^0+t(x-x^0))
      \frac{\partial}{\partial x_j} (x_l^0+t(x_l-x_l^0))\\
      &= v_j(x^0+t(x-x^0)) + \sum_{k=1}^n \frac{\partial v_k}{\partial
        x_l} (x^0+t(x-x^0))t (x_k-x_k^0)\\
      &= v_j(x^0+t(x-x^0)) + t \sum_{k=1}^n \frac{\partial v_j}{\partial
        x_k} (x^0+t(x-x^0))(x_k-x_k^0)\\
      &= \frac{d}{dt} \left[ tv_j (x^0+t(x-x^0))\right] \Rightarrow
      \frac{\partial u}{\partial x_j} = \int_0^1 \frac{d}{dt} \left[
        tv_j (x^0+t(x-x^0))\right]dt\\
      &= v_j(x)-0=v_j(x) \qquad \forall j
    \end{align*}
  \end{proof}
\end{satz}

\begin{bsp}
  Für alle $x\in \R^n\setminus\{0\}$ sei $\vec{v}(x)= \kappa(\norm{x})
  \frac{x}{\norm{x}}=\kappa(r)\frac{x}{r}$ mit $r=\norm{x}=
  \sqrt{x_1^2+\ldots +x_n^2}$ ein konservatives Vektorfeld. Ein
  typisches Beispiel dafür ist $\kappa(r)=-\frac{mMG}{r^2}$, wobei
  $\kappa(r)$ stetig auf $\R^n\setminus\{0\}$ ist. Dabei sind $m,M$
  Massen und $G$ die Gravitationskonstante. In dem Falle ist $\vec{v}$
  konservativ ($\vec{v}=\grad u(r)$).  Denn $\frac{\partial
    r}{\partial x_j}= \frac{x_j}{r}$:
  \begin{align*}
    \frac{\partial u(r)}{\partial x_j} &= u'(r)\frac{x_j}{r}=
    \frac{\kappa(r) x_j}{r} \Rightarrow \grad u(r)= \kappa(r)
    \frac{x_j}{r} = \vec{v}
  \end{align*}
\end{bsp}

\begin{bemerk}
  \autoref{satz:VFaequi} gilt auch für eine größere Klasse von
  Gebieten (aber nicht für alle Gebiete). Er ist auch für einfach
  zusammenhängende Gebiete wahr. Wobei ein einfach zusammenhängendes
  Gebiet dadurch charakterisiert ist, dass sich jede geschlossene
  Kurve in $\Omega$ auf einen Punkt zusammenziehen lässt. Somit hat
  $\Omega$ keine "`Löcher"'.
\end{bemerk}

\begin{bemerk}
  Wie bestimmt man ein Potential?
  \begin{enumerate}
    \item $u(x)=\int_{\Gamma} \vec{v} \vec{dx}$\\
    Beispiel:
    \begin{align*}
      \vec{v}(x,y) &= \int_{(0,0)}^{(x,0)} \vec{v} \vec{dx} +
      \int_{(x,0)}^{(x,y)} \vec{v} \vec{dx} = \int_0^x
      \begin{bmatrix}
        0\\t^2
      \end{bmatrix}
      \begin{bmatrix}
        1\\0
      \end{bmatrix} dt + \int_0^y
      \begin{bmatrix}
        2xt+t^2\\x^2+2xt
      \end{bmatrix}
      \begin{bmatrix}
        0\\1
      \end{bmatrix} dt\\
      &= 0+ \int_0^y (x^2+2xt)dt= x^2y+xy^2
    \end{align*}
    \item Stammfunktion ermitteln:
    \begin{align*}
      \frac{\partial u}{\partial x} = v_1 \wedge \frac{\partial
        u}{\partial y} = v_2 &\Leftrightarrow \frac{\partial
        u}{\partial y}= x^2+2xy\\
        &\Leftrightarrow x^2+2xy+c'(y) =
        x^2+2yx \Leftrightarrow c'(y)=0 \Leftrightarrow
        c(y)=\text{const}\\
        \frac{\partial u}{\partial x} = 2xy+y^2 &\Leftrightarrow
        u(x,y)= x^2y+y^2x+c(y)\Rightarrow u(x,y) = x^2y+y^2x+c
    \end{align*}
  \end{enumerate}
\end{bemerk}

\subsection{Vektorpotentiale}

\begin{defini}
  Sei $\vec{v}\colon\Omega\rightarrow\R$ ein $C^1$-Vektorfeld, $\Omega
  \subseteq \R^3$ offen, $\vec{w}$ ein $C^2$-Vektorfeld. Dann heißt $\vec{w}$
  genau dann \emph{Vektorpotential} von $\vec{v}$, wenn
  $\vec{v}=\rot{\vec{w}}$.
\end{defini}

\begin{bemerk}
  \begin{enumerate}
    \item Notwendige Bedingung: $\vec{v}=\rot{\vec{w}}\Rightarrow \Div
    \vec{v}= 0$
    \item Wenn $\vec{w}$ ein Vektorpotential von $\vec{v}$ ist und
    $\Phi\in C^2(\Omega)$, dann ist $\vec{w}+\grad \Phi$ wieder ein
    Vektorpotential.
    \item Sei $\Omega$ sternförmig und $\vec{w}, \vec{b}$
    Vektorpotentiale von $\vec{v}$. Dann ist $\rot (\vec{w}-\vec{b})
    =0$. Denn aus \autoref{satz:VFaequi} folgt, $\vec{w}-\vec{b}=
    \grad \Phi$.
  \end{enumerate}
\todo{Beweis noch einfügen}
\end{bemerk}

\section{Integralsätze}

\subsection{Die Greensche Formel im \texorpdfstring{$\R^2$}{R2}}
\label{sec:821}

Das Ziel ist, einen Zusammenhang zwischen dem Flächenintegral und dem
Kurvenintegral herzustellen:\\
Sei $B\subset\Omega\subset\R^2, \Omega$ offen, $B$ kompakt, $\vec{v}\colon
\Omega\rightarrow \R^2$ ein $C^1$-Vektorfeld:
\begin{gather*}
  \Rightarrow \int_B (\partial_1v_2-\partial_2v_1)dx= \int_{\partial
    B} \vec{v}\vec{dx}
\end{gather*}

\begin{lemma}\label{lem:821-1}
  Sei $G\subset \R^{n+1}$ offen, $(x,t)\in G, x\in\R^n, t\in\R, f\colon G
  \rightarrow\R$ stetig, $\exists \frac{\partial f}{\partial t}$
  stetig auf $G$, $B\subset \R^n$ kompakt und jordanmessbar, $B\times
  [\alpha, \beta]\subset G$
  \begin{gather*}
    \Rightarrow\frac{d}{dt} \underbrace{\int_B f(x,t) dx}_{=:F(t)} =
    \int_B \frac{\partial}{\partial t} f(x,t) dx \qquad \forall t\in
    (\alpha, \beta)
  \end{gather*}
  \begin{proof}
    \begin{align}
      \label{eq:82}
      \abs{\frac{F(t+h)-F(t)}{h}- \int_B \frac{\partial}{\partial t}
        f(x, t)dx} &\leq \int_B\abs{\underbrace{\frac{f(x,t+h)
            -f(x,t)}{h}}_{\frac{\partial f}{\partial x} (x, t+\theta
          h) \text{ mit } 0<\theta<1} -\frac{\partial f}{\partial x}
        (x,t)}dx\\
      \label{eq:83}
      &\leq \int_B \abs{\underbrace{\frac{\partial f}{\partial x}
          (x,t+\theta h)-\frac{\partial f}{\partial x} (x,t)}_{\leq
          \epsilon \text{ falls } \abs{h}\leq\delta(\epsilon)}}dx\leq
      \epsilon\mu(B)
    \end{align}
    Die Folgerung in \autoref{eq:82} ergibt sich nach dem Mittelwertsatz
    der Differentialrechnung und \autoref{eq:83} folgt aus der
    gleichmäßigen Stetigkeit.
  \end{proof}
\end{lemma}

\begin{folger}
  Für $n=1$ im obigen Lemma folgt:
  \begin{gather*}
    \frac{d}{dt} \int_{\phi(t)}^{\psi(t)} f(x,t)dx =
    \int_{\phi(t)}^{\psi(t)} \frac{\partial f}{\partial t} (x,t) dx+
    f(\psi(t), t)\dot{\psi}(t)-f(\phi(t),t)\dot{\phi} (t)
  \end{gather*}
  \begin{proof}
    Mittels der Hilfsfunktion: $F(u,v,t):= \int_u^v f(x,t)dx$:
    \begin{align*}
      \Rightarrow \frac{d}{dt} \int_{\phi(t)}^{\psi(t)} f(x,t)dx &=
      \frac{d}{dt} F(\phi(t), \psi(t), t)\\
      &= \frac{\partial F}{\partial u} (\phi(t), \psi(t),
      t)\dot{\phi}(t) + \frac{\partial F}{\partial v} (\phi(t),
      \psi(t), t)\dot{\psi} (t)+ \frac{\partial F}{\partial t}
      (\phi(t), \psi(t), t)\\
      &= -f(\phi(t), t)\dot{\phi}(t)+ f(\psi(t), t)\dot{\psi}(t) +
      \int_{\phi(t)}^{\psi(t)} \frac{\partial f}{\partial t} (x,t)dt
    \end{align*}
  \end{proof}
\end{folger}

\todo{Skizze mit Normalbereich einfügen} \help{Wie sah die nochmal aus?}

\begin{satz}
  \label{satz:821-3}
  Sei $\Omega\subset\R^2$ offen, $B\subset \Omega$ ein Normalbereich
  und $\vec{v}$ ein $C^1$-Vektorfeld auf $\Omega$. Dann gilt:
  \begin{gather*}
    \int_B (\partial_1v_2-\partial_2v_1)dx=\int_{\partial B} \vec{v}
    \vec{dx}
  \end{gather*}
  \begin{proof}
    Nach dem Satz von Fubini für Normalbereiche gilt:
    \begin{align*}
      \int_B \partial_1 v_2 dx &= \int_a^b
      \bigg(\int_{\phi(x_1)}^{\psi(x_1)} \frac{\partial v_2}{\partial
          x_1} (x_1,x_2)dx_2\bigg) dx_1\\
      &= \int_a^b \bigg(\frac{d}{dx_1} \int_{\phi(x_1)}^{\psi(x_1)}
        v_2 (x_1, x_2)dx_2\bigg) dx_1 + \int_a^b v_2(x_1, \phi(x_1))
      \dot{\phi} (x_1)dx_1\\
      &\qquad- \int_a^b v_2(x_1, \psi(x_1))\dot{\psi}
      (x_1)dx_1\\
      &= \int_{\phi(b)}^{\psi(b)} v_2(b,x_2)dx_2-
      \int_{\phi(a)}^{\psi(a)} v_2(a,x_2)dx_2+ \int_{\Gamma_1} v_2dx_2
      + \int_{\Gamma_3} v_2dx_2\\
      &= \int_{\Gamma_2} v_2dx_2+ \int_{\Gamma_4} v_2dx_2+
      \int_{\Gamma_1} v_2dx_2+ \int_{\Gamma_3}v_2dx_2= \int_{\partial
        B} v_2dx_2
    \end{align*}
    Außerdem ist:
    \begin{align*}
      -\int_B \partial_2 v_1dx &= \int_a^b \bigg(
        \int_{\phi(x_1)}^{\psi(x_1)} \frac{\partial v_1}{\partial x_2}
        (x_1, x_2) dx_2\bigg) dx_1\\
      &= -\int_a^b v_1(x_1, \psi(x_1))dx_1+ \int_a^b v_1(x_1,
      \phi(x_1)) dx_1= \int_{\Gamma_3} v_1dx_1+\int_{\Gamma_1} v_1dx_1
    \end{align*}
    Der letzte Schluss ergibt sich daraus, dass $\int_{\Gamma_2} v_1
    dx_1 = \int_{\Gamma_4} v_1dx_1=0$ ist.
  \end{proof}
\end{satz}

\begin{bemerk}
  \begin{itemize}
    \item \autoref{satz:821-3} gilt auch für allgemeinere Gebiete. Dabei
    reicht es, wenn $\phi$ und $\psi$ nür stückweise differenzierbar
    sind.
    \item Der Flächeninhalt kann als Kurvenintegral über den Rand der
    Flächen interpretiert werden:
    \begin{align*}
      \vec{v}=
      \begin{bmatrix}
        -x_2\\x_1
      \end{bmatrix}
      &\Rightarrow \partial_1 v_2-\partial_2 v_1=2\Rightarrow
      2\int_Bdx= \int_{\partial B}
      \begin{bmatrix}
        -x_2\\x_1
      \end{bmatrix}
      \begin{bmatrix}
        dx_1\\dx_2
      \end{bmatrix}
      \Rightarrow \mu(B)\\
      \mu(B) &= \nicefrac{1}{2} \int_{\partial B} x_1dx_2-x_2dx_1
    \end{align*}
  \end{itemize}
\end{bemerk}

% 9.11.05

\subsection{Der Satz von Stokes (im \texorpdfstring{$\R^{3}$}{R3})}

\begin{bsp}[Zylindermantel]
  \begin{figure}
    \ifpdf
    \input{Zylinder-Normbereich.pdf_t}
    \else
    \input{Zylinder-Normbereich.eps_t}
    \fi
    \todo{gnuplot-Bild mit einem halben Zylinder, Höhe 1, radius 1}
    \caption{Abbildung des Normalbereichs auf die Zylindermantelfläche}
  \end{figure}
  \begin{gather*}
    \left.\begin{aligned}
      S\colon x_{1} &= \cos \phi\\
      x_{2} &= \sin \phi\\
      x_{3} &= z\\
    \end{aligned}\right\} x=g(\phi,z)\qquad
       \begin{split}
         0\leq \phi\leq \pi\\
         0\leq z\leq 1
       \end{split}
  \end{gather*}
  $\phi,z$ ist ein Normalbereich. Der Rand des Normalbereichs ist
  $\partial B=\Gamma_{1}+\Gamma_{2}+\Gamma_{3}+\Gamma_{4}$. Der Rand von
  $S$ ist $\partial S=g(\Gamma_{1}) +g(\Gamma_{2})+g(\Gamma_{3})+
  g(\Gamma_{4})$.

  Der Normalenvektor auf $S$ ist
  \begin{gather*}
    \vec{n} = \frac{g_{\phi}\times g_{z}}{\norm{g_{\phi}\times g_{z}}} =
       \begin{bmatrix}
         \cos \phi\\\sin \phi\\ 0
       \end{bmatrix}\qquad
       g_{\phi} = \begin{bmatrix}
                    \frac{\partial g_{1}}{\partial\phi}\\
                    \frac{\partial g_{2}}{\partial\phi}\\
                    \frac{\partial g_{3}}{\partial\phi}
                  \end{bmatrix},
       g_{z} =  \begin{bmatrix}
                    \frac{\partial g_{1}}{\partial z}\\
                    \frac{\partial g_{2}}{\partial z}\\
                    \frac{\partial g_{3}}{\partial z}
                  \end{bmatrix}
  \end{gather*}

  \begin{align*}
    \vec{k}\colon \int_{S}\vec{k}\vec{dS} &= \int_{B} \vec{k}(g(\phi,z))\cdot
       g_{\phi}\times g_{z} d(\phi,z)\\
    &= \int_{B} \vec{k}(g(\phi,z))\cdot \vec{n}(\phi,z)
       \norm{g_{\phi}\times g_{z}}d(\phi,z)\\
    &= \int_{S} \vec{k}\cdot\vec{n}\,dS
  \end{align*}
\end{bsp}

\begin{bemerk}
  (vergleiche mit Definition 7.3.1/3) $G\subseteq\R^{2}$ sei ein offenes
  Gebiet und $g\colon G\rightarrow\R^{3}$ eine stetig differenzierbare
  Abbildung. Die Teilmenge $B\subseteq G$ sei kompakt und Jordan-messbar
  (z.\,B. Normalbereich)

  \begin{enumerate}
   \item $S:= g(B) = \{g(u,v)\colon (u,v)\in B\}$\\ $(S,g)$ ist eine
    \emph{kompakte Fläche} \gdwdef $\exists N\subseteq B$ Jordansche
    Nullmenge mit
    \begin{enumerate}
     \item $g$ injektiv auf $B\setminus N$ und
     \item $g$ ist regulär auf $B\setminus N$, d.\,h. der Rang auf
      $B\setminus N$ ist
      \begin{gather*}
        \begin{bmatrix}
          \frac{\partial g_{1}}{\partial u} &
            \frac{\partial g_{1}}{\partial v}\\
          \frac{\partial g_{2}}{\partial u} &
            \frac{\partial g_{2}}{\partial v}\\
          \frac{\partial g_{3}}{\partial u} &
            \frac{\partial g_{3}}{\partial v}
        \end{bmatrix} = 2
      \end{gather*}
      (oder anders: $g_{u}\times g_{v}\ne0$ auf $B\setminus N$)
    \end{enumerate}
   \item $(S, g)$ kompakte Fläche
    \begin{gather*}
      g_{u} :=
          \begin{bmatrix}
            \partial_{u} g_{1}\\
            \partial_{u} g_{2}\\
            \partial_{u} g_{3}\\
          \end{bmatrix},
         g_{v} :=
          \begin{bmatrix}
            \partial_{v} g_{1}\\
            \partial_{v} g_{2}\\
            \partial_{v} g_{3}\\
          \end{bmatrix},
         \vec{n} := \frac{g_{u}\times g_{v}}{\norm{g_{u}\times g_{v}}}
    \end{gather*}
    auf $B\setminus N$ Normalenvektor
  \end{enumerate}
\end{bemerk}

\begin{defini}
  $(S,g)$ kompakte Fläche wie oben, $B$ Normalbereich mit Rand $\partial
  B=\Gamma$ orientiert wie in \autoref{sec:8.2.1} ("`$B$ links
  von $\partial B$"'). Dann heißt $g(\Gamma)=g(\partial S)$ \emph{Rand}
  von $S$. Bezeichnung $\partial S=g(\partial B)$.
\end{defini}

\begin{bemerk}[Parametrisierung von $\partial S$]
  \begin{enumerate}
   \item
    \begin{align*}
      x_{1} &= g_{1}(\phi_{1}(t), \phi_{2}(t) )\\
      x_{2} &= g_{2}(\phi_{1}(t), \phi_{2}(t) )\\
      x_{3} &= g_{3}(\phi_{1}(t), \phi_{2}(t) )
    \end{align*}
    wobei $\phi\colon[a,b]\rightarrow\partial B$ und $a\leq t\leq b$
    Parametrisierung von $\partial B$.
   \item Beispiel Kugeloberfläche
    \begin{align*}
      g\colon x_{1} &= r\cos\phi\sin\theta &0\leq\phi\leq2\pi\\
      x_{2} &= r\sin\phi\sin\theta & 0\leq\theta\leq\pi\\
      x_{3} &= r\cos\theta
    \end{align*}

    $S$ nennt man eine \emph{Fläche ohne Rand} oder auch
    \emph{geschlossene Fläche}.

    Ist $S$ eine geschlossene Fläche, dann erhält man für das
    Randintegral $\int_{\partial S}\vec{K}\vec{dx}=0$.
  \end{enumerate}
\end{bemerk}

\begin{satz}[Satz von Stokes]\label{satz:stokes}
  Sei $S=g(B)$ eine kompakte Fläche. Der Rand von $S$ sei definiert als
  $\partial S = g(\partial B)$. Wir betrachten ein $C^{1}$-Vektorfeld
  $\vec{v}\colon\Omega\rightarrow\R^{3}$ auf einem offenen Gebiet
  $\Omega\subseteq\R^{3}$ und $S\subseteq\Omega$.

  Dann gilt:
  \begin{gather*}
    \int_{S}\rot \vec{v}\vec{dS} = \int_{\partial S} \vec{v}\vec{dx}
  \end{gather*}

  \begin{proof}
    Zurückführung auf die Greensche Formel aus \autoref{satz:821-3}
    \begin{enumerate}
     \item
      \begin{gather*}
        \int_{\partial S}\vec{v}\vec{dx} = \sum_{j=1}^{4}
           \int_{g(\Gamma_{j})}\vec{v}\vec{dx}\qquad
           \Gamma_{j}\colon[a,b]\rightarrow(\phi_{1}(t),\phi_{2}(t))
           \text{stetig differenzierbar}
      \end{gather*}
      Dann ist
      \begin{align*}
        \int_{g(\Gamma_{j})} \vec{v}\vec{dx} &= \int_{a}^{b}
           \sprod{\vec{v}\big(g(\phi(t))\big)}
             {\frac{d}{dt}\big(g(\phi(t))\big)}
           \,dt\\
        &= \int_{a}^{b} \sum_{l=1}^{3}v_{l}\big(g(\phi(t))\big)
           (\partial_{u}g_{l}(\phi(t))\dot{\phi_{1}}(t) +
           \partial_{v}g_{l}(\phi(t))\dot{\phi_{2}}(t))\,dt\\
        &= \int_{a}^{b} \underbrace{\sum_{l=1}^{3} v_{l}\big(g(\phi(t))\big)
           \partial_{u}g_{l}(\phi(t))}_{=w_{1}(\phi(t))}
           \dot{\phi_{1}}(t) +
           \int_{a}^{b} \underbrace{\sum_{l=1}^{3}
           v_{l}\big(g(\phi(t))\big)
           \partial_{v}g_{l}(\phi(t))}_{w_{2}(\phi(t))}
           \dot{\phi_{1}}(t)\,dt\\
        &= \int_{a}^{b} \vec{w}(\phi(t))\cdot\dot{\phi}(t)\,dt =
           \int_{\Gamma_{j}} (w_{1}\,du + w_{2}\,dv)
      \end{align*}
      ist das Kurvenintegral von $\vec{w}$ längs $\Gamma_{j}$.

      Mit $w_{1} := \sum_{l=1}^{3} v_{l}(g(u,v))\partial_{u} g_{l}(u,v)$
      und $w_{2} := \sum_{l=1}^{3} v_{l}(g(u,v))\partial_{v} g_{l}(u,v)$
      und $\vec{w} = \begin{bmatrix}w_{1}(u,v)\\w_{2}(u,v)\end{bmatrix}\colon G
      \rightarrow\R^{2}$ $C^{1}$-Vektorfeld

      \autoref{satz:821-3} liefert
      \begin{gather}\label{eq:2}
        \int_{\partial S}\vec{v}\vec{dx} = \int_{\Gamma=\partial B}
           w_{1}\,du + w_{2}\,dv = \int_{B} \partial_{u} w_{2} -
           \partial_{v} w_{1}\,d(u,v)
      \end{gather}
     \item
      \begin{gather*}
        \int_{S}\rot\vec{v}\vec{dS} = \int_{B}
           \underbrace{\rot\vec{v}(g(u,v))\cdot(g_{u}\times
           g_{v})(u,v)}_{=f(u,v) \stackrel{=}{?}
           \partial_{u}w_{2}-\partial_{v}w_{1}}\,d(u,v)
      \end{gather*}\help{Was soll das Fragezeichen?}
      Es gilt:
      \begin{gather}\label{eq:3}
        \partial_{u}w_{2}-\partial_{v}w_{1} = \sum_{l=1}^{3}
           \sum_{j=1}^{3} \frac{\partial v_{l}}{\partial x_{j}}(g(u,v))
           \Big(\partial_{u} g_{j}(u,v) \partial_{v}g_{l}(u,v) -
           \partial_{v}g_{j}\partial_{u}g_{l}\Big)
      \end{gather}
      Andererseits ist:
      \begin{align*}
        f(u,v) &= \rot\vec{v}(g(u,v))\cdot g_{u}\times g_{v}\\
        &= (\partial_{2}v_{3}-\partial_{3}v_{2})(g(u,v)) (\partial_{u}
           g_{2}\partial_{v}g_{3} - \partial_{v}g_{2}\partial_{u}g_{3}) +
           \ldots +\ldots
      \end{align*}
      Dieses stimmt mit dem Ausdruck in \autoref{eq:3} überein.
    \end{enumerate}
  \end{proof}
\end{satz}

\begin{bemerk}
  \begin{enumerate}
   \item
    \begin{gather*}
      \int_{\partial S}\vec{v}\vec{dx} =
         \int_{S}\rot\vec{v}\cdot\vec{n}\,dS
    \end{gather*}
   \item Das Integral einer geschlossenen Fläche $S$ ist 0
    \begin{gather*}
      \int_{S}\rot\vec{v}\cdot\vec{n}\,dS = 0
    \end{gather*}
   \item Für eine Fläche $S\subseteq\R^{2}\{0\}$ und ein $\vec{v}=
    \begin{bmatrix}v_{1}(x_{1},x_{2})\\v_{2}(x_{1},x_{2})\\\end{bmatrix}$
    ergibt sich genau die \emph{Greensche Formel}
    (\autoref{satz:821-3}). Die Greensche Formel ist also ein Spezialfall des
    Stokes'schen Satzes (\autoref{satz:stokes}).
  \end{enumerate}
\end{bemerk}

\subsection{Der Satz von Gauß-Ostrogradski -- "`Divergenzsatz"'}
\label{sec:8.2.3}
\begin{bemerk}\label{bem:823-1}
  Wir betrachten $n=2$. Es sei also $B$ ein Normalbereich und
  $\vec{n}$ sei der äußere Normaleneinheitsvektor. Wir definieren
  wieder ein $C^{1}$-Vektorfeld $\vec{v}\colon G\rightarrow\R^{2}$ mit
  $B\subseteq G$ offen. Wir wollen uns dann überlegen, dass
  \begin{gather*}
    \int_{B}\Div \vec{v}\,dx = \int_{\partial B}\vec{v}\cdot\vec{n}\,ds
  \end{gather*}
  ($ds$ ist das skalare Linienelement)

  \begin{proof}
    $\vec{w} := \begin{bmatrix}-v_{2}\\v_{1}\end{bmatrix} \Rightarrow
    \Div \vec{v} = \partial_{1}w_{2}-\partial_{2}w_{1} \Rightarrow$
    \begin{align*}
      \int_{B} \Div \vec{v}\,dx &= \int_{B}
         \partial_{1}w_{2}-\partial_{2}w_{1}\,dx\\
      &= \int_{\partial B}\vec{w}\,dx&\text{nach \autoref{satz:821-3}}\\
      &= \int_{a}^{b} v_{1}(\phi(t)) \dot{\phi_{2}}(t) -
         v_{2}(\phi(t))\dot{\phi_{1}}(t)\,dt\\
      &= \int_{a}^{b} \vec{v}(\phi(t))\cdot
         \underbrace{\begin{bmatrix}\dot{\phi_{2}}(t)\\-\dot{\phi_{1}}(t)
           \end{bmatrix}}
         _{\makebox[0pt]{$=\vec{n}(\phi(t))\cdot\norm{\dot{\phi}(t)}$}}
         \,dt = \int_{\partial B} \vec{v} \cdot \vec{n}\,ds
    \end{align*}
  \end{proof}
\end{bemerk}

\begin{bemerk}
  Wir setzen im folgenden voraus:
  \begin{gather*}
    G=\{(x_{1},x_{2})\colon a\leq x_{1}\leq b, \phi(x_{1})\leq x_{2}\leq
       \psi(x_{2})\}
  \end{gather*}
  wobei $\phi,\psi \colon [a,b]\rightarrow\R$ stetig differenzierbar.
  $G\subseteq U$, $U\subseteq \R^{2}$ offen, $g,h\colon U\rightarrow \R$,
  $g,h\in C^{1}(U)$
  \begin{gather*}
    B:= \{(x,_{1},x_{2},x_{3})\colon (x_{1},x_{2})\in G, g(x_{1},x_{2})\leq
       x_{3}\leq h(x_{1},x_{2})\}
  \end{gather*}
  Normalbereich im $\R^{3}$ (Jordan-messbar)
\end{bemerk}

\begin{bemerk}
  Parametrisierung:
  \begin{enumerate}
   \item
    \begin{figure}
      \caption{\label{fig:2}\todo{Bild}}\help{Wie sieht das aus?}
    \end{figure}
    Wir betrachten zuerst den Normalbereich $G$ in der Ebene
    (s.\,\autoref{fig:2}). Der Rand $\partial G$ setzt sich aus bis zu
    vier Teilkurven ($\Gamma_{2}$ und $\Gamma_{4}$ können zu einem Punkt
    entarten) zusammen. $\partial G=\Gamma_{1}+\Gamma_{2}+\Gamma_{3}
    +\Gamma_{4}$. $\Gamma_{1}=
    \begin{bmatrix}x_{1}\\\phi(x_{1})\end{bmatrix}, a\leq x_{1}\leq b$.
    Der Normalenvektor an $\phi$ ist
    \[\vec{\nu}_{\phi} = \frac{1}{\sqrt{1+\phi'^{2}(x_{1})}}
    \begin{bmatrix}\phi'(x_{1})\\-1\end{bmatrix}\]
    \help{Kann man das jetzt besser lesen?}

    analog: $\Gamma_{2},\Gamma_{3},\Gamma_{4}$
   \item Der Normalbereich $B$ ist ein säulenförmiger Körper im $\R^{3}$
    dessen Querschnitt $G$ ist. Der Rand $\partial B$ von $B$ sind
    6~Flächen. Bezeichnen wir den Boden mit $S^{u}$, den Deckel mit
    $S^{o}$ und die verbleibenden Flächen mit $S^{1}\ldots S^{4}$.
    \begin{gather*}
      \partial B = S^{u}+S^{o}+S^{1}+S^{2}+S^{3}+S^{4}
    \end{gather*}
    Die Normalenvektoren $\vec{n}^{u}, \vec{n}^{o}, \vec{n}^{1},\ldots,
    \vec{n}^{4}$ der Flächen müssen jeweils so orientiert werden, dass
    sie nach außen (vom Körper weg) zeigen.
    \begin{gather*}
      S^{o} \colon \begin{bmatrix}x_{1}\\x_{2}\\h(x_{1},x_{2})\end{bmatrix},
         (x_{1}, x_{2})\in G\\
      \vec{n}^{o} = \frac{1}{\sqrt{1+\partial_{1} h^{2}+
         \partial_{2}h^{2}}}
         \begin{bmatrix}-\partial_{1}h\\\partial_{2}h\\1\end{bmatrix}\\
      \vec{n}^{o}dS =
         \begin{bmatrix}-\partial_{1}h\\-\partial_{2}h\\1\end{bmatrix}
         d(x_{1},x_{2})
         \qquad\text{(Oberflächenelement)}\\
      -S^{u} \colon \begin{bmatrix}x_{1}\\x_{2}\\g(x_{1},x_{2})\end{bmatrix},
         (x_{1}, x_{2})\in G\\
      % \vec{n}^{u} = \frac{1}{\sqrt{1+\partial_{1} g^{2}+
      %    \partial_{2}g^{2}}}
      %    \begin{bmatrix}-\partial_{1}g\\\partial_{2}g\\1\end{bmatrix}\\
      \vec{n}^{u}dS =
         \begin{bmatrix}-\partial_{1}g\\-\partial_{2}g\\1\end{bmatrix}
         \qquad\text{(Oberflächenelement)}\\
      S^{1}\colon \begin{bmatrix}x_{1}\\\phi(x_{1})\\x_{3}\end{bmatrix}, a\leq
         x_{1}\leq b\\
    \end{gather*}
    Wir erhalten für $S^{1}$ in der $x_{1}$-$x_{3}$-Ebene einen Normalbereich
    \begin{gather*}
      A := \{(x_{1}, x_{3})\colon a\leq x_{1}\leq b, g(x_{1},\phi(x_{1}))\leq
         x_{3}\leq h(x_{1},\phi(x_{1}))\}
    \end{gather*}
    Das Oberflächenelement $\vec{n}\,dS =
    \begin{bmatrix}\phi'(x_{1})\\-1\\0\end{bmatrix} d(x_{1},x_{3})$

    analog: $S^{2}, S^{3}$ und $S^{4}$.
  \end{enumerate}
\end{bemerk}

\begin{satz}[Gauß für $n=3$]\label{satz:gauss}
  Sei $B$ Normalbereich, $\partial B$ Rand, $\vec{n}$ äußerer
  Normaleneinheitsvekor an $\partial B$, $B\subset \Omega\subseteq
  \R^{3}$, $\Omega$ offen, $\vec{v}$ ein $C^{1}$-Vektorfeld auf $\Omega$.

  Dann gilt:
  \begin{gather*}
    \int_{B}\Div \vec{v}\,dx =\int_{\partial B}\vec{v}\cdot\vec{n}\,dS
  \end{gather*}

  \begin{proof}
    Sei $\vec{n} = \begin{bmatrix}n_{1}\\n_{2}\\n_{3}\end{bmatrix}$.
    Es reicht, zu zeigen
    \begin{gather*}
      \int_{B} \Div \vec{v}\,dx = \int_{B} \sum_{l=1}^{3} \partial_{l}
         v_{l}\,dx = \int_{\partial B} v_{l} n_{l}\,dS
    \end{gather*}
    Wir brauchen also nur zu zeigen, dass die Gleichheit für jeweils einen
    Summanden gilt. Sei \obda $l=1$. Dann ist
    \begin{gather*}
      \int_{B} \frac{\partial v_{1}}{\partial x_{1}}dx = \int_{G} \Big(
         \underbrace{\int_{g(x_{1},x_{2})}^{h(x_{1},x_{2})}
           \frac{\partial}{\partial x_{1}} v_{1}(x_{1}, x_{2}, x_{3})}
         _{=: f(x_{1},x_{2})}\Big)d(x_{1},x_{2})
    \end{gather*}

    Aus \autoref{lem:821-1} folgt mit $F(u,v,x_{1},x_{2}) :=
    \int_{u} v_{1}(x_{1},x_{2},x_{3})\,dx_{3}$

    \begin{multline*}
      \frac{\partial}{\partial x_{1}}
         \int_{g(x_{1},x_{2})}^{h(x_{1},x_{2})}
         v_{1}(x_{1},x_{2},x_{3})\,dx_{3} = -v_{1}(x_{1},x_{2},
         g(x_{1},x_{2}))\partial_{1} g\\
      +v_{1}(x_{1},x_{2}, h(x_{1},x_{2}))\partial_{1} h
      +\underbrace{\int_{g(x_{1},x_{2})}^{h(x_{1},x_{2})}
           \frac{\partial}{\partial x_{1}} v_{1}(x_{1},x_{2},x_{3})
           \,dx_{3}}_{=f(x_{1},x_{2})}
    \end{multline*}
    einsetzen:
    \begin{align*}
      \int_{B} \frac{\partial v_{1}}{\partial x_{1}}dx &= \int_{G}
         v_{1}(x_{1},x_{2}, g(x_{1},x_{2}))\partial_{1} g(x_{1},x_{2})
         d(x_{1},x_{2})\\
      &\quad- \int_{G} v_{1}(x_{1},x_{2},
         h(x_{1},x_{2}))\partial_{1} h(x_{1},x_{2}) d(x_{1},x_{2})\\
      &\quad+\int_{G} \frac{\partial}{\partial x_{1}} \underbrace{
         \int_{g(x_{1},x_{2})}^{h(x_{1},x_{2})} v_{1}(x)dx_{3}}
         _{:=w_{1}(x_{1},x_{2})} d(x_{1},x_{2})\\
      &= \int_{S^{u}} v_{1}n^{u}_{1}dS - \int_{S^{o}} v_{1}n^{o}_{1}dS +
         \int_{G}\partial_{1} w_{1}d(x_{1},x_{2})\\
      &= \int_{S^{u}+S^{o}} v_{1}n^{u}_{1}dS
         + \int_{G}\partial_{1} w_{1}d(x_{1},x_{2})
    \end{align*}
    Nach \autoref{bem:823-1} (Gauß für $n=2$) gilt:
    \begin{gather*}
      \int_{G} \partial_{1}w_{1}d(x_{1},x_{2}) = \int_{\partial G}
         w_{1}\cdot \nu_{1}\,dS
    \end{gather*}
    wir zeigen:
    \begin{gather*}
      \int_{\partial G} w_{1}\cdot \nu_{1}\,dS =
         \int_{S^{1}+\ldots+S^{4}} v_{1}\cdot n_{1}\,dS
    \end{gather*}
    Es ist:
    \begin{align*}
      \int_{\Gamma_{1}} w_{1}\cdot\nu_{1}\,dS &= \int_{a}^{b}
         w_{1}(x_{1},\phi(x_{1}))\cdot \phi'(x_{1})\,dx_{1} =
         \int_{a}^{b} \int_{g(x_{1},x_{2})}^{h(x_{1},x_{2})}
         v_{1}(x_{1}, \phi(x_{1}), x_{3})\,dx_{3} \phi'(x_{1})\,dx_{1}\\
      &= \int_{A} v_{1}(x_{1},\phi(x_{1}),
         x_{3})\phi'(x_{1})\,d(x_{1},x_{3}) = \int_{S^{1}} v_{1}n_{1}\,dS
    \end{align*}
    analog zeigt man $\int_{\Gamma_{i}} w_{1}\nu_{1}\,dS = \int_{S^{i}}
    v_{1}n_{1}\,dS$ für $i=2,3,4$
  \end{proof}
\end{satz}

\begin{bemerk}
  \begin{enumerate}
   \item Der Satz \todo{link}\help{welcher?} gilt für alle $n\geq 2$
    und für allgemeine Bereiche $B$!
   \item Als einen \emph{zulässigen Bereich} bezeichnen wir einen
    Bereich, für den der Gauß'sche Satz (\autoref{satz:gauss}) gilt
   \item Für $\vec{v} = \begin{bmatrix}0\\0\\x_{3}\end{bmatrix}$ ist
    $\Div \vec{v} = 1$ und der Satz\todo{link}\help{welcher?} liefert
    \begin{gather*}
      \underbrace{\int_{B}dx}_{=\mu(B)} = \int_{\partial B} x_{3}\cdot
         n_{3}\,dS = \frac{1}{3} \int_{\partial B} x\cdot\vec{n}\,dS
    \end{gather*}
    $\mu(B)$ ist das Volumen des Körpers
  \end{enumerate}
\end{bemerk}

\begin{satz}[Die Green'schen Sätze]\label{satz:823-6}
  Es sei $B\subseteq \Omega$ ein zulässiger Bereich in einer offenen
  Menge $\Omega$. $u,v\in C^{2}(\Omega)$. Dann gilt:
  \begin{gather*}
    \int_{B} u\,\Delta v\,dx = \int_{\partial B}\cdot \frac{\partial
       v}{\partial \vec{n}}dS - \int_{B} \grad u\cdot\grad v\,dx\\
    \int_{B}(u\,\Delta v -v\,\Delta u)\,dx = \int_{\partial B} u\cdot
       \frac{\partial v}{\partial \vec{n}} - v
       \frac{\partial u}{\partial \vec{n}}\,dS
  \end{gather*}

  \begin{proof}
    Die zweite Gleichung folgt sofort aus der ersten, indem man einmal
    $u$ und $v$ vertauscht und die beiden von einander anzieht.
    \begin{gather*}
      \todo{machen}
    \end{gather*}

    Die erste Gleichung ergibt sich durch Anwendung des Satz von
    Gauß (\autoref{satz:gauss}) auf das Vektorfeld $\vec{w} := u\grad v$
    $\Rightarrow$ $\Div \vec{w} = u\,\Delta v + \grad u\cdot \grad v$
  \end{proof}
\end{satz}

% 15.11.05

\section{Ergänzungen}
\subsection{Flächenintegrale im \texorpdfstring{$\R^{n}$}{Rn} und die
  Oberfläche der Einheitskugel im \texorpdfstring{$\R^{n}$}{Rn}}

Bisher hatten wir für Flächen im $\R^{3}$ die folgenden Definitionen
getroffen:
\begin{itemize}
 \item $S=g(B)$ mit $B\subseteq G\subseteq \R^{2}$, wobei $B$ eine
  kompakte Menge und $G$ eine offene Menge ist, und der $C^{1}$-Abbildung
  $g\colon G\rightarrow\R^{3}$, wobei $g$ injektiv auf $B\setminus N$
  (Jordansche Nullmenge)
  \begin{gather*}
    \text{Rang } Dg = \text{Rang } \begin{bmatrix}
                     \partial_{u}g_{1}& \partial_{v}g_{1}\\
                     \partial_{u}g_{2}& \partial_{v}g_{2}\\
                     \partial_{u}g_{3}& \partial_{v}g_{3}
                     \end{bmatrix} = 2 \text{ auf } B\setminus N
  \end{gather*}
 \item
  \begin{align*}
    dS &= \norm{g_{u}\times g_{v}} d(u,v)&\text{Oberflächenelement}\\
    &= \sqrt{
       \begin{vmatrix}
         g_{u}\cdot g_{u} & g_{u}\cdot g_{v}\\
         g_{u}\cdot g_{v} & g_{v}\cdot g_{v}
       \end{vmatrix}
         } d(u,v) &\text{Lemma 7.3.2/3}
  \end{align*}
  \begin{gather*}
    \int_{S} F\,dS := \int_{B} F(g(u,v))\sqrt{\ldots} d(u,v)
  \end{gather*}
  in expliziter Darstellung $S=\{(x_{1},x_{2},f(x_{1},x_{2}))\colon
  (x_{1},x_{2})\in B\}$
  \begin{gather*}
    dS = \sqrt{1+ f_{x_{1}}^{2}+ f_{x_{2}}^{2}} d(x_{1},x_{2})\\
    \vec{n} = \frac{1}{\sqrt{\ldots }} \begin{bmatrix}
                                         -f_{x_{1}}\\
                                         -f_{x_{2}}\\
                                         1
                                       \end{bmatrix}
  \end{gather*}
\end{itemize}

Jetzt wollen wir $m$-Flächen im $\R^{n}$ mit $m<n$ beschreiben. $S=g(B)$
mit $B\subseteq G\subseteq \R^{m}$ ($G$ ist dabei eine offene Menge und
$B$ ein Normalbereich)
$g\colon G\rightarrow\R^{n}$ $C^{1}$-Abbildung, injektiv, $\text{Rang } Dg = m$
\begin{gather*}
  dS := \sqrt{\det(g_{ik})} d(u_{1},\ldots,u_{m})
\end{gather*}
wobei
\begin{gather*}
  g_{ik} = \sprod{\frac{\partial g}{\partial u_{i}}} {\frac{\partial
     g}{\partial u_{k}}}\qquad i,k=1,\ldots,m
\end{gather*}
Damit können wir das Integral über eine $m$-Fläche $S$ erklären:
\begin{gather*}
  \int_{S} F\,dS = \int_{B} F(g(u_{1},\ldots,u_{m})) \sqrt{det(g_{ik})}
     d(u_{1},\ldots,u_{m})
\end{gather*}

Für den Fall $m=n-1$ spricht man von einer $(n\!-\!1)$-dimensionale
\emph{Hyperfläche}. Dieser Fall tritt z.\,B. auf, wenn man den Rand
$S=\partial\Omega$ eines Normalbereichs $\Omega\subseteq\R^{n}$
betrachtet. Oder für den Fall, dass die Fläche eine explizite
Darstellung $S=\{x\colon x'=(x_{1},\ldots,x_{n-1})\in B\subseteq \R^{n-1},
f(x') = x_{n}\}$ erhält man
\begin{align*}
  dS &= \sqrt{1+f_{x_{1}}^{2}+\ldots+f_{x_{n-1}}^{2}}
     d(x_{1},\ldots,x_{n-1})\\
  \vec{n} &:= \frac{1}{\sqrt{\ldots}}
     \begin{bmatrix}
       -f_{x_{1}}\\ -f_{x_{2}}\\\vdots\\-f_{x_{n-1}}\\1
     \end{bmatrix}\qquad\text{äußerer Normalenvektor}\\
  \int_{S} F\,dS &= \int_{B} F(x_{1},\ldots,x_{n-1},
     f(x_{1},\ldots,x_{n-1})) \sqrt{\ldots} %1+f_{x_{1}}+\ldots+f_{x_{n-1}}}
     \;d(x_{1},\ldots,x_{n-1})
\end{align*}

Der Satz von Gauß (\autoref{satz:gauss}) und alle Folgerungen daraus lassen
sich auch für den $\R^{n}$ verallgemeinern. $\vec{v}\colon\Omega\rightarrow
\R^{n}, \Omega\subseteq\R^{n}, \Omega$ Normalbereich
\begin{gather*}
  \int_{\Omega} \Div\vec{v}\,dx = \int_{\partial\Omega} \sprod{\vec{v}}
     {\vec{n}}\,dS
\end{gather*}

\subsubsection{Die Oberfläche der Einheitskugel im $\R^{n}$}
\label{sec:1}

Die Oberfläche der Einheitskugel im $\R^{n}$ wurde beschrieben mit
$\omega_{n} :=\{x\colon x_{1}^{2}+\ldots+x_{n}^{2}=1\}$. Wir führen dazu die
Polarkoordinaten im $\R^{n}$ ein
\begin{align*}
  \Phi\colon\quad x_{1} &= r\cos\phi \sin\theta_{1} \sin\theta_{2} \ldots
     \sin\theta_{n-2}\\
  x_{2} &= r\sin\phi \sin\theta_{1} \sin\theta_{2} \ldots
     \sin\theta_{n-2}\\
  x_{3} &= r\cos\theta_{1}\sin\theta_{2}\ldots \sin\theta_{n-2}\\
  &\vdots\\
  x_{n-1} &= r\cos\theta_{n-3}\sin\theta_{n-2}\\
  x_{n} &= r \cos\theta_{n-2}
\end{align*}
wobei $r\geq 0, 0\leq\phi\leq 2\pi, 0\leq\theta_{i}\leq\pi$. Daraus
ergibt sich $x^{2}_{1}+x^{2}_{2}+\ldots+x^{2}_{n} = r^{2}$. Für Beweise
und weitere Ausführungen siehe Walter, Analysis 2, Seite 254.

Noch ein paar Worte zur Jacobi-Determinante:
\begin{gather*}
     \frac{\partial(x_{1},\ldots,x_{n})}{\partial(r,\phi,\theta_{1},
     \ldots,\theta_{n-2})} = r^{n-1}
     \sin\theta_{1}\sin^{2}\theta_{2}\ldots \sin^{n-2}\theta_{n-2}
\end{gather*}

Auf die Einheitskugel bezogen ergibt sich so das Oberflächenelement als
\begin{gather*}
  d\omega_{n} = \sin\theta_{1}\sin^{2}\theta_{2}\ldots \sin^{n-2}\theta_{n-2}
     \,d\phi d\theta_{1}\ldots d\theta_{n-2}\\
  \int_{\omega_{n}} F\,d\omega_{n} = \int_{0}^{2\pi}\int_{0}^{2\pi}\ldots
     \int_{0}^{2\pi} F(\Phi(1,\phi,\theta_{1},\ldots,\theta_{n-2}))
     \sin\theta_{1}\sin^{2}\theta_{2}\ldots \sin^{2}\theta_{n-2}
     \,d\phi d\theta_{1}\ldots d\theta_{n-2}\\
  \abs{\omega_{n}} := \int_{\omega_{n}} 1\,d\omega_{n}\qquad\text{Flächeninhalt von
     $\omega_{n}$}
\end{gather*}

Folgerungen daraus:
\begin{gather*}
  \int_{\R^{n}} F\,dx = \int_{0}^{\infty}\int_{\omega_{n}} r^{n-1}
     F(\Phi(r,\phi,\theta_{1},\ldots,\theta_{n-2}))\,d\omega_{n} dr\\
  \tilde{f}=f(r), r=\norm{x} \Rightarrow
     \int_{\R^{n}} \tilde{f}\,dx = \abs{\omega_{n}} \int_{0}^{\infty} r^{n-1}
     f(r)\,dr
\end{gather*}

\begin{satz}
  $n\geq2$. Dann gilt:
  \begin{gather*}
    \abs{\omega_{n}} = \frac{2\pi^{\nicefrac{n}{2}}}{\Gamma(\frac{n}{2})} =
       2\pi^{\nicefrac{n}{2}} \begin{cases}
                                \frac{1}{(\frac{n}{2}-1)!} & :n\text{
                                gerade}\\
                                \sqrt{\pi}(\frac{n}{2}-1)(\frac{n}{2}-2)
                                \ldots \frac{1}{2}&:n \text{ ungerade}
                              \end{cases}
  \end{gather*}

  \begin{proof}
    Aus Analysis 2 wissen wir bereits
    \begin{gather*}
      I = \int_{-\infty}^{\infty} e^{-t^{2}}\,dt = \sqrt{\pi}
    \end{gather*}
    Also ist
    \begin{align*}
      \pi^{\frac{n}{2}} &= \Big( \int_{-\infty}^{\infty} e^{-t^{2}}\,dt
         \Big)^{n}\\
      &= \int_{\R^{n}} e^{-\abs{x}^{2}}\,dx&\text{nach Satz von Fubini}\\
      \abs{\omega_{n}} \int_{0}^{\infty} r^{n-1} e^{-r^{2}}\,dr
      &= \frac{1}{2} \abs{\omega_{n}} \int_{0}^{\infty} e^{-\rho}
         \rho^{\frac{n}{2}-1}\,d\rho &\text{mit } r^{2}=\rho,
         2r\,dr=d\rho\\
      &= \frac{1}{2}\abs{\omega_{n}}\Gamma\big(\frac{n}{2}\big)
    \end{align*}
    $\Rightarrow = \frac{2 \pi^{\frac{n}{2}}} {\Gamma\big(\frac{n}{2}\big)}$ Außerdem ist
      $\Gamma\big(\frac{1}{2}\big) = \sqrt{\pi}$, da
    \begin{gather*}
      \Gamma\big(\frac{1}{2}\big) = \int_{0}^{\infty} t^{-\frac{1}{2}}
         e^{-t}\,dt = 2 \int_{0}^{\infty} e^{-r^{2}}\,dr =
         \int_{-\infty}^{\infty} e^{-r^{2}}\,dr
    \end{gather*}
  \end{proof}
\end{satz}

\begin{bemerk}
  \begin{enumerate}
   \item $\lim_{n\rightarrow\infty} \abs{\omega_{n}} = 0$
   \item $\abs{\omega_{2}} = 2\pi, \abs{\omega_{3}} = 4\pi,
    \abs{\omega_{4}} = 2\pi^{2}, \abs{\omega_{5}} = \frac{8}{3}\pi^{2},
    \abs{\omega_{6}} = \pi^{3}, \abs{\omega_{7}} = \frac{16}{15} \pi^{3}
    = \max_{n} \abs{\omega_{n}}$
  \end{enumerate}
\end{bemerk}

\subsection{Differentialoperatoren in krummlinigen Koordinaten}
$n=3$: \emph{Krummlinige Koordinaten} auf $\Omega\subseteq\R^{3}$,
$\Omega$ offen: $g\colon G\rightarrow \Omega$ bijektive $C^{1}$-Abbildung
(\emph{Diffeomorphismus}), d.\,h. $x=g_{1}(u,v,w), y=g_{2}(u,v,w),
z=g_{3}(u,v,w)$

setzen:
\begin{gather*}
  \partial_{u} g = \begin{bmatrix}
                     \partial_{u}g_{1}\\ \partial_{u}g_{2}\\
                     \partial_{u}g_{3}
                   \end{bmatrix}
     \qquad \vec{e}_{u} = \frac{1}{\norm{\partial_{u}g}}\partial_{u}g
\end{gather*}

analog: $\partial_{v}g, \vec{e}_{v}, \partial_{w}g, \vec{e}_{w}$

mit:
\begin{gather*}
  \frac{\partial(x,y,z)}{\partial(u,v,w)} > 0\ \text{auf}\ G
\end{gather*}

Schreibweise: $h_{u} := \norm{\partial_{u}g}, h_{v} :=
\norm{\partial_{v}g}, h_{w} := \norm{\partial_{w}g}$

Die Koordinaten $(u,v,w)$ (wie oben) heißen \emph{orthogonal} \gdwdef
\begin{gather*}
  \forall u,v,w\colon \sprod{\partial_{u}g}{\partial_{v}g} = 0,
     \sprod{\partial_{u}g}{\partial_{w}g} = 0,
     \sprod{\partial_{v}g}{\partial_{w}g} = 0
\end{gather*}
dann bilden $\vec{e}_{u}, \vec{e}_{v}, \vec{e}_{w}$ ein
\emph{Orthonormalsystem} im $\R^{3}$.

\begin{satz}
  Für ein skalares Feld $f=f(u,v,w)$ bezüglich der Koordinaten $(u,v,w)$
  und ein Vektorfeld $\vec{F} = F_{u} \vec{e}_{u} + F_{v}\vec{e}_{v} +
  F_{w}\vec{e}_{w}$ ebenfalls bezüglich der Koordinaten $(u,v,w)$ gilt:
  \begin{gather}
    \label{eq:4}\index{Gradient}
    \grad f = \frac{1}{h_{u}} \partial_{u} f \vec{e}_{u} +
       \frac{1}{h_{v}} \partial_{v} f \vec{e}_{v} +
       \frac{1}{h_{w}} \partial_{w} f \vec{e}_{w}\\
    \label{eq:5}\index{Divergenz}
    \Div \vec{F} = \frac{1}{h_{u}h_{v}h_{w}}
       \big(\partial_{u}(h_{v}h_{w}F_{u}) +
       \partial_{v}(h_{u}h_{w}F_{v}) + \partial_{w}(h_{u}h_{v}F_{w})
       \big)\\
    \label{eq:6}\index{Laplace-Operator}
    \Delta f = \Div \grad f =
       \frac{1}{h_{u}h_{v}h_{w}}
       \big(\partial_{u}(\frac{h_{v}h_{w}}{h_{u}}\partial_{u}f) +
       \partial_{v}(\frac{h_{u}h_{w}}{h_{v}}\partial_{v}f) +
       \partial_{w}(\frac{h_{u}h_{v}}{h_{w}}\partial_{w}f)
       \big)\\
    \notag\index{Rotation}
    \rot\vec{F} = \frac{1}{h_{u}h_{v}h_{w}}
       \begin{bmatrix}
         h_{u} \vec{e}_{u} & \partial_{u} & h_{u} F_{u}\\
         h_{v}\vec{e}_{v} & \partial_{v} & h_{v} F_{v}\\
         h_{w}\vec{e}_{w} & \partial_{w} & h_{w} F_{w}
       \end{bmatrix}\qquad\text{\textit{formal!}}
  \end{gather}

  \begin{proof}
    zur \autoref{eq:4}: $\{\vec{e}_{u}, \vec{e}_{v}, \vec{e}_{w}\}$ ist
    ein Othonormalsystem. Es ist also zu zeigen, dass
    \begin{gather*}
      \frac{1}{h_{u}}\;\partial_{u}f = \sprod{(\grad f)}{\vec{e}_{u}},\ldots
    \end{gather*}
    Da $g$ bijektiv ist, gelten die folgenden Beziehungen:
    \begin{gather*}
      f(u,v,w) = f(g^{-1}(x,y,z)) =: \tilde{f}(x,y,z) = \tilde{f}(g(u,v,w))
    \end{gather*}
    und wir erhalten dann
    \begin{align*}
      \grad f &= \grad \tilde{f} =
         \begin{bmatrix}\partial_{x}\tilde{f}\\ \partial_{y}\tilde{f}\\
           \partial_{z}\tilde{f}
         \end{bmatrix}\\
      \sprod{(\grad f)}{\vec{e}_{u}} &= \frac{1}{h_{u}}
         (\partial_{x} \tilde{f} \partial_{u} g_{1} +
         \partial_{y}\tilde{f} \partial_{u}g_{2} + \partial_{z}\tilde{f}
         \partial_{u} g_{3})\\
         &= \frac{1}{h_{u}} \partial_{u} f(u,v,w)&\text{mit Kettenregel}
    \end{align*}
    analog für $v,w$

    \autoref{eq:5} + \autoref{eq:6} Übungsserie 32 \todo{ergänzen}
  \end{proof}
\end{satz}

Wir betrachten als ersten Spezialfall ein gedrehtes Koordinatensystem,
also eine lineare Transformation.
\begin{folger}
  $T\in SO(3)$ \emph{Drehung} (orthogonale Matrix, $\det T=1$). Damit
  sind $h_{u}=h_{v}=h_{w}=1$. Daraus folgt, dass der Divergenz, Gradient,
  Rotation und der Laplace-Operator invariant bezüglich einer Drehung
  sind.
\end{folger}

\begin{folger}[Der Laplace-Operator für Kugelkoordinaten]
  \begin{gather*}
    x = r\sin\theta\cos\phi, y=r\sin\theta\sin\phi, z=r\cos\theta\\
    \Rightarrow h_{r}=1, h_{\theta}=r, h_{\phi}= r\sin\theta
  \end{gather*}
  (Beweis Übungsserie 32\todo{ergänzen})

  $\Rightarrow$
  \begin{gather*}
    \Delta f = \frac{1}{r^{2}}\partial_{r}(r^{2}\partial_{r}f) +
       \frac{1}{r^{2}\sin\theta}\partial_{\theta}(\sin\theta
       \partial_{\theta} f) + \frac{1}{r^{2}\sin^{2}\theta}
       \partial^{2}_{\phi} f
  \end{gather*}
\end{folger}

\begin{folger}[Der Laplace-Operator für Zylinderkoordinaten]
  \begin{gather*}
    x = \rho\cos\phi, y =\rho\sin\phi, z=z\\
    \Rightarrow h_{\rho}=1, h_{\phi}=\rho, h_{z}=1\\
    \Rightarrow\Delta f = \frac{1}{\rho}(\partial_{\rho}(\rho
       \partial_{\rho}f)) + \frac{1}{\rho^{2}} \partial^{2}_{\phi} f +
       \partial^{2}_{z} f
  \end{gather*}
\end{folger}

\begin{folger}[Der Laplace-Operator für Polarkoordinaten]
  \begin{gather*}
    x = r\cos\phi, y =r\sin\phi\\
%    \Rightarrow h_{\rho}=1, h_{\phi}=\rho, h_{z}=1\\
    \Rightarrow\Delta f = \frac{1}{r}(\partial_{r}(r
       \partial_{r}f)) + \frac{1}{r^{2}} \partial^{2}_{\phi} f
  \end{gather*}
\end{folger}

\subsection{Die Maxwell'schen Gleichungen}

Wir betrachten gewisse Vektorfelder $\vec{E}(x,t)$ (elektrische
Feldstärke), $\vec{B}(x,t)$ (magnetische Induktion), $\vec{D}(x,t)$
(dielektrische Verschiebung) und $\vec{H}(x,t)$ (magnetische Feldstärke),
die von einem Ortsvektor $x$ und der Zeit $t$ abhängen. Dazu sind einige
Quellen $\vec{j}(x,t)$ (Stromdichte) und $\vec{\rho}(x,t)$
(Ladungsdichte) gegeben, mit denen man das Verhalten der Vektorfelder über
die Zeit hin betrachten will.

Materialgleichungen mit den Stoffkonstanten $\epsilon_{0}$ und $\mu_{0}$
\begin{align*}
  \vec{D}(x,t) &= \epsilon_{0} \vec{E}(x,t)\\
  \vec{B}(x,t) &= \mu_{0} \vec{H}(x,t)\\
\end{align*}

\subsubsection{Grundgleichungen von Maxwell (1864)}
\begin{gather}
  \rot \vec{E} + \frac{\partial}{\partial t}\vec{B} = 0\label{eq:7}\\
  \Div \vec{D} = \rho\label{eq:8}\\
  \rot \vec{H} - \frac{\partial}{\partial t} \vec{D} = \vec{j}\label{eq:12}\\
  \Div \vec{B} = 0\label{eq:13}
\end{gather}

\begin{bemerk}[Integrale Form der Maxwell'schen Gleichung]
  Mithilfe des Satz von Stokes (\autoref{satz:stokes}) kann man die
  \autoref{eq:7} auch mit Integralen schreiben:
  \begin{gather*}
    \int_{\partial S} \vec{E} \vec{dx}+ \frac{d}{dt}\int_{S}
       \vec{B}\vec{dS} = 0
  \end{gather*}

  \autoref{eq:8} Satz von Gauß (\autoref{satz:gauss})
  \begin{gather*}
    \int_{\partial \Omega} \sprod{\vec{D}}{\vec{n}} \vec{dS} =
       \int_{\Omega}\rho\,dx
  \end{gather*}
\end{bemerk}

\begin{bemerk}[Elektrostatik (Zeitunabhängigkeit, keine Ströme)]
  \autoref{eq:7} und \autoref{eq:8} wird zu
  \begin{gather}
    \rot \vec{E} = 0\label{eq:9}\\
    \Div \vec{D} = \rho(x)\label{eq:10}\\
    \vec{D}(x) = \epsilon_{0}\vec{E}(x)\label{eq:11}
  \end{gather}
  Aus \autoref{sec:8.1.2} wissen wir, dass wenn die Rotation 0
  ist (\autoref{eq:9}), wir ein konservatives Vektorfeld haben und damit ein Potential
  $u(x)$ existiert. $\vec{E}(x) = -\grad u(x)$. Mithilfe der
  Materialgleichung \autoref{eq:11} ergibt sich $-\grad u(x) =
  \frac{1}{\epsilon_{0}}\vec{D}(x)$. Mithilfe von \autoref{eq:10} ergibt
  sich eine partielle Differenzialgleichung ?ter \help{wieviel war das nochmal?} Ordnung $-\Delta u =
  \frac{1}{\epsilon_{0}} \rho(x)$ (\emph{Laplace-Poisson-Gleichung},
  \emph{Potentialgleichung})
\end{bemerk}

\begin{bemerk}[allgmeiner Fall der Maxwell'schen Gleichungen]
  ($\epsilon_{0}=\mu_{0}=1$) Dann ergibt sich aus
  \autoref{eq:7}--\autoref{eq:13}
  \begin{gather*}
    \vec{H} = \rot\vec{A}\\
    \vec{E} = -\grad u - \frac{\partial}{\partial u} \vec{A}\\
    \Div \vec{A} + \frac{\partial u}{\partial t} = 0\\
    \frac{\partial^{2}u}{\partial t^{2}} -\Delta u - \rho(x,t) \qquad
       \text{Wellengleichung im $\R^{3}$}\\
    \frac{\partial^{2}\vec{A}}{\partial t^{2}} - \Delta\vec{A} =
       \vec{j}(x,t)
  \end{gather*}
\end{bemerk}

% 22.11.05

\chapter{Partielle Differentialgleichungen}
\section{Die Laplace-Poisson-Gleichung}
\subsection{Einleitung}

Laplace-Gleichung:
\begin{gather*}
  \Delta u(x) = 0\quad \forall x\in\Omega\subseteq \R^{n}
\end{gather*}
Laplace-Poisson-Gleichung:
\begin{gather*}
  -\Delta u(x) = f(x)\quad\forall x\in\Omega\quad(f\ \text{gegeben})
\end{gather*}
Helmholtzgleichung:
\begin{gather*}
  \Delta u+k^{2} u=0\quad\text{auf}\ \Omega
\end{gather*}

Man betrachtet die folgenden Spezialfälle der Helmholtzgleichung gesondert:
\begin{gather*}
  -\Div\big(A(x) \grad u(x)\big)+\vec{b}(x)\grad u(x) + c(x)u(x) = f(x)\\
  \text{wobei:}\quad A(x) = \bigg(A_{ij}(x)\bigg), \vec{b}(x) =
     \begin{bmatrix}b_{1}\\\vdots\\b_{n}(x)\end{bmatrix}, c(x), f(x)
\end{gather*}
heißt \emph{elliptische Differentialgleichung 2.\,Ordnung}, falls die
Matrix $A(x)$ positiv definit auf $\Omega$ ist.

\emph{Randwertproblem} oder \emph{Dirichlet-Problem}:
\begin{gather*}
  -\Delta u(x) = f(x)\quad x\in\Omega
     u\big|_{\partial\Omega} = g
\end{gather*}

\emph{Neumann-Problem}:
\begin{gather*}
  -\Delta u(x) = f(x)\quad x\in\Omega
     \frac{\partial u}{\partial\vec{n}}\Big|_{\partial\Omega} = g
\end{gather*}

\subsection{Die Green'sche Darstellungsformel}

\begin{bemerk}
  $\Omega\subseteq\R^{n}$ zulässiges Gebiet, d.\,h. es gilt der Satz von
  Gauß (\autoref{satz:gauss})
  \begin{gather*}
    \int_{\Omega}\Div \vec{w}\,dx = \int_{\partial\Omega}
       \sprod{\vec{w}}{\vec{n}}\,dS
  \end{gather*}
\end{bemerk}

\begin{bemerk}
  \begin{gather*}
    C^{m}(\Omega) := \{u\colon \exists D^{\alpha}u, \abs{\alpha}\leq m,
       \text{stetig auf}\ \Omega\}
  \end{gather*}
  $\Omega$ offen und $m\in \N_{0}$
  \begin{gather*}
    C^{m}(\overline{\Omega}) := \{u\in C^{m}(\Omega)\colon \forall\alpha, \abs{\alpha}\leq m,
       \exists\ \text{stetige Fortsetzung auf dem Rand}\ \partial\Omega\}
  \end{gather*}
  dann: $D^{\alpha} u(x^{0}) :=\lim_{x\rightarrow x_{0}} D^{\alpha}u(x)$
  für $x^{0}\in\partial\Omega$
  \begin{gather*}
    \frac{\partial u}{\partial \vec{n}} (x^{0}) := \sprod{\nabla
       u(x^{0})}{\vec{n}},\quad \abs{\vec{n}}=1
  \end{gather*}
\end{bemerk}

\begin{bemerk}
  Sei $\Omega\subseteq\R^{n}$ zulässiges Gebiet. Nach 
  \autoref{satz:gauss} ist (vgl. \autoref{sec:8.2.3})
  \begin{enumerate}
   \item $u\in C^{2}(\overline{\Omega}), v\in C^{1}(\overline{\Omega})$ $\Rightarrow$
    \begin{gather}\label{eq:14}
      \int_{\Omega} v\,\Delta u\,dx = -\int_{\Omega} \sprod{\nabla
         u}{\nabla v}\,dx + \int_{\partial\Omega} v\frac{\partial
         u}{\partial\vec{n}}\,dS
    \end{gather}

    \begin{proof}
      \begin{gather*}
        \vec{w} = v\nabla u \Rightarrow \Div \vec{w} = \sprod{\nabla
           v}{\nabla u} + v \Delta u\\
        v\Delta u = \Div\vec{w} - \sprod{\nabla u}{\nabla v}
      \end{gather*}
    \end{proof}
   \item $u,v\in C^{2}(\overline{\Omega})$ $\Rightarrow$
    \begin{gather}\label{eq:15}
      \int_{\Omega} v\Delta u - u\Delta v\,dx = \int_{\partial\Omega}
         v\frac{\partial u}{\partial\vec{n}} - u\frac{\partial
         v}{\partial\vec{n}}\,dS
    \end{gather}
  \end{enumerate}
\end{bemerk}

\begin{defini}
  Sei wieder $\Omega\subseteq\R^{n}$ ein offenes Gebiet. Eine Funktion
  $u$ heißt \emph{harmonisch} auf $\Omega$ \gdwdef $u\in C^{2}(\Omega)$
  und $\Delta u(x)=0$ auf $\Omega$.
\end{defini}

\begin{bemerk}[Beispiele für harmonische Funktionen]
  \begin{gather*}
    u(x) = x^{2}_{i} - x^{2}_{j} \Rightarrow \Delta u=0\ \text{auf}\
       \R^{n}\\
    u(x) = x_{1}x_{2}x_{3} \Rightarrow \Delta u=0\ \text{auf}\
       \R^{3}
  \end{gather*}

  Harmonische Funktionen bilden einen Vektorraum. Jetzt: Alle
  harmonischen Funktionen der Form: $u(x) = v(\abs{x}), r=\abs{x}=
  (x^{2}_{1}+\ldots+x^{2}_{n})^{\nicefrac{1}{2}}$
\end{bemerk}

\begin{lemma}
  Für $n\geq2$ ist $u(x) =v(\abs{x})$ harmonisch auf $\R^{n}\setminus\{0\}$
  \gdw
  \begin{gather*}
    u(x) = \begin{cases}
             b\ln r+c&: n=2\\
             \frac{b}{r^{n-2}}+c&: n>2\\
           \end{cases}
  \end{gather*}
  wobei $b,c\in\C$.

  \begin{proof}
    \begin{align*}
      \partial_{j}u &= v'(r)\partial_{j} r, &\partial_{j} r &=
         \frac{\partial}{\partial x_{j}}(x^{2}_{1}
         +\ldots+x^{2}_{n})^{\nicefrac{1}{2}} = \frac{x_{j}}{r}\\
      &= v'(r) \frac{x_{j}}{r}\\
      \partial^{2}_{j} u &= \partial_{j}(v'(r)\frac{x_{j}}{r})\\
      &= v''(r) \frac{x^{2}_{j}}{r} + v'(r) \big(\frac{1}{r} -
         \frac{x^{2}_{j}}{r^{3}}\big)\\
      \Rightarrow \Delta u &= v''(r) + v'(r)\big(\frac{n}{r} -
         \frac{1}{r}\big)\\
      \Delta u &= v''(r) + \frac{n-1}{r} v'(r) \stackrel{!}{=} 0
    \end{align*}

    Wir setzen $v'=w$ und erhalten eine Differentialgleichung mit
    getrennten Variablen: $w'(r) + \frac{n+1}{r} w=0$. Für $n=2$ erhalten
    wir als Lösung $w=\frac{b}{r}$ und können $v$ als Stammfunktion von
    $w$ bestimmen: $v(r) = b\ln r +c$.

    Im Fall von $n\geq 2$ erhalten $w(r) = \frac{b'}{r^{n-1}}$ und $v(r)
    = \frac{b}{r^{n-2}} +c$.
  \end{proof}
\end{lemma}

\begin{defini}
  Für $x\neq y$ setzen wir:
  \begin{gather*}
    \Gamma(x,y) = \Gamma(\abs{x-y}) =
       \begin{cases}
         \frac{1}{2\pi}\ln \abs{x} &: n=2\\
         -((n-2) \abs{\omega_{n}})^{-1} \abs{x-y}^{2-n} &:n>2
       \end{cases}
  \end{gather*}
  \textit{Achtung: $\Gamma$ ist nicht die $\Gamma$-Funktion!} $\omega_{n}$
  bezeichnet die Oberfläche der Einheitskugel im $\R^{n}$; siehe
  \autoref{sec:1}

  $\Gamma$ heißt \emph{Fundamentallösung} der Laplace-Gleichung.
\end{defini}

\begin{bemerk}
  \begin{enumerate}
   \item $\Gamma(x,y)$ ist harmonisch auf $\R^{n}\setminus\{y\}$ (als
    Funktion von $x$)
   \item $\Gamma(x,y)\in C^{\infty}(\R^{n}\setminus\{y\})$
   \item $\frac{\partial}{\partial x_{j}}\Gamma(x,y)$ und
    $\frac{\partial}{\partial \vec{n}}\Gamma(x,y)$ sind harmonisch auf
    $C^{\infty}(\R^{n}\setminus\{y\})$
   \item Das Integral $\int_{K_{1}(y)}\Gamma(x,y)\,dx$ existiert als
    uneigentliches Integral
    \begin{gather*}
      \int_{K_{1}(y)}\Gamma(x,y)\,dx =
         \begin{cases}
           \int_{\abs{x}\leq1}\ln \abs{x}\,dx = 2\pi\int_{0}^{1} r\ln
           r\,dr < \infty &n=2\\
           \int_{\abs{x}\leq1}\frac{1}{\abs{x}^{n-2}}\,dx =
           \abs{\omega_{n}} \int_{0}^{1} \frac{1}{r^{n-2}} r^{n-1}\,dr <
           \infty &n>2
         \end{cases}
    \end{gather*}
  \end{enumerate}
\end{bemerk}

\begin{satz}[Greensche Darstellungsformel]\label{satz:912-9}
  Sei $\Omega\subseteq\R^{n}$ ein zulässiges Gebiet, $u\in
  C^{2}(\overline{\Omega})$, $\vec{n}(x)$ äußerer Normalenvektor an
  $x\in\partial\Omega$. Dann gilt für alle $y\in\Omega$
  \begin{gather}\label{eq:17}
    u(y) = \int_{\partial\Omega}u(x)\frac{\partial\Gamma}
       {\partial\vec{n}(x)}(x,y) - \Gamma(x,y) \frac{\partial
       u}{\partial\vec{n}}\, dS(x) + \int_{\Omega}\Gamma(x,y)\Delta
       u(x)\,dx
  \end{gather}

  \begin{proof}
    Da die Singularität (Problemstelle $y$) Probleme bereitet, legen wir
    eine Kugel $\overline{K_{\epsilon}(y)}\subset \Omega$ um $y$ (für
    hinreichend kleines $\epsilon$) und betrachten $\Omega\setminus
    \overline{K_{\epsilon}(y)}$. Dies ist ein zulässiges Gebiet, da wir
    den Rand $\partial\Omega$ um den Rand der Kugel erweitern und den
    Normalenvektor auf diesem Stück in Richtung $y$ zeigen lassen, und wir
    können damit den Satz von Gauß (\autoref{satz:gauss}) anwenden.

    Es gilt:
    \begin{gather*}
      \int_{\Omega} \Gamma(x,y)\Delta u(x)\,dx =
         \lim_{\epsilon\rightarrow0}
         \int_{\Omega\setminus\overline{K_{\epsilon}(y)}}
         \Gamma(x,y)\Delta u(x)\,dx
    \end{gather*}
    Wir wenden \autoref{eq:15} auf
    $\Omega\setminus\overline{K_{\epsilon}(y)}$ an ($\Delta\Gamma=0$
    $\Rightarrow$ zweiter Summand unter Integral entfällt) und erhalten
    \begin{align*}
      \int_{\Omega\setminus\overline{K_{\epsilon}(y)}} \Gamma(x,y) \Delta
         u(x)\,dx &= \int_{\partial\Omega} \Gamma(x,y)\frac{\partial
         u}{\partial\vec{n}}(x) -
         u(x)\frac{\partial\Gamma}{\partial\vec{n}}(x,y)\,dS(x)\\
      &\quad + \int_{\partial K_{\epsilon}(y)} \Gamma(x,y)\frac{\partial
         u}{\partial\vec{n}}(x) -
         u(x) \frac{\partial\Gamma}{\partial\vec{n}}(x,y)\,dS(x)
    \end{align*}
    Auf $\partial K_{\epsilon}(y)$ ist $\Gamma(x,y) = \Gamma(\abs{x-y}) =
    \Gamma(\epsilon)$ $\Rightarrow$
    \begin{align*}
      \abs[\Big]{\int_{\partial K_{\epsilon}(y)}
         \Gamma(x,y)\frac{\partial u}{\partial\vec{n}}(x)\,dS(x)} &\leq
         \Gamma(\epsilon) \sup_{x\in\Omega} \abs{\nabla n(x)}
         \epsilon^{n-1} \abs{\omega_{n}} \\
      &\leq \sup_{x\in\Omega}
         \abs{\nabla u(x)}
         \begin{cases}
           \epsilon \ln \epsilon& n=2\\
           \frac{1}{n-2}\epsilon & n>2
         \end{cases}\quad \xrightarrow{\epsilon\rightarrow0} 0
    \end{align*}

    % 23.11.05

    noch zu zeigen: ($y$ fest)
    \begin{gather*}
      -\int_{\partial K_{\epsilon}(y)} u(x) \frac{\partial\Gamma}
         {\partial\vec{n}(x)}(x,y)\,dS(x)
         \xrightarrow{\epsilon\rightarrow0} u(y)
    \end{gather*}
    $\vec{n}(x) = \frac{y-x}{\abs{x-y}}$ äußere Normale,
    $\frac{\partial\Gamma}{\partial\vec{n}(x)} = \sprod{\nabla_{x}
    \Gamma(x,y)}{\vec{n}(x)}$. Es gilt für $n>2$:
    \begin{gather*}
      \frac{\partial}{\partial x_{j}} (\abs{x-y}^{-n+2}) = (-n+2)
         \abs{x-y}^{-n+1} \frac{1}{2} \frac{1}{\abs{x-y}} 2(x_{j}-y_{j})
         = -(n-2) \frac{x_{j}-y_{j}}{\abs{x-y}^{n}}\\
      \Rightarrow \nabla_{x}\Gamma(x,y) = \frac{1}{\abs{\omega_{n}}}
         \frac{x-y}{\abs{x-y}^{n}}
    \end{gather*}

    Für $n=2$:
    \begin{gather*}
      \frac{\partial}{\partial x_{j}} (\ln\abs{x-y}) =
         \abs{x-y}^{-1} \frac{x_{j}-y_{j}}{\abs{x-y}}
         = \frac{x_{j}-y_{j}}{\abs{x-y}^{2}}\\
      \Rightarrow \nabla_{x}\Gamma(x,y) = \frac{1}{2\pi}
         \frac{x-y}{\abs{x-y}^{2}}
    \end{gather*}

    Zusammen ergibt sich für $n\geq 2$
    \begin{gather*}
      \frac{\partial\Gamma}{\partial\vec{n}(x)} =
         \frac{1}{\abs{\omega_{n}}} \frac{x-y}{\abs{x-y}^{n}}
         \frac{y-x}{\abs{x-y}}
         = -\frac{1}{\abs{\omega_{n}}} \frac{1}{\abs{x-y}^{n-1}}
         \Big(= -\frac{1}{\abs{\omega_{n}}} \frac{1}{\epsilon^{n-1}}
         \quad\text{auf}\ \partial K_{\epsilon}(y)\Big)\\
      \Rightarrow -\int_{\partial K_{\epsilon}(y)}
         u(x)\frac{\partial\Gamma}{\partial\vec{n}(x)}(x,y)\,dS(x) =
         \frac{1}{\abs{\omega_{n}}\epsilon^{n-1}} \int_{\partial
         K_{\epsilon}(y)} u(x)\,dS(x)
         = \frac{1}{\abs{\partial K_{\epsilon}(y)}} \int_{\partial
         K_{\epsilon}(y)} u(x)\,dS(x) \xrightarrow{\epsilon\rightarrow0}
         u(y)\\
      \intertext{denn}
      \abs[\Big]{u(y) - \frac{1}{\abs{\partial K_{\epsilon}(y)}}
         \int_{\partial K_{\epsilon}(y)} u(x)\,dS(x)} \leq
         \frac{1}{\abs{\partial K_{\epsilon}(y)}}
         \int_{\partial K_{\epsilon}(y)} \abs{\underbrace{u(y)-u(x)}
         _{\leq\delta}}\,dS(x) \leq\delta\qquad(\forall\delta)
    \end{gather*}
  \end{proof}
\end{satz}

\begin{folger}
  Für harmonische Funktionen $u$ auf $\Omega$ (d.\,h. $\Delta u=0$) gilt
  ($y\in\Omega$)
  \begin{gather*}
    u(y) = \int_{\partial\Omega}
       u(x)\frac{\partial\Gamma}{\partial\vec{n}}(x,y) -
       \Gamma(x,y)\frac{\partial u}{\partial\vec{n}}(x)\,dS
  \end{gather*}
\end{folger}

\begin{folger}\label{fol:1}
  Sei $\Omega$ ein zulässiges Gebiet und wir definieren ein zusätzliche
  komplexwertige Funktion $\Phi$ auf $\Omega\times\Omega$ mit $\Phi(x,y)
  \in C^{2}(\overline{\Omega})$ als Funktion von $x$ bei festem $y$.
  Zusätzlich soll $\Phi$ harmonisch sein, d.\,h. $\Delta_{x}\Phi(x,y) =
  0$ für alle $y\in\Omega$.

  Wir setzen $G(x,y) := \Gamma(x,y) = \Phi(x,y)$ für alle $y,x\in
  \overline{\Omega},x\neq y$.

  Dann gilt die Greensche Darstellungsformel mit $G$ anstelle von $\Gamma$
  \begin{gather}\label{eq:16}
    u(y) = \int_{\partial\Omega}
       u(x)\frac{\partial G}{\partial\vec{n}}(x,y) -
       G(x,y)\frac{\partial u}{\partial\vec{n}}(x)\,dS
       + \int_{\Omega} G(x,y)\Delta u(x)\,dx
  \end{gather}

  \begin{proof}
    folgt aus \autoref{eq:17} und \autoref{eq:15} mit $v(x) = \Phi(x,y)$
  \end{proof}
\end{folger}

\begin{bemerk}
  Wählen $\Phi$ in \autoref{fol:1}, so daß $G(x,y) = 0$ für $y\in\Omega$
  und $x\in\partial\Omega$. Für $\Delta u=0$ gilt:
  \begin{gather}\label{eq:18}
    u(y) = \int_{\partial\Omega} u(x)\frac{\partial G}{\partial\vec{n}(x)}
       (x,y)\,dS(x)
  \end{gather}
\end{bemerk}

\subsection{Die Green'sche Funktion für die Kugel und das Poisson-Integral}

\begin{defini}
  Sei $\Omega\subseteq\R^{n}$ zulässiges Gebiet und 
  $\Phi\colon\overline{\Omega}\times\overline{\Omega}\rightarrow\C$ mit
  $\Phi(x,y)\in C^{2}(\overline{\Omega})$ für jedes $y\in\Omega$ (als
  Funktion von $x$) und $\Phi(x,y)$ sei harmonisch auf $\Omega$ für jedes
  $y\in\Omega$ (als Funktion von $x$). Dann heißt $G(x,y) :=
  \Gamma(x,y) + \Phi(x,y)$ \emph{Green'sche Funktion}  für $\Omega$
  \gdwdef $G(x,y)=0$ für alle $y\in\Omega$ und  $x\in\partial\Omega$.
\end{defini}

\begin{figure}
  \center
  \ifpdf\input{Spiegelung-Kugel.pdf_t}\else\input{Spiegelung-Kugel.eps_t}\fi
  \caption{\label{fig:3}Spiegelung an Einheitskugel}
\end{figure}

\begin{lemma}[Green'sche Funktion für die Einheitskugel im $\R^{n}$]
  Es sei $K=\{y\colon \abs{y}< 1\}$. Es sei $\overline{y}:=
  \frac{y}{\abs{y}^{2}}$ für $y\neq 0$. (siehe \autoref{fig:3})

  Dann gilt:
  \begin{gather*}
    G(x,y) = \begin{cases}
               \Gamma(\abs{x-y}) - \Gamma(\abs{y}\abs{x-\overline{y}})&:
               y\neq 0\\
               \Gamma(\abs{x})-\Gamma(1)&: y=0
             \end{cases}
  \end{gather*}
  ist die \emph{Green'sche Funktion} für die Einheitskugel.

  \begin{proof}
    \begin{gather*}
      \Phi(x,y) = -\begin{cases}
                     \Gamma(\abs{y}\abs{x-\overline{y}})&:y\neq 0\\
                     \Gamma(1)&:y=0
                   \end{cases}
    \end{gather*}
    ist harmonisch auf $K$ für alle $y\in K$. Überprüfen, ob
    Randbedingung erfüllt: Wenn $\abs{x}=1$ und $y=0$, dann ist $G(x,y) =
    G(x,0) = \Gamma(1)-\Gamma(1) = 0$. $0<\abs{y}<1$ $\Rightarrow$
    $(\abs{y}\abs{x-\overline{y}})^{2} = \abs{y}^{2}(x-\overline{y})
    (x-\overline{y}) = \abs{y}^{2}(\abs{x}^{2} - 2x\overline{y} +
    \abs{y}^{2}) =\abs{y}^{2} ( \underbrace{\abs{x^{2}}}_{=1} -
    2\frac{xy}{\abs{y}^{2}} + \frac{1}{\abs{y}^{2}}) = \abs{y}^{2} - 2xy
    + \abs{x}^{2} = \abs{x-y}^{2}$ (drandenken: wir haben Skalarprodukte)
    $\Rightarrow$ $G(x,y) = 0$
  \end{proof}
\end{lemma}

\begin{lemma}
\label{913-3}
  Sei $u$ eine zweimal stetig fortsetzbare Funktion auf dem
  Rand der Einheitskugeln ($u\in C^{2}(\overline{K})$) und harmonisch auf
  $K$. Dann gilt:
  \begin{gather*}
    u(y) = \frac{1-\abs{y}^{2}}{\abs{\omega_{n}}} \int_{\partial K}
       \frac{u(x)}{\abs{x-y}^{n}}dS(x)\qquad y\in K
  \end{gather*}

  \begin{proof}
    $G$ Green'sche Funktion für $K$ $\Rightarrow$ Es gilt \autoref{eq:18}

    Es gilt auf $\partial K$: $\frac{\partial G}{\partial\vec{n}(x)}(x,y)
    = \sprod{\nabla_{x} G(x,y)}{x}$, $\vec{n}(x) = x$, $\nabla_{x} G(x,y)
    = \nabla_{x}(\Gamma(\abs{x-y}) -
    \nabla_{x}(\Gamma(\abs{y}\abs{x-\overline{y}})) =
    \nabla_{x}(\Gamma(\abs{x-y})) - \abs{y}^{-(n-2)}
    \nabla_{x}(\Gamma(\abs{x-\overline{y}})) =^{\text{Beweis von Satz 1}}
    \frac{1}{\abs{\omega_{n}}}\Big(\frac{x-y}{\abs{x-y}^{n}} -
    \abs{y}^{-n+2} \frac{x-\overline{y}}{\abs{x-\overline{y}}^{n}}\Big) =
    \frac{1}{\abs{\omega_{n}}}\Big(\frac{x-y}{\abs{x-y}^{n}} -
    \frac{(x-\overline{y})\abs{y}^{2}}{(\abs{y}\abs{x-\overline{y}})^{n}}
    \Big) = \frac{1}{\abs{\omega_{n}}} \frac{1}{\abs{x-y}^{n}}(x-y
    -x\abs{y}^{2} + y) =
    -\frac{x(1-\abs{y}^{2})}{\abs{\omega_{n}}\abs{x-y}^{n}}$

    Für den Rand der Kugel ($\abs{x}=1$) ist
    \begin{gather*}
      \frac{\partial G}{\partial \vec{n}(x)}(x,y) =
         \frac{1-\abs{y}^{2}}{\abs{\omega_{n}}\abs{x-y}^{n}}
    \end{gather*}
  \end{proof}
\end{lemma}

\begin{satz}[Poisson'sche Darstellungsformel, Lösung des
  Dirichlet-Problems für Einheitskugel im $\R^{n}$]
  \index{Dirichlet-Problem}

  Es sei $\phi\colon\partial K\rightarrow\C$ stetig und es sei
  \begin{gather*}
    u(y) = \frac{1-\abs{y}^{2}}{\abs{\omega_{n}}} \int_{\partial K}
       \frac{\phi(x)}{\abs{x-y}^{n}}dS(x) \makebox[0pt][l]{$\qquad\forall
       y\in K$}
  \end{gather*}
  Dann gilt:
  \begin{enumerate}
   \item $u$ ist harmonisch auf $K$: $\Delta u(y) =0$
   \item $\forall y^{0}\in\partial K\colon \lim_{y\rightarrow y^{0}} u(y) =
    \phi(y^{0})$ Das heißt $u$ lässt sich stetig auf dem Rand als $\phi$
    fortsetzen.
  \end{enumerate}

  \begin{proof}
    \begin{enumerate}
    \item $\phi(x)$ in \autoref{eq:18} statt $u(x)$ Laplace-Operator unter das
    Integral, für $\phi(x)$ ohne Wirkung, da Laplace nach $y$, Anwendung
    auf $G$, geht weil $G$ harmonisch $\Rightarrow$ alles harmonisch
    $\rightarrow$ Weltfrieden :)
    \begin{align*}
      \Delta u(y) &= \Delta_y \int_{\partial K} \frac{1-\lvert
        y\rvert^2}{\lvert\omega\rvert \lvert x-y\rvert^n} \phi(x)
      dS(x)\\
      &= \int_{\partial K} \Delta_y \Bigg( \underbrace{\frac{1-\lvert
          y\rvert^2}{\lvert\omega\rvert \lvert
          x-y\rvert^n}}_{\frac{\partial}{\partial \vec{n}(x)}
        G(x,y)}\Bigg) \phi(x) dS(x)
    \end{align*}
    Aus der Tatsache unterhalb der Klammer folgt nun wegen der
    Greenschen Funktion: $\frac{\partial}{\partial \vec{n}} \Delta_y
      G(x,y) =0$.
    \item Für $u(x)=1 \,(\forall x\in K)$ folgt aus \autoref{913-3}:
      \begin{align*}
        1 &= \int_{\partial K} \frac{1-\lvert
          y\rvert^2}{\lvert\omega_n \rvert \lvert x-y\rvert^n} dS(x)\\
        &\Rightarrow \phi(y^0)-1 = \int_{\partial K} \frac{(1- \lvert
          y\rvert^2) \phi(y^0)}{\lvert\omega_n\rvert \lvert
          x-y\rvert^n} dS(x)\\
        &\Rightarrow \lvert u(y)-\phi(y^0)\rvert = \Bigg\lvert
        \int_{\partial K} \phi(x)-\phi(y^0) \frac{1-\lvert y\rvert^2}{
        \lvert\omega_n\rvert \lvert x-y\rvert^n} dS(x)\Bigg\rvert
      \end{align*}
      Wir wählen ein $S_1$ so, dass $\max_{x\in S_1} \lvert \phi(x) -
      \phi(y^0)\rvert \leq\epsilon$ ist. Dies funktioniert, da die
      $\phi$ stetig in $y^0$ sind. Weiterhin wählen wir ein $\rho$ so,
      dass $1-\lvert y\rvert^2\leq\epsilon$ für $y\in K\rho(y^0) \cap
      K=:A$ und $\lvert y-x\rvert\geq c>0$ für $y\in A$ und $x\in
      S_2$. Dabei ist $c$ eine Konstante und es gilt für $y\in A$:
      \begin{align*}
        \lvert u(y)-\phi(y^0)\rvert &\leq \int_{S_1} \lvert
        \underbrace{\phi(x) - \phi(y^0)}_{\leq\epsilon}\rvert
        \underbrace{\frac{1-\lvert y\rvert^2}{\lvert\omega\vert \lvert
            x-y\rvert^n}}_{=1} dS(x) \\
        &\qquad + \int_{S_2} \lvert
        \underbrace{\phi(x)-\phi(y^0)}_{\leq 2\max_{\partial K}
          \lvert\phi(x) \rvert}\rvert \frac{1-\lvert y\rvert^2}{\lvert\omega
          \rvert \lvert x-y\rvert^n} dS(x)\\
        &\leq \epsilon+2\max_{\partial K} \lvert\phi(x) \rvert
        \frac{1}{\lvert \omega\rvert}\epsilon \frac{1}{c^n}
        \underbrace{\int_{S_2} 1dS(x)}_{\leq\lvert\omega_n\rvert}\\
        &\leq \epsilon \underbrace{(1+2\max_{\partial K} \lvert\phi(x) \rvert
          \frac{1}{\lvert \omega\rvert} \frac{1}{c^n}
          \lvert\omega_n\rvert)}_{=c} \leq \epsilon c\\
        &\Rightarrow \lim_{y\rightarrow y^0} u(y) = \phi(y^0)
      \end{align*}
    \end{enumerate}
  \end{proof}
\end{satz}

\begin{folger}
  \[\phi\colon\partial K_R \rightarrow \C \Rightarrow u(y)=
  \frac{R^2-\lvert y\rvert^2}{\lvert\omega_n\rvert R} \int_{\partial
    K_R} \frac{\phi(x)}{\lvert x-y\rvert^n} dS(x)\]
  ist die Lösung von $\Delta u=0$ auf $K_R$ und $u=\phi$ auf $\partial
  K_R$. Denn sei $\Delta v=0$ mit $v(y)=\phi(Ry)=\psi(y)$ für $\lvert
  y\rvert =1$. Wegen der Kettenregel in der Ableitung und $u(y)=
  v(\frac{y}{R})$ folgt, dass $\Delta u=0$:
  \begin{align*}
    \lvert y\rvert=R &\Rightarrow u(y)=v(\frac{y}{R})
    =\phi(R\frac{y}{R})=\phi(y)\\
    &\Rightarrow u(y)=v(\frac{y}{R})= \frac{R^2-\lvert
      y\rvert^2}{\lvert \omega_n\rvert R^2} \int_{\partial K}
    \frac{\phi(Rx)}{\lvert x-\frac{y}{R}\rvert^n} dS(x)\\
    &= \frac{R^2-\lvert y\rvert^2}{\lvert \omega_n\rvert R^2}
    \underbrace{\int_{\partial K} \frac{\phi(Rx)}{\lvert Rx-y\rvert^n}
      R^{n-1}dS(x)}_{\int_{\partial K_R} \frac{\phi(x)}{\lvert
        x-y\rvert^n} dS(x)}
  \end{align*}
\end{folger}

\begin{satz}
  Sei $\Omega\subset\R^n$ offen, $u\in C^2(\Omega)$ harmonisch auf
  $\Omega$. Dann gilt, dass $u$ beliebig oft differenzierbar ist
  ($u\in C^\infty(\Omega)$).
\todo{Beweis auf Korrektheit prüfen}
  \begin{proof}
    Wir betrachten $v(z):=u(y+z)$. Diese ist harmonisch in $K_r(0)$,
    wenn $v$ beliebig oft differenzierbar ist. Weiter ist $v$ stetig
    auf $u\in C^2(K_r(0))$. Aus \autoref{913-3} folgt: $v(z)=
    \frac{r^2- \lvert z \rvert}{\lvert \omega_n\rvert r}
    \int_{\partial K_r} \frac{v(x)}{\lvert x-z \rvert^n}dS(x)
    \frac{1}{\lvert x-y\rvert^n}, \lvert z\rvert^2\in
    C^\infty(K_r(x)) \Rightarrow v\in C^\infty(K_r(0)) \Rightarrow
    u\in C^\infty(K_r(y))$.
  \end{proof}
\end{satz}

\begin{bemerk}
  Die Existenz der Greenschen Funktionen für allgemeine $\Omega$ ist
  schwierig und hängt von den Eigenschaften des Randes $\partial
  \Omega$ ab.
\end{bemerk}


\subsection{Mittelwerteigenschaften}

\begin{defini}
  Sei $\Omega\subset\R^n$ offen und $u\in C^2(\Omega)$.
  \begin{enumerate}
  \item $u$ heißt genau dann
    \emph{subharmonisch}, wenn gilt: $\Delta
    u(x)\geq 0$ auf $\Omega$.
  \item $u$ heißt genau dann
    \emph{superharmonisch}, wenn gilt: $\Delta
    u(x) \leq 0$ auf $\Omega$.
  \end{enumerate}
\end{defini}

\begin{satz}
  \label{satz:914-2}
  Sei $\Omega\subset\R^n$ offen, $u\in C^2(\Omega)$ mit $\Delta u\geq
  0$ auf $\Omega$.\footnote{Dieser Satz gilt gleichermaßen für die
    Beziehung $\leq$ und $=$.} Dann gilt für jede Kugel $K_R(y)$ mit
  $\overline{K_R(y)} <\Omega$:
  \begin{enumerate}
  \item \emph{sphärische Mittelwerteigenschaft}:
    \[u(y)\leq \frac{1}{\lvert \partial K_R \rvert} \int_{\partial
      K_R} u(x)dS(x)\]
  \item \emph{Kugelmittelwerteigenschaft}:
    \[u(y)\leq \frac{1}{\lvert K_R\rvert} \int_{K_R} u(x) d(x)\]
    Wobei hier gilt, dass $\lvert K_R\rvert =\frac{R^n \lvert \omega_n
      \rvert}{n}$ das Volumen der Kugel ist und $\lvert \partial K_R
    \rvert =R^{n-1} \lvert \omega_n\rvert$ die Oberfläche der Kugel.
    \begin{proof}
      Für den Beweis ist es ausreichend, $\Delta u\geq 0$ zu
      betrachten. Es sei nochmals in Erinnerung gerufen, dass aus der
      Tatsache, das $\Omega$ ein zulässiges Gebiet ist und $u\in
      C^2(\overline{\Omega_0})$ ist, folgt:
      \begin{gather}
        \label{gl:914-1}
        \int_{\Omega_0} \Delta udx= \int_{\partial \Omega_0}
        \frac{\partial u}{\partial \vec{n}} dS
      \end{gather}
      \begin{enumerate}[1. Schr{i}tt]
      \item Sei $\overline{K_R(y)}<\Omega$. Aus \autoref{gl:914-1}
        folgt für $\Delta u>0\colon \int_{\partial \overline{K_R(y)}}
        \frac{\partial u}{\partial \vec{n}} dS>0$. Wir setzen $v(x)=
        u(x+y)$ und es folgt, $\int_{K_r(0)} \frac{\partial
          v}{\partial \vec{n}} (x)dS>0$ für $0<r<R$. Weiter gilt für
        das $r$:
        \begin{align*}
          \int_{\partial K_r(0)} \frac{\partial v}{\partial \vec{n}}
          dS &= \int_{\lvert x\rvert=r} \nabla
          v(x)\underbrace{\vec{n}}_{\frac{x}{r}} dS = r^{n-1}
          \int_{\lvert x \rvert=r} \underbrace{\nabla
            v(rx)x}_{\frac{d}{dr} (v(rx))} dS\\
          &= r^{n-1} \frac{d}{dr} \int_{\lvert x\rvert=r} v(rx)dS=
          r^{n-1} \frac{d}{dr} \Bigg(\frac{1}{r^{n-1}} \int_{\lvert
            x\rvert =r} v(x)dS\Bigg)>0\\
          &\Rightarrow \frac{1}{\lvert\omega_n\rvert r^{n-1}}
          \int_{\lvert x\rvert =r} v(x)dS \text{ ist streng monoton
            wachsend auf } (0,R)\\
          &\Rightarrow v(0)=\lim_{r\rightarrow 0} \frac{1}{\lvert
            \omega_n \rvert r^{n-1}} \int_{\lvert x\rvert=r} v(x)dS<
          \frac{1}{\lvert \omega_n\rvert R^{n-1}} \int_{\lvert
            x\rvert=R} v(x)dS\\
          &\Rightarrow u(y) < \frac{1}{\lvert \omega_n\rvert r^{n-1}}
          \int_{\lvert x\rvert=R} u(y)dS=\frac{1}{\lvert\partial
            K_R\rvert} \int_{K_R(u)} u(x)dS(x)
        \end{align*}
      \item Aus erstens folgt zweitens. Denn für $0<r<R$ folgt:
        \begin{align*}
          u(y)&\leq \frac{1}{\lvert\omega_n \rvert r^{n-1}}
          \int_{\lvert x-y\rvert=r} u(x)dS\\
          &\Rightarrow u(y) \lvert \omega_n\rvert r^{n-1} \leq
          \int_{\lvert x-y\rvert=r} u(x)dS\\
          &\Rightarrow u(y) \underbrace{\lvert \omega_n \rvert
            \frac{R^n}{n}}_{\lvert K_R\rvert} \leq \int_0^R
          \int_{\lvert x-y\rvert=r} u(x)dSdr=\int_{K_r(y)} u(x)dx
        \end{align*}
      \end{enumerate}
    \end{proof}
  \end{enumerate}
\end{satz}

\begin{folger}
  Sei $\Omega\subset\R^n$ offen und $u\in C^2(\Omega)$ erfülle für
  alle $\overline{K_R(y)}\subset\Omega$ die sphärische
  Mittelwerteigenschaft. Dann ist $\Delta u(y)\geq 0$ auf $\Omega$,
  d.\,h. subharmonisch (Analog gilt dies auch für $\geq$
  bzw. $=$.). Insbesondere ist $u$ auf $\Omega$ genau dann harmonisch,
  wenn gilt, $u(y)=\frac{1}{\lvert \partial K_R \rvert} \int_{\partial
    K_R (y)} u(x)dS$ für alle $\overline{K_R(y)} \subset\Omega$.
  \begin{proof}
    Wir nehmen an, die Beziehung $\Delta u(y)\geq 0$ gelte
    nicht. Damit folgt, dass ein $y\in\Omega$ existiert für das
    $\Delta u(y)<0$ gilt. Weiterhin folgt, es existiert ein $R$ mit
    $\overline{K_R (y)}\subset\Omega$ und $\Delta u<0$ auf
    $\overline{K_R (y)}$. Dies gilt wegen der Stetigkeit von $\Delta
    u$. Aus \autoref{satz:914-2} folgt damit $u(y)>
    \frac{1}{\lvert \partial K_R\rvert \int_{\partial K_R(y)}}
      u(x)dS$. Dies ist jedoch ein Widerspruch zur Voraussetzung.
  \end{proof}
\end{folger}

\begin{bemerk}
  Sei $u\in C^2(\Omega)$ und für alle $\overline{K_R(y)}
  \subset\Omega$ gelte $u(y)= \frac{1}{\lvert K_R\rvert} \int_{K_R(y)}
  u(x)dx$. Dann gilt für alle $\overline{K_R(y)}\subset\Omega$ die
  sphärische Mittelwerteigenschaft.
  \begin{proof}
    siehe Übung \todo{Beweis hinzufügen}
  \end{proof}
\end{bemerk}

\begin{folger}
  Sei $u\in C^2(\Omega)$. Dann ist $u$ genau dann harmonisch auf
  $\Omega$, wenn für alle $\overline{K_R(y)} \subset\Omega\colon u(y)=
  \frac{1}{\lvert K_R\rvert} \int_{K_R(y)} u(x)dx$ gilt.
\end{folger}

\subsection{Maximum- und Minimumprinzipien}

\begin{satz}
  Sei $\Omega\subset\R^n$ ein offenes und zusammenhängendes Gebiet.
  \begin{enumerate}
  \item Sei $u\in C^2(\Omega)$ mit $\Delta u\geq 0$ auf
    $\Omega$. Ferner existiere $y^0\in\Omega$ mit $u(y^0)=
    \sup_{y\in\Omega} u(y)$. Dann ist $u$ konstant.
  \item Sei $u\in C^2(\Omega)$ mit $\Delta u\leq 0$ auf
    $\Omega$. Ferner existiere $y^0\in\Omega$ mit $u(y^0)=
    \inf_{y\in\Omega} u(y)$. Dann ist $u$ konstant.
  \end{enumerate}
  \begin{proof}
    Es ist zu zeigen, dass aus dem ersten Punkt der zweite folgt. Denn
    man braucht nur $-u$ statt $u$ zu betrachten.

    Sei $y^0\in\Omega, u(y^0)=\sup_{\Omega} u=:M, \overline{K_r (y^0)}
    \subset\Omega$. Nach \autoref{satz:914-2} gilt:
    \begin{align*}
      u(y^0) &\leq \frac{1}{\lvert K_r \rvert} \int_{K_r(y)} u(x)dx\\
      &\Rightarrow \forall y\in K_r(y^0)\colon 0= u(y^0)-M\leq
      \frac{1}{\lvert K_r\rvert} \int_{K_r(y^0)} u(x)dx-
      \frac{1}{\lvert K_r\rvert} \int_{K_r(y^0)} Mdx\\
      &= \frac{1}{\lvert K_r \rvert} \int_{K_r(y^0)}
      (\underbrace{u(x)-M}_{\leq 0})dx=0\\
      &\Rightarrow \int_{K_r(y^0)} (u(x)-M)dx=0
    \end{align*}
    Wegen der Stetigkeit gilt für alle $x$ aus $K_r(y^0)$, dass
    $u(x)=M$ und somit konstant ist.

    Sei nun $y\in\Omega$ und $\Gamma$ ein stetiger Polygonzug von
    $y^0$ nach $y$. Dieser existiert immer, da $\Omega$ ein
    zusammenhängendes Gebiet ist und es existiert auch ein
    $d=\text{dist}(\Gamma, \partial \Omega)>0$.  Denn
    $\Gamma\subset\Omega$ und $\Gamma$ sind kompakt. Außerdem ist
    $\Omega$ offen. Somit existieren aber endlich viele Kugeln
    $K_r(y^j)$ mit $r<d, y^j\in\Gamma, y^j\in
    \overline{K_r(y^{j-1})}$ und $\bigcup_j
    K_r(y^j)\supset\Gamma$. Durch die iterative Anwendung des obigen
    Arguments erhält man dann den Schluss $u(y)=u(y^0)=M$.
  \end{proof}
\end{satz}

\begin{folger}
\label{folg:915-3}
  Sei $\Omega\subset\R^n$ beschränkt und $u\in\ C^2(\Omega) \wedge
  C^2(\overline{\Omega})$. Dann folgt:
  \begin{itemize}
  \item $u(x)\leq \max_{\partial \Omega} u$ für alle $x\in\Omega$,
    falls $\Delta u\geq 0$ auf $\Omega$
  \item $u(x)\geq \min_{\partial \Omega} u$ für alle $x\in\Omega$,
    falls $\Delta u\leq 0$ auf $\Omega$
  \item $\min_{\partial \Omega} u\leq u(x)\leq \max_{\partial \Omega}
    u$ auf $\Omega$, falls $\Delta u =0$
  \end{itemize}
\end{folger}

\begin{folger}
  Sei $\Omega\subset\R^n$ ein (nicht notwendigerweise beschränktes)
  Gebiet und $u\in C^2 (\Omega)\wedge C^2(\overline{\Omega})$. Dann
  folgt für $\Delta u=0$ auf $\Omega$, dass $\inf_{\partial \Omega}
  u\leq u(x)\leq \sup_{\partial \Omega} u$.
\end{folger}

\begin{satz}[Satz von Liouville]
  Sei $u\in C^2(\R^n)$ beschränkt und harmonisch auf $\R^n$. Dann ist
  $u$ konstant.
  \begin{proof}
    siehe Übung \todo{Beweis einfügen}
  \end{proof}
\end{satz}

\begin{satz}
  Sei $\Omega\subset\R^n$ ein Gebiet, $\partial \Omega\neq \emptyset,
  f\in C(\Omega)$ und $u,v\in C^2(\Omega)\wedge C(\overline{\Omega})$
  Lösungen der Laplace-Poissongleichung $-\Delta u=f$ auf $\Omega$.
  \begin{enumerate}
  \item $\forall y\in\partial\Omega\colon u(y)\leq v(y) \Rightarrow \forall
    x\in \Omega\colon u(x)\leq v(x)$
  \item $\forall y\in\partial\Omega\colon u(y)=v(y) \Rightarrow \forall
    x\in \Omega\colon u(x)=v(x)$
  \end{enumerate}
  \begin{proof}
    \begin{enumerate}
    \item Wir setzen $w(x):=v(x)-u(x) \Rightarrow \Delta w= \Delta(u
      -v)=0$ auf $\Omega$. Da $y\in\partial\Omega$ folgt, dass
      $w(y)\geq 0$ und es folgt weiter, dass das Infimum über den Rand
      von $\Omega$ existiert und größer als Null ist. Wegen der
      \autoref{folg:915-3} gilt für alle $x\in\Omega\colon w(x)\geq
      \inf_{\partial \Omega} w\geq 0$.
    \item Wenn $u(y)=v(y)\Rightarrow \inf_{\partial \Omega} w=0 \leq
      u(x)\leq \sup_{\partial \Omega} w\Rightarrow w(x)=0$
    \end{enumerate}
  \end{proof}
\end{satz}

\begin{bemerk}
  Sei $-\Delta u=f$ mit $f\in C(\Omega)$ und $u|_{\partial\Omega}=g$
  mit $g\in C(\partial\Omega)$. Dann folgt, dass das Randwertproblem
  (Dirichletproblem) höchstens eine Lösung besitzt.
\end{bemerk}

\begin{bemerk}
  Das Randwertproblem ist nicht immer lösbar. Sei beispielsweise
  $\Delta u=0$ auf $K_1(0)\setminus\{0\}$ und $u(y)=0$ für $\lvert
  y\rvert=1$ sowie $u(0)=1$ die Randbedingungen. Dann ist das in
  unserem Sinne nicht lösbar.
\end{bemerk}

\begin{folger}[Stabilität, stetige Abbildung von Randwerten]
  Es seien $u,v\in C^2(\Omega)\wedge C(\overline{\Omega})$ Lösungen
  von $-\Delta u=f$ auf $\Omega$ mit $u|_{\partial\Omega}=\phi$ und
  $v|_{\partial\Omega} =\psi$. Es gelte $\sup_{y\in\partial\Omega}
  \lvert \phi(y)-\psi(y)\rvert \leq\epsilon \Rightarrow \forall x\in
  \Omega\colon \lvert u(x)-v(x)\rvert\leq\epsilon$.
  \begin{proof}
    Sei $\Delta(u-v)=0$ auf $\Omega$ und
    $(u-v)(y)=\phi(y)-\psi(y)$. Aus der \autoref{folg:915-3} kann man
    schliessen, dass $-\epsilon\leq \inf_{\partial\Omega} (u(y)-v(y))
    \leq u(x)-v(x)\leq \sup_{\partial \Omega} (u(x)-v(x))\leq\epsilon
    \Rightarrow \lvert u(x)-v(x)\rvert \leq\epsilon$ für $x\in\Omega$.
  \end{proof}
\end{folger}

% 6.12.05

\subsection{Das Newton-Potential}

\begin{bemerk}
  Ziel dieses Abschnittes ist es die folgende Gleichung für ein gegebenes
  $f$ zu lösen.
  \begin{gather*}
    -\Delta u=f\ \text{auf}\ \Omega\subseteq\R^{n}
  \end{gather*}

  Annahme: $u$ ist eine zweimal stetig differenzierbare Funktion mit
  kompaktem Träger ($u\in C^{2}(\Omega), \supp u\subset\Omega$ kompakt).
  Die Greensche Formel (\autoref{satz:912-9}) liefert uns
  \begin{gather}\label{eq:19}
    u(x) = \int_{\Omega} \Gamma(x,y)\Delta u(y)\,dy
  \end{gather}
  Die Vermutung ist, dass die Lösung von $-\Delta u=f$ sich so darstellen
  lässt
  \begin{gather*}
    u(x) = \int_{\Omega}\Gamma(x,y) f(y)\,dy
  \end{gather*}
\end{bemerk}

\begin{defini}
  $f\in C(\overline{\Omega}), \Omega\subseteq\R^{n}$ zulässiges Gebiet im
  $\R^{n}$ definieren wir die folgende Funktion, die man als
  \emph{Newton-Potential} bezeichnet.
  \begin{gather*}
    u(x) = \int_{\Omega} \Gamma(\abs{x-y}) f(y)\,dy
  \end{gather*}
  Für y$\rightarrow$ x geht $\Gamma$ gegen unendlich $\rightarrow$
  Singularität $\rightarrow$ uneigentliches Integral, aber es geht, da
  die Singalarität schwach ist und wir können darüber integrieren. Das
  Integral existiert also für alle $x\in \R^{n}$.

  Insbesondere sind
  \begin{gather*}
    u(x) = \frac{1}{2\pi} \int_{\Omega} f(y)\ln\abs{x-y}\,dy\quad, n=2\\
    u(x) = -\frac{1}{4\pi} \int_{\Omega} \frac{f(y)}{\abs{x-y}}\,dy\quad,
       n=3\\
  \end{gather*}
\end{defini}

\begin{lemma}
  Wenn $f$ eine stetig differenzierbare Funktion ist und $u$ das
  Newton-Potential, dann können wir folgendes beweisen:
  \begin{enumerate}
   \item $u\in C^{1}(\R^{n})$
   \item $\frac{\partial u}{\partial x_{j}}(x) =
    \int_{\Omega}\frac{\partial}{\partial x_{j}}\Gamma(\abs{x-y}) f(y)\,dy$
   \item für $n\geq3$ ist $\lim_{\abs{x}\rightarrow0} u(x) = 0$
  \end{enumerate}

  \begin{proof}
    Es gilt $\abs[\bigg]{\frac{\partial}{\partial
    x_{j}}\Gamma(\abs{x-y})} \leq \frac{1}{\abs{\omega_{n}}}
    \frac{1}{\abs{x-y}^{n-1}}$. Daraus folgt, dass die Singularität
    schwach ist und wir darüber integrieren können. Es existiert also das
    Integral $\int_{\Omega} \frac{\partial}{\partial x_{j}}
    \Gamma(\abs{x-y})f(y)\,dy$ für alle $x\in\R^{n}$ (als uneigentliches
    Integral), falls $x\in\overline{\Omega}$.

    \begin{figure}
      \center
      \ifpdf\input{eta.pdf_t}\else\input{eta.eps_t}\fi
      \caption{\label{fig:4} \todo{Text fürs Bild}}
    \end{figure}
    Wir wählen uns eine Hilfsfunktion $\eta(t)$, die im Bereich $[0,1]$
    beliebig oft differenzierbar ist ($\in C^{\infty}$) und auf
    $(-\infty,0]$ $\eta(t)=0$ und $\eta(t)=1$ auf $[2,\infty)$. Siehe
    \autoref{fig:4}

    Wir betrachten jetzt $\eta\big(\frac{\abs{x-y}}{\epsilon}\big)$.
    \todo{nettes Bildchen davon malen}.

    $\eta$ ist eine \emph{Abschneidefunktion}.

    Es sei für $\epsilon>0$
    \begin{gather*}
      u_{\epsilon}(x) = \int_{\Omega}\Gamma(\abs{x-y})
         \eta\bigg(\frac{\abs{x-y}}{\epsilon}\bigg)f(y)\,dy\\
      v_{j}(x) := \int_{\Omega} \frac{\partial \Gamma}{\partial x_{j}}
         \big(\abs{x-y}\big)f(y)\,dy
    \end{gather*}
    $u_{\epsilon}(x)$ ist $\in C^{1}(\R^{n})$ und $\frac{\partial
    u_{\epsilon}}{\partial x_{j}} = \int_{\Omega}
    \frac{\partial}{\partial x_{j}} \Big(\Gamma(\abs{x-y})
    \eta(\frac{\abs{x-y}}{\epsilon}) \Big)f(y)\,dy$

    Es gilt:
    \begin{align*}
      \abs{u_{\epsilon}(x) - u(x)} &\leq \int_{\Omega}
         \abs{\Gamma(\abs{x-y})} \abs{\eta(\frac{\abs{x-y}}{\epsilon})-1}
         \underbrace{\abs{f(x)}}_{\leq c}\,dy\\
      &= c \int_{\abs{x-y}\leq2\epsilon} \abs{\Gamma(\abs{x-y})}\,dy \leq
         c \begin{cases}\epsilon^{2}& n>2\\\epsilon^{2} \abs{1+\ln
             2\epsilon}& n=2
           \end{cases} \xrightarrow{\epsilon\rightarrow0} 0\\
      \abs{v_{j}(x)-\frac{\partial u_{\epsilon}}{\partial x_{j}}(x)} &\leq
         \int_{\Omega} \abs{\frac{\partial}{\partial x_{j}}
         \big(\Gamma(\abs{x-y})\,
         (1-\eta(\frac{\abs{x-y}}{\epsilon}))\big)} \abs{f(y)}\,dy\\
      &\leq \int_{\abs{x-y}\leq2\epsilon} \abs{\frac{\partial}{\partial
         x_{j}} \Gamma(\abs{x-y})} + \abs{\Gamma(\abs{x-y})}
         \frac{1}{\epsilon} c\,dy\\
      &\leq c\begin{cases}\epsilon& n>2\\\epsilon(1+\abs{\ln 2\epsilon})
               &n=2\end{cases} \xrightarrow{\epsilon\rightarrow0} 0
    \end{align*}
    (Hinweis: Integrale mit Kugelkoordinaten ausrechnen.)

    Damit haben wir gezeigt, dass $u_{\epsilon}(x)$ gleichmäßig
    \footnote{Abschätzung unabhängig von $x$} gegen $u(x)$ konvergiert
    auf jeder kompakten Teilmenge des $\R^{n}$ und $\frac{\partial
    u_{\epsilon}}{\partial x_{j}}$ gleichmäßig gegen $v_{j}(x)$
    konvergiert auf jeder kompakten Teilmenge des $\R^{n}$. Aus einem
    Satz von früher folgt dann, dass die Ableitung $\frac{\partial
    u}{\partial x_{j}}$ auf $\R^{n}$ existiert und $\frac{\partial
    u}{\partial x_{j}}= v_{j}$ ist. Damit ist (1) und (2) gezeigt.
  \end{proof}
\end{lemma}

\begin{satz}[Eigenschaften des Newton-Potentials]
  Die Funktion $f$ sei einmal stetig differenzierbar auf $\Omega$
  (zulässiges Gebiet) und stetig auf dem Abschluß $\overline{\Omega}$
  ($f\in C^{1}(\Omega)\cap C(\overline{\Omega})$). $u$ sei das
  Newton-Potential von $f$. Dann gilt:
  \begin{enumerate}
   \item $u\in C^{2}(\Omega)$ und $\Delta u(x) = f(x)$ für alle
    $x\in\Omega$.
   \item $u\in C^{1}(\R^{n})$
   \item $u$ ist eine harmonische Funktion außerhalb von $\Omega$ ($u\in
    C^{\infty}(\R^{n}\setminus\overline{\Omega})$ und $\Delta u=0$ auf
    $\R^{n}\setminus\overline{\Omega}$.
  \end{enumerate}
\end{satz}

\begin{bemerk}
  Dirichlet-Problem für Poissongleichung:
  \begin{gather}\label{eq:20}
    \begin{aligned}
      -\Delta u &= f &\text{auf $\Omega\subseteq\R^{n}$ beschränkt}\\
      u\big|_{\partial\Omega} &= g &\text{auf $\Omega$}
    \end{aligned}
  \end{gather}

  Annahme: $\exists w\in C^{2}(\Omega)\cdot C(\overline{\Omega})$ mit
  $-\Delta w=f$ auf $\Omega$. Dann Ansatz: $u=v+w$. (Bestimmt $v$, so
  dass $u$ in \autoref{eq:20} erfüllt ist.)

  $u$ erfüllt die \autoref{eq:20} \gdw $\Delta v=0$ auf $\Omega$ und
  $u\big|_{\partial\Omega} + w\big|_{\partial} = g$ \gdw
  $v\big|_{\partial\Omega} = g-w\big|_{\partial} = \phi$
\end{bemerk}

\begin{folger}
  Sei $\Omega$ eine Kugel $K_{R}(0)$ mit Radius $R$ um 0 und $g$ eine
  stetige Funktion $g\colon\partial K_{R} \rightarrow \R$ und $f\in
  C^{1}(K_{R}) \cap C(\overline{K})$. Dann ist
  \begin{align*}
    w(x) &= -\int_{\Omega}\Gamma(\abs{x-y}) f(y)\,dy
       &\text{(Newton-Potential)}\\
    v(x) &= \frac{R^{2}-\abs{x}^{2}}{\abs{\omega_{n}}R}
       \int_{\abs{x-y}=R} \frac{g(y)-w(y)}{\abs{x-y}^{n}}\,dS(y)
  \end{align*}
  $\Rightarrow$ $u(x) = v(x)+w(x)$ ist die Lösung des Dirichlet-Problems
  \autoref{eq:20} für die Kugel.
\end{folger}

\section{Cauchy-Probleme}
\subsection{Die Wärmeleitungsgleichung}

Sei $x\in\R^{n}$ ein Punkt im $\R^{n}$ (Ortskoordinate) und $t\in\R$
(Zeit). $u=u(x,t)$

Gegeben ist $f(x,t)$. Gelöscht werden soll:
\begin{gather*}
  u_{t}(x,y) - a^{2}\Delta u(x,t) = f(x,y)
\end{gather*}
Die Gleichung heißt \emph{Wärmeleitungsgleichung} oder
\emph{Diffusionsgleichung}.

Gesucht ist $u(x,t)$ mit $x\in\R^{n}$ und $t>0$.

Diese Gleichung ist ein Spezialfall einer \emph{parabolischen
Differentialgleichung}:
\begin{gather*}
  u_{t} - \Div K \grad u + \sprod{\vec{b}}{\grad u} + cu = f(x,t)
\end{gather*}

\begin{defini}[Cauchyproblem für Wärmeleitungsgleichung]
  Gegeben sei $f(x,t)$ und $u_{0}(x)$ und gesucht ist $u(x,t)$, so dass
  \begin{align*}
    u_{t} - \Delta u &= f(x,t) &(x\in\R^{n}, t>0)\\
    u(x,0) = u_{0}(x)
  \end{align*}
  Damit ist ein \emph{Anfangswertproblem} beschrieben.

  \obda ist $a^{2}=1$, sonst muss man noch eine Koordinatentransformation
  durchführen $u(x,t) = u(\frac{x}{a}, t), \tilde{f}(x,t) =
  f(\frac{x}{a}, t)$.
\end{defini}

\begin{lemma}[Fundamentallösung der Wärmeleitungsgleichung]\label{lem:1}
  Sei $x\in\R^{n}, t>0$. Wir definieren eine Funktion
  \begin{gather*}
    \Phi(x,t) := \frac{1}{(4\pi t)^{\nicefrac{n}{2}}}
       e^{-\frac{\abs{x}^{2}}{4t}}
  \end{gather*}
  Dann gilt:
  \begin{enumerate}
   \item $\Phi_{t}(x,t) - \Delta \Phi(x,t) = 0$ für alle $x\in\R^{n}$ und
    $t>0$
   \item
    \begin{gather*}
      \int_{\R^{n}} \Phi(x,t)\,dx = 1\qquad\forall t>0
    \end{gather*}
  \end{enumerate}

  \begin{proof}
    \begin{align*}
      \frac{\partial}{\partial t}\Big( t^{-\frac{n}{2}}
         e^{-\frac{\abs{x}^{2}}{4t}}\Big) &= -\frac{n}{2} t^{-\frac{n}{2}-1}
         e^{-\frac{\abs{x}^{2}}{4t}} + t^{-\frac{n}{2}}
         e^{-\frac{\abs{x}^{2}}{4t}} \frac{\abs{x}^{2}}{4t^{2}}\\
      &= t^{-\frac{n}{2}} e^{-\frac{\abs{x}^{2}}{4t}}
         \Big(\frac{\abs{x}^{2}}{4t^{2}} - \frac{n}{2t}\Big)\\
      \frac{\partial}{\partial x_{j}}\Big( t^{-\frac{n}{2}}
         e^{-\frac{\abs{x}^{2}}{4t}}\Big) &= t^{-\frac{n}{2}}
         e^{-\frac{\abs{x}^{2}}{4t}} \Big(\frac{x_{j}}{4t}\Big) =
         t^{-\frac{n}{2}} e^{-\frac{\abs{x}^{2}}{4t}}
         \Big(-\frac{x_{j}}{2t}\Big)\\
      \frac{\partial^{2}}{\partial x_{j}^{2}}\Big( t^{-\frac{n}{2}}
         e^{-\frac{\abs{x}^{2}}{4t}}\Big) &= t^{-\frac{n}{2}}
         e^{-\frac{\abs{x}^{2}}{4t}} \Big(\frac{x_{j}^{2}}{4t^{2}} -
         \frac{1}{2t}\Big)\\
      \intertext{Damit ergibt sich für den Laplace-Operator}
      \Delta\Big( t^{-\frac{n}{2}} e^{-\frac{\abs{x}^{2}}{4t}}\Big) &=
         \sum_{j=1}^{n} \frac{\partial^{2}}{\partial x_{j}^{2}} =
         t^{-\frac{n}{2}} e^{-\frac{\abs{x}^{2}}{4t}}
         \Big(\frac{\abs{x}^{2}}{4t^{2}} - \frac{n}{2t}\Big)
    \end{align*}
    $\Rightarrow (\ldots)_{t} = \Delta(\ldots)$

    Es ist
    \begin{align*}
      \int_{\R^{n}} e^{-\frac{\abs{x}^{2}}{4t}}\,dx &= \int_{\R^{n}}
         e^{-\frac{x_{1}^{2}+\ldots+x_{n}^{2}}{4t}}\,dx\\
      &= \prod_{j=1}^{n} \int_{-\infty}^{\infty}
         e^{-\frac{x_{j}^{2}}{4t}}\,dx_{j} &\text{Nach Satz von Fubini}\\
      &= \Big( \int_{-\infty}^{\infty} e^{-\frac{r^{2}}{4t}}\,dr\Big)^{n}
         &\text{Subst.:}\ \frac{r}{2\sqrt{t}}=\rho, dr=2\sqrt{t}d\rho\\
      &= \Big(2\sqrt{t} \int_{-\infty}^{\infty} e^{-\rho^{2}}\Big)^{n} =
         2^{n} t^{\frac{n}{2}} \pi^{\frac{n}{2}} = (4\pi t)^{\frac{n}{2}}
    \end{align*}

    (2) folgt durch hinsehen
  \end{proof}
\end{lemma}

\begin{figure}
  \center
  \input{Fundamental-waerme.tex}
  \caption{\label{fig:5} Die Fundamentallösung der Wärmeleitungsgleichung
    (\autoref{lem:1}) im $\R^{3}$ für verschiedene $t$}
\end{figure}

\begin{bemerk}
  Die Fundamentallösung der Wärmeleitungsgleichung $\Phi(x,t)$ geht für
  $t\rightarrow+0$ --- wenn man sich also immer mehr zum Startzeitpunkt
  zurück begibt --- für $x=0$ gegen Unendlich und für $x\neq 0$ gegen 0.
  \help{haben die Physiker dafür eine anschauliche Interpretation?} Siehe
  \autoref{fig:5}
  \begin{gather*}
    \Phi(x,t) \xrightarrow{t\rightarrow0+}
       \begin{cases}
         \infty& x=0\\
         0 & x\neq 0
       \end{cases}
  \end{gather*}
\end{bemerk}

\begin{satz}[Cauchyproblem für die homogene Wärmeleitungsgleichung]
  Es sei $u_{0}\in C(\R^{n})$ beschränkt. Es sei $u(x,t) = \int_{\R^{n}}
  \Phi(x-y, t) u_{0}(y)\,dy$ mit $x\in \R^{n}, t>0$. Dann gilt
  \begin{gather}
    \label{eq:21} u\in C^{\infty}(\R^{n}\times(0,\infty))\ 
       \text{beschränkt}\\
    \label{eq:22} u_{t}-\Delta u=0\ \text{auf}\ \R^{n}\times(0,\infty)\\
    \label{eq:23} \lim_{(x,t)\rightarrow(x^{0},0)} = u(x^{0})
    \quad\forall x^{0}\in\R^{n}
  \end{gather}
  $u$ ist \textit{eine} Lösung des Cauchyproblems.

  Als ersten Schritt zeigen wir \autoref{eq:21} und \autoref{eq:22}.
  $\abs{u_{0}(x)}\leq M$ auf $\R^{n} \Rightarrow \abs{u(x,t)} \leq
  \int_{\R^{n}} \Phi(x-y,t) \abs{u_{0}(y)}\,dy \leq M$ nach
  \autoref{lem:1}. $\Phi(x-y, t)\in C^{\infty}(\R^{n}\times(0,\infty))$
  als Funktion von $x$ und $t$ für jedes $y\in\R^{n}$. Alle Ableitungen
  sind schnell fallend für $\abs{y}\rightarrow\infty$. Das erlaubt uns
  die Ableitung unter das Integral zu ziehen. $\Rightarrow$ $\exists
  D^{\alpha}_{x}\Delta^{\beta}_{t} u(x,t) = \int_{\R^{n}}
  D^{\alpha}_{x}\Delta^{\beta}_{t} u(x,t) \Phi(x-y,t) u(y)\,dy$ für alle
  $\alpha\in\N_{0}^{n}, b\in\N_{0}$ stetig und $\Rightarrow$ $u\in
  C^{\infty}(\R^{n}\times(0,\infty))$ und $u_{t}-\Delta u = \int_{\R^{n}}
  \big(\Phi_{t}(x-y,t) - \Delta\Phi(x-y,t)\big) u_{0}(y)\,dy = 0$ (nach
  \autoref{lem:1}) auf $\R^{n}\times(0,\infty)$.

  Im zweiten Schritt zeigen wir noch \autoref{eq:23}. \todo{schönes
  Bildchen mit Rechteck}

  $u_{0}$ ist gleichmäßig stetig auf $K_{1}(x^{0})$. Es sei $\epsilon>0$.
  Dann existiert ein $\delta(\epsilon)$ und es gilt:
  $\abs{u_{0}(x) - u_{0}(y)}\leq \epsilon$, falls $x,y\in K_{1}(x^{0})$
  und $\abs{x-y}\leq \delta(\epsilon)$. Außerdem können wir
  folgendermaßen argumentieren:
  \begin{gather*}
    \abs{u(x,t) - u_{0}(x)} =^{\text{\autoref{lem:1}}} \abs{\int_{\R^{n}}
       \Phi(x-y, t) u_{0}(y)\,dy - \int_{\R^{n}}
       \underbrace{\Phi(y,\frac{1}{4})}_{=\pi^{-\nicefrac{n}{2}}e^{-\abs{y}^{2}}}
       u_{0}(x)\,dy}
  \end{gather*}
  Substitution im ersten Integral: $\frac{x-y}{\sqrt{4t}} = z \gdw
  y=x-\sqrt{4t}z$ und $dy = (4t)^{\nicefrac{n}{2}}\,dz$

  \begin{align*}
    \abs{u(x,t) - u_{0}(x)} &\leq \pi^{-\nicefrac{n}{2}} \int_{\R^{n}}
       e^{-\abs{z}^{2}} \abs{u_{0}(x-\sqrt{4t}z)- u_{0}(x)}\,dz\\
    &= \pi^{-\nicefrac{n}{2}} \int_{\abs{z}\leq R} e^{-\abs{z}^{2}}
       \underbrace{\abs{u_{0}(x-\sqrt{4t}z) - u_{0}(x)}} _{\leq\epsilon\ 
       \text{falls}\ t<t_{0}(\epsilon)}\,dz + \pi^{-\nicefrac{n}{2}}
       \underbrace{\int_{\abs{z}> R} e^{-\abs{z}^{2}} 2M\,dz}
       _{<\epsilon, R\geq R(\epsilon)}\\
    \intertext{wobei $t_{0}(\epsilon)$, so dass $\sqrt{4t}R(\epsilon)\leq
      \delta(\epsilon)$}
    &\leq 2\epsilon
  \end{align*}

  Dann ist
  \begin{gather*}
    \abs{u(x,t) - u_{0}(x^{0})} \leq \underbrace{\abs{u(x,t) - u_{0}(x)}}
       _{<2\epsilon}+ \underbrace{\abs{u_{0}(x)-u_{0}(x^{0})}}
       _{<\epsilon} = 3\epsilon
  \end{gather*}
  $\abs{x-x^{0}} < \delta(\epsilon), t<t_{0}(\epsilon)$
\end{satz}

\todo{hier fehlt die Vorlesung vom 13. 12.}

% 14.12.05

\begin{satz}
  \begin{gather*}
    u_{tt}-c^{2}u_{xx}=0\qquad (x\in\R, t>0)\\
    \gdw u(x,t) = \phi(x-ct) + \psi(x+ct)
  \end{gather*}
\end{satz}

\begin{bemerk}
  \todo{Bild mit zwei Glockenkurven, linke ist $\phi(x)$, rechte um $ct$
    verschoben}
\end{bemerk}

\begin{satz}\label{satz:1}
  $f\in C(\R\times [0,\infty)), u_{0}, u_{1}\in C(\R)$

  Das Cauchyproblem
  \begin{gather*}
    u_{tt}-c^{2}u_{xx} = f(x,t)\qquad(x\in\R, t>0)\\
    u(x,0) = u_{0}(x), u_{t}(x,0) = u_{1}(x)\qquad(x\in\R)
  \end{gather*}
  besitzt höchstens eine Lösung $u\in C^{2}(\R\times(0,\infty))\cap
  C^{1}(\R\times[0,\infty))$

  \begin{proof}
    Für die Differenz zweier Lösungen $w=u-v$ gilt:
    \begin{align*}
      w_{tt}-c^{2}w_{xx} = 0 & w(x,0) = w_{t}(x,0) = 0
    \end{align*}

    Nach \autoref{satz:1} ist
    \begin{gather*}
      w(x,t) = \phi(x-ct) + \psi(x+ct)\qquad(\phi,\psi\in C^{2}(\R))\\
      \intertext{mit $w(x,0)=0$ ergibt sich}
      \phi(x) + \psi(x) = 0 \Rightarrow \phi'(x) + \psi'(x) = 0\\
      \intertext{mit $w_{t}(x,0)$ ist}
      -c\phi'(x) + c\psi'(x) = 0 \Rightarrow \phi'(x) = \psi'(x)
    \end{gather*}
    Diese beiden Bedingungen sind nur erfüllt, wenn $\phi'(x) = \psi'(x)
    = 0$ sind. $\phi$ und $\psi$ sind also Konstanten, wobei $\phi(x)=a$
    und $\psi(x) = -a$.
  \end{proof}
\end{satz}

\begin{bemerk}[Lösungsansatz des Cauchy-Problems]
  \hfill
  \begin{minipage}[t]{.45\linewidth}
    \begin{gather}\label{eq:24}
      \begin{split}
        v_{tt} - c^{2}v_{xx} &= 0\\
        v(x,0) &= u_{0}(x)\\
        v_{t}(x,0) &= u_{1}(x)
      \end{split}
    \end{gather}
  \end{minipage}\hfill
  \begin{minipage}[t]{.45\linewidth}
    \begin{gather}\label{eq:25}
      \begin{split}
        w_{tt}-c^{2}w_{xx} &= f\\
        w(x,0) &= 0\\
        w_{t}(x,0) &= 0
      \end{split}
    \end{gather}
  \end{minipage}\hfill

  zu \autoref{eq:24}:
  \begin{align*}
    v(x,t) &= \phi(x-ct) + \psi(x+ct)\\
    v(x,0) &= \phi(x)+\psi(x) = u_{0}\taglabel{eq:26}\\
    v_{t}(x,0) &= c\phi'(x)+c\psi'(x) = u_{1}(x)\\
    \intertext{$\Longrightarrow$}
    c\phi'(x) + c\psi'(x) &= cu_{0}'(x)\\
    -c\phi'(x)+c\psi'(x) &= u_{1}(x)\\
    \intertext{$\Longrightarrow$}
    2c\psi'(x) &= cu_{0}(x) + u_{1}(x)\\
    \intertext{$\Longrightarrow$}
    \psi(x) &= \frac{1}{2} u_{0}(x) + \frac{1}{2c}
       \int_{0}^{x}u_{1}(y)\,dy + a\\
    \intertext{$\Longrightarrow$ mit \autoref{eq:26}}
    \phi(x) &= u_{0}(x) - \psi(x) = \frac{1}{2c} \int_{0}^{x} u_{1}(y)\,dy
       -a\\
    \intertext{$\Longrightarrow$}
    v(x,t) &= \frac{1}{2} u_{0}(x-ct) - \frac{1}{2c}\int_{0}^{x-ct}
       u_{1}(y)\,dy + \frac{1}{2} u_{0}(x+ct) + \frac{1}{2c}
       \int_{0}^{x+ct} u_{1}(y)\,dy = \frac{1}{2}\big(u_{0}(x-ct)+
       u_{0}(x+ct)\big)+\frac{1}{2c}\int_{x-ct}^{x+ct} u_{1}(y)\,dy
  \end{align*}
\end{bemerk}

\begin{satz}
  Es seien $u_{0}\in C^{2}(\R), u_{1}\in C^{1}(\R)$. Dann ist
  \begin{gather*}
    u(x,t) = \frac{1}{2} \big(u_{0}(x-ct) + u_{0}(x+ct)\big)+\frac{1}{2c}
       \int_{x-ct}^{x+ct} u_{1}(y)\,dy
  \end{gather*}
  die eindeutig bestimmte Lösung des Cauchy-Problems
  \begin{gather*}
    u_{tt}-c^{2}u_{xx} = 0\qquad(x\in\R, t>0)\\
    u(x,0) = u_{0}(x), u_{t}(x,0) = u_{1}(x)\qquad(x\in\R)
  \end{gather*}
\end{satz}

\begin{bemerk}\label{bem:1}
  Für die Lösung $u(x,t)$ in einem Punkt benötigt man nur die Information
  von $u_{0}$ in den Punkten $(x-ct, 0)$ und $(x+ct, 0)$ und die Summe
  der Werte von $u_{1}$ auf der $x$-Achse zwischen $(x-ct, 0)$ und
  $(x+ct, 0)$. Alle Werte für die Lösung liegen also in der
  "`Vergangenheit"' -- $u(x,\tilde{t})$ wird nur von $u_{0}$ und $u_{1}$
  für $t<\tilde{t}$ beeinflusst.

  $u_{0}$ hat nur in einem Intervall $t\in[t_{0},t_{1}]$ auf die Lösung
  einen Einfluss. $u_{1}$ hingegen hat einen Einfluss ab einem bestimmten
  Zeitpunkt $t\geq t_{0}$.

  \todo{Bild vom "`Vergangenheitskegel"'}
\end{bemerk}

\begin{satz}
  Es sei $f\in C^{1}(\R\times[0,\infty))$. Dann ist
  \begin{gather*}
    u(x,t) = \frac{1}{2c} \int_{0}^{t}
       \int_{x-c(t-s)}^{x+c(t-s)}f(y,s)\,dy\,ds
  \end{gather*}
  die eindeutig bestimmte Lösung des Cauchy-Problems
  \begin{gather*}
    u_{tt} - c^{2}u_{xx} = f\\
    u(x,0) = u_{t}(x,0) = 0
  \end{gather*}

  \begin{proof}
    Um zu überprüfen, ob die gegebene Gleichung wirklich die Lösung ist,
    prüfen wir, ob sie die Bedingungen des Cauchy-Problems erfüllt. Dabei
    sind die Ableitungen von $u(x,t)$ notwendig, was sich etwas aufwendig
    gestaltet, da $x$ und $t$ in beiden Integralen vorkommen. Daher
    formen wir zuvor etwas um:
    \begin{gather*}
      u(x,t) = \frac{1}{2c} F(x,t,t), \text{ wobei } F(x,t,z) =
         \int_{0}^{z} \int_{x-c(t-s)}^{x+c(t-s)} f(y,s)\,dy\,ds
    \end{gather*}

    Für die Ableitungen bzgl. $x$ ergibt sich also
    \begin{align*}
      F_{x} &= \int_{0}^{z} f(x+c(t-s),s) - f(x-c(t-s),s)\,ds\\
      F_{xx} &= \int_{0}^{z} f_{x}(x+c(t-s),s) - f_{x}(x-c(t-s), s)\,ds
    \end{align*}
    mit $z=t$ ergibt sich
    \begin{gather*}
      c^{2}u_{xx}(x,t) = \frac{c}{2} \int_{0}^{t} f_{x}(x+c(t-s), s) -
         f_{x}(x-c(t-s))\,ds
    \end{gather*}

    Für die Ableitungen nach $t$ ist zu beachten, dass $z$ eine Funktion
    von $t$ ist.
    \begin{align*}
      u_{t} &= \frac{1}{2c} \int_{0}^{z} f(x+c(t-s),s) c - f(x-c(t-s),s)
         (-c)\,ds\Big|_{z=t} + \underbrace{\int_{x-c(t-z)}^{x+c(t-z)}
         f(y,z)\,dy\Big|_{z=t}}_{=0}\\
      u_{tt} &= \frac{1}{2} \int_{0}^{z} f_{x}(x+c(t-s),s)c +
         f_{x}(x-c(t-s), s) (-c)\,ds \Big|_{z=t} + \frac{1}{2c}
         \Big[f(x+c(t-s), s) c + f(x-c(t-s),s) c\Big]_{s=t}\\
      &= c^{2} u_{xx} + f(x,t)
    \end{align*}
    $\Rightarrow$ Wellengleichung erfüllt.

    Anfangsbedingung: Für Ableitung gegen $x$ braucht man nur die
    Umgebung von $x$ zu untersuchen. Dazu wählen wir ein endliches
    Rechteck $Q$ ($\Rightarrow$ kompakt). Damit ist $f$ beschränkt
    ($\abs{f(y,s)}\leq M$ auf $Q$) und $f_{x}$ ist beschränkt
    ($\abs{f_{x}(y,s)}\leq M$ auf $Q$). Nach \autoref{bem:1}
    benötigt man für die Berechnung des Wertes nur Werte aus dem Gebiet
    $Q$ ("`Vergangenheitskegel"').

    \begin{gather*}
      \abs{u(x,t)} \leq \int_{0}^{t} \int_{x-c(t-s)}^{x+c(t-s)}
         \underbrace{\abs{f(y,s)}}_{\leq M\ \text{auf}\ Q}\,dy\,ds \leq M
         \int_{0}^{t}(t-s)\,ds = M\frac{t^{2}}{2}
         \xrightarrow{t\rightarrow0}0
    \end{gather*}
    In einem solchen lokalen Gebiet $Q$ kann man eine solche Abschätzung
    produzieren und die Anfangsbedingung $u(x,0)$ ist 0.

    Für die Ableitung gilt:
    \begin{gather*}
      \abs{u_{t}(x,t)}\leq \frac{1}{2c}\int_{0}^{t}
         \underbrace{\abs[\Big]{f(x+c(t-s),s) + f(x+c(t-s),s)}} _{\leq
         2M}\,ds = Mt \xrightarrow{t\rightarrow0} 0
    \end{gather*}
    Damit ist auch die zweite Anfangsbedingung erfüllt.
  \end{proof}
\end{satz}

\begin{bemerk}
  Analog zu \autoref{bem:1}: Für die Lösung in einem Punkt
  $u(x,t)$ sind nur die Werte der Funktion innerhalb des
  Vergangenheitskegels notwendig. Alles, was außerhalb des Kegels liegt,
  wird für die Lösung nicht benötigt.

  \todo{Bild vom Vergangenheitskegel}
\end{bemerk}

% 3.1.2006

\subsection{Die 3-dimensionale Wellengleichung} % 9.2.3

Cauchy-Problem:
\begin{align*}
  u_{tt} - c^{2}\Delta u &= f(x,t) &(x\in \R^{3}, t>0)\\
  % Anfangsbedingung:
  u(x,0) &= u_{0}(x), u_{t}(x,0) = u_{1}(x) &(x\in\R^{3})
\end{align*}

\obda c=1, sonst $\tilde{u}(x,t) = u(x,\frac{t}{c})$ $\Leftrightarrow$
$u(x,t) = \tilde{u}(x,ct)$

\begin{align*}
  u_{tt}-c^{2}\Delta u = f(x,t) &\Leftrightarrow
     c^{2}\tilde{u}_{tt}(x,ct) - c^{2}\Delta \tilde{u}(x,ct) = f(x,t)\\
  &\Leftrightarrow \tilde{u}_{tt}-\Delta \tilde{u} = \frac{1}{c^{2}}
     f(x,ct) = \tilde{f}(x,t)
\end{align*}

ohne Beweis: Das Cauchy-Problem hat höchstens eine Lösung!

\begin{satz}
  Folgende Voraussetzungen seien erfüllt: $u_{0}\in C^{3}(\R^{3}),
  u_{1}\in C^{2}(\R^{3})$. Dann ist
  \begin{gather*}
    u(x,t) = \frac{1}{4\pi t} \int_{\abs{x-y}=t} u_{1}(y)\,dS(y) +
       \frac{1}{4\pi} \frac{\partial}{\partial t}\Big( \frac{1}{t}
       \int_{\abs{x-y}=t} u_{0}(y)\,dS(y) \Big)
  \end{gather*}
  (\textit{Anm.: mit $\abs{x-y}=t$ wird über den Rand der Kugel $K_{t}(x)$ integriert.})
  Die (eindeutig bestimmte) Lösung des Cauchy-Problems $u_{tt}-\delta u =
  0$ mit den Anfangsbedingungen $u(x,0)=u_{0}(x)$ und $u_{t}(x,0) =
  u_{1}(x)$ ($x\in \R^{3}, t>0$).

  Die Gleichung heißt \emph{Kirchhoff'sche Formel}.
\end{satz}

\begin{bemerk}[Betrachtungen zur Kirchhoff'schen Formel]
  Formt man die Kirchhoff'sche Formel etwas um, so erhält man
  \begin{gather*}
    u(x,t) = t \underbrace{\Big(\frac{1}{4\pi t^{2}} \int_{\abs{x-y}=t} u_{1}(y)\,dS
       \Big)}_{= Mu_{1}(x,t)} + \frac{\partial}{\partial t} \Big(t
       \underbrace{\Big(\frac{1}{4\pi
       t^{2}} \int_{\abs{x-y}=t} u_{0}(y)\,dS \Big)}_{=Mu_{0}(x,t)} \Big)
  \end{gather*}
  wobei
  \begin{gather*}
    Mg(x,t) = \frac{1}{4\pi t^{2}} \int_{\abs{x-y}=t} g(y)\,dS =
       \frac{1}{4\pi} \int_{\abs{y}=1} g(x+ty)\,dS
  \end{gather*}

  Diese Darstellung ist vorteilhaft, da der Parameter $t$ nicht mehr in
  den Integralgrenzen auftaucht und nur noch unter dem Integral steht.
  Dies wird später vorteilhaft sein, wenn wir Ableitungen bilden müssen.

  Diese Formel nennt man den \emph{sphärischen Mittelwert} von $g$.

  \begin{proof}
    1.\,Schritt: Anfangsbedingungen sind erfüllt. Es gilt:
    \begin{gather*}
      u(x,t) = t\frac{1}{4\pi} \int_{\abs{y}=1} u_{1}(x+ty)\,dS +
         \frac{\partial}{\partial t}\Big( t \frac{1}{4\pi}
         \int_{\abs{y}=1} u_{0}(x+ty)\,dS \Big)
    \end{gather*}
    Für $t\rightarrow 0$ bekommen wir:
    \begin{gather*}
      u(x,0) = 0\cdot u_{1}(x) + \underbrace{\frac{1}{4\pi} \int_{\abs{y}=1}
         u_{0}(x)\,dS}_{=u_{0}(x)} + \Big[ t\frac{1}{4\pi} \frac{\partial}{\partial t}
         \int_{\abs{y}=1} u_{0}(x+ty)\,dS \Big]_{t=0}
    \end{gather*}
    Überzeugen wir uns noch davon, dass der dritte Summand Null ist.
    Dafür muss der Integrand konstant sein, damit das Produkt mit $t$
    gegen Null geht.
    \begin{gather}\label{eq:27}
      \frac{\partial}{\partial t} \int_{\abs{y}=1} u_{0}(x+ty)\,dS
         = \int_{\abs{y}=1} \sum_{j=1}^{3} \frac{\partial
         u_{0}}{\partial x_{j}}(x+ty)\cdot y_{j}\,dS
    \end{gather}
    für $t=0$ ergibt sich
    \begin{gather*}
      \int_{\abs{y}=1} \sum_{j=1}^{3} \frac{\partial u_{0}}{\partial
         x_{j}}(x)\cdot y_{j}\,dS = \sum_{j=1}^{3} \frac{\partial
         u_{0}}{\partial x_{j}}\,dS = \sum_{j=1}^{3} \frac{\partial
         u_{0}}{\partial x_{j}}(x) \int_{\abs{y}=1}
         \sprod{\vec{e_{j}}}{\vec{n}} =^{nach Gauß} \int_{\abs{y}\leq1}
         \Div \vec{e_{j}}\,dy = 0
    \end{gather*}

    Es bleibt also $u(x,0) = u_{0}(x)$.

    \begin{align*}
      u_{t}(x,t) &= \frac{1}{4\pi} \int_{\abs{y}=1} u_{1}(x+ty)\,dS +
         \underbrace{t\cdot\frac{1}{4\pi} \frac{\partial}{\partial t} \Big(
         \int_{\abs{y}=1} u_{1}(x+ty)\,dS\Big)
         }_{\xrightarrow{t\rightarrow0}0 \text{~nach \autoref{eq:27}}} +
         \underbrace{\frac{\partial}{\partial
         t} \Big(\frac{1}{4\pi} \int_{\abs{y}=1} u_{0}(x+ty)\,dS \Big)
         }_{\xrightarrow{t\rightarrow0}0 \text{~nach \autoref{eq:27}}}\\
      &\quad +\underbrace{\frac{\partial}{\partial t} \Big(t\frac{1}{4\pi}
         \frac{\partial}{\partial t} \int_{\abs{y}=1}
         u_{0}(x+ty)\,dS\Big) }_{= \underbrace{\frac{1}{4\pi} \frac{\partial}{\partial
         t} \int_{\abs{y}=1}
         u_{0}(x+ty)\,dS}_{\xrightarrow{t\rightarrow0}0 \text{~nach \autoref{eq:27}}} +
         \underbrace{\frac{t}{4\pi}\frac{\partial^{2}}{\partial t^{2}}
         \int_{\abs{y}=1} u_{0}(x+ty)\,dS }_{\xrightarrow{t\rightarrow0}0}}
    \end{align*}

    für $t\rightarrow0$ bleibt also $u_{t}(x,0) = u_{1}(x) +0$.

    2.\,Schritt: Wir zeigen, $u$ erfüllt homogene Wellengleichung
    \begin{gather*}
      u(x,t) = \underbrace{t Mu_{1}(x,t)}_{=: v(x,t)} +
         \frac{\partial}{\partial t} \big(\underbrace{t Mu_{0}(x,t) }_{=:
         w(x,t)} \big)
    \end{gather*}
    Wir zeigen: $v$ und $\frac{\partial}{\partial t} w$ erfüllen die
    homogene Wellengleichung.

    Es gilt:
    \begin{gather*}
      v_{t} = Mu_{1}(x,t) + t\frac{\partial}{\partial t} Mu_{1}(x,t),
         v_{tt} = 2 \frac{\partial}{\partial t} Mu_{1}(x,t) +
         t\frac{\partial^{2}}{\partial t^{2}} Mu_{1}(x,t)
    \end{gather*}
    Es gilt:
    \begin{gather*}
      \frac{\partial}{\partial t} Mu_{1}(x,t) = \frac{1}{4\pi}
         \frac{\partial}{\partial t} \int_{\abs{y}=1} u_{1}(x+ty)\,dS
         =^{\text{\autoref{eq:27}}} \frac{1}{4\pi t^{2}} \int_{\abs{x-y}=t}
         \frac{\partial u_{1}}{\partial \vec{n}}dS
    \end{gather*}

    Wiederholung der Green'schen Sätze \autoref{satz:823-6}
    \begin{gather*}
      \int_{B} u\Delta v\,dy = \int_{\partial B} u\cdot\frac{\partial
         v}{\partial \vec{n}}\,dS - \int_{B}\nabla u\cdot\nabla v\,dy
    \end{gather*}
    mit $u=1$ ergibt sich
    \begin{gather*}
      \int_{B}\Delta v\,dy = \int_{\partial B}\frac{\partial v}{\partial
         \vec{n}}dS
    \end{gather*}

    \begin{gather}\label{eq:28}
      \frac{\partial}{\partial t} Mu_{1}(x,t) = \frac{1}{4\pi t^{2}}
         \int_{\abs{x-y}\leq t} \Delta u_{1}\,dy
    \end{gather}

    und weil es schon schön war, das ganze nochmal
    \begin{gather*}
      \frac{\partial^{2}}{\partial t^{2}} Mu_{1}(x,t) = -\frac{1}{2\pi
         t^{3}} \int_{\abs{x-y}\leq t} \Delta u_{1}(y)\,dy +
         \frac{1}{4\pi t^{2}} \frac{\partial}{\partial t} \underbrace{\Big(
         \int_{0}^{t} \int_{\abs{x-y}=\rho} \Delta u_{1}(y)\,dS\,d\rho
         \Big)}_{= \int_{\abs{x-y}=t} \Delta u_{1}(y)\,dS }
    \end{gather*}
    \begin{gather}\label{eq:29}
      t\frac{\partial^{2}}{\partial t^{2}} Mu_{1}(x,t) = -\frac{1}{2\pi
         t^{2}} \int_{\abs{x-y}\leq t} \Delta u_{1}(y)\,dy +
         \frac{1}{4\pi t} \int_{\abs{x-y}= t} \Delta u_{1}(y)\,dS
    \end{gather}

    Aus \autoref{eq:28} und \autoref{eq:29} folgt
    \begin{gather*}
      v_{tt} = \frac{1}{4\pi t}\int_{\abs{x-y}= t} \Delta u_{1}(y)\,dS
    \end{gather*}

    bleibt noch zu zeigen, dass $v_{tt}=\Delta v$.
    Andererseits ist
    \begin{gather*}
      \Delta v(x,t) = \frac{t}{4\pi} \Delta\Big(\int_{\abs{y}=1}
         u_{1}(x+ty)\,dS \Big) = \frac{t}{4\pi} \int_{\abs{y}=1} (\Delta
         u_{1})(x+ty)\,dS = \frac{1}{4\pi t} \int_{\abs{x-y}=t} \Delta
         u_{1}(y)\,dS
    \end{gather*}

    $v$ und $w$ unterscheiden sich nur darin, dass in $v$ $u_{1}$
    verwendet wird und in $w$ $u_{0}$. Die ganze Rechnung lässt sich also
    ebenso für $w$ durchführen und es ergibt sich, dass $w$ auch eine
    Lösung der Wellengleichung ist: $w_{tt} = \Delta w$. Wir wollen aber
    zeigen, dass $w_{t}$ eine Lösung der Wellengleichung ist:
    \begin{gather*}
      (w_{t})_{tt} = (w_{tt})_{t} = (\Delta w)_{t} = \Delta w_{t}
    \end{gather*}
    (mit Hilfe des Satzes von Schwarz)

    Also ergibt sich als Gesamtergebnis: $v+w_{t}$ ist Lösung der
    homogenen Wellengleichung.
  \end{proof}
\end{bemerk}

\begin{bemerk}[Die Huygensche Eigenschaft -- Schallausbreitung]
  Modellierung: $u(x,t) = p(x,t) - p_{0}$ mit $p$ als Druck und $p_{0}$
  als Normalendruck, $u_{0}(x)$ und $u_{1}(x)$ sind dann die Abweichungen
  von $p_{0}$ zum Zeitpunkt $t=0$.

  \begin{gather*}
    u(x,t) = \frac{1}{4\pi t} \int_{\abs{x-y}=t} u_{1}(y)\,dS +
       \frac{1}{4\pi t^{2}} \int_{\abs{x-y}=t} \frac{\partial
       u_{0}}{\partial \vec{n}}\,dS + \frac{1}{4\pi t^{2}}
       \int_{\abs{x-y}=t} u_{0}(y)\,dS
  \end{gather*}

  Da nur über den Rand der Kugel um $x$ integriert wird, wirken sich
  lokale Störungen ($u_{0}$ oder $u_{1}\neq 0$) nur zu den Zeitpunkten
  aus, die $u_{0}$ und $u_{1}$ berücksichtigen. Bei einem beschränkten
  Träger von $u_{0}$ bzw. $u_{1}$ ist also eine lokale Störung nur in
  einem beschränkten Zeitraum wahrnehmbar -- davor und danach nicht.
  \help{Stimmt das?}
\end{bemerk}

% Hier fehlt die Vorlesung von 4.1.06

% 10.1.06

\section{Separationsansätze (Fourier'sche Methode)}
\subsection{Wellengleichung -- schwingende Saite}\label{sec:931}

Wir betrachten das Anschlagen oder Zupfen einer Saite eines Instruments
der Länge $l$. Die Anfangsauslenkung sei durch $u_{0}(x)$ gegeben.
\help{was ist dann $u_{1}$?} Wie verändert die Saite ihre Lage über die
Zeit?

\begin{enumerate}
 \item\label{enu:1} $u_{tt} - c^{2} u_{xx} =0\quad(x\in (0,l), t>0)$
 \item\label{enu:2} $u(0,t) = u(l,t) =0\quad(t>0)$ ist die
   Randbedingung und $u_{1}(x)$ die Anfangsgeschwindigkeit
 \item\label{enu:3} $u(x,0) = u_{0}(x)\quad(x\in(0,l))$ und $u_{t}(x,0) =
  u_{1}(x)$ sind die Anfangsbedingungen.
\end{enumerate}

Diesen Typ von Fragestellungen bezeichnen wir als
\emph{Rand-Anfangswert-Problem} für die homogene Wellengleichung.

Noch einige Bezeichnungen: $c=\sqrt{\frac{s}{\rho}}$, wobei $s$ die
Spannung und $\rho$ die Dichte der Saite ist.

\subsubsection{Separation}

Man finde alle Lösungen der Form $u(x,t) = X(x)T(t)$ von \autoref{enu:1}
und \autoref{enu:2}!
\begin{gather*}
  u_{tt} - c^{2} u_{xx} = XT'' - c^{2}X''T = 0 \Leftrightarrow c^{2} X''T
     =XT'' \Leftarrow \frac{X''}{T} = \frac{T''}{c^{2}T} = \lambda
     \exists \lambda\in\R (\forall x \forall t)
\end{gather*}

Man löse das Randwertproblem (1) "`Bestimme $\lambda\in\R$, so dass $X''
= \lambda X$ auf $(0,l)$ und $X(0) = X(l) =0$"' und die gewöhnliche
Differentialgleichung (2) $T''=c^{2}\lambda T$ für $\lambda$ aus dem
Randwertproblem (1).

% Sollte vielleicht besser ein \paragraph sein
\minisec{Lösen des Randwertproblems (1)}

Ansatz: $X=e^{\mu x}$ $\Rightarrow$ charakteristisches Polynom:
$\mu^{2}=\lambda$
\begin{faelle}
 \item Für $\lambda>0$ ergibt sich $\mu_{1/2} = \pm\sqrt{\lambda}$. Die
  allgemeine Lösung lautet also $X(x)= c_{1}e^{\sqrt{\lambda}x} +
  c_{2}e^{-\sqrt{\lambda}x}$. Die Randbedingung \autoref{enu:2}
  $X(0) = X(l) = 0$ liefert $c_{1}+c_{2}=0$ und
  $c_{1}e^{\sqrt{\lambda}l} + c_{2}e^{-\sqrt{\lambda}l} =0$. Da $c>0$
  (nach Definition), kann nur gelten $c_{1}=c_{2}=0$.

  Dieses Ergebnis ist jedoch uninteressant, da dies bedeutet, dass die
  Spannung der Saite Null ist.
 \item Für $\lambda=0$ ergibt sich analog $c_{1}=c_{2}=0$.

 \item $\lambda<0$ $\Rightarrow$ $\mu_{1/2}=\pm i\sqrt{-\lambda}$
  $\Rightarrow$ allgemeine Lösung: $X=c_{1} \cos\sqrt{-\lambda} x +
  c_{2}\sin\sqrt{-\lambda}x$ $(c_{1},c_{2}\in\R)$

  $X(0) = 0 \Leftrightarrow c_{1}=0$ und $X(l) = 0 \Leftrightarrow
  c_{2}\sin\sqrt{-\lambda} l =0 \Leftrightarrow c_{2}$ oder
  $\sqrt{-\lambda}l = k\pi$ bzw. $\lambda =
  -\big(\frac{k\pi}{l}\big)^{2}$ $(k\in\N)$
\end{faelle}

$\Rightarrow$ Lösung für $\lambda_{k}=-\big(\frac{k\pi}{l}\big)^{2}$
$(k\in\N)$, $X_{k}(x) = c_{k}\sin\frac{k\pi}{l} x$ $(c_{k}\in\R)$

% Sollte vielleicht besser ein \paragraph sein
\minisec{Lösen der Differentialgleichung (2) für
  $\lambda=\lambda_{k}$}

\begin{gather*}
  T_{k}'' + c^{2} \big(\frac{k\pi}{l}\big)^{2} T_{k}=0
\end{gather*}
Ansatz: $T_{k}= e^{\rho t}$ $\Rightarrow$ $\rho^{2} +
\big(\frac{ck\pi}{l}\big)^{2} = 0, \rho_{1/2} = \pm i
\frac{ck\pi}{l}$

$\Rightarrow$ $T_{k}(t) = A_{k}\cos\frac{ck\pi}{l} t +
B_{k}\sin\frac{ck\pi}{l} t$ mit $k\in\N, A_{k},B_{k}\in\R$

Damit können wir jetzt das gesamte Problem lösen -- Lösungen der
Separation:
\begin{gather*}
  U_{k}(x,t) = (a_{k}\cos\frac{ck\pi}{l}t + b_{k}\sin\frac{ck\pi}{l} t)
     \sin\frac{k\pi}{l} x
\end{gather*}
mit den Freiheitsgraden $k\in\N$ und $a_{k},b_{k}\in\R$.

\begin{bemerk}
  $\sum_{\text{endl}} u_{k}(x,t)$ ist ebenfalls Lösung der Separation.
\end{bemerk}

Jetzt Übergang zu einer unendlichen Reihe: Ist $\sum_{k=1}^{\infty}
u_{k}(x,t)$ eine Lösung? Für $u_{k} = 0$ ist natürlich auch die Summe 0
und somit eine Lösung der Differentialgleichung. Die Frage ist nun, ob
man $a_{k}$ und $b_{k}$ so bestimmen kann, dass sie der Randbedingung
genügen.

\subsubsection{Superposition}

Man finde $a_{k},b_{k}\in\R$, so dass
\begin{gather*}
  u(x,t) := \sum_{k=1}^{\infty} (a_{k}\cos\frac{ck\pi}{l} t + b_{k}\sin
     \frac{ck\pi}{l} t) \sin \frac{k\pi}{l} x
\end{gather*}
die Anfangsbedingung \autoref{enu:3} erfüllt!

d.\,h.
\begin{align}
  u(x,0) &= \sum_{k=1}^{\infty} a_{k} \sin\frac{k\pi}{l} x = u_{0}(x)
     \label{eq:30}\\
  u_{t}(x,0) = \sum_{k=1}^{\infty} \underbrace{\frac{ck\pi}{l}
     b_{k}}_{=:\tilde{b_{k}}} \sin\frac{k\pi}{l} x = u_{1}(x) \label{eq:31}
\end{align}
Beim Ableiten von $u$ nach $t$ haben wir den Konvergenzradius der Reihe
ignoriert (nicht betrachtet oder halt \obda machbar)

Wir haben jetzt zwei gleiche Probleme gefunden: einmal für $u_{0}$ mit
$a_{k}$ und $u_{1}$ mit $\tilde{b_{k}}$.

% Sollte vielleicht besser ein \paragraph sein
\minisec{Berechnung der Fourierkoeffizienten $a_{k}, b_{k}$ ($k\in\N$)}

Verwende:
\begin{gather*}
  \int_{0}^{l} \sin\bigg(\frac{k\pi}{l} x\bigg)  \sin \frac{j\pi}{l} x\,dx =
     \begin{cases}
       0 & j\neq k\\ \frac{l}{2} & j=k
     \end{cases}\\
\end{gather*}
denn:
\begin{align*}
  \int_{0}^{l} \ldots \,dx &= \frac{l}{x} \int_{0}^{\pi} \sin kx \sin
     jx\,dx\\
  &= \frac{l}{\pi} \int_{0}^{\pi} \frac{1}{2} (\cos (k-j)x - \cos(k+j) x
     )\,dx\\
  &= \frac{l}{2\pi} \begin{cases}0&j\neq k\\ \int_{0}^{\pi} (1-\cos
                      2kx)\,dx = \pi &k=j\end{cases}
\end{align*}

Machen wir erstmal eine Analyse, was wir erhalten: Annahme
\autoref{eq:30} gilt, dann haben wir
\begin{align*}
  \int_{0}^{l}\sin\frac{k\pi}{l} x u_{0}(x)\,dx &= \sum_{j=1}^{\infty}
     a_{j} \int_{0}^{l} \sin \bigg(\frac{j\pi}{l} x\bigg) \sin\bigg(\frac{k\pi}{l}
     x\bigg)\,dx &(k\in\N)\\
  &= a_{k} \int_{0}^{l} \bigg(\sin\frac{k\pi}{l} x\bigg)^{2}\,dx = a_{k}\frac{l}{2}
\end{align*}

Wenn es also möglich ist, dann müssen die Koeffizienten so aussehen:
\begin{gather*}
  a_{k} = \frac{2}{l} \int_{0}^{l} u_{0}(x) \sin\frac{k\pi}{l} x\,dx
     \quad(k\in\N)
\end{gather*}

Nehmen wir an \autoref{eq:31} gilt und wir bekommen heraus, dass
\begin{gather*}
  b_{k} = \frac{2}{ck\pi} \int_{0}^{l} u_{1}(x) \sin\frac{k\pi}{l} x\,dx
     \quad(k\in\N)
\end{gather*}

$a_{k}$ und $b_{k}$ bezeichnet man als die Fourierkoeffizienten von
$u_{0}$ und $u_{1}$.

\subsubsection{Interpretation der Theorie der Fourierreihen}

Von der Musik her kennen wir Schwingungen, die sich dadurch auszeichnen,
dass sie periodisch sind, d.\,h. $f(t+T) = f(t)$. Das kleinste $T$
bezeichnet man als die Schwingungsdauer und $\nu=\frac{1}{T}$ als die
(Grund-)Frequenz. Die Fouriertheorie besagt, dass sich $f$ durch
Teilschwingungen $f_{k}$ beschreiben lässt. (Wichtige Aussage der
Fouriertheorie: Jede Schwingung lässt sich als Summe (Überlagerung) von
Einzelschwingungen darstellen)
\begin{gather*}
  f_{k}(t) = a_{k} \cos\frac{ck\pi}{l} t + b_{k}\sin \frac{ck\pi}{l} t
\end{gather*}
$\Rightarrow$ $T_{k}=\frac{2l}{c}\frac{1}{k}$ mit $k\in\N$ $\Rightarrow$
$\nu_{k} = \frac{c}{2l} k$. $\frac{c}{2l}$ ist die Grundfrequenz. $k=1$
bezeichnet man als den Grundton, $k>1$ als Obertöne = $k$-fache Frequenz
der Frequenz des Grundtons.

Wandeln wir unser Randwertproblem etwas ab und setzen für \autoref{enu:1}
$u_{tt} - c^{2} u_{xx} = f(x,t)$ mit $x\in(0,l)$ und $t>0$.

Machen wir dazu den Ansatz: $u(x,t) = v(x,t) + w(x,t)$, wobei
\begin{enumerate}
 \item $w_{tt} - c^{2}w_{xx} = 0$
 \item $w(0,t) = w(l,t) = 0$
 \item $w(x,0) = u_{0}(x)$ und $w_{t}(x,0) = u_{1}(x)$
\end{enumerate}
Dieses Problem ist wieder das ursprüngliche Problem.

Als weiterer Fall ergibt sich:
\begin{enumerate}
 \item $v_{tt} - c^{2}v_{xx} = f(x,t)$ (inhomogene Differentialgleichung!)
 \item $v(0,t) = v(l,t) = 0$
 \item $v(x,0) = v_{t}(x,0) =0$
\end{enumerate}

Dafür machen wir folgenden Ansatz:
\begin{gather*}
  v(x,t) := \sum_{k=1}^{\infty} T_{k}(t) \sin\frac{k\pi}{l} x
\end{gather*}
Man entwickle $f(x,t)$ bei festem $t$ in eine Sinusreihe, d.\,h.
\begin{gather*}
  f(x,t) = \sum_{k=1}^{\infty} f_{k}(t) \sin\frac{k\pi}{l} x\\
  f_{k}(t) = \frac{2}{l} \int_{0}^{l} f(x,t)\sin \frac{k\pi}{l} x\,dx
\end{gather*}
($k\in\N, t>0$)

Dann ist $v(x,t)$ Lösung \gdw $T_{k}'' + c^{2}
\big(\frac{k\pi}{l}\big)^{2} T_{k} = f_{k}(t)$ und $T_{k}(0) = T_{k}'(0)
= 0$ mit $k\in\N$

Das heißt wir führen die Lösung des Randwertproblem auf eine
Fourierreihenentwicklung und ein Randwertproblem zurück.

% 11.01.06

\minisec{(C) Rand-Anfangswert-Problem}

\begin{align}
  u_{tt} - c^{2}u_{xx} &= f(x,t) &x\in(0,l), t>0\\
  \begin{split}
    u(0,t) &= \mu_{1}(t)\\
    u(l,t) &= \mu_{2}(t)
  \end{split} && t>0 (\text{Randbedingung inhomogen}) \label{eq:32}\\
  \begin{split}
    u(x,0) &= u_{0}(x)\\
    u_{t}(x,0) &= u_{1}(x)
  \end{split} && x\in(0,l) (\text{Anfangsbedingung inhomogen})\\
\end{align}

\minisec{Lösungsmethode}
Ansatz: $u(x,t) = v(x,t) + w(x,t)$, wobei $w(x,t) := \mu_{1}(t) +
\frac{x}{l}(\mu_{2}(t)-\mu_{1}(t))$. $\Rightarrow$ $w(x,t)$ erfüllt die
Randbedingung \autoref{eq:32} und $w_{xx}=0$.

$\Rightarrow$ $u(x,t)$ ist Lösung des Rand-Anfangswert-Problems \gdw
$v$ die neue XY erfüllt.
\begin{gather}\label{eq:33}
  v_{tt}-c^{2}v_{xx} = f(x,t) - w_{tt}(x,t)
\end{gather}

neue Randbedingung:
\begin{gather}\label{eq:34}
  v(0,t) = v(l,t) = 0
\end{gather}

neue Anfangsbedingung:
\begin{align}\label{eq:35}
  v(x,0) &= u_{0}(x) - w(x,0)\\
  v_{t}(x,0) &= u_{1}(x) - w_{t}(x,0)
\end{align}

Dieses neue Rand-Anfangswert-Problem entspricht den Problem (B).

\subsection{Fourierreihen}
\subsubsection{Das trigonometrische System}

Sei $l>0$ und wir betrachten die Funktionen auf dem Intervall $[-l,l]$
(vorzugsweise $l=\pi$) Riemann-integrierbar sind. Wir betrachten diesen
Raum $R([-l,l])$ als einen euklidischen Vektorraum mit
\begin{itemize}
 \item dem Skalarprodukt
  \begin{gather*}
    \sprod{f}{g} := \int_{-l}^{l} f(x) \overline{g(x)}\,dx
  \end{gather*}
  für $f,g\in R([-l,l])$
 \item und der Norm
  \begin{gather*}
    \norm{f} := \sprod{f}{f}^{\frac{1}{2}} = \Big( \int_{-l}^{l}
       \abs{f(x)}^{2}\,dx \Big)
  \end{gather*}
\end{itemize}

Man kann jetzt leicht zeigen, dass all diese Integrale existieren (da
Riemann-integrierbar), das Skalarprodukt alle Bedingungen eines
Skalarprodukts und die Norm alle Bedingungen einer Norm erfüllt. Also ist
$R([-l,l])$ ein normierter linearer Raum.

In einem solchen Raum konvergiert $f_{j}\rightarrow f$ in $R([-l,l])$ \gdw
$\norm{f_{j}-f} = (\int_{-l}^{l} \abs{f_{j}(x) - f(x)}^{2}\,dx
)^{\nicefrac{1}{2}} \xrightarrow{j\rightarrow\infty} 0$.

Wir betrachten ein Orthonormalsystem in dem Raum
\begin{gather*}
  \bigg\{ \underbrace{\frac{1}{\sqrt{2l}}}_{=:\phi_{0}} \bigg\} \cup
     \bigg\{ \underbrace{\frac{1}{\sqrt{l}}\cos\frac{k\pi}{l} x}_{=:\phi_{k}},
       \underbrace{\frac{1}{\sqrt{l}}\sin\frac{k\pi}{l} x}_{=:\psi_{k}}:
       k\in\N\bigg\}
\end{gather*}

d.\,h. es gilt für $j\in\N_{0}, k\in\N$
\begin{align*}
  \sprod{\phi_{j}}{\phi_{k}} &= \delta_{jk} =
     \begin{cases}1&j=k\\0&j\neq k\end{cases}\\
  \sprod{\psi_{j}}{\psi_{k}} &= \delta_{jk}\\
  \sprod{\phi_{j}}{\psi_{k}} &= 0
\end{align*}

Der Wunsch ist nun:
\begin{gather*}
  f = \sprod{f}{\phi_{0}} \phi_{0} + \sum_{k=1}^{\infty}
     (\sprod{f}{\phi_{k}} \phi_{k} + \sprod{f}{\psi_{k}} \psi_{k} )
\end{gather*}
im Sinne der Konvergenz bezüglich $\norm{\cdot}$.

Fourierkoeffizienten: Es ist
\begin{align*}
  \sprod{f}{\phi_{0}}\phi_{0} &= \frac{1}{\sqrt{2l}} \int_{-l}^{l} f(x)
     \frac{1}{\sqrt{2l}}\,dx = \underbrace{\frac{1}{l} \int_{-l}^{l}
     f(x)\,dx}_{=: a_{0}} \cdot \frac{1}{2}\\
  \sprod{f}{\phi_{k}} \phi_{k} &= \frac{1}{\sqrt{l}} \cos\frac{k\pi}{l} x
     \int_{-l}^{l} f(x) \cos\frac{k\pi}{l} x\,dx \cdot \frac{1}{\sqrt{l}}\\
  &= \underbrace{\frac{1}{l} \int_{-l}^{l} \cos \frac{k\pi}{l} x\,dx
     }_{=: a_{k}, k\in\N} \cos\frac{k\pi}{l} x\\
  \sprod{f}{\psi_{k}} \psi_{k} &= \underbrace{\frac{1}{l} \int_{-l}^{l}
     f(x) \sin\frac{k\pi}{l} x\,dx }_{=: b_{k}, k\in\N} \sin
     \frac{k\pi}{l} x
\end{align*}
$a_{k}$ und $b_{k}$ heißen \emph{Fourierkoeffizienten} von $f$.

\emph{Fourierreihe} zur Rekonstruktion der Funktion mithilfe der
Fourierkoeffizienten:
\begin{gather*}
  s_{n}f(x) := \frac{a_{0}}{2} + \sum_{k=1}^{n}\bigg(a_{k}\cos\frac{k\pi}{l} x
     + b_{k} \sin\frac{k\pi}{l} x\bigg)
\end{gather*}
ist die $n$-te Partialsumme der Fourierreihe, wobei $n\in\N_{0}$.

Es gilt (ohne Beweis): $\norm{s_{n}f -f} \xrightarrow{n\rightarrow\infty}
0$, d.\,h.
\begin{gather*}
  \frac{a_{0}}{2} + \sum_{k=1}^{\infty} (a_{k}\cos\frac{k\pi}{l} x
     +b_{k}\sin\frac{k\pi}{l} x) = f
\end{gather*}
im Sinne der Normkonvergenz.

Für Fourierreihen gilt die \emph{Parseval'sche Gleichung}: Es gilt (ohne
Beweis) $f\in R([-l,l])$ $\Rightarrow$ $\norm{f}^{2} =
\abs{\sprod{f}{\phi_{0}}}^{2} + \sum_{k=1}^{\infty}
(\abs{\sprod{f}{\phi_{k}}}^{2} + \abs{\sprod{f}{\psi_{k}}}^{2} )$
d.\,h.
\begin{gather}
  \norm{f}^{2} = l( \frac{\abs{a_{0}}}{2} + \sum_{k=1}^{\infty}
     (\abs{a_{k}}^{2} + \abs{b_{k}}^{2})
\end{gather}
(das ist die Parseval'sche Gleichung)

Stellt man eine weitere Anforderung (Punktweise Konvergenz
$\sum_{k=1}^{\infty} (\abs{a_{k}}+ \abs{b_{k}}) <\infty$) an die
Fourierkoeffizienten, so erhält man eine gleichmäßige Konvergenz für die
Fourierreihe
\begin{gather*}
  \sup_{x\in[-l,l]} \abs{s_{n}f(x) - f(x)}
     \xrightarrow{n\rightarrow\infty} 0
\end{gather*}
da $\sum_{k=1}^{\infty} (\abs{a_{k}}+ \abs{b_{k}}) <\infty$ eine obere
Majorante für die Fourierreihe ist.

Da jedes Folgenglied stetig ist, ist auch $f$ stetig und jedes Folgeglied
periodisch ($f(-l)=f(l)$). Somit muss auch die Funktion periodisch sein: $f\in
C_{perio}([-l,l])$.

Umgekehrung gilt nicht! $\exists f\in C_{perio}([-l,l])$ mit
$(S_{n}f(x_{0})_{n}$ divergent.

Mithilfe weiterer Bedingungen an die Funktion $f$ kann man sichern, dass
die Fourierreihe punktweise konvergiert; z.\,B.: $x_{0}\in[-l,l]$

\begin{gather*}
  \exists f_{+}'(x_{0}) = \lim_{h\downarrow 0} \frac{f(x_{0}+h) -
     f(x_{0}+0)}{h}\\
  \exists f_{-}'(x_{0}) = \lim_{h\downarrow 0} \frac{f(x_{0}-0) -
     f(x_{0}-h)}{h}\\
\end{gather*}

Die Funktion muss nicht stetig und nicht differenzierbar sein, aber es
genügt, wenn sie links- und rechtsseitig differenzierbar ist.

$\Rightarrow$ $\exists\lim_{n\rightarrow\infty} S_{n}f(x_{0}) =
\frac{f(x_{0}+0) + f(x_{0}-0)}{2}$

Man darf Fourierreihen \emph[index=Fourierreihe!differenzieren u.\,%
integrieren,rand=Fourierr.\,diff.\,u.\,int.]{differenzieren \textnormal{und}
integrieren}, falls zusätzliche Bedingungen an die Funktion erfüllt sind.

Sinus-Reihen und Cosinus-Reihen (vgl. \autoref{sec:931}): Betrachten eine
Funktion $f$, die nur auf $[0,l]$ definiert ist. Setzen wir $f$ gerade
($f(-x) = f(x)$) auf $[-l,l]$ fort, so sind die Koeffizienten $b_{k}=0$.
Die Koeffizienten $a_{k}\neq 0$. Die Funktion $f$ ist eine reine
\emph{Cosinus-Reihe}
\begin{gather*}
  f(x) = \frac{a_{0}}{2} + \sum_{k=1}^{\infty} a_{k}\cos \frac{k\pi}{l} x
\end{gather*}

Für eine ungerade Funktion sind die $a_{k}=0$ und die $b_{k}\neq 0$, so
dass sich $f$ als reine \emph{Sinus-Reihe} darstellen lässt.
\begin{gather*}
  f(x) = \sum_{k=1}^{\infty} b_{k}\sin\frac{k\pi}{l} x
\end{gather*}

\begin{bsp}
  $l=\pi$ Hutfunktion
  \begin{gather*}
    f(x) = \begin{cases}
             x & x\in[0,\frac{\pi}{2}]\\
             \pi-x & (\frac{\pi}{2}, \pi]
           \end{cases}
  \end{gather*}
  gesucht ist eine Sinusreihe von $f$ auf $[0,\pi]$

  \begin{align*}
    \Rightarrow
       b_{k} &= \frac{2}{\pi} \int_{0}^{\pi} f(x)\sin kx\,x = \frac{2}{\pi}
       \Big( \int_{0}^{\frac{\pi}{2}} x \sin kx\,dx +
       \int_{\frac{\pi}{2}}^{\pi} (\pi-x\sin kx)\,dx\Big)\\
    &= \frac{2}{\pi} \Big[ -x \frac{\cos kx}{k} \Big]_{0}^{\frac{\pi}{2}}
       + \int_{0}^{\frac{\pi}{2}} \frac{1}{k} \cos kx\,dx + \frac{2}{\pi}
       \Big[-(\pi-x) \frac{\cos kx}{k} \Big]_{\frac{2}{\pi}}^{\pi} -
       \frac{1}{k} \int_{\frac{2}{\pi}}^{\pi} \cos kx\,dx\\
    &= \frac{2}{\pi} \frac{2}{k^{2}} \sin \frac{k\pi}{2} = \frac{4}{\pi
       k^{2}} \begin{cases}0& k\text{ gerade}\\ (-1)^{l}& k\text{
                ungerade} \end{cases}
  \end{align*}

  \begin{gather*}
    \Rightarrow
    f(x) = \frac{4}{\pi} \sum_{l=0}^{\infty} \frac{(-1)^{l}}{(2l+1)^{2}}
       \sin(2l+1)x\qquad x\in[0,\pi]
  \end{gather*}

  für $x=\frac{\pi}{2}$ $\Rightarrow$
  \begin{gather*}
    \frac{\pi}{2} = \frac{4}{\pi} \sum_{l=0}^{\infty}
       \frac{(-1)^{l}}{(2l+1)^{2}} \sin(2l+1) x\qquad x\in[0,\pi]\\
    \frac{\pi^{2}}{8} = \sum_{l=0}^{\infty} \frac{1}{(2l+1)^{2}}
  \end{gather*}
\end{bsp}

% 17.01.06

\subsubsection{Orthonormalbasen im Hilbertraum}

\begin{defini}[Hilbertraum]
  Als \emph{Hilbertraum} $H$ bezeichnet man einen Vektorraum (i.\,A.
  einen unendlichdimensonalen) mit folgenden Eigenschaften
  \begin{itemize}
   \item es ist ein Skalarprodukt $\sprod{f}{g}$ definiert
   \item es gibt eine Norm $\norm{f}=\sprod{f}{f}^{\frac{1}{2}}$
    ($\Rightarrow$ Metrik, Konvergenz)
   \item $H$ vollständig, d.\,h. jede Cauchyfolge ist in $H$ konvergent
  \end{itemize}
\end{defini}

\begin{bemerk}
  Der Raum $R([-l,l])$ aus dem letzten Abschnitt ist nicht vollständig
  bzgl. $\norm{f} = \big(\int_{-l}^{-l} \abs{f(x)}^{2}\,dx
  \big)^{\frac{1}{2}}$. Wir können aber zu dem vollständigen Raum
  $L_{2}([-l,l]) := \{ f\colon \int_{-l}^{-l} \abs{f(x)}^{2}\,dx <\infty\}
  \supset R([-l,l])$ übergehen. Das Integral im $L_{2}$ ist das
  Lebesgue-Integral.
\end{bemerk}

\begin{defini}[Orthonormalbasis]
  Eine Menge $\{v_{j}\}_{j\in J}\subset H$ heißt Orthonormalbasis
  (ONB) \gdwdef
  \begin{itemize}
   \item $\forall j,k\in J\colon \sprod{v_{j}}{v_{k}} = \begin{cases}1&j=k\\
                                                     0&j\neq k
                                                   \end{cases}$
    (Orthonormalsystem/ONS)
   \item $\forall v\in H$ gilt $v=\sum_{j\in J} \sprod{v}{v_{j}} v_{j}$
    konvergent in $H$
  \end{itemize}
\end{defini}

Ein Bespiel für eine Orthonormalbasis ist z.\,B. das trigonometrische
System.

\begin{bemerk}
  $\{ v_{j}\}_{j\in J}$ sei ein Orthonormalsystem. Dann sind äquivalent:
  $\forall v\in H$ gilt $v=\sum_{j\in J} \sprod{v}{v_{j}} v_{j}$
  konvergent in $H$
  \begin{align*}
    &\gdw \norm{v^{2}} = \sum_{j\in J} \abs{\sprod{v}{v_{j}}}^{2}
       &\forall v\in H\\
    &\gdw \forall v\in H\colon \sprod{v}{v_{j}}=0 \forall j\in J \gdw v=0
  \end{align*}
\end{bemerk}

\subsection{Die Wärmeleitungsgleichung}

Rand-Anfangswert-Problem:
\begin{flalign}
  \label{eq:36} u_{t} - u_{xx} &= f(x,t)  &x\in(0,\pi), t>0\\
  \label{eq:37} u(0,t) &= \mu_{1}(t), u(\pi,t) = \mu_{2}(t) &t>0\\
  \label{eq:38} u(x,0) &= u_{0}(x) &x\in(0,\pi)
\end{flalign}
\autoref{eq:36} partielle DGL, \autoref{eq:37} Randbedingung,
\autoref{eq:38} Anfangsbedingung

\minisec{(A) $f(x,t)=0, \mu_{1}(t) = \mu_{2}(t)=0$}
\begin{enumerate}
 \item Separation: Finde alle $u(x,t)= X(x)T(t)$ mit \autoref{eq:36} und
  \autoref{eq:37}. Analog zu \autoref{sec:931}.
  \begin{enumerate}
   \item \label{enu:4} $X'' -\lambda X =0$ und $X(0) = X(\pi)=0$
    (Bestimme alle $\lambda, X$)

    Lösung: $\lambda_{k}=-k^{2} (k\in\N), X_{k}=c_{k}\sin kx$
   \item $T'-\lambda T=0$ für alle $\lambda$ aus \autoref{enu:4}.

    Lösung: $T' = -k^{2}T, T_{k}(t) = d_{k}e^{-k^{2}t}$ wobei $k\in\N$
  \end{enumerate}

  Lösung: $k\in\N$ $u_{k}(x,t) = b_{k}\sin kxe^{-k^{2}t}$
 \item Superposition: Bestimme $b_{k}\in\C$, so dass
  \begin{gather*}
    u(x,t) := \sum_{k=1}^{\infty} b_{k}\sin kx e^{-k^{2}t}\\
    u_{0}(x) = \sum_{k=1}^{\infty} b_{k} \sin kx
  \end{gather*}
  Das haben wir bereits gelöst. Die $b_{k}$ müssen die
  Fourierkoeffizienten sein.
  \begin{gather*}
    b_{k} = \frac{2}{\pi} \int_{0}^{\pi} u_{0}(x)\sin kx\,dx
  \end{gather*}
\end{enumerate}

% Ich kann kein B.1 finden. Daher in B geaendert.
\minisec{(B) $f(x,t)\neq 0, \mu_{1}(t) =\mu_{2}(t)=0, u_{0}(x) =0$}
Ansatz:
\begin{gather*}
  u(x,t) = \sum_{k=1}^{\infty} T_{k}(t) \sin kx
\end{gather*}
dazu:
\begin{gather*}
  f(x,t) = \sum_{k=1}^{\infty} f_{k}(t) \sin kx
\end{gather*}
für festes $t$ mit $f_{k}$ als Fourierkoeffizienten
\begin{gather*}
  f_{k}(t) = \frac{2}{\pi} \int_{0}^{\pi} f(x,t) \sin kx\,dx
\end{gather*}

$u(x,t)$ ist Lösung, falls: $T_{k}' + k^{2} T_{k} = f_{k}(t)$ und
$T_{k}(0) = 0$ für $k\in\N$.

\minisec{(C) allgemeiner Fall}
Wie \autoref{sec:931} und in den Übungen.

\subsection{Die Laplace-Poisson-Gleichung}

Dirichlet-Problem:
\begin{gather*}
  \Delta u=f\quad\text{auf $\Omega\subset\R$ beschränkt}\\
  u\big|_{\partial \Omega} = g \qquad\text{(Randbedingung)}
\end{gather*}

Modellfall $n=2$ und $\Omega= (0,\pi)\times(0,\pi)$
\todo{Bildchen für die Nummerierung der Randstücke link $\Gamma_{1}$,
  unten $\Gamma_{3}$, rechts $\Gamma_{2}$, oben $\Gamma_{4}$},
$\partial\Omega = \Gamma_{1}\cup\ldots \cup\Gamma_{4}$.

\minisec{(A) $f=0$ Laplace-Gleichung}
\begin{gather}\label{eq:39}
  \Delta u(x,y) = 0\quad(x,y) \in (0,\pi)\times(0,\pi)\\
  \label{eq:40} u(0,y) = u(\pi,y) =0\quad y\in[0,\pi]\\
  \label{eq:41} u(x,0) =0, u(x,\pi) = g(x)\quad x\in[0,\pi]
\end{gather}
$u$ ist also Null auf $\Gamma_{1}, \Gamma_{2}$ (\autoref{eq:40}) und
$\Gamma_{3}$ (\autoref{eq:41}).

\begin{enumerate}
 \item Separation: Finde $u(x,y) = X(x) Y(y)$ mit \autoref{eq:39} und
  \autoref{eq:40}, sowie $u(x,0) = 0$ aus \autoref{eq:41}.

  \begin{enumerate}
   \item $X'' -\lambda X=0$ und $X(0) = X(\pi)=0$
   \item $Y''+\lambda Y=0$ und $Y(0)=0$
  \end{enumerate}

  Lösung: $u_{k}(x,y) = b_{k}\sin kx \sinh ky$ mit $k\in\N$
 \item Superposition: Bestimme $b_{k}$, so dass
  \begin{gather*}
    u(x,y) = \sum_{k=1}^{\infty} b_{k} \sin kx \sinh ky
  \end{gather*}
  eine Lösung von (A) sind. \gdw
  \begin{align*}
    u(x,\pi) &= \sum_{k=1}^{\infty} b_{k}\sinh k\pi \sin kx = g(x)
       &x\in[0,\pi]\\
    \gdw b_{k} \sinh k\pi &= \frac{2}{\pi} \int_{0}^{\pi} g(x) \sin
       kx\,dx &k\in\N
  \end{align*}
  siehe Übungsaufgaben 6+7 in Serie 39.
\end{enumerate}

\minisec{(B) Die Poisson-Gleichung: $f\neq 0, g=0$}
\begin{gather}\label{eq:42}
  -\Delta u(x,y) = f\quad\text{auf $\Omega$}\\
  \label{eq:43} u\big|_{\partial\Omega} =0
\end{gather}

Idee: $f=\sum_{j} a_{j} u_{j}$, wobei $(u_{j})_{j}$ sind ein
Orthonormalsystem bzgl. $\sprod{u}{v} = \int_{\Omega}
u(x)\overline{v(x)}\,dx$, d.\,h. $a_{j} = \sprod{f}{u_{j}}$.

Lösungsansatz:
\begin{gather*}
  u=\sum_{j=1}^{\infty} b_{j} u_{j}
\end{gather*}
$u$ erfüllt \autoref{eq:42} und \autoref{eq:43} \gdw
\begin{gather*}
  \sum_{j=1}^{\infty} b_{j}\Delta u_{j} = \sum_{j=1}^{\infty} a_{j} u_{j}\\
  u_{j}\big|_{\partial\Omega} =0\quad \forall j\in\N
\end{gather*}
erfüllt, falls:
\begin{gather*}
  -\Delta u_{j} = \frac{a_{j}}{b_{j}} u_{j}\quad j\in J\\
  u_{j}\big|_{\partial\Omega} =0
\end{gather*}
d.\,h. $\lambda_{j}=\frac{a_{j}}{b_{j}}$ ist ein Eigenwert und $u_{j}$
zugehörige Eigenfunktion.

Lösungsmethode:
\begin{enumerate}
 \item Eigenwerte und Eigenfunktionen:
  \begin{gather*}
    -\delta u =\lambda u\\
    u_{j}\big|_{\partial\Omega} =0
  \end{gather*}
  $\Rightarrow$ $(\lambda_{j})_{j}$ Eigenwerte und $u_{j}$
  Eigenfunktionen und $(u_{j})_{j}$ ist ein Orthonormalsystem.
 \item Superposition
  \begin{gather*}
    f= \sum_{j=1}^{\infty} \sprod{f}{u_{j}} u_{j}
  \end{gather*}
  $\Rightarrow$
  \begin{gather*}
    u(x) = \sum_{j=1}^{\infty} \frac{\sprod{f}{u_{j}}}{\lambda_{j}} u_{j}
  \end{gather*}
  ist Lösung.
\end{enumerate}

\begin{bsp}
  \begin{gather*}
    \Omega = (0,\pi)\times(0,\pi)\\
    -\Delta u = f\\
    u_{j}\big|_{\partial\Omega} =0
  \end{gather*}

  \begin{enumerate}
   \item Eigenwerte und Eigenfunktionen:
    \begin{gather*}
      -\Delta u =\lambda u\\
      u_{j}\big|_{\partial\Omega} =0
    \end{gather*}

    Wir machen wieder für die Separation den Ansatz $u(x,y) = X(x) Y(y)$
    mit $X(0) = X(\pi) = 0$ und $Y(0) = Y(\pi) =0$ und bekommen die zwei
    Teilproblem:
    \begin{enumerate}
     \item\label{enu:5} $Y'' -\mu Y=0$ und $Y(0) = Y(\pi) = 0$ für alle
      $\mu$.

      \underline{Lösung:}
      \begin{align*}
        u &= -n^{2} &n\in\N\\
        Y_{n} &= c_{n} \sin ny &n\in\N
      \end{align*}

     \item $X'' + (\lambda+\mu) X =0$ und $X(0) = X(\pi) = 0$ für $\mu$
      aus \autoref{enu:5}.

      \underline{Lösung:}
      \begin{align*}
        X'' + (\lambda-n^{2}) X &=0\\
        X(0) = X(\pi) &= 0
      \end{align*}
      \gdw für jedes $n$ gilt: $-(\lambda-n^{2}) = -m^{2}$ mit beliebigem
      $m\in \N$ oder anders geschrieben: $\lambda_{m,n} = m^{2}+n^{2}$.

      $X_{m} = d_{n}\sin mx$
    \end{enumerate}

    $\Rightarrow$ Eigenwerte: $\lambda_{m,n} = m^{2}+n^{2}$ ($m,n\in \N$)
    und Eigenfunktionen $u_{m,n}(x,y) = b_{m,n} \sin mx \sin ny$

   \item Superposition: Es ist leicht zu sehen, dass sich die beiden
    Sinusterme orthogonal zueinander sind und wir können in eine
    Doppelreihe entwickeln.
    \begin{gather*}
      f(x,y) = \sum_{m=1}^{\infty} \sum_{n=1}^{\infty} b_{m,n} \sin mx
         \sin ny \gdw\\
      b_{m,n} = \frac{4}{\pi^{2}} \int_{0}^{\pi}\int_{0}^{\pi} f(x,y)
         \sin mx \sin ny\,dx dy
    \end{gather*}
    \begin{gather*}
      \Rightarrow
      u(x,y) = \sum_{m=1}^{\infty} \sum_{n=1}^{\infty}
         \frac{b_{m,n}}{m^{2}+n^{2}} \sin mx \sin ny
    \end{gather*}
  \end{enumerate}
\end{bsp}

% 18.1.06
\chapter{Komplexe Funktionen}
\section{Komplexe Differenzierbarkeit}
\subsection{Definition und Grundregeln}

\begin{bemerk}
  \begin{enumerate}
   \item
    \begin{itemize}
     \item Wir kennen bereits den vollständig normierten Raum der
      komplexen Zahlen $(\C, \abs{\cdot})$.
     \item topologische Grundbegriffe: offen, abgeschlossen, kompakt,
      Rand, Häufungspunkt
     \item Konvergenz und Grenzwert für Folgen und Reihen
    \end{itemize}
   \item Eine Funktion $f\colon G\rightarrow\C$ mit dem Wertebereich
    $G\subset\C$ offen nennen wir eine \emph{komplexe Funktion}. Bereits
    bekannt ist: $\lim_{z\rightarrow z_{0}} f(z)$, $f$ stetig in $z_{0}$,
    Sätze über stetige Funktionen

    $f(z) = \Re f(z) + i\Im f(z)$, Vereinbarung: für $z=x+iy$ kann man
    schreiben:
    \begin{gather*}
      f(x+iy) = u(x,y) + i v(x,y)
    \end{gather*}
    wobei $u,v\colon G\subset\R^{2} \rightarrow \R$. Die Menge $\{ (x,y)
    \colon x+iy\in G\subset\C\} = \tilde{G} \subset \R^{2}$ kann auch mit
    einer Menge von komplexen Zahlen identifiziert werden ($\cong G$). Wir
    fassen also $G$ als Gebiet im $\R^{2}$ und in $\C$ auf.
  \end{enumerate}
\end{bemerk}

\begin{bsp}
  \begin{enumerate}
   \item $f(z) = z^{2} = (x+iy)^{2} = x^{2}-y^{2} + i2xy$ -- Strahlen
    werden auf Strahlen abgebildet, Sektoren auf Sektoren
   \item für $z\neq 0$ sei $f(z) = \frac{1}{z} =
    \frac{x-iy}{x^{2}+y^{2}}$ -- Kreise werden auf Kreise abgebildet
   \item $f(z) = e^{z} = \sum_{k=0}^{\infty} \frac{z^{k}}{k!} =
    1+z+\frac{z^{2}}{2} + \ldots = e^{x}\cos y + i e^{x} \sin y$ -- Ein
    Streifen der Breite $2\pi i$ wird auf die komplexe Ebene ohne den
    Nullpunkt abgebildet.
  \end{enumerate}
\end{bsp}

\begin{defini}\label{def:1011-3}
  Wir betrachten eine Menge $D\subset\C$ und einen inneren Punkt
  $z_{0}\in D^{0}\neq \emptyset$. Wir nennen $f$
  \emph[rand=komplexdiff'bar]{komplex differenzierbar} in $z_{0}$ \gdwdef
  der Grenzwert des Differenzenquotient existiert und eine komplexe Zahl
  ist. Diesen Grenzwert bezeichnen wir dann als \emph[index=komplexe
  Funktion!Ableitung]{Ableitung} von $f$ an der Stelle $z_{0}$.
  \begin{gather*}
    \exists\lim_{z\rightarrow z_{0}} \frac{f(z) -f(z_{0})}{z-z_{0}}\in \C
       \quad\Longrightarrow\quad
       f'(z_{0}) = \lim_{z\rightarrow z_{0}} \frac{f(z) -
       f(z_{0})}{z-z_{0}} 
  \end{gather*}
\end{defini}

\begin{bsp}
  \begin{enumerate}
   \item $f(z) = z^{n}$ für $n\in\N$ $\Rightarrow$ $f'(z) = n z^{n-1}$
    $\forall z$
   \item $f(z) = \frac{1}{z}$ ist komplex differenzierbar in allen Punkten
    $z\neq 0$, $f'(z) = -\frac{1}{z^{2}}$
   \item $f(z) = \Re z$ nirgends komplex differenzierbar: läuft man auf
    der Geraden $z=x+iy_{0}$ auf $z_{0}$ zu, so ergibt sich für den
    Differenzenquotienten $\frac{f(z) - f(z_{0}) }{z-z_{0}} =
    \frac{x-x_{0}}{x-x_{0}} =1$. Nähert man sich dem Punkt auf der
    Geraden $z=x_{0}+iy$ erhält man für den Differenzenquotienten
    $\frac{f(z) - f(z_{0}) }{z-z_{0}} = \frac{x_{0}-x_{0}}{y-y_{0}} = 0$.
    Die beiden Grenzwerte sind nicht gleich und damit existiert der Limes
    nicht.
   \item $f(z) = e^{z}$ komplex differenzierbar, $(e^{z})' = e^{z}$
    \begin{gather*}
      e^{z} -e^{z_{0}} = e^{z_{0}}(e^{z-z_{0}} -1) = e^{z_{0}}
         \sum_{k=1}^{\infty} \frac{(z-z_{0})^{k}}{k!} = e^{z_{0}}
         (z-z_{0}) \underbrace{\sum_{k=1}^{\infty}
         \frac{(z-z_{0})^{k-1}}{k!}}_{\xrightarrow{z\rightarrow z_{0}} 1}
    \end{gather*}
  \end{enumerate}
\end{bsp}

\begin{satz}\label{satz:1011-5}
  Sei $f$ wie in \autoref{def:1011-3}. Dann sind folgende Aussagen
  äquivalent:
  \begin{enumerate}
   \item $f$ ist komplex differenzierbar in $z_{0}$
   \item $\exists c\in\C$ und $\frac{f(z)-f(z_{0}) - c(z-z_{0})}{z-z_{0}}
    \xrightarrow{z\rightarrow z_{0}} 0$. Dann ist $c = f'(z_{0})$.
   \item $\exists h\colon D\rightarrow \C$ stetig in $z_{0}$ mit $f(z) =
    f(z_{0}) + h(z)(z-z_{0})$ (Differenzenquotienten anders
    aufgeschrieben). Dann ist $f'(z_{0}) = h(z_{0})$.
  \end{enumerate}

  \begin{proof}
    wie im reellen Fall.
  \end{proof}
\end{satz}

\begin{folger}
  Wenn $f$ differenzierbar in $z_{0}$, dann ist $f$ auch stetig in
  $z_{0}$.
\end{folger}

\begin{bemerk}
  Wie im reellen Fall gelten die bekannten Differentiationsregeln:
  \begin{itemize}
   \item $(f+g)' = f'+g'$
   \item $(f\cdot g)'=f'g+fg'$
   \item $(\frac{f}{g})' = \frac{f'g-fg'}{g^{2}}$
   \item $(f\circ g)' = f'(g) g'$
  \end{itemize}
\end{bemerk}

\subsection{Die Cauchy-Riemannschen Differentationsgleichungen}

Sei $f\colon D\rightarrow\C$, $f(x+iy) = u(x,y) + i v(x,y)$ mit $u,v\colon
D\rightarrow\R, D\subset\R^{2}$

\begin{satz}\label{satz:1012-1}
  Ist $f$  wie oben gegeben und $z_{0} = x_{0}+iy_{0}\in
  D^{0}\neq\emptyset$, dann gilt:
  \begin{enumerate}
   \item $f$ komplex differenzierbar in $z_{0}$ \gdw $u,v$ sind (total)
    differenzierbar in $(x_{0},y_{0})$ und es gelten die
    Cauchy-Riemannschen Differentialgleichungen
    \begin{align*}
      u_{x}(x_{0},y_{0}) &= v_{y}(x_{0}, y_{0})\\
      u_{y}(x_{0}, y_{0}) &= -v_{x}(x_{0}, y_{0})
    \end{align*}

   \item Wenn $f$ differenzierbar in $z_{0}=x_{0}+iy_{0}$, dann ist
    \begin{align*}
      f'(z_{0}) &= u_{x}(x_{0},y_{0}) + i v_{x}(x_{0},y_{0})\\
      &= v_{y}(x_{0}, y_{0}) - i u_{y}(x_{0},y_{0})
    \end{align*}
  \end{enumerate}

  \begin{proof}
    zur Erinnerung: In Definition 5.3.1/10 hatten wir festgelegt, dass eine
    Funktion $u$ (total) differenzierbar in einem Punkt $(x_{0},y_{0})$
    heißt, wenn es $a_{1}, a_{2}$ gibt, so dass
    \begin{gather*}
      \frac{u(x,y) - u(x_{0}, y_{0}) - \big(a_{1}(x-x_{0}) +
         a_{2}(y-y_{0}) \big)}{\norm{(x,y) - (x_{0},y_{0})}}
         \xrightarrow{(x,y)\rightarrow(x_{0},y_{0})} 0
    \end{gather*}
    und $a_{1}= u_{x}(x_{0},y_{0}, a_{2} = u_{y}(x_{0},y_{0})$.

    Aus \autoref{satz:1011-5} folgt: $f$ ist differenzierbar in $z_{0}$
    genau dann, wenn es eine komplexe Zahl $c\in\C$ gibt und
    \begin{gather*}
      \abs{\frac{ f(z)-f(z_{0}) - c(z-z_{0})}{z-z_{0}}}
         \xrightarrow{z\rightarrow z_{0}}0
    \end{gather*}
    Für $c=a+ib$ ergibt sich so
    \begin{gather*}
      \abs{\frac{ u(x,y)+ iv(x,y) - u(x_{0}, y_{0}) - iv(x_{0},y_{0}) -
         (a+ib) (x-x_{0}+i(y-y_{0}))}{\norm{(x,y)-(x_{0},y_{0})}}}
         \xrightarrow{(x,y)\rightarrow(x_{0},y_{0})} 0
    \end{gather*}

    Etwas umformuliert dargestellt: $\exists a,b\in\R$
    \begin{gather*}
      \frac{u(x,y) - u(x_{0},y_{0}) - \big(a(x-x_{0}) - b(y-y_{0})\big)}
         {\norm{(x,y)-(x_{0},y_{0})}}
         + i \frac{v(x,y) - v(x_{0},y_{0}) - \big(b(x-x_{0}) +
         a(y-y_{0})\big)}{\norm{(x,y)-(x_{0},y_{0})}}
    \end{gather*}
    Dies gilt wiederum, wenn $u$ und $v$ differenzierbar in
    $(x_{0},y_{0})$ sind.

    Außerdem liefert dies gleich die partielle Ableitungen
    \begin{align*}
      a &= u_{x}(x_{0},y_{0}) & b&= v_{x}(x_{0}, y_{0})\\
      -b &= u_{y}(x_{0},y_{0}) & a &= v_{y}(x_{0},y_{0})
    \end{align*}

    Der Punkt (2) ergibt sich aus $f'(z_{0}) = c = a+ib$
  \end{proof}
\end{satz}

\begin{defini}
  \begin{enumerate}
   \item Eine Funktion $f\colon D \rightarrow \C$ ($D\subset\C$ und offen)
    heißt \emph{holomorph} in $z_{0}\in D$ \gdwdef $f$ ist
    komplex differenzierbar in einer Umgebung $K_{\delta}(z_{0}) = \{ z\colon
    \abs{z-z_{0}}<\delta\}$.
   \item Eine Funktion $f\colon D \rightarrow \C$ ($D\subset\C$ und offen)
    heißt \emph{holomorph} \gdwdef $f$ ist holomorph in \textit{jedem}
    Punkt $z\in D$. (\gdw $f$ ist komplex differenzierbar in jedem Punkt
    von $D$)
  \end{enumerate}
\end{defini}

\begin{folger}
  \begin{enumerate}
   \item Sei $f$ differenzierbar in $z_{0}=x_{0}+iy_{0} \Rightarrow$ Es
    gelten die Cauchy-Riemannschen Differentialgleichungen in
    $(x_{0},y_{0})$ (eine notwendige Bedingung für Differenzierbarkeit)
   \item Seien $u$ und $v$ stetig differenzierbar in $(x_{0},y_{0})$ und
    es gelten die Cauchy-Riemannschen Differentialgleichungen
    $\Rightarrow$ $f$ ist differenzierbar in $z_{0} = x_{0}+iy_{0}$ (eine
    hinreichende Bedingung für Differenzierbarkeit)
   \item $f$ holomorph in $G\subset\C$ und $u,v\in C^{2}(G)$
    $\Rightarrow$ $u$ und $v$ sind harmonische Funktionen: $\Delta u =
    \Delta v = 0$ auf $G$ (eine notwendige Bedingung für
    Differenzierbarkeit)
  \end{enumerate}

  \begin{proof}
    nur von (3): Aus \autoref{satz:1012-1} folgt, dass die
    Cauchy-Riemannsche Differentialgleichungen gelten, falls $f$
    holomorph ist
    \begin{gather*}
      \begin{split}
        u_{x} &= v_{y}\\ u_{y} = -v_{x}
      \end{split}
         \Rightarrow
         \begin{split}
           u_{xx} &= v_{yx}\\ u_{yy} = -v_{xy}
         \end{split}
    \end{gather*}
    Nach dem Satz von Schwarz sind die Ableitungen gleich $v_{xy} =
    v_{yx}$ und es ergibt sich $\Delta u=u_{xx} + u_{yy} = 0$.

    Analog folgt mit der Ableitung von $u$ nach $y$ und $v$ nach $x$,
    dass $\Delta y=0$.
  \end{proof}
\end{folger}

% 24.1.06

\begin{bemerk}
  \begin{enumerate}
   \item $f(z) = \overline{z}$ ist nirgends differenzierbar\\
    $f(z) = x-iy$ $\Rightarrow$ $u_{x}=1 \neq v_{y} =-1$
   \item $f(z) = \abs{z}^{2} = x^{2}+y^{2}$ ist differenzierbar in $z=0$,
    aber sie ist nirgends holomorph\\
    Cauchy-Riemannsche Differentialgleichungen:
    \begin{gather*}
      u_{x} = 2x = v_{y} = 0 \Leftrightarrow x=0\\
      u_{y} = 2y = -v_{x} = 0 \Leftrightarrow y=0
    \end{gather*}
   \item Wenn $u$ und $v$ harmonische Funktionen sind, dann ist die
    Funktion $u+iv$ i.\,A. nicht holomorph. Beispiel: $u=x, v=-y$, d.\,h.
    $u+iv = x-iy = \overline{z}$ nirgends holomorph nach Bemerkung (1).
    Aber $\Delta u=\Delta v=0$ auf $\R^{2}$.
  \end{enumerate}
\end{bemerk}

\begin{satz}
  Wir betrachten ein sternförmiges Gebiet $G\subset \C$, d.\,h. $G$ ist
  offen und es gibt einen Punkt $z_{0}$, so dass für jeden Punkt $z\in G$
  die Verbindungsgerade $[z_{0}, z]\in G$. Zusätzlich sei $u(x,y)$
  harmonisch auf $G$.

  Dann existiert eine harmonische Funktion $v(x,y)$ auf $G$, so dass
  $f(x+iy) := u(x,y) + iv(x,y)$ harmonisch auf $G$ ist. Man nennt $v$ die
  \emph{konjungierte harmonische Funktion} zu $u$.

  \begin{proof}
    Betrachten auf $G$ das Vektorfeld
    $\begin{bmatrix}-u_{y}(x,y)\\u_{x}(x,y)\end{bmatrix}$ (da $u$
    harmonisch ist, ist dies ein $C^{\infty}$-Vektorfeld). Da $u$
    harmonisch ist, ist die Summe $u_{xx} + u_{yy} =0$, also
    $(-u_{y})_{y} = (u_{x})_{x}$, woraus wiederum nach
    \autoref{satz:VFaequi} folgt, dass $\begin{bmatrix}-u_{y}\\u_{x}\end{bmatrix}$
    konservativ ist. Also existiert ein $v$ mit $\grad
    v=\begin{bmatrix}-u_{y}\\u_{x}\end{bmatrix}$ $\Rightarrow$ $\Delta v
    = \Div \grad v = -u_{yx}+u_{xy} = 0$ (nach Satz von Schwarz).

    Außerdem ist $v_{x} = -u_{y}$ und $v_{y} = u_{x}$, d.\,h. die
    Cauchy-Riemannsche Differentialgleichungen gelten und somit ist
    $u+iv$ harmonisch.
  \end{proof}
\end{satz}

\begin{satz}[Potenzreihen als harmonische
  Funktionen]\label{satz:10.1.2/6}
  Es sei $f(z) := \sum_{k=0}^{\infty} a_{k}(z-z_{0})^{k}$ für
  $\abs{z-z_{0}}<R$ ($R$ \emph{Konvergenzradius} der Potenzreihe).

  Dann gilt:
  \begin{enumerate}
   \item $f$ ist beliebig oft komplex differenzierbar (insbesondere ist
    sie damit holomorph auf $D = \{ z\big| \abs{z-z_{0}}<R \}$ und
    $f^{(j)}(z) = \sum_{k=0}^{\infty} a_{k} k(k-1)\ldots
    (k-j+1)(z-z_{0})^{k-j}$.
   \item Für alle $k\in\N_{0}$ gilt: $a_{k} =\frac{f^{(k)}(z_{0})}{k!}$
  \end{enumerate}

  \begin{proof}
    \obda sei $z_{0}=0$.
    \begin{gather*}
      g(z) := \sum_{k=0}^{\infty} k a_{k} z^{k-1}
         \quad\text{absolut konvergent in $D$ (d.\,h.
         $\sqrt[k]{k}\rightarrow 1$)}
    \end{gather*}
    Wir wählen ein festes $z\in D$ und beschränken unsere Betrachtungen
    auf ein $K_{\delta}$ mit $\overline{K_{\delta}(z)}\subseteq D$.
    Weiterhin gibt es ein $\rho<R$ mit $\abs{w} \leq \rho$ für $w\in
    K_{\delta}(z)$.

    \begin{gather*}
      \Rightarrow
      \abs[\Big]{\frac{f(w)-f(z)}{w-z} - g(z)} =
         \abs[\Big]{\sum_{k=1}^{\infty} a_{k} \frac{w^{k}-z^{k}}{w-z} -
         ka_{k}z^{k-1} }
    \end{gather*}
    ($\frac{w^{k}-z^{k}}{w-z}$ ist der Differenzenquotient von $z$ und
    wird für $w\rightarrow z$ gegen die Ableitung $z'$ konvergieren, da
    $z$ harmonisch).

    Es gilt: $(w^{k}-z^{k}) = (w-z)(\underbrace{w^{k-1}+w^{k-2}z+\ldots+w
    z^{k-2}+z^{k-1}}_{\text{$k$-Summanden}}) \Rightarrow
    \frac{w^{k}-z^{k}}{w-z} \xrightarrow{w\rightarrow z} kz^{k-1}$

    \begin{align*}
      \abs{\frac{w^{k}-z^{k}}{w-z}} &= \abs{w^{k-1} + w^{k-2}z +\ldots+ w
         z^{k-2}+z^{k-1}}\\
      &\leq k\rho^{k-1}&\text{für $k\in K_{\delta}(z)$}
    \end{align*}

    \begin{align*}
      \abs[\Big]{\frac{f(w)-f(z)}{w-z} - g(z)} &\leq
         \sum_{k=1}^{n} \abs{a_{k}} \abs{\frac{w^{k}-z^{k}}{w-z}
         -kz^{k-1} } + \sum_{k=n+1}^{\infty} \abs{a_{k}}
         \abs{\frac{w^{k}-z^{k}}{w-z} -kz^{k-1} }\\
      &\leq \sum_{k=1}^{n} \abs{a_{k}} \abs{\frac{w^{k}-z^{k}}{w-z}
         -kz^{k-1} } + 2\sum_{k=n+1}^{\infty} \abs{a_{k}} k\rho^{k-1}
    \end{align*}
    für hinreichend großes $n\geq n_{0}(\epsilon)$ lässt sich der zweite
    Summand beliebig klein machen. Für den ersten Summanden, kann man den
    Betrag $\abs{\frac{w^{k}-z^{k}}{w-z}-kz^{k-1} }$ durch $\epsilon
    (\sum_{k=1}^{n}\abs{a_{k}})^{-1}$ abschätzen für $\abs{z-w}
    <\delta(\epsilon)$. Damit kann die gesamte Summe durch $2\epsilon$
    abgeschätzt werden.
  \end{proof}
\end{satz}

\begin{defini}[Komplexe trigonometrische Funktionen]
  Für eine komplexe Zahl $z\in\C$ sind die trigonometrischen Funktionen
  wie folgt definiert:
  \begin{align*}
   \cos z &:= \frac{e^{iz}+e^{-iz}}{2}&
       \sin z &:= \frac{e^{iz} - e^{-iz}}{2i}\\
   \cosh z &:= \frac{e^{z} + e^{-z}}{2}&
       \sinh z &:=\frac{e^{z}-e^{-z}}{2}
  \end{align*}
  Da die Exponentionalfunktion eine harmonische Funktion ist, sind die
  trigonometrischen Funktionen ebenfalls harmonisch.
\end{defini}

\begin{folger}
  Folgende Zusammenhänge bestehen zwischen den komplexen
  trigonometrischen Funktionen:
  \begin{align*}
   \cosh iz &= \cos z& \sinh iz &= i\sin z\\
   (\cos z)' &= -\sin z& (\sin z)' &= \cos z\\
   (\cosh z)' &= \sinh z& (\sinh z)' &= \cosh z\\
   \cosh z &= \sum_{k=0}^{\infty} \frac{z^{2k}}{(2k)!}&
       \sinh z &= \sum_{k=0}^{\infty} \frac{z^{2k+1}}{(2k+1)!}
  \end{align*}
\end{folger}

\section{Integration}
\subsection{Komplexe Kurvenintegrale}

Zu Beginn einige Wiederholungen:
\begin{bemerk}
  Kurven in $\C$ (oder $\R^{2}$) vergleiche mit Abschnitt 7.2 und \autoref{sec:8.1.2}
  \begin{itemize}
   \item $(\Gamma,g)$ glatte (Jordan-)Kurve mit $g$ in
    Parameterdarstellung $g\colon[a,b] \rightarrow \C$ stetig differenzierbar
    (für Jordan-Kurve zusätzlich injektiv auf $(a,b)$), mit komplexen
    Zahlen können wir $g$ auch als $g(t) = \alpha(t) + i\beta(t)$
    schreiben.

    Zusätzlich verlangen wir, dass die Ableitung $\dot{g}(t) =
    \dot{\alpha}(t) + i\dot{\beta}(t) \neq 0$ für $t\in(a,b)$.
   \item zulässige Parameterdarstellung: $h\colon[c,d] \rightarrow \C$ heißt
    zulässig \gdw $h$ stetig differenzierbar und $g(t) = h(\mu(t))$ mit
    $\mu'(t)>0$.
   \item Als eine stückweise glatte Kurve bezeichnet man eine Kurve
    $\Gamma$, die sich aus endlich vielen glatten Teilstücken
    $\Gamma_{j}$ zusammensetzt:
    \begin{gather*}
      \Gamma = \sum_{j=1}^{n} \Gamma_{j}
    \end{gather*}
  \end{itemize}
\end{bemerk}

% 25.1.06

\begin{defini}\label{def:2}
  $G\subseteq \C$ offen, $f\colon G\rightarrow\C$
  \begin{enumerate}
   \item $\Gamma = (\Gamma,g)$ glatte Kurve (Parameterdarstellung
    $g\colon[a,b] \rightarrow G$ stetig differenzierbar, $\dot{g}(t)
    \neq 0$
    auf $(a,b)$)
    \begin{gather*}
      \int_{\Gamma} f(z)\,dz := \int_{a}^{b} \underbrace{f
         \big(g(t)\big)\cdot\dot{g}(t)}_{=: h(t)}\,dt
         = \int_{a}^{b} \Re h(t)\,dt + i\int_{a}^{b} \Im h(t)\,dt\\
      L(\Gamma) := \int_{a}^{b} \abs{\dot{g}(t)}\,dt = \int_{a}^{b}
         \sqrt{\dot{\alpha}(t)^{2} + \dot{\beta}(t)^{2}} dt\qquad g(t) =
         \alpha(t)+i\beta(t)
    \end{gather*}
    $h$ ist stetig $\Rightarrow$ Riemannintegral existiert

    $L$ heißt \emph[index=Länge einer Kurve]{Länge} von $\Gamma$

   \item $\Gamma = \sum_{j=1}^{n} \Gamma_{j}$ stückweise glatte Kurve in
    $G$:
    \begin{gather*}
      \int_{\Gamma} f(z)\,dz := \sum_{j=1}^{n} \int_{\Gamma_{j}} f(z)\,dz\\
      L(\Gamma) := \sum_{j=1}^{n} L(\Gamma_{j})
    \end{gather*}
  \end{enumerate}
\end{defini}

\begin{bemerk}
  \autoref{def:2} ist unabhängig von der Auswahl der zulässigen
  Parameterdarstellung. (\todo{Übungsaufgabe})
\end{bemerk}

\begin{bsp}[fundamentales Beispiel für komplexe
  Kurvenintegrale]\label{bsp:10.2.1/4}
  $\Gamma$ soll ein Kreis um $z_{0}\in\C$ mit positivem Umlaufsinn sein.
  Parameterdarstellung der Kurve: $g(t) = z = z_{0}+R e^{it}$
  $\Rightarrow$ $z-z_{0} = Re^{it}$ mit $t\in[0,2\pi]$.
  \begin{gather*}
    \int_{\Gamma} (z-z_{0})^{n}\,dz = \oint_{\abs{z-z_{0}}=R}
       (z-z_{0})^{n}\,dz = \int_{0}^{2\pi} R^{n}e^{int} Rie^{it}\,dt =
       iR^{n+1} \int_{0}^{2\pi} e^{i(n+1)t}\,dt =
       \begin{cases}2\pi i& n=-1\\0&n\neq -1\end{cases}
  \end{gather*}
\end{bsp}

\begin{bemerk}[Zurückführung auf Kurvenintegrale 2.\,Art im $\R^{2}$]
  $z=x+iy = g(t) = \alpha(t)+i\beta(t), f(z) = f(x+iy) = u(x,y) + iv(x,y)$
  \begin{align}
    \int_{\Gamma} f(z)\,dz &= \int_{a}^{b} \big( u(\alpha(t), \beta(t)) +
       iv(\alpha(t), \beta(t))\big)\cdot
       \big(\dot{\alpha}(t)+i\dot{\beta}(t)\big)\,dt\notag\\
    &= \int_{a}^{b} \big( u(\alpha(t), \beta(t))\dot{\alpha}(t) -
       v(\alpha(t), \beta(t))\dot{\beta}(t)\big) + \int_{a}^{b}
       v(\alpha(t),\beta(t))\dot{\alpha}(t) + u(\alpha(t),
       \beta(t))\dot{\beta}(t) \,dt\notag\\
    &= \int_{\Gamma} u\,dx - v\,dy + i\int_{\Gamma} v\,dx + u\,dy \label{eq:44}
  \end{align}
  Wegunabhängigkeit $\sim$ $\begin{bmatrix}u\\-v\end{bmatrix} \wedge
  \begin{bmatrix}v\\u\end{bmatrix}$ Vektorfelder sind konservativ $\sim$
  falls $G$ sternförmig (\autoref{satz:VFaequi}): $u_{y}=-v_{x}
  \wedge v_{y}= u_{x}$ $\sim$ die
  Cauchy-Riemannschen Differentialgleichungen gelten.
\end{bemerk}

\begin{satz}[Cauchy'scher Integralsatz für sternförmige Gebiete]\label{satz:2}
  Es gelten die Voraussetzungen: $G\subset\C$ sei ein sternförmiges
  Gebiet, $f\colon G\rightarrow\C$ holomorph in $G$, die Ableitung $f'$ sei
  stetig in $G$ und $\Gamma$ sei eine geschlossene stückweise glatte
  Kurve in $G$. Dann ist
  \begin{gather*}
    \int_{\Gamma} f(z)\,dz = 0
  \end{gather*}

  \begin{proof}
    Wenn $f=u+iv$ holomorph ist, dann hat \todo{link:satz 10.1.2/10}
    \help{Der Satz existiert nicht. Wer hat den korrekten Verweis?}
    gezeigt, dass $u$ und $v$ differenzierbar (jedoch nicht stetig
    differenzierbar) sind und die
    Cauchy-Riemannschen Differentialgleichungen $u_{x} = v_{y}, u_{y} =
    -v_{x}$ gelten. Außerdem ist $f'(z) = u_{x} + iv_{x} = v_{y}-iu_{y}$.
    Die Forderung nach Stetigkeit von $f'$ liefert und auch, dass $u_{x},
    u_{y}, v_{x}$ und $v_{y}$ stetig in $G$ sind, d.\,h. $u$ und $v$ sind
    $C^{1}(G)$-Abbildungen.

    Mit \autoref{eq:44} und \autoref{satz:VFaequi} ergibt sich so der Satz.
  \end{proof}
\end{satz}

\begin{folger}
  Unter den Voraussetzungen von \autoref{satz:2} folgt die
  Wegunabhängigkeit der Integrale:
  \begin{gather*}
    \int_{\Gamma_{1}} f(z)\,dz = \int_{\Gamma_{2}} f(z)\,dz
  \end{gather*}
\end{folger}

\begin{satz}
  $\Gamma\subset G$ stückweise glatte Kurve, $G\subset \C$ offen,
  $f\colon G\rightarrow\C$ stetig. Dann:
  \begin{gather*}
    \int_{-\Gamma} f(z)\,dz = -\int_{\Gamma} f(z)\,dz\\
    \abs[\Big]{\int_{\Gamma} f(z)\,dz} \leq \sup_{z\in\Gamma}
       \abs{f(z)}\: L(\Gamma)
  \end{gather*}

  \begin{proof}
    Für die zweite Gleichung ist es ausreichend zu zeigen, dass für eine
    glatte Kurve $\Gamma=(\Gamma, g)$ mit $g\colon[a,b] \rightarrow G$ stetig
    differenzierbar gilt:
    \begin{align*}
      \abs[\Big]{\underbrace{\int_{\Gamma} f(z)\,dz}_{=Re^{i\pi}}}
         &= \abs[\Big]{\int_{a}^{b}
         \underbrace{f(g(t))\dot{g}(t)}_{=:h(t)}\,dt} = R = \Re R = \Re
         \big(e^{-i\pi} R e^{i\pi}\big)\\
      &= \Re\big( e^{-i\pi} \int_{a}^{b} h(t)\,dt \big)
         = \int_{a}^{b} \Re(e^{-i\pi} h(t))\,dt\\
         &\leq \int_{a}^{b} \abs[\big]{\Re (e^{i\pi} h(t))}\,dt
         \leq \int_{a}^{b} \abs{h(t)}\,dt
         = \int_{a}^{b} \abs{f(g(t))\dot{g}(t)}\\
      &\leq \sup_{z\in\Gamma} \abs{f(z)} \int_{a}^{b} \abs{\dot{g}(t)}\,dt
    \end{align*}
  \end{proof}
\end{satz}

\subsection{Stammfunktionen}

\begin{defini}
  $G\subset \C$ offen und $f\colon G\rightarrow\C$ stetig. Eine Funktion
  $F\colon G\rightarrow\C$ heißt \emph{Stammfunktion} von $f$ \gdwdef $F$
  holomorph in $G$ und $F'(z) = f(z)$ für alle $z\in G$
\end{defini}

\begin{lemma}\label{lem:2}
  $G$ offen und $F\colon G\rightarrow\C$ differenzierbar in $z_{0}\in G$ und
  $g\colon[a,b]\rightarrow\C$ differenzierbar in $t_{0}\in (a,b)$ mit
  $z_{0}=g(t_{0})$. Dann ist die zusammengesetzte Funktion $F\circ g$
  differenzierbar in $t_{0}$ und es gilt die Kettenregel $(F\circ
  g)'(t_{0}) = F'(g(t_{0}))\dot{g}(t_{0})$.

  \begin{proof}
    Da $F$ in $t_{0}$ differenzierbar gelten die
    Cauchy-Riemannschen Differentialgleichungen und weiter analog zum
    reellen Fall ($F$ als Realteil + Imaginärteil schreiben, Kettenregeln
    für reelle Funktionen anwenden und ausrechnen). $\rightarrow$ Übung
  \end{proof}
\end{lemma}

\begin{satz}\label{satz:1022-3}
  Sei $G\subset\C$ offen und $\Gamma\subset G$ eine stückweise glatte
  Kurve von $z_{1}\in G$ nach $z_{2}\in G$, $f\colon G\rightarrow\C$
  stetig, $F$ Stammfunktion von $f$. Dann gilt:
  \begin{gather*}
    \int_{\Gamma} f(z)\,dz = F(z_{2}) - F(z_{1})
  \end{gather*}

  \begin{proof}
    \obda ist $\Gamma$ eine glatte Kurve, da man sonst für das Integral
    $\int_{\Gamma}\ldots$ eine Teleskopsumme $\sum_{j=1}^{n}
    \int_{\Gamma_{j}}\ldots$ erhält, mit der man genauso argumentieren
    kann.

    Dann: $g\colon[a,b] \rightarrow G$ zulässige Parameterdarstellung, $g(a) =
    z_{1}, g(b) =z_{2}$
    \begin{align*}
      \int_{\Gamma} f(z)\,dz &= \int_{a}^{b} f(g(t))\dot{g}(t)\,dt
         = \int_{a}^{b} F'(g(t))\dot{g}(t)\,dt\\
      &= \int_{a}^{b} \frac{d}{dt}\big(F(g(t))\,dt &\text{
         \makebox[0pt][r]{nach \autoref{lem:2}}}\\
      \intertext{mit dem Hauptsatz der Differential und Integralrechnung
        ergibt sich}
      &= F(g(b)) - F(g(a)) = F(z_{2}) -F(z_{1})
    \end{align*}
  \end{proof}
\end{satz}

% 31.1.06

\begin{satz}\label{satz:10.2.2/4}
  Sei $G\subseteq\C$ offen und $f\colon G\rightarrow\C$ stetig. Dann
  sind äquivalent:
  \begin{enumerate}
   \item $f$ besitzt eine Stammfunktion in $\C$ ($\exists F\colon
    G\rightarrow\C$ holomorph, $F'(z)=f(z)$)
   \item für jede stückweise stetig differenzierbare geschlossene Kurve
    $\Gamma\subset G$ ist $\int_{\Gamma} f(z)\,dz = 0$
   \item Für je zwei stetige Polygonzüge in $\Gamma$ und $\Gamma'$ in
    $G$, die zwei beliebige Punkte $z_{1}\in G$ und $z_{2}\in G$
    verbunden sind, gilt:
    \begin{gather*}
      \int_{\Gamma} f(z)\,dz = \int_{\Gamma'} f(z)\,dz
    \end{gather*}
  \end{enumerate}

  \begin{proof}
    vgl. \autoref{satz:8.1.2/10} und \autoref{fol:8.1.2/11}: zunächst
    für Gebiete $G$, dann $G=\bigcup_{k=1}^{\infty} G_{k}$, wobei
    $G_{k}$ Gebiete, die paarweise disjunkt sind.

    \obda $G$ sei ein Gebiet. Es gilt (1) $\Rightarrow$ (2) wegen
    \autoref{satz:1022-3}, (2) $\Rightarrow$ (3) ist klar.

    zeigen: (3) $\Rightarrow$ (1). Es sei $z\in G, \epsilon>0$,
    $\exists\delta >0\forall w\in K_{\delta}(z)\colon \abs{f(z)-f(w)}\leq
    \epsilon$, da $f$ stetig.

    $F(z) := \int_{\Gamma}f(\zeta)\,d\zeta$ unabhängig von der Auswahl
    von $\Gamma$ nach Voraussetzung (3). Für ein $w\in K_{\delta}(z)$
    folgt also $F(w) = F(z) = \int_{[z,w]} f(\zeta)\,d\zeta$. $\Rightarrow$
    \begin{gather*}
      \abs{F(w)-F(z)-f(z)\:(w-z)} = \abs[\Big]{ \int_{[z,w]}
         f(\zeta)\,d\zeta - \int_{[z,w]} f(z)\,d\zeta} =
         \abs[\Big]{\int_{[z,w]} f(\zeta)-f(z)\,d\zeta} \leq \epsilon
         \abs{w-z}
    \end{gather*}
    $\Rightarrow$ $\lim_{w\rightarrow z} \frac{F(w) - F(z)}{w-z} = f(z)$
  \end{proof}
\end{satz}

\subsection{Der Cauchy'sche Integralsatz}

In \autoref{satz:2} haben wir unter den Voraussetzungen (1) $f$
holomorph in $G$, (2) $f'$ stetig in $G$ und (3) $G$ stetig gezeigt, dass
für alle geschlossenen Kurven $\Gamma$ das Kurvenintegral null ist.

\autoref{satz:10.2.2/4}: $\exists$ Stammfunktion und $G\subset \C$ offen
$\Leftrightarrow $ für alle geschlossenen Kurven $\Gamma$ das
Kurvenintegral $\int_{\Gamma} f(z)\,dz=0$.

Jetzt wollen wir: nur noch (1) und $G$ einfach zusammenhängend
$\Rightarrow$ für alle geschlossenen Kurven $\Gamma$ das Kurvenintegral
$\int_{\Gamma} f(z)\,dz =0$.

\begin{lemma}[Satz von Goursat]\label{lem:1023-1}
  $G\subset \C$ offen, $f\colon G\rightarrow\C$ holomorph $\Rightarrow$ Für
  jedes abgeschlossene Dreieck $\Delta\subset G$ ist das Integral über
  den Rand
  \begin{gather*}
    \int_{\partial\Delta} f(z)\,dz = 0
  \end{gather*}

  \begin{proof}
    $\Rightarrow$ $\int_{\partial\Delta} f\,dz = \sum_{j=1}^{4}
    \int_{\partial\Delta^{(j)}}f\,dz$

    Es gelten folgende Eigenschaften: $\exists
    \Delta_{1}\in\{\Delta^{(1),\ldots,\Delta^{(4)}}\}$ mit:
    \begin{itemize}
     \item $\abs{\int_{\partial\Delta} f(z)\,dz} \leq 4
      \abs{\int_{\partial\Delta_{1}} f(z)\,dz}$ (Beweis geht indirket)
     \item $L(\partial \Delta_{1}) = \frac{1}{2} L(\partial\Delta)$
     \item $d(\Delta_{1}) = \max_{z, w\in\Delta_{1}} \abs{z-w} =
      \frac{1}{2}d\Delta$
    \end{itemize}

    Iteration (gleiche Prozedur mit $\Delta_{1}$ stelle von
    $\Delta$,\ldots). Bekommen daraus eine Folge von Dreiecken
    $(\Delta_{j})_{j}$ ($j\in\N$) mit:
    \begin{enumerate}
     \item $\Delta\supseteq\Delta_{1}\supset \Delta_{2}\supset\ldots $
     \item $\abs{\int_{\partial\Delta} f\,dz} \leq 4^{j}
      \abs{\int_{\partial\Delta_{j}} f\,dz}$
     \item $L(\partial\Delta_{j}) = 2^{-j} L(\partial \Delta)$
     \item $d(\Delta_{j}) = 2^{-j} d(\Delta)$
    \end{enumerate}

    Auswahl einer Folge $(z_{j})_{j}$ mit $z_{j}\in\Delta_{j}$
    ($j\in\N$). $(z_{j})_{j}$ ist eine Cauchyfolge, da $z_{k}\in
    \Delta_{j}$ ($k\geq j$) und $d(\Delta_{j})
    \xrightarrow{j\rightarrow\infty} 0$. Daraus folgt dann, dass der Limes
    der Folge existiert und in $\Delta_{j}$ liegt
    \begin{gather*}
      \lim_{k\rightarrow\infty} z_{k} = z_{0}\in \Delta_{j}\quad (\forall
         j)
    \end{gather*}

    Es sei $\exists>0$. $f$ holomorph in $z_{0}$ $\Rightarrow$
    \begin{gather*}
      \abs{\frac{f(z) - f(z_{0}) - f'(z_{0})\:(z-z_{0})}{z-z_{0}}} =
         \abs{h(z)} \leq \epsilon\qquad\text{für }\abs{z-z_{0}\leq \delta}
    \end{gather*}
    $\Rightarrow$ $f(z) = f(z_{0}) + f'(z_{0})\:(z-z_{0}) +
    h(z)\:(z-z_{0})$ mit $\abs{h(z)}\leq \epsilon$ Für $j\geq j_{0}$ ist
    $\Delta_{j}\subset K_{\delta}(z_{0})$. Dann können wir folgendermaßen
    argumentieren:
    \begin{gather*}
      \int_{\partial\Delta_{j}} f(z)\,dz = f(z_{0})
         \int_{\partial\Delta_{j}} dz + f'(z_{0})
         \int_{\partial\Delta_{j}} (z-z_{0})\,dz +
         \int_{\partial\Delta_{j}} h(z)\:(z-z_{0})
    \end{gather*}
    Da die Stammfunktion zu 1 und $(z-z_{0})$ (\autoref{bsp:10.2.1/4})
    existiert, ist das Integral 0. \help{wieso?}
    \textit{Hinweis von Fabian: Die Integrale werden null,
      weil 1 und $(z-z_0)$ holomorphe Funktionen sind und wir über eine
      geschlossene Kurve (in diesem Fall ein Dreieck) integrieren. --
      Anmerkung von Jörg: das ist doch die Aussage des Lemmas, das wir
      beweisen wollen.}

    \begin{gather*}
      \abs{\int_{\partial\Delta_{j}} f(z)\,dz} = \abs{
         \int_{\partial\Delta_{j}} h(z)\:(z-z_{0})\,dz} \leq \epsilon
         2^{-j} d(\Delta) 2^{-j} L(\partial\Delta)
    \end{gather*}

    mit (2) folgt:
    \begin{gather*}
      \abs{\int_{\partial\Delta} \epsilon d(\Delta) L(\partial\Delta)}
         \Rightarrow ^{\forall \epsilon>0} \int_{\partial\Delta} f(z)\,dz
         =0
    \end{gather*}
  \end{proof}
\end{lemma}

\begin{lemma}[Verschärfung des Satz' von Goursat]
  $G\subset \C$ offen, $\Delta\subset G$ abgeschlossenes Dreieck, $a\in
  G$, $h\colon G\rightarrow\C$ stetig in $G$ und $h$ holomorph in
  $G\setminus\{a\}$ $\Rightarrow$
  \begin{gather*}
    \int_{\partial\Delta} h\,dz = 0
  \end{gather*}

  \begin{proof}
    Es sei ein Dreieck gegeben durch $\Delta = (z_{1}, z_{2}, z_{3})$.
    Wir müssen die verschiedene Fälle bzgl. der Lage von $a$ betrachten:
    \begin{faelle}
     \item Wenn $a$ außerhalb des Dreiecks $\Delta$ liegt
      ($a\notin\Delta$), kann man eine offene Umgebung um das Dreieck
      $\Delta$ finden, die nicht $a$ enthält und wir können
      \autoref{lem:1023-1} anwenden. Also $\int_{\partial\Delta} h\,dz =0$

     \item Ist $a$ ein Eckpunkt des Dreiecks (\obda $a=z_{1}$), können wir
      das Dreieck $\Delta$ in drei Einzeldreiecke $\Delta_{1},
      \Delta_{2},\Delta_{3}$ zerlegen, so dass $a$ nur im Dreick
      $\Delta_{1}$ liegt. Nach dem ersten Fall sind die Integrale über
      $\Delta_{2}$ und $\Delta_{3}$ Null. Es bleibt also
      $\int_{\partial\Delta} f\,dz = \int_{\partial\Delta_{1}} h\,dz$. Da
      $h$ stetig ist, ist
      \begin{gather*}
        \abs{\int_{\partial\Delta_{1}} h(z)\,dz} \leq \sup_{z\in\Delta}
           \abs{h(z)} L(\partial \Delta_{1}) \rightarrow 0
      \end{gather*}
      gegen Null, weil man das Dreieck belieb klein machen kann

     \item Ist $a$ ein Punkt auf dem Rand des Dreiecks (\obda
      $a\in[z_{1},z_{2}]$), so kann man das Dreieck in zwei Dreiecke
      $(z_{1}, a, z_{3})$ und $(a, z_{2}, z_{3})$ zerlegen und mit Fall 2
      sind die Integrale über beide Dreiecke Null.

     \item Als letzter Fall könnte $a$ noch ein innerer Punkt des
      Dreiecks sein. Dann können wir aber mit einer Strecke eines
      beliebigen Eckpunkts aus durch $a$ das Dreieck in zwei Teildreiecke
      zerlegen und erhalten die gleiche Situation wie in Fall 3.
    \end{faelle}
  \end{proof}
\end{lemma}

\begin{bemerk}[Polygonzüge]
  $z_{0}, z_{1}, \ldots,z_{n}\in G\subset\C, \Gamma_{j}=[z_{j-1}, z_{j}]$
  \begin{gather*}
    \Gamma = \sum_{j=1}^{n} \Gamma_{j} = [z_{0}, z_{1}, \ldots,z_{j-1},
       z_{j}, \ldots,z_{n}]
  \end{gather*}
  $\Gamma$ heißt \emph{stetiger Polygonzug} (stückweise stetig
  differenzierbar)

  $[z_{j}, z_{j}]\sim $ Punkt heißt \emph{leerer Polygonzug}.

  zulässige Operationen für Polygonzüge in $G$:
  $\Gamma = [z_{0}, \ldots,z_{j-1}, z_{j}, z_{j+1}, \ldots,z_{n}]$ und
  $\Gamma^{\ast} = [z_{0}, \ldots,z_{j-1}, z_{j+1}, \ldots,z_{n}]$ Die
  Überführung von $\Gamma$ nach $\Gamma^{\ast}$ bzg. von $\Gamma^{\ast}$
  nach $\Gamma$ heißt \emph{zulässige Operation} \gdwdef Das
  abgeschlossene Dreieck $\Delta_{j} = (z_{j-1}, z_{j}, z_{j+1})$ liegt
  in $G$
\end{bemerk}

% 1.2.06

\begin{defini}
  Wir bezeichnen $G\subset \C$ als ein \emph{zusammenhängendes Gebiet}
  \gdwdef
  \begin{enumerate}
   \item $G$ ist zusammenhängend (d.\,h. Gebiet) und
   \item jeder geschlossener Polygonzug in $G$ lässt sich durch endlich
    viele zulässige Operationen in einen leeren Polygonzug überführen.
  \end{enumerate}
\end{defini}

\begin{bsp}
  Sei $G$ konvexes Gebiet $\Rightarrow G$ ist sternförmig $\Rightarrow G$
  ist einfach zusammenhängend.
\end{bsp}

\begin{bemerk}
  Sei $\Gamma\subset \C$ geschlossener Polygonzug, doppelpunktfrei
  (Jordanscher Polygonzug) $\Rightarrow$ Das Komplement von $\Gamma$
  besteht aus zwei disjunkten Gebieten. Eines der Gebiet ist beschränkt
  ("`Innengebiet"') (und einfach zusammenhängend), das andere ist
  unbeschränkt ("`Außengebiet"').

  Diese Aussage gilt auch für beliebige stetige Jordankurven
  (\emph{Jordanscher Kurvensatz}).

  Außerdem gilt für ein Gebiet $G$: $G$ einfach zusammenhängend \gdw Für
  jede geschlossene stetige Jordankurve in $G$ gehört das Innengebiet zu
  $G$.
\end{bemerk}

\begin{lemma}
  $G$ einfach zusammenhängendes Gebiet, $\Gamma\subset G$ geschlossener
  Polygonzug $\Rightarrow$ $\Gamma = \sum\pm\partial\Delta_{j}$
  (endliche Summe), wobei $\Delta_{j}\subset G$ abgeschlossenes Dreieck.

  \begin{proof}
    (Pseudobeweis) Eine Polygon lässt sich immer in Dreiecke zulegen.
    (Mit Inklusions-Exklusions-Prinzip \help{lässt sich das wirklich im
    IEP machen oder sieht das nur auf den ersten Blick so aus? DML1/2}
    lässt sich dann der Polygonzug durch $\Gamma = \partial\Delta_{1} +
    \partial\Delta_{2} - \partial\Delta_{3}$ schreiben)
  \end{proof}
\end{lemma}

\begin{lemma}\label{lem:10.2.3/8}
  Sei $G\subset \C$ einfach zusammenhängendes Gebiet, $a, z_{0}, z_{1}\in G,
  \Gamma_{1}, \Gamma_{2}$ seien Polygonzüge von $z_{0}$ nach $z_{1}$
  und $f\colon G\rightarrow\C$ stetig und holomorph in $G\setminus\{a\}$. Dann
  ist
  \begin{gather*}
    \int_{\Gamma_{1}} f\,dz = \int_{\Gamma_{2}} f\,dz
  \end{gather*}

  \begin{proof}
    $\Gamma:= \Gamma_{1}-\Gamma_{2}$ ist dann eine geschlossene Kurve in
    $G$.
    \begin{gather*}
      \int_{\Gamma} f\,dz =^{Lemma 7} \sum \pm \int_{\partial\Delta_{j}}
         f\,dz =^{lemma 2} 0\\
      \Rightarrow \int_{\Gamma_{1}} f\,dz = \int_{\Gamma_{2}} f\,dz
    \end{gather*}
  \end{proof}
\end{lemma}

\begin{satz}[Cauchy'scher Integralsatz]\satz{satz:10.2.3/9}
  Es sei $G\subset\C$ ein einfach zusammenhängendes Gebiet,
  $f\colon G\rightarrow\C$ holomorph. Dann gilt für jede geschlossene
  stückweise stetig differenzierbare Kurve $\Gamma\subset G$:
  \begin{gather*}
    \int_{\Gamma} f(z)\,dz = 0
  \end{gather*}

  \begin{proof}
    nach \autoref{satz:10.2.2/4} ist es ausreichend zu zeigen, dass
    $f$ eine Stammfunktion besitzt. Definieren: $F(z) := \int_{\Gamma}
    f(\zeta)\,d\zeta$, wobei $\Gamma$ ein stetiger Polygonzug von
    $z_{0}$ (fest) nach $z\in G$. \autoref{lem:10.2.3/8} liefert:
    Definition unabhängig von Auswahl des Polygonzugs $\Gamma$. $F$ ist
    Stammfunktion (Siehe Schritt (3)$\Rightarrow$(1) in
    \autoref{satz:10.2.2/4}) 
  \end{proof}
\end{satz}

\begin{folger}\label{fol:10.2.3/10}
  Die Aussage von \autoref{satz:10.2.3/9} gilt auch für $f\colon G\rightarrow\C$
  stetig, holomorph in $G\setminus\{a\}$ ($a\in G$).
\end{folger}

\subsection{Die Cauchy'sche Integralformel}

\begin{lemma}\label{lem:10.2.4/1}
  $G\subset \C$ offen, $z_{0}\in G, r>0, \delta>0$, so dass
  $\overline{K_{r}(z_{0})} = \{z\colon \abs{z-z_{0}}\leq r\}\subset G$.
  Es sei $z\in K_{r}(z_{0})$ und $\overline{K_{\delta}(z)}\subset
  K_{r}(z_{0})$. Es sei $h$ holomorph in $G\setminus\{z\}$. $\Rightarrow$
  \begin{gather*}
    \oint_{\abs{\zeta-z_{0}}=r} h(\zeta)\,d\zeta =
       \oint_{\abs{\zeta-z}=\delta} h(\zeta)\,d\zeta
  \end{gather*}

  \begin{proof}
    $\Omega := K_{r+\epsilon}(z_{0})\setminus\gamma$ ist sternförmiges
    Gebiet, $\Omega\subset G$, $h$ ist holomorph in $\Omega$. $\Gamma_{1}
    +\Gamma_{2}+\Gamma_{3}+\Gamma_{4}$ ist eine geschlossene stückweise
    glatte Kurve in $\Omega$. $\Rightarrow$ $^{Satz 10.2.3/9}$
    \begin{gather*}
      \int_{\Gamma_{1}} h\,d\zeta + \ldots+ \int_{\Gamma_{4}} h\,d\zeta = 0
    \end{gather*}

    analog zeigt man:
    \begin{gather*}
      \int_{\Gamma_{5}} h\,d\zeta - \int_{\Gamma_{4}} h\,d\zeta +
         \int_{\Gamma_{6}} h\,d\zeta - \Gamma_{2}h\,d\zeta =0
    \end{gather*}
    Summe über beide:
    \begin{gather*}
      \int_{\Gamma_{1}+\Gamma_{3}+\Gamma_{5}+\Gamma_{6}} h\,d\zeta = 0
         \Leftrightarrow \int_{\Gamma_{1}+\Gamma_{5}} h\,d\zeta =
         -\int_{\Gamma_{3}+\Gamma_{6}} h\,d\zeta
    \end{gather*}
    Das Minus ist begründet in der Orientierung der Kurven. \todo{Leider
    fehlen hier die wichtigen Skizzen}.
  \end{proof}
\end{lemma}

\begin{satz}[Die Cauchy'sche Integralformel]\label{satz:10.2.4/2}
  $G\subset \C$ offen, $f\colon G\rightarrow\C$ holomorph, $z_{0}\in G$,
  $\overline{K_{r}(z_{0})}\subset G$ ($r>0$). Dann gilt:
  \begin{gather*}
    f(z) = \frac{1}{2\pi i} \oint_{\abs{\zeta-z_{0}}=r}
       \frac{f(\zeta)}{\zeta-z}\,d\zeta
  \end{gather*}
  für alle $z\in K_{r}(z_{0})$.

  \begin{proof}
    Wir betrachten das sternförmige Gebiet $\Omega :=
    K_{r+\epsilon}(z_{0})$ (existiert, das $G$ offen ist). Für $z\in G$
    ist
    \begin{gather*}
      h(\zeta) := \begin{cases}
                    \frac{f(\zeta)-f(z)}{\zeta-z}& \zeta\neq z\\
                    f'(z)& \zeta=z
                  \end{cases}
    \end{gather*}
    stetig in $\Omega$ und holomorph auf $\Omega\setminus\{z\}$. Nach
    \autoref{fol:10.2.3/10} gilt der Cauchy'sche Integralsatz für $h$ und
    \begin{align*}
      0 &= \oint_{\abs{\zeta-z_{0}}=r} h(\zeta)\,d\zeta =
         \oint_{\abs{\zeta-z_{0}}=r} \frac{f(\zeta)}{\zeta-z}d\zeta -
         \oint_{\abs{\zeta-z_{0}}=r} \frac{f(z)}{\zeta-z}d\zeta\\
      &= \oint_{\abs{\zeta-z_{0}}=r} \frac{f(\zeta)}{\zeta-z}d\zeta -
         f(z)\oint_{\abs{\zeta-z_{0}}=r} \frac{1}{\zeta-z}d\zeta\\
      &=\oint_{\abs{\zeta-z_{0}}=r} \frac{f(\zeta)}{\zeta-z}d\zeta -
         f(z)\oint_{\abs{\zeta-z}=\delta} \frac{d\zeta}{\zeta-z}
         &\text{nach \autoref{lem:10.2.4/1}}\\
      &= \oint_{\abs{\zeta-z_{0}}=r} \frac{f(\zeta)}{\zeta-z}d\zeta -
         f(z) 2\pi i &\text{nach \autoref{bsp:10.2.1/4}}
    \end{align*}
  \end{proof}
\end{satz}

\begin{bsp}
  \begin{gather*}
    \int_{\abs{z}=2} \frac{\sin z}{z+i}dz = 2\pi i \sin(-i) = 2\pi i
       \frac{1}{2 i}(e-e^{-1}) = \pi (e-\frac{1}{e})
  \end{gather*}
  Singularität bei $-i$.
\end{bsp}

% 7. Feb. 06

\begin{bemerk}
  Für $z=z_{0}$ gilt
  \begin{gather*}
    f(z_{0}) = \frac{1}{2\pi i} \oint_{\abs{\zeta-z_{0}}=r}
       \frac{f(\zeta)}{\zeta-z_{0}}d\zeta,\qquad \zeta-z_{0} = re^{it}
  \end{gather*}
  $\Rightarrow$
  \begin{gather*}
    f(z_{0}) = \frac{1}{2\pi} \int_{0}^{2\pi} f(z_{0}+r e^{it})\,dt =
       \frac{1}{2\pi i} \int_{0}^{2\pi} \frac{f(z_{0}+ re^{it})}{re^{it}}
       ire^{it}\,dt
  \end{gather*}
  \emph{Mittelwerteigenschaft}
\end{bemerk}

\begin{lemma}
\label{lem:1024-5}
  Es sei $z_{0}\in\C, r>0$ und $f$ stetig auf $\partial K_{r}(z_{0}) =
  \{\zeta\colon \abs{\zeta-z_{0}}=r \}$, $H(z) =
  \oint_{\abs{\zeta-z_{0}}=r} \frac{f(\zeta)}{\zeta-z}d\zeta$ für $z$ mit
  $\abs{z-z_{0}}<r$ $\Rightarrow$ $H(z) = \sum_{k=0}^{\infty} a_{k}
  (z-z_{0})^{k}$, wobei $a_{k} = \oint_{\abs{\zeta-z_{0}}=r}
  \frac{f(\zeta)}{(\zeta-z_{0})^{k+1}}d\zeta$ absolut konvergent für
  $\abs{z-z_{0}}<r$ und gleichmäßig konvergent auf $\{z\colon
  \abs{z-z_{0}}\leq r_{1}<r\}$

  \begin{proof}
    Es sei $\abs{z-z_{0}}=r_{1}< r$ und $\abs{\zeta-z_{0}}=r$ $\Rightarrow$
    \begin{gather*}
      \abs[\Big]{\frac{z-z_{0}}{\zeta-z_{0}}} = \frac{r_{1}}{r} < 1
         \Rightarrow \frac{1}{\zeta-z} = \frac{1}{\zeta-z_{0}}
         \frac{\zeta-z_{0}}{\zeta-z} = \frac{1}{\zeta-z_{0}}
         \frac{1}{\frac{\zeta-z+z_{0}-z_{0}}{\zeta-z}} =
         \frac{1}{\zeta-z_{0}}
         \frac{1}{1-\Big(\frac{z-z_{0}}{\zeta-z_{0}}\Big)}
    \end{gather*}
    \todo{hier fehlt noch der Rest}
  \end{proof}
\end{lemma}

\begin{satz}\label{satz:10.2.4/6}
  $G\subset\C$ offen, $f\colon G\rightarrow\C$ holomorph. Dann:
  \begin{enumerate}
   \item Es sei $0<r <R \leq\infty, z_{0}\in G, K_{R}(z_{0})\subset G$
    $\Rightarrow$ $f(z) = \sum_{k=0}^{\infty} a_{k}(z-z_{0})^{k}$ für
    alle $z\in K_{R}(z_{0})$. Die Koeffizienten $a_{k}$ sind eindeutig
    bestimmt und es gilt:
    \begin{gather*}
      a_{k} = \frac{1}{2\pi i} \oint_{\abs{\zeta-z_{0}}=r}
         \frac{f(\zeta)}{(\zeta-z)^{k+1}}d\zeta =
         \frac{f^{(k)}(z_{0})}{k!}\quad(k\in\N_{0})
    \end{gather*}

   \item $f$ ist auf $G$ beliebig oft differenzierbar (weil $f$ für jeden
    Punkt in $G$ als Potenzreihe darstellbar und diese Potenzreihe ist
    beliebig oft differenzierbar) und es gilt:
    \begin{gather*}
      f^{(k)}(z) = \frac{k!}{2\pi i} \oint_{\abs{\zeta-z_{0}}=r}
         \frac{f(\zeta)}{(\zeta-z)^{k+1}}d\zeta \quad(k\in\N_{0})
    \end{gather*}
    wobei $z_{0}\in G, \overline{K_{r}(z_{0})}\subset G$ und $z\in
    K_{r}(z_{0})$
    \emph{Cauchy-Integralformel für Ableitungen}
  \end{enumerate}

  \begin{proof}
    \begin{enumerate}[1.\,Schr{i}tt]
     \item (1) $G_{0} = K_{R}(z_{0})$ \autoref{satz:10.2.4/2} $\Rightarrow$
      \begin{gather*}
        f(z) = \frac{1}{2\pi i} \oint_{\abs{\zeta-z_{0}}=\rho}
           \frac{(\zeta)}{\zeta-z}d\zeta \quad\text{für } z\in K_{\rho}
           (z_{0}), \rho<R
      \end{gather*}
      Lemma 5 $\Rightarrow$
      \begin{gather*}
        f(z) = \sum_{k=0}^{\infty} a_{k} (z-z_{0})^{k}
      \end{gather*}
      wobei
      \begin{gather*}
        a_{k} = \frac{1}{2\pi i} \oint_{\abs{\zeta-z_{0}}=\rho}
           \frac{f(\zeta)}{(\zeta-z)^{k+1}}d\zeta =^{lemma 1} \frac{1}{2\pi
           i} \oint_{\abs{\zeta-z_{0}}=r} \frac{f(\zeta)}{\zeta-z}d\zeta
      \end{gather*}
      für $0<r<R$

     \item (2) Nach \autoref{satz:10.1.2/6} ist $f$ beliebig oft
      differenzierbar in $K_{R}(z_{0})$ für beliebiges $z_{0}\in G$.
      $\Rightarrow$ $f$ beliebig oft differenzierbar.

      Es sei $z_{0}\in G, \overline{K_{r}(z_{0})}\subset G$ Aus (1) folgt
      (Entwicklung in $z$)
      \begin{gather*}
        f^{(k)}(z) = \frac{k!}{2\pi i} \oint_{\abs{\zeta-z_{0}}=\delta}
           \frac{f(\zeta)}{(\zeta-z)^{k+1}}d\zeta =^{Lemma 1}
           \frac{k!}{2\pi i} \oint_{\abs{\zeta-z_{0}}=r}
           \frac{f(\zeta)}{\zeta-z}d\zeta
      \end{gather*}
    \end{enumerate}
  \end{proof}
\end{satz}

\begin{folger}\label{fol:3}
  Sei $G\subset\C$ eine offene Menge. Dann sind folgende Aussagen
  äquivalent:
  \begin{enumerate}
   \item $f$ ist holomorph in $G$
   \item $f$ besitzt eine lokale Stammfunktion (d.\,h. in jedem
    Punkt aus $K_{r}(z_{0})\subset G$)
   \item $f$ lokal als Potenzreihe darstellbar (d.\,h. in jedem Punkt aus
    $K_{r}(z_{0})\subset G$)
   \item $f(x+iy) = u(x,y) + iv(x,y)$ und $u,v$ differenzierbar in $G$
    und es gelten die Cauchy-Riemannsche Differentialgleichungen.
  \end{enumerate}
\end{folger}

\begin{folger}[Riemannscher Hebbarkeitssatz]\label{fol:10.2.4/8}
  Sei $G\subset G$ offen und $z_{0}\in G$
  \begin{enumerate}
   \item $f$ holomorph in $G\setminus\{z_{0}\}$ und stetig in $z_{0}$
    $\Rightarrow$ $f$ ist holomorph in $z_{0}$
   \item $f$ holomorph in $G\setminus\{z_{0}\}$ und beschränkt in
    $K_{\delta}(z_{0})$ $\Rightarrow$ $\exists$ eine holomorphe Funktion
    $h\colon G\rightarrow\C$ mit $h(z) =f(z)$ für alle $z\neq z_{0}$
  \end{enumerate}

  \begin{proof}
    Sei $f$ stetig in $z_{0}$ und holomorph in $G\setminus\{z_{0}\}$. Nach
    \autoref{fol:10.2.3/10} besitzt $f$ eine Stammfunktion in
    $K_{\delta}(z_{0})$. Nach \autoref{fol:3} $f=F'$ holomorph in
    $K_{\delta}(z_{0})$

    $f$ holomorph in $K_{\delta}(z_{0})\setminus\{z_{0}\}$, beschränkt in
    $K_{\delta}(z_{0})$ $\Rightarrow$ setzen:
    \begin{gather*}
      g(z) := \begin{cases}
                (z-z_{0})f(z)&z\neq z_{0}\\
                0&z=z_{0}
              \end{cases}
    \end{gather*}
    $\Rightarrow$ $G$ stetig in $z_{0}$, holomorph in
    $K_{\delta}(z_{0})\setminus\{z_{0}\}$ $\Rightarrow$ $^{(1)}$ $g$ ist
    holomorph in $K_{\delta}(z_{0})$ $\Rightarrow$
    \begin{gather*}
      h(z) = \begin{cases}
               \frac{g(z)-g(z_{0})}{z-z_{0}} & z\neq z_{0}\\
               g'(z_{0}) & z=z_{0}
             \end{cases}
         = \begin{cases}f(z) & z\neq z_{0}\\ g'(z_{0})&z=z_{0}\end{cases}
    \end{gather*}
    holomorph nach (1)
  \end{proof}
\end{folger}

\begin{folger}[Satz von Morera]
  $G\subset \C$ offen, $f\colon G\rightarrow\C$ stetig. Für jedes
  abgeschlossene Dreieck $\Delta\subset G$ gilt:
  \begin{gather*}
    \oint_{\partial\Delta} f\,dz = 0
  \end{gather*}
  Dann ist $f$ holomorph in $G$.

  \begin{proof}
    Es sei $K_{r}(z_{0})\subset G$. Aus $\oint_{\partial\Delta} f\,dz=0$
    für alle $\Delta\subset K_{r}(z_{0})$ folgt, dass die Aussage von
    \autoref{lem:10.2.3/8} $\Rightarrow$ wie in \autoref{satz:10.2.3/9}
    existiert eine Stammfunktion $F$ auf $K_{r}(z_{0})$, d.\,h. $F'=f$.
    $F$ holomorph $\Rightarrow$ $f$ holomorph \autoref{fol:3}.
  \end{proof}
\end{folger}

\section{Singularitätentheorie}
\subsection{Laurentreihen}

\begin{lemma}
\label{lem:1031-1}
  $0<r<R\leq \infty, z_{0}\in\C, K(z_{0},r,R) = K := \{z\colon r
  <\abs{z-z_{0}}<R\}$ (\emph{Kreisring}) $g\colon K\rightarrow \C$ holomorph.
  Dann gilt für alle $r_{1},r_{2}$ mit $r<r_{1}<r_{2}<R$
  \begin{gather*}
    I_{1} = \oint_{\abs{z-z_{0}}=r_{1}} g(z)\,dz = \oint_{\abs{z-z_{0}}=r_{2}}
       g(z)\,dz = I_{2}
  \end{gather*}

  \begin{proof}
    analog zu \autoref{lem:10.2.4/1}

    Wir schneiden den Kreisring $K$ mit einem Strahl $\delta$ aus $z_{0}$
    auf. Damit ergeben sich zwei zusammenhängende Gebiete $I_{1}$ und
    $-I_{2}$, deren Summe nach dem Cauchy'schen Integralsatz Null sein
    muss.
  \end{proof}
\end{lemma}

\begin{lemma}
\label{lem:1031-2}
  Sei $0<r<R\leq \infty, K:=K(z_0, r,R)= \{z\colon r< \lvert z-z_0\rvert
  <R\}, f\colon K\rightarrow \C$ holomorph. Dann gilt für $r< r_1< \lvert
  z-z_0 \rvert <r_2<R$:
  \begin{align*}
    f(z) &= \frac{1}{2\pi i} \oint_{\lvert \zeta -z_0\rvert=r_1}
    \frac{f(\zeta)}{\zeta-z} d\zeta &- \frac{1}{2\pi i} \oint_{\lvert
      \zeta -z_0\rvert=r_2} \frac{f(\zeta)}{\zeta-z} d\zeta\\
    &= f_2(z) &+ f_1(z)
  \end{align*}
  \begin{proof}
    Wie vorausgesetzt, ist $z$ fest und $\zeta\in K$. Dann ist die
    Funktion $g(\zeta)$ wie folgt definiert:
    \begin{gather*}
      g(\zeta) :=
      \begin{cases}
        \frac{f(\zeta)-f(z)}{\zeta-z} & \zeta\neq z\\
        f'(z) & \zeta=z
      \end{cases}
    \end{gather*}
    Aus dem \autoref{lem:1031-1} folgt:
    \begin{align*}
      \oint_{\lvert \zeta-z_0\rvert =r_1} g(\zeta)d\zeta &=
      \oint_{\lvert \zeta-z_0\rvert =r_2} g(\zeta)d\zeta \\
      &\Rightarrow \oint_{\lvert \zeta-z_0\rvert =r_1}
      \frac{f(\zeta)}{\zeta-z} d\zeta -f(z) \underbrace{\oint_{\lvert
        \zeta-z_0\rvert =r_1} \frac{d\zeta}{\zeta-z}}_{=0}\\
      &= \oint_{\lvert \zeta-z_0\rvert =r_2} \frac{f(\zeta)}{\zeta-z}
      d\zeta -f(z) \underbrace{\oint_{\lvert \zeta-z_0\rvert =r_2}
        \frac{d\zeta}{\zeta-z}}_{= \oint_{\lvert\zeta-z\rvert =\delta}
        \frac{d\zeta}{\zeta-z} = 2\pi i}
    \end{align*}
  \end{proof}
\end{lemma}

\begin{satz}[Laurentreihensatz]
  Sei $K=K(z_0,r,R)$ ein Kreisring, $f$ holomorph auf $K$. Dann gilt:
  \begin{enumerate}
  \item Für alle $z\in K$ ist die Reihe
    \[f(z) = \underbrace{\sum_{k=0}^\infty a_k (z-z_0)^k}_{f_2(z)} +
    \underbrace{\sum_{k=-1}^{-\infty} a_k(z-z_0)^k}_{f_1(z)}\]
    absolut konvergent. Sie heißt auch
    \emph{Laurentreihe}.
  \item Die Koeffizienten $(a_k)$ sind eindeutig bestimmt und es gilt:
    \[\forall k\in\Z, r<\rho<R\colon a_k= \frac{1}{2\pi i}
    \oint_{\lvert \zeta-z_0\rvert=\rho}
    \frac{f(\zeta)}{(\zeta - z_0)^{k+1}} d\zeta\]
  \item Der Hauptteil der Laurentreihe $f_1$ konvergiert absolut und
    gleichmäßig auf $\{z\colon \lvert z-z_0\rvert \geq r_1\}$ mit $r_1>r$
    und ist holomorph auf $\C\setminus \overline{K_r(z_0)}$. Weiter
    ist $f_2$ ebenfalls absolut konvergent und gleichmäßig auf $\{z\colon
    \lvert z-z_0\rvert \leq r_2\}$ mit $r_2<R$ und ist holomorph auf
    $K_R(z_0)$.
  \end{enumerate}
  \begin{proof}
    \begin{enumerate}[1.\,Schr{i}tt:]
    \item Für die Aussage in (1) wird das \autoref{lem:1031-2}
      angewendet und es folgt, $f(z)=f_2(z)+f_1(z)$. Nun kann das
      \autoref{lem:1024-5} angewendet werden und man hat:
      \begin{align*}
        f_2(z) &= \frac{1}{2\pi i} \oint_{\lvert \zeta -
          z_0\rvert = r_2} \frac{f(\zeta)}{\zeta-z} d\zeta =
        \sum_{k=0}^\infty a_k (z-z_0)^k\\
        a_k &= \frac{1}{2\pi i} \oint_{\lvert \zeta- z_0\rvert
          = r_2} \frac{f(\zeta)}{(\zeta-z)^{k+1}} d\zeta
      \end{align*}
    \item Wir betrachten nun $f_1(z)$ mit $\lvert z-z_0\rvert >r_1,
      \lvert\zeta -z_0\rvert =r_1 \Rightarrow \left\lvert \frac{\zeta-
          z_0}{z-z_0} \right\lvert<1$. Es ist:
      \begin{align*}
        \frac{1}{z-\zeta} &= \frac{1}{z-z_0} \frac{z-z_0}{z-\zeta}
        =\frac{1}{z-z_0} \frac{1}{\frac{z-\zeta}{z-z_0}} =
        \frac{1}{z-z_0} \frac{1}{1-\frac{\zeta-z_0}{z-z_0}}\\
        &= \sum_{k=0}^\infty \frac{(\zeta-z_0)^k}{(z-z_0)^{k+1}}\\
        &\Rightarrow f_1(z) \frac{1}{2\pi i} \sum_{k=0}^\infty \bigg(
        \oint_{\lvert \zeta-z_0\rvert =r_1} f(\zeta)
        (\zeta-z_0)^k d\zeta\bigg)\frac{1}{(z-z_0)^{k+1}}\\
        &= \frac{1}{2\pi i} \sum_{k=-1}^{-\infty} \bigg(
        \oint_{\lvert \zeta-z_0\rvert =r_1}
        \frac{f(\zeta)}{(\zeta-z_0)^{k+1}} d\zeta\bigg) (z-z_0)^k
      \end{align*}
      Der Term $(z-z_0)^k$ kann als Potenzreihe für
      $w=\frac{1}{z-z_0}$ betrachtet werden. Damit ist diese absolut
      konvergent für $\lvert w \rvert> \frac{1}{r_1}\Rightarrow \lvert
      z-z_0 \rvert >r_1$.
    \item Es ist zu zeigen, dass $f_1$ holomorph in $\{z\colon \lvert
      z-z_0\rvert >r\}$ ist. Wir betrachten die Funktion $\Phi(z) :=
      f_1(z_0 +\frac{1}{z})= \sum_{k=-1}^{-\infty} a_k\frac{1}{z^k} =
      \sum_{k=1}^\infty a_{-k} z^k$. Diese ist somit eine Potenzreihe
      und es folgt, dass $\Phi$ holomorph für $\lvert z\rvert
      <\frac{1}{r}$ ist. Weiter kann man folgern, dass gilt $f_1(z)=
      f_1(z_0+z-z_0) =\Phi(\frac{1}{(z-z_0)})$ und man sieht, dass
      $f_1$ holomorph in $\lvert z-z_0\rvert >r$ ist.
    \item Nun ist noch offen, dass die $(a_k)$ eindeutig bestimmt
      sind. Wir nehmen an, $f(z)= \sum_{k=0}^\infty b_k (z-z_0)^k +
      \sum_{k=-1}^{-\infty} b_k (z-z_0)^k$ auf $r<\lvert z-z_0 \rvert
      <R$. Sei $r<\rho<R$ und es folgt:
      \[\oint_{\lvert z-z_0\rvert =\rho}
      \frac{f(z)}{(z-z_0)^{l+1}} dz= \sum_{k=-\infty}^\infty b_k
      \oint_{\lvert z-z_0\rvert=\rho} (z-z_0)^{k-l-1} dz=
      2\pi ib_l\]
    \end{enumerate}
  \end{proof}
\end{satz}

\begin{bemerk}
  Die Funktion
  \[f_1(z)= \sum_{k=-1}^{-\infty} a_k (z-z_0)^k= a_{-1}\frac{1}{z-z_0}
  + a_{-2}\frac{1}{(z-z_0)^2}+ \ldots\]
  heißt \emph[index={Hauptteil\,d.\,Laurentreihe}]{Hauptteil} und beschreibt die
  Singularität von $f$ an der Stelle $z_0$. Insbesondere gilt für $a_{-1}$
  \begin{gather*}
    \oint_{\abs{z-z_0}=\rho} f(z)dz=2\pi ia_{-1}
  \end{gather*}
  $a_{-1}$ heißt \emph{Residuum}\footnote{Schreibweise: $\Res(f, z_0)$}
  von $f$ in $z_0$.
\end{bemerk}

\begin{bsp}
  Gegeben sei eine Funktion $f(z)=\frac{1}{1+z^2}$, die holomorph in
  $\C\setminus \{i,-i\}$ ist.
  \begin{faelle}
  \item Für $\abs{z}<1$ können wir die Funktion um $z_{0}=0$ mithilfe der
    geometrischen Reihe als eine Potenzreihe darstellen:
    \begin{gather*}
      \frac{1}{1+z^2} =\sum_{k=0}^\infty (-z^2)^k
         =\sum_{k=0}^\infty (-1)^k z^{2k}
    \end{gather*}
  \item Außerhalb des Einheitskreises ($\abs{z}>1$) um $z_0=0$ können wir
    durch gekonntes Umstellen und Anwendung der geometrischen Reihe,
    ebenfalls $f$ als Potenzreihe darstellen:
    \begin{gather*}
      \frac{1}{1+z^2}= \frac{1}{z^2}
         \frac{1}{1+\frac{1}{z^2}} = \frac{1}{z^2} \sum_{k=0}^\infty (-1)^k
         z^{-2k} = \frac{1}{z^2}-\frac{1}{z^4}+ \frac{1}{z^6}-\ldots
    \end{gather*}
    Die Laurententwicklung wäre also nur der Hauptteil.
  \item \help{hier weiß ich erstmal nicht weiter. Fehlt hier die
    Betrachtung von $z_{0}=-i$ noch? Haben wir dann den ersten Fall nicht
    doppel? Jedenfalls passiert da unten eine Partialbruch} $z_0=i\wedge 0<\lvert z-i\rvert <2$:
    \begin{align*}
      \frac{1}{1+z^2}&= \frac{1}{(z-i)(z+i)}= \frac{1}{2i}
         \Big(\frac{1}{z-i} -\frac{1}{z+i}\Big)\\
      &= \frac{1}{2i}
         \Big(\frac{1}{z-1} -\frac{1}{2i(1+\frac{z-i}{2i})}\Big) = \frac{1}{2i}
         \frac{1}{z-i} +\frac{1}{4} \sum_{k=0}^\infty i^k \frac{(z-i)^k}{2^k}
    \end{align*}
  \end{faelle}
\end{bsp}

\subsection{Der Residuensatz}

\begin{defini}
  Der Koeffizient $a_{-1}$ in der Laurentreihenentwicklung von $f$
  heißt \emph{Residuum} von $f$ in $z_0\colon \Res(f,z_0)
  := a_{-1}$, wobei $f(z)=\sum_{k=-\infty}^\infty a_k (z-z_0)^k$ ist.
\end{defini}

\begin{folger}
  Sei $f$ holomorph in $K(z_0, r,R)\Rightarrow \oint_{\abs{z-z_0} =r}
  f(z)dz=2\pi i \Res(f,z_0)$.
\end{folger}

% 14.2.06

\begin{bsp}
  \begin{gather*}
    \oint_{\abs{z}=r} \frac{e^{z}}{z^{2}} = 2\pi i
  \end{gather*}
  da $\Res(\frac{e^{z}}{z^{2}}, 0) = 1$

  Laurentreihe:
  \begin{gather*}
    \frac{e^{z}}{z^{2}} = \frac{1}{z^{2}} (1+z+\frac{z^{2}}{2!} +
       \frac{z^{3}}{3!} + \ldots) = \frac{1}{z^{2}} \frac{1}{z} +
       \frac{1}{2} + \ldots
  \end{gather*}
\end{bsp}

\begin{bsp}
  \begin{gather*}
    \oint_{\abs{z-i}=1} \frac{dz}{1+z^2}=2\pi i \Res(\frac{1}{1+z^{2}},
       i) = 2\pi i\frac{1}{2i}= \pi
  \end{gather*}

  da die Laurentreihe so aussieht:
  \begin{gather*}
    \frac{1}{1+z^{2}} = \frac{1}{2i} \frac{1}{z-1} + \frac{1}{4}
       \sum_{k=0}^{\infty} \frac{i^{k}}{2^{k}} (z-i)^{k}
  \end{gather*}
\end{bsp}

\begin{bemerk}
  Ausdehnung auf beliebige geschlossene stückweise glatte Kuren $\Gamma$
  (\textit{nicht} notwendig Jordankurve). dazu: \emph{Umlaufzahl}
  (beschreibt wie oft eine Kurve um einen Punkt eine 360°-Drehung
  vollzieht)

  Dazu wählen wir für $\Gamma$ eine Parameterdarstellung als
  Polarkoordinaten mit $z_{0}$ als Nullpunkt und einen beliebigen festen
  Strahl aus $z_{0}$ als den Winkel null.
  \begin{gather*}
    g(t) = z_{0} + t(t) e^{i\phi(t)}, g\colon[a,b] \rightarrow\C
  \end{gather*}

  Für eine geschlossene Kurve $\Gamma$ gilt $g(a)=g(b)$ und $r(a)=r(b)$
  und $\phi(a) = \phi(b)+2\pi n$ mit $n\in\Z$. $n$ nennt man die
  \emph{Umlaufzahl}.

  Es gilt:
  \begin{gather*}
    \int_{\Gamma} \frac{dz}{z-z_{0}} = \int_{a}^{b}
       \frac{g'(t)}{g(t)-z_{0}}dt = \int_{a}^{b} \frac{r'(t) e^{i\phi(t)} +
       r(t) \phi'(t) e^{i\phi(t)} }{r(t) e^{i\phi(t)}} dt = \int_{a}^{b}
       \frac{r'(t)}{r(t)}dt + i \int_{a}^{b} \phi'(t)\,dt = \ln r(t)
       \big\|_{a}^{b} + i\phi(t) \big\|_{t=a}^{b} = i(\phi(b)-\phi(a)) =
       (2\pi i) n
  \end{gather*}
  \textit{Anmerkung: $\ln r(t)$ ist null, da $r(a)=r(b)$}

  Wir können also die Umlaufzahl wie folgt beschreiben
  \begin{gather*}
    n = \frac{1}{2\pi i}\int_{\Gamma} \frac{dt}{z-z_{0}}
  \end{gather*}
\end{bemerk}

\begin{lemma}\label{lem:10.3.2/5}
  Für einen Punkt $z_{0}\in\C$ und eine geschlossene stückweise glatte
  Kurve $\Gamma$ in $\C$, wobei $z_{0}\ne\Gamma$, ist die Umlaufzahl eine
  ganze Zahl
  \begin{gather*}
    \frac{1}{2\pi i} \int_{\Gamma} \frac{dz}{z-z_{0}}\; \in \Z
  \end{gather*}

  (ohne Beweis)
\end{lemma}

\begin{defini}
  $\Gamma$ und $z_{0}$ wie in \autoref{lem:10.3.2/5}
  \begin{gather*}
    n(\Gamma, z_{0}) := \frac{1}{2\pi i} \int_{\Gamma} \frac{dz}{z-z_{0}}
  \end{gather*}
  heißt \emph{Umlaufzahl} von $\Gamma$ bezüglich $z_{0}$.
\end{defini}

\begin{satz}[Residuensatz]\label{satz:10.3.2/7}
  Sei $G$ einfach zusammenhängendes Gebiet, $\{z_{1}, z_{2},\ldots,z_{N}\}
  \subset G$, $f$ holomorph in $G\setminus\{z_{1},\ldots,z_{N}\}$,
  $\Gamma$ geschlossene stückweise glatte Kurve in $G$, die $\{z_{1},
  \ldots,z_{N}\}$ nicht enthält. Dann gilt:
  \begin{gather*}
    \int_{\Gamma} f(z)\,dz = 2\pi i\sum_{j=1}^{N} n(\Gamma, z_{j})
       \Res(f, z_{j})
  \end{gather*}
\end{satz}

\begin{folger}
  Das Integral über eine geschlossene Jordankurve $\Gamma$ ist
  \begin{gather*}
    \int_{\Gamma} f(z)\,dz = 2\pi i \sum_{z_{j}\in IG} \Res(f,
       z_{j})
  \end{gather*}
  Das \emph{Innengebiet} $IG$ sind alle Punkte, für die die Umlaufzahl
  größer null ist oder bildlich dargestellt, ist es das Gebiet, das von
  der Kurve umschlossen wird.
\end{folger}

\begin{folger}[Allgemeine Cauchy-Integralformel]
  Auf einem einfach zusammenhängendes Gebiet $G$ mit einer geschlossene stückweise glatte
  Kurve $\Gamma\subset G$ und einer holomorphen Funktion $f\colon
  G\rightarrow\C$ gilt für einen Punkt $z\in G$, der nicht von $\Gamma$
  durchlaufen wird:
  \begin{gather*}
    n(\Gamma, z) f^{(k)}(z) ) \frac{k!}{2\pi i} \int_{\Gamma}
       \frac{f(\zeta)}{(\zeta-z)^{k+1}} d\zeta
  \end{gather*}

  \begin{proof}
    \begin{align*}
      g(\zeta) &= \frac{f(\zeta)}{(\zeta-z)^{k+1}} =
         \frac{1}{(\zeta-z)^{k+1}} \sum_{j=0}^{\infty}
         \frac{f^{(j)}(z)}{j!} (\zeta-z)^{j}\\
         &= \frac{1}{(\zeta-z)^{k+1}} (f(z) + f'(z)\:(\zeta-z) + \ldots+
         \frac{f^{(k)}(z)}{k!} (\zeta-z)^{k} + \ldots)
    \end{align*}
    $\Rightarrow$ $\Res(g,z) =  \frac{f^{(k)}(z)}{k!}$,
    \autoref{satz:10.3.2/7} $\Rightarrow$ $\int_{\Gamma}
    g(\zeta)\,d\zeta = 2\pi i n(\Gamma,z) \frac{f^{(k)}(z)}{k!}$
  \end{proof}
\end{folger}

\subsection{Singularitäten}

\begin{defini}
  $f$ sei holomorph in $K_{R}(z_{0})\setminus\{z_{0}\}$. Es sei
  $\sum_{k=-\infty}^{\infty} a_{k}(z-z_{0})^{k} =f(z)$ die Laurentreihe
  von $f$ in $K_{R}(z_{0})\setminus\{z_{0}\}$.
  \begin{enumerate}
   \item $z_{0}$ heißt \emph[index=Singularität!hebbare]{hebbare
    Singularität} \gdwdef $a_{-k}=0$ für alle $k\in\N$

   \item $z_{0}$ heißt \emph{Pol $n$-ter Ordnung} von $f$ \gdwdef $a_{-n}
    \ne 0$ und $a_{-k}=0$ für alle $k>n$

   \item $z_{0}$ heißt \emph[index=Singularität!wesentliche]{wesentliche
    Singularität} \gdwdef $a_{-k}\ne 0$ für unendlich viele $k\in\N$
  \end{enumerate}
\end{defini}

\begin{bsp}
  Die Funktion $f(z) = \frac{\sin z}{z}$ hat an der Stelle $z_{0}=0$ eine
  Singularität. Da die Laurentreihenentwicklung für die Funktion keine
  $z$ mit negativem Exponenten hat, ist $z_{0}$ eine hebbare
  Singularität.
  \begin{gather*}
    f(z) = \frac{\sin z}{z} = \frac{1}{z^{2}} ( z - \frac{z^{3}}{3!} +
       \frac{z^{5}}{5!} -+ \ldots ) = 1- \frac{z^{2}}{3!} +
       \frac{z^{4}}{5!} -+\ldots
  \end{gather*}

  Die Laurentreihenentwicklung für $f(z) = \frac{\cos z}{z}$ liefert ein
  Glied mit negativem Exponenten. Die Singularität $z_{0}=0$ ist ein Pol
  2.\,Ordnung.
  \begin{gather*}
    f(z) = \frac{\cos z}{z} = \frac{1}{z^{2}} ( 1 - \frac{z^{2}}{2!} +
       \frac{z^{4}}{4!} -+ \ldots ) = \frac{1}{z^{2}} - \frac{1}{2} +
       \frac{z^{2}}{4!} - \frac{z^{4}}{6!} +-\ldots
  \end{gather*}

  Für $e^{z^{-1}}$ ist die Singularität bei $z_{0}=0$ eine wesentliche
  Singularität.
  \begin{gather*}
    f(z) = e^{\frac{1}{z}} = \sum_{k=0}^{\infty} \frac{1}{k!}
       \big(\frac{1}{z}\big)^{k} = 1+\frac{1}{z} + \frac{1}{2z^{2}} +
       \frac{1}{3! z^{3}} + \ldots
  \end{gather*}

  analog $f(z) = \sin\frac{1}{x}$
\end{bsp}

\begin{bemerk}
  Aus dem Riemannschen Hebbarkeitssatz (\autoref{fol:10.2.4/8}) folgt: $z_{0}$
  ist eine hebbare Singularität \gdw $f$ beschränkt in einer Umgebung von
  $z_{0}$ und holomorph in $U(z_{0})\setminus\{z_{0}\}$ ist.

  Außerdem klar: $z_{0}$ Polstelle $\Rightarrow$
  $\lim_{\abs{z}\rightarrow\infty} \abs{f(z)} = \infty$, da $f(z) =
  \frac{1}{(z-z_{0})^{n}} (a_{-n} + a_{-n+1}(z-z_{0}) +\ldots)$
\end{bemerk}

\begin{satz}[Casorati-Weierstraß]
  $z_{0}$ ist eine wesentliche Singularität von $f$ \gdw für jedes
  $w\in\C$ existiert eine Folge $(z_{n})_{n}$ mit der Eigenschaft, dass
  $z_{n}\rightarrow z_{0}$ und $f(z_{n}) \rightarrow w$ für
  $n\rightarrow\infty$.
\end{satz}

\section{Eigenschaften holomorpher Funktionen}
\subsection{Der Identitätssatz für holomorphe Funktionen}

\begin{satz}
  Es sei $G\subset \C$ ein beliebiges Gebiet und wir betrachten
  holomorphe Funktionen $f,g\colon G\rightarrow \C$. Dann sind folgende
  Aussagen äquivalent:
  \begin{enumerate}
   \item Es existiert eine Menge $M\subset G$, die in $G$ einen
    Häufungspunkt besitzt, so dass $f(z) = g(z)$ für alle $z\in M$.

   \item Es existiert ein Punkt $z_{0}\in G$, in dem alle Ableitungen von
    $f$ und $g$ übereinstimmen: $f^{(k)}(z_{0})  =gf^{(k)}(z_{0})$
    $\forall k\in\N_{0}$.

   \item Es ist $f(z) = g(z)$ $\forall z\in G$.
  \end{enumerate}

  % 15. 2. 2006

  \begin{proof}
    \begin{enumerate}[1.\,{Schritt}]
     \item (1) $\Rightarrow$ (2) Es sei $h(z) := f(z)-g(z)$ $\Rightarrow$
      $h(z) = 0$ auf $M$, $\exists z_{0}\in G$, $z_{0}$ ist Häufungspunkt
      von $M$ $\Rightarrow$ $h(z_{0}) = 0$, da $h$ stetig in $z_{0}$.

      zeigen $h^{(k)}(z_{0}) = 0 (\forall k\in \N)$ Annahme: Sei $m$ die
      kleinste natürliche Zahl mit $h^{(m)}(z_{0})\ne0$
      Potenzreihenentwicklung von $h$ in $z_{0}$
      (\autoref{satz:10.2.4/6}) $\Rightarrow$
      \begin{gather*}
        h(z) = \sum_{k=m}^{\infty}
           \underbrace{\frac{h^{(k)}(z_{0})}{k!}}_{=a_{k}} (z-z_{0})^{k}
           = (z-z_{0})^{m} (a_{m} + a_{m+1}(z-z_{0}) + \ldots)
      \end{gather*}
      $a_{m}\ne0, h_{m}(z) =a_{m} + a_{m+1}(z-z_{0}) + \ldots$ ist
      holomorph in $K_{r}(z_{0})$

      $\Rightarrow$ $h_{m}(z_{0})\ne0$ $\Rightarrow$ $\exists
      K_{\delta}(z_{0})$ und $h_{m}(z)\ne0$ für alle $z\in
      K_{\delta}(z_{0})$, da $h_{m}$ stetig in $z_{0}$

      $\Rightarrow$ $h\ne0$ auf $K_{\delta}(z_{0})\setminus\{z_{0}\}$
      $\Rightarrow$ $M\cap K_{\delta}(z_{0})\setminus\{z_{0}\} =
      \emptyset$ $\Rightarrow$ $z_{0}$ kein Häufungspunkt.

     \item (2)$\Rightarrow$(3) Es sei $z_{0}$ wi in (2). $z\in G$
      beliebig. $\exists$ stetiger Polygonzug $\Gamma\subset G$ von
      $z_{0}$ nach $z$ und $\exists r>0$, so dass $\forall\zeta\in\Gamma$
      ist $\overline{K_{r}(\zeta)}\subset G$

      Aus der Potenzreihenentwicklung von $f$ und $g$ in $z_{0}$ folgt:
      $f=g$ auf $\overline{K_{r}(z_{0})}$. \textit{Anm.: Alle Ableitungen
      stimmen überein, dann stimmt die Potenzreihenentwicklung überein,
      dann stimmen die Funktionen überein}

      wählen $z_{1}\in\Gamma$ mit $\abs{z_{1}-z_{0}}=r$ $\Rightarrow$
      $f^{(k)}(z_{1}) = g^{(k)}(z_{1})\forall k$ $\Rightarrow$ $f=g$ auf
      $\overline{K_{r}(z_{1})}$. Da der Polygonzug endlich ist, erreicht
      man nach endlich vielen Iterationen den Punkt $z$ $\Rightarrow$
      $f(z) = g(z)$.
    \end{enumerate}
  \end{proof}
\end{satz}

\begin{folger}[Fortsetzung aus dem Reellen]
  $(a,b)\subset G\subset \C$, $G$ Gebiet, $f$ beliebig oft
  differenzierbar auf $(a,b)$ $\Rightarrow$ $\exists$ höchstens eine in
  $G$ holomorphe Funktion, die mit $f$ auf $(a,b)$ übereinstimmt.
\end{folger}

\begin{folger}
  $f\colon G\rightarrow\C$ holomorph, $f\ne0$, $z_{0}\in G$, $f(z_{0})=0$
  $\Rightarrow$ $\exists K_{\delta}(z_{0})\subset G$ mit $f(z)\ne0$ für
  alle $z$ aus $K_{\delta}(z_{0})\setminus\{z_{0\}}$ \textit{Anm.:
  Nullstellen sind Isoliert, Nullstellen bilden keine Häufungspunkte}

  $\exists m\in\N$, so dass $f(z)= (z-z_{0})^{m}g(z)$ mit $g(z_{0}) \ne0$
\end{folger}

\subsection{Ganze analytische Funktionen}

\begin{defini}
  $f\colon\C\rightarrow\C$ heißt \emph{ganze analytische Funktion}
  \gdwdef $f$ holomorph auf $\C$.
\end{defini}

\begin{satz}[Satz von Liouville]\label{satz:10.4.2/2}
  $f$ ganze analytische Funktion. $\exists c>0, n\in\N_{0}$, so dass
  $\forall z\in\C\colon \abs{f(z)}\leq c(1+\abs{z})^{n}$. Dann ist $f$
  ein Polynom höchstens $n$-ten Grades.

  \begin{proof}
    Potenzreihenentwicklung bei $0$ $\Rightarrow$ $f(z) =
    \sum_{k=0}^{\infty} a_{k} z^{k}\forall z\in\C$ mit
    $a_{k}=\frac{1}{2\pi i}\int_{\abs{z}=r} \frac{f(z)}{z^{k+1}}dz$,
    wobei $0<r<\infty$ (nach \autoref{satz:10.2.4/6}).

    Nach Vorrausetzung ist $\abs{z}>1$:
    \begin{gather*}
      \abs{f(z)} \leq 2^{n}c\abs{z}^{n} \Rightarrow ^{r>1} \abs{a_{k}}
         \leq \frac{1}{2\pi} 2^{n} c \frac{r^{n}}{r^{k+1}} 2\pi r = c_{1}
         \frac{1}{r^{k-n}} \xrightarrow{r\rightarrow\infty} 0 \forall k>n
    \end{gather*}
    $\Rightarrow$ $a_{k}=0$ für $k>n$
  \end{proof}
\end{satz}

\begin{folger}
  Für $n=0$ im Satz \autoref{satz:10.4.2/2} ergibt sich, dass konstante
  Funktionen die einizgsten ganzen analytischen Funktionen in $\C$ sind.
\end{folger}

\begin{satz}[Fundamentalsatz der Algebra]
  Ein Polynom $n$-ten Grades ($n\geq 1$) besitzt mindestens eine komplexe
  Nullstelle $z_{0}\in\C$.

  \begin{proof}
    indirekt. Annahme $P(z) \ne0$ $\forall z$ $\Rightarrow$
    $\frac{1}{P(z)}$ ist holomorph und beschränkt $\Rightarrow$
    $^{Folgerung 3}$ $\frac{1}{P(z)}$ ist konstant $\Rightarrow$
    Widerspruch zu $n\geq 1$
  \end{proof}
\end{satz}

\subsection{Maximumprinzip}

\begin{satz}[Maximumprinzip]
  Es sei $G\subset\C$ ein Gebiet
  \begin{enumerate}
   \item $f\colon G\rightarrow\C$ holomorph in $G$ und $\abs{f}$ habe
    lokales Maximum in $G$ $\Rightarrow$ $f=$const. in $G$

   \item $f\colon\overline{G}\rightarrow\C$ stetig, holomorph in $G$ und
    $G$ ein beschränktes Gebiet $\Rightarrow$ $\abs{f(z)} \leq
    \max_{\zeta\in\partial G} \abs{f(\zeta)}$ $\forall z\in\overline{G}$,
    d.\,h. $f$ nimmt Maximum auf dem Rand $\partial G$ an.
  \end{enumerate}
\end{satz}

\begin{satz}[Minimumprinzip]
  $G\subset \C$ Gebiet
  \begin{enumerate}
   \item $f\colon G\rightarrow\C$ holomorph, $\abs{f}$ habe lokales
    Minimum in $z_{0}\in G$ $\Rightarrow$ $f(z_{0})=0$ oder $f=$ konstant
    in $G$.

   \item $f\colon\overline{G}\rightarrow\C$ stetig und holomorph in $G$,
    $G$ beschränkt $\Rightarrow$ $f$ hat Nullstellen in $G$ oder
    $\abs{f}$ nimmt Minimum auf dem Rand an.
  \end{enumerate}
\end{satz}

\subsection{Konforme Abbildungen}

\begin{defini}
  $U,V\subset \C$ offen. $f\colon U\rightarrow V$ heißt \emph{konform}
  \gdwdef $f$ ist bijektiv und holomorph
\end{defini}

\begin{bemerk}
  Man kann zeigen:
  \begin{enumerate}
   \item $f\colon U\rightarrow\C$ holomorph, $U$ offen $\Rightarrow$
    $f(U) = \{w\colon f(z), z\in U\}$ offen

   \item $G\subset \C$ zusammenhängendes Gebiet, $f\colon G\rightarrow\C$
    holomorph $\Rightarrow$ $f(G)$ ist ein Gebiet -- \emph{Gebietstreue}

   \item $f\colon U\rightarrow V$ konform $\Rightarrow$ $f'(z) \ne0$ für
    alle $z\in U$, $f^{-1}\colon V\rightarrow U$ ist konform und
    $(f^{-1})'(f(z)) = (f'(z))^{-1}$
  \end{enumerate}
\end{bemerk}

Problem: Man finde alle $U\subset\C$ offen, so dass $\exists f\colon
U\rightarrow K_{1}(0)=\{z\colon\abs{z}<1\}$ konform!

\begin{satz}[Riemannscher Abbildungssatz]
  Es sei $G\subset\C$ eine nicht leere, offene Menge komplexer Zahlen.
  Dann sind äquivalent:
  \begin{enumerate}
   \item Es existiert eine konforme Abbildung von $G$ auf $K_{1}(0)$ oder
    $G=\C$.

   \item $G$ ist ein einfach zusammenhängendes Gebiet.
  \end{enumerate}
\end{satz}

\begin{bsp}
  Eine wichtige Rolle für Anwendungen spielen gebrochene lineare
  Transformationen
  \begin{gather*}
    F(z) = \frac{i-z}{i+z} \Rightarrow F^{-1}(w) = i\frac{1-w}{1+w}
  \end{gather*}
  $F\colon\{z\colon \Im z>0\} \leftrightarrow K_{1}(0)$
\end{bsp}

\vfill
\begin{center}
  \Huge Ende
\end{center}
\vfill\null\vfill

\clearpage
\appendix
\pdfbookmark[0]{Index}{index}
\printindex

\end{document}
