% Einige zusätzliche Informationen für rubber
%  rubber erkennt nicht, dass die Datei weg kann, daher sagen wir es ihm
% rubber: clean $base.thm
%  rubber soll nach Änderungen an der Datei nochmal bauen
% rubber: watch $base.thm
% rubber: index.tool      xindy
% rubber: index.language  german-din
%
% scrreprt trifft am Besten die Bedürfnisse eines Skripts, das ganze wird
% zweiseitig (twoside), d.h. es wird zwischen linker und rechter Seite
% unterschieden, und wir verwenden zwischen den Absätzen einen Abstand
% von einer halben Zeile (halfparskip) und dafür keinen Absatzeinzug,
% wobei die letzte Zeile eines Absatzes zu min. 1/4 leer ist.

\RequirePackage[l2tabu,orthodox]{nag}  % nag überprüft den Text auf veraltete
                   % Befehle oder solche, die man nicht in LaTeX verwenden
                   % soll -- l2tabu-Checker in LaTeX

\RequirePackage[ngerman=ngerman-x-latest]{hyphsubst} % einbinden der neuen
                   % Trennmuster, diese korrigieren einige Fehler der alten
                   % und bieten mehr Trennstellen

\documentclass[ngerman,draft,parskip=half*,twoside]{scrreprt}

\usepackage[ngerman]{babel}
\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage[all,warning]{onlyamsmath}  % warnt bei Verwendung von nicht
                                       % amsmath-Umgebungen z.\,B. $$...$$
\usepackage{amssymb}     % wird für \R, \C,... gebraucht
\usepackage{fixmath}     % ISO-konforme griech. Buchstaben
\usepackage[euro]{isonums} % definiert Komma als Dezimaltrennzeichen
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amscd}
\usepackage{units}
\usepackage{ae}
\usepackage{wasysym}
\usepackage{enumerate}
\usepackage{index}
\usepackage{nicefrac}
\usepackage{svn}         % Zum Auswerten und ordentlichen Darstellen der
                         % SVN-Schlüsselwörter (s. vor \begin{document})
                         % dafür muss in SVN noch das Flag svn:keywords
                         % auf "LastChangedRevision LastChangedDate"
                         % gesetzt werden
\usepackage{mathtools}   % Zur Definition von \abs und \norm
\usepackage[draft=false,colorlinks,bookmarksnumbered,linkcolor=blue,breaklinks]{hyperref}

\makeindex

\usepackage[scaled=.90]{helvet}
\usepackage{courier}

\newcommand*{\N}{\mathbb{N}}
\newcommand*{\Z}{\mathbb{Z}}
\newcommand*{\Q}{\mathbb{Q}}
\newcommand*{\R}{\mathbb{R}}
\newcommand*{\K}{\mathbb{K}}
\newcommand*{\C}{\mathbb{C}}
\newcommand*{\LL}{\mathcal{L}}
\newcommand*{\RR}{\mathcal{R}}
\newcommand*{\ZZ}{\mathfrak{Z}}
\newcommand*{\MM}{\mathfrak{M}}
\newcommand*{\CC}{\mathcal{C}}
\newcommand*{\perdef}{\colon\Leftrightarrow}

\theoremstyle{plain}
\newtheorem{definition}{Definition}[section]
%%\newtheorem{remark}[definition]{Bemerkung}
\newtheorem{proposition}[definition]{Feststellung}
\newtheorem{lemma}[definition]{Lemma}
\newtheorem{theorem}[definition]{Satz}
\newtheorem{notation}[definition]{Notation}
\newtheorem{Folg}[definition]{Folgerung}

\theoremstyle{remark}
\newtheorem*{remark}{Bemerkung}
\newtheorem*{beispiel}{Beispiel}


\SVN $LastChangedRevision$
\SVN $LastChangedDate$

\begin{document}
\title{Vorlesungsskript zu Analysis II
  \thanks{$LastChangedRevision$ vom $LastChangedDate$}}
\author{Jens Kubieziel}
\date{Sommersemester 2004}
\maketitle

\clearpage
\chapter*{Vorwort}

{\itshape
  Dieses Dokument wurde als Skript für die auf der
  Titelseite genannte Vorlesung erstellt und wird jetzt im Rahmen des
  Projekts
  "`\href{http://uni-skripte.lug-jena.de/}
  {Vorlesungsskripte der Fakultät für Mathematik}
  \href{http://uni-skripte.lug-jena.de/}{und Informatik}"'
  weiter betreut. Das
  Dokument wurde nach bestem Wissen und Gewissen angefertigt. Dennoch
  garantiert weder der auf der Titelseite genannte Dozent, die Personen,
  die an dem Dokument mitgewirkt haben, noch die
  Mitglieder des Projekts für dessen Fehlerfreiheit. Für etwaige Fehler
  und dessen Folgen wird von keiner der genannten Personen eine Haftung
  übernommen. Es steht jeder Person frei, dieses Dokument zu lesen, zu
  verändern oder auf anderen Medien verfügbar zu machen, solange ein
  Verweis auf die Internetadresse des Projekts
  \url{http://uni-skripte.lug-jena.de/}
  enthalten ist.

  Diese Ausgabe trägt die Versionsnummer~\SVNLastChangedRevision{} und ist vom
  \SVNDate{}. Eine neue Ausgabe könnte auf der Webseite des Projekts verfügbar
  sein.

  Jeder ist dazu aufgerufen, Verbesserungen, Erweiterungen und
  Fehlerkorrekturen für das Skript einzureichen bzw. zu melden oder diese
  selbst einzupflegen -- einfach eine E-Mail an die
  \href{mailto:uni-skripte@lug-jena.de}{Mailingliste
  \nolinkurl{<uni-skripte@lug-jena.de>}} senden. Weitere Informationen
  sind unter der oben genannten Internetadresse verfügbar.

  Hiermit möchten wir allen Personen, die an diesem Skript mitgewirkt
  haben, vielmals danken:
  \begin{itemize}
   \item \href{mailto:jens@kubieziel.de}{Jens Kubieziel \nolinkurl{<jens@kubieziel.de>}}
  \end{itemize}
}


\tableofcontents
\chapter{Normierte Räume}
\section{Definition und Beispiele für normierte Räume}

\begin{definition}
  Sei $E$ ein linearer Raum (Vektorraum) über $\K$\footnote{$\K=\R$ oder
  $\K=\C$}. Eine Funktion $||\cdot||\colon E\rightarrow [0,\infty[$ heißt
  \emph{Norm\index{Norm}} auf $E$, wenn für beliebige $x,y\in E$ und
  $\alpha\in\K$ gilt:
  \begin{enumerate}[(N1)]
    \item $||x||\geq 0 \wedge ||x||=0\perdef x=0$
    \item $||\alpha x||=|\alpha|\cdot ||x||$ Homogenität\index{Homogenität}
    \item $||x+y||\leq ||x||+||y||$ Dreiecksungleichung
  \end{enumerate}
  Das Paar $[E,||\cdot ||]$ heißt \emph{normierter
    Raum\index{Raum!normierter}}.
\end{definition}

\begin{remark}
  Durch den Ansatz $d(x,y)\coloneqq ||x-y||$ wird auf $E$ eine
  Metrik erklärt. Damit ist $E$ insbesondere ein metrischer
  Raum. Begriffe, wie konvergente Folge, Cauchyfolge,
  offene/abgeschlossene Mengen etc. gelten auch für normierte
  Räume. z.B.: $(x_n)\subset E$ konvergiert in $E\colon  \exists x\in E \,
  \forall \varepsilon>0 \, \exists n_\varepsilon\in \N \, \forall
  n>n_\varepsilon\colon ||x_n-x||\leq \varepsilon$
\end{remark}

\begin{definition}
  Ein vollständiger normierter Raum heißt
  \emph{Banachraum\index{Banachraum}}.
\end{definition}

\begin{beispiel}
  \begin{enumerate}
  \item $[\R,|\cdot|]$ ist der normierte Raum über den reellen Zahlen
    mit der Betragsfunktion.
  \item $[\R^n,||\cdot||_p], x=(\xi_1,\dots,\xi_n),||x||_p=
    \begin{cases}
      \left(\sum_{i=1}^n |\xi_i|^p\right)^{\nicefrac{1}{p}} & 1\leq p<\infty\\
      \max_{1\leq i \leq n} |\xi_i| & p=\infty
    \end{cases}$
    \begin{itemize}
    \item $||\cdot||_1 = \sum_{i=1}^n |\xi_i|$ heißt
      Summennorm\index{Summennorm}.
    \item $||\cdot||_2= \sqrt{\sum_{i=1}^n |\xi_i|^2}$ heißt
      euklidische Norm\index{Norm!euklidische}.
      \item $||\cdot||_\infty$ heißt Maximumnorm\index{Maximumnorm}.
    \end{itemize}
  \item
    \begin{enumerate}[(a)]
    \item Normierter Raum der beschränkten Funktionen auf einer Menge
      $\Omega\colon $\\
      $[B(\Omega),||\cdot||_\infty]$,
      $B(\Omega)\coloneqq \{f\colon \Omega\rightarrow\R|f\text{ beschränkt}\},
      ||f||_\infty\coloneqq \sup_{x\in\Omega}|f(x)|$\\
      Bemerkung: $B(\{1,\dots,n\})=\R^n, f=(f(1),\dots,f(n)), B(\N)$
      Raum der beschränkten Folgen
    \item Sei $[X,d]$ ein metrischer Raum. Normierter Raum der 
      beschränkt stetigen Funktionen auf $X\colon [C_b(X),||\cdot||_\infty],
      C_b(X)\coloneqq \{f\colon X\rightarrow\R|f \text{ beschränkt stetig}\}$
    \end{enumerate}
  \item Ist $X$ ein kompakter metrischer Raum, so gilt: $C_b(X)=C(X),
    [C_b(X),||\cdot||_\infty]=[C(X),||\cdot||_\infty]$
  \item Normierter Raum der $\RR$-integrierbaren Funktionen:
    $[\RR[a,b],||\cdot||_\infty], \RR[a,b]=\{f\colon [a,b]
    \rightarrow\R|f\text{ Riemann-integrierbar}\}, ||f||_\infty\coloneqq 
    \sup_ {x\in I}|f(x)|$
  \item $[C^1[a,b],||\cdot||_\infty], C^1[a,b]\coloneqq \{f\in C[a,b]|f 
    \text{ stetig differenzierbar auf } ]a,b[\}$
  \end{enumerate}
\end{beispiel}

\begin{theorem}
  $[B(\Omega),||\cdot||_\infty], [C_b(X),||\cdot||_\infty],[
  \RR[a,b],||\cdot||_\infty]$ sind Banachräume. Daraus folgt,
  dass auch $[\R^n,||\cdot||_\infty]$ ein Banachraum ist, denn 
  $B(\{1,\dots,n\})=\R^n$.
\end{theorem}
\begin{proof}: Vollständigkeit von $[C_b(X),||\cdot||_\infty]$:\\
  Sei $(f_n)\subset C_b(X)$ eine Cauchyfolge. Dann ist zu zeigen, dass
  ein  $f\in C_b(X)$ mit $\lim_{n\rightarrow\infty}||f_n-f||_\infty=0$
  existiert.
  \begin{enumerate}
  \item Existenz des Limes\\
    $(f_n)$ ist eine Cauchyfolge, d.h. $\forall \varepsilon>0 \,
    \exists n_\varepsilon \in \N \, \forall n,m \geq n_\varepsilon \colon 
    ||f_n-f_m||_\infty\leq\varepsilon$\\
    $||f_n-f_m||=\sup_{x\in X} |f_n(x)-f_m(x)|\leq\varepsilon
    \Leftrightarrow \forall x\in X \colon  |f_n(x)-f_m(x)|\leq\varepsilon$
    Bei festem $x\in X$ gilt: $(f_n(x))$ ist eine Cauchyfolge in $\R$.
    Da $\R$ vollständig ist, folgt daher: $\exists \lim_{n\rightarrow\infty}
    f_n(x)=\colon f(x)$
  \item Beschränkheit von $f$:\\
    $\forall x\in X \, \forall m\geq n\geq n_\varepsilon \colon  |f_n(x)-f_m(x)|
    \leq\varepsilon\xrightarrow{m\rightarrow\infty}\forall x\in X
    \, \forall n\geq n_\varepsilon \colon  |f_n(x)-f(x)|\leq\varepsilon
    \Rightarrow ||f_n-f||\leq\varepsilon \text{ für } n\geq n_\varepsilon$
    Insbesondere gilt: $||f||_\infty=||f_{n_\varepsilon}+f-f_{n_\varepsilon}
    ||_\infty\leq ||f_{n_\varepsilon}||_\infty + ||f-f_{n_\varepsilon}||_\infty
    \leq ||f_{n_\varepsilon}||_\infty + \varepsilon <\infty$
    d.h. $f$ ist beschränkt.
  \item Stetigkeit von $f$:\\
    Sei $x_0\in X$ beliebig und $f_{n_\varepsilon}$ stetig: 
    $\exists\delta_\varepsilon>0 \, \forall x\in X\colon  d(x,x_0)\leq
    \delta_\varepsilon\Rightarrow|f_{n_\varepsilon}(x)-f_{n_\varepsilon}(x_0)|
    \leq\varepsilon\Rightarrow |f(x)-f(x_0)|\leq |f(x)-f_{n_\varepsilon}(x)|
    +|f_{n_\varepsilon}(x)-f_{n_\varepsilon}(x_0)|+|f_{n_\varepsilon}
    (x_0)-f(x_0)|\leq\varepsilon + \varepsilon + \varepsilon =3\varepsilon$
    D.h. $f$ ist in $x_0$ stetig und es folgt, dass auch $f$ auf $X$ stetig
    ist.
  \end{enumerate}
  Die Punkte 2 und 3 implizieren, dass $f\in C_b(X)$ und 
  $\lim_{n\rightarrow\infty}||f_n-f||=0\Rightarrow [C_b(X),||\cdot||_\infty]$
  ist ein vollständiger normierter Raum.
  \qed\\
  Die Vollständigkeit von $[B(\Omega),||\cdot||_\infty]$ kann analog zu
  1. und 2. bewiesen werden.\\
  Für die Vollständigkeit von $[\RR[a,b],||\cdot||_\infty]$ genügt es, zu
  zeigen, dass $[\RR[a,b],||\cdot||_\infty]$ in $B[a,b]$ abgeschlossen
  ist:\\
  Sei $(f_n)\subset\RR[a,b]\colon f_n\rightarrow f\in B[a,b] (||f_n-f||_\infty
  \rightarrow 0)$. zu zeigen: $f\in\RR [a,b]$:\\
  Sei $\varepsilon >0$. Für $\eta\coloneqq \frac{\varepsilon}{4(b-a)}$ wählen
  wir $n_0\in\N\colon ||f_n-f||_\infty=\sup_{x\in[a,b]} |f_{n_0}(x)-f(x)|
  \leq \eta\Leftrightarrow \forall x\in[a,b]\colon -\eta-f_{n_0}(x)\leq f(x)
  \leq \eta + f_{n_0}(x)\Rightarrow\overline{S}(f;\ZZ)\leq \overline{S}
  (f_{n_0}+\eta;\ZZ)\leq \overline{S}(f_{n_0};\ZZ)+\overline{S}(\eta;\ZZ)
  =\overline{S}(f_{n_0};\ZZ)+\eta(b-a)=\overline{S}(f_{n_0};\ZZ)+
  \frac{\varepsilon}{4}$\\
  $\underline{S}(f;\ZZ)\geq \underline{S}(f_{n_0}-\eta;\ZZ)\geq
  \underline{S}(f_{n_0};\ZZ)+\underline{S}(-\eta;\ZZ)=\underline{S}
  (f_{n_0};\ZZ)-\eta(b-a)=\underline{S}(f_{n_0};\ZZ)-\frac{\varepsilon}{4}$\\
  Also:
  \begin{align*}
    \overline{S}(f;\ZZ)-\underline{S}(f;\ZZ) & \leq & \overline(f_{n_0};\ZZ)
    +\frac{\varepsilon}{4}-(\underline{S}(f_{n_0};\ZZ)-\frac{\varepsilon}{4})\\
    & = & \overline{S}(f_{n_0};\ZZ)-\underline{S}(f_{n_0};\ZZ)+
    \frac{\varepsilon}{2}
  \end{align*}
  $f_{n_0}\in\RR[a,b]\Rightarrow\exists\ZZ_\varepsilon\colon \overline{S}
  (f_{n_0};\ZZ)-\underline{S}(f_{n_0};\ZZ\leq\frac{\varepsilon}{2}
  \Rightarrow\overline{S}(f;\ZZ_\varepsilon)-\underline{S}f;\ZZ_\varepsilon)
  \leq \frac{\varepsilon}{2}+\frac{\varepsilon}{2}=\varepsilon$, d.h. $f
  \in\RR[a,b]$ ist in $B[a,b]$ abgeschlossen. Daraus folgt, dass 
  $\RR[a,b]$ vollständig ist.
\end{proof}

\begin{remark}
  Konvergenz bezüglich $||\cdot||_\infty$ heißt \emph{gleichmässige
  Konvergenz\index{Konvergenz!gleichmässige}} von
  Funktionen in $B(\Omega), C_b(X)$ oder $\RR[a,b]$.\\
  $||f_n-f||_\infty\rightarrow 0\Leftrightarrow\forall\varepsilon>0\,
  \exists n_\varepsilon\in\N\,\forall n\geq
  n_\varepsilon\colon ||f_n-f||_\infty =\sup_x |f_n(x)-f(x)|\leq\varepsilon
  \Leftrightarrow$
  \[\forall\varepsilon>0\,\exists n_\varepsilon\in\N\,\forall n\geq
  n_\varepsilon\,\forall x\colon  |f_n(x)-f(x)|\leq\varepsilon\] Im
  Gegensatz dazu ist die punktweise
  Konvergenz\index{Konvergenz!punktweise} einer Folge wie folgt
  definiert:
  \[\forall x\,\forall\varepsilon>0\,\exists n_\varepsilon\in\N\,
  \forall n\geq n_\varepsilon\colon |f_n(x)-f(x)|\leq\varepsilon\]
  Aus gleichmässiger Konvergenz folgt punktweise Konvergenz.
\end{remark}

\subsubsection{Gleichmässige Konvergenz und Integration}
\begin{theorem}
  \label{satz:gleichKonvInt}
  $(f_n)\subset\RR[a,b]$ und $f_n \xrightarrow{||\cdot||_\infty} f$.
  Dann gilt: 
  \[f\in\RR[a,b]\text{ und }\lim_{n\rightarrow\infty} \int_a^b
  f_ndx=\int_a^b \lim f_ndx=\int_a^bfdx\]
\end{theorem}
\begin{proof}
  $(f_n)\in\RR[a,b], f_n\xrightarrow{||\cdot||_\infty}
  f\Rightarrow f\in\RR[a,b]$\\
  Sei $\varepsilon>0$. Dann existiert $n_\varepsilon\in\N\,\forall n\geq
  n_\varepsilon\colon ||f_n-f||_\infty\leq\varepsilon$
  \begin{align*}
    \left|\int_a^bf_ndx-\int_a^bfdx\right|
    & = \left|\int_a^b(f_n-f)dx\right| \leq \int_a^b |f_n-f|dx\\
    & =  \int_a^b |f_n(x)-f(x)|dx \leq \int_a^b ||f_n-f||_\infty dx\\
    & \leq \int_a^b\varepsilon dx = \varepsilon(b-a) \quad\text{für }
    n\geq n_\varepsilon
  \end{align*}
  Dies heißt, dass $\lim\int_a^b f_n(x)dx=\int_a
  ^b \lim f_n(x)dx=\int_a^b fdx$.
\end{proof}

\begin{remark}
\begin{enumerate}[(i)]
\item Der Satz \ref{satz:gleichKonvInt} gilt nicht für punktweise Konvergenz.
  \begin{beispiel}
    $f_n\colon [0,1]\rightarrow\R,f_n(x)\coloneqq \max\{n-n^2|x-\frac{1}{n}|;0\}=
    \begin{cases}
      n^2x & 0\leq x\leq \frac{1}{n}\\
      2n-n^2x & \frac{1}{n}\leq x \leq\frac{2}{n}\\
      0 & \frac{2}{n}\leq x\leq 1
    \end{cases}$\\
    $f_n(x)\rightarrow 0$ punktweise\\
    $f_n$ ist nicht punktweise konvergent gegen 0. Denn $||f_n-f||_\infty
    =||f_n-0||_\infty=||f_n||_\infty=n\rightarrow\infty$\\
    $\int_a^b f_n(x)dx=1 \, \forall n\geq 2,\lim\int_0
    ^1 f_n(x)dx=1$, Aber $\int_0^1\lim_{n\rightarrow\infty}
    f_n(x)dx=\int_0^1 0dx=0$
  \end{beispiel}
\item Satz \ref{satz:gleichKonvInt} gilt nicht für uneigentliche Integrale
  (unendliche Intervalle).\\
  Beispiel: $f_n\colon [0,\infty[\rightarrow\R,f_n(x)\coloneqq \frac{x}{n^2}e^{-\frac{x}{n}},
  ||f_n||_\infty=\frac{1}{en}, ||f_n||_\infty\rightarrow 0$.\\
  Aber $\int
  _0^\infty f_n(x)dx=\frac{1}{n}+1\rightarrow 1$ und $\int
  _0^\infty\lim f_n(x)dx=\int_0^\infty0dx=0$
\end{enumerate}
\end{remark}

\paragraph{Gleichmässige Konvergenz und Differentiation}
\begin{theorem}
  Seien $f_n\colon [a,b]\rightarrow\R$ stetig differenzierbar und $f_n
  \rightarrow f\colon [a,b]\rightarrow\R$ punktweise konvergent.
  Die Folge der Ableitungen $f_n'[a,b]\rightarrow\R$ konvergiere
  gleichmässig. Dann ist $f$ stetig differenzierbar und es gilt
  \[f'(x)=\lim_{n\rightarrow\infty}f_n'(x)\]
\end{theorem}
\begin{proof}
  $f_n'\xrightarrow{||\cdot||}g\in  C[a,b]$\\
  zu zeigen: $g=f'$\\
  $\forall x\in [a,b] \, f_n(x)=f_n(a)+\int_{a}^{x} f_n'(t)dt$\\
  $f_n'$ ist stetig. Obiges kann man wegen des Hauptsatzes der
  Differential- und Integralrechnung schliessen. Aus dem Satz
  \ref{satz:gleichKonvInt} folgt
  $\lim_{n\rightarrow\infty}\int_{a}^{x} f_n'(t)dt= \int_{a}^{x}
  \lim_{n\rightarrow\infty}f_n'(t)dt= \int_{a}^{x} g(t)dt$. Also:
  $f(x)=f(a)+\int_{a} ^{x} f_n'(t)dt\Rightarrow f'(x)=g(x)\Rightarrow
  f'=g$
\end{proof}

\begin{remark}
  \begin{itemize}
  \item Selbst wenn gilt $f_n\xrightarrow{||\cdot||}f$, impliziert $f$
    differenzierbar i.a. nicht, dass $\lim f_n' (x)=f'(x)$.
  \item $f_n\colon [-N,N]\rightarrow\R\quad f_n(x)=\frac{1}{n}\sin (nx)$
    beliebig oft differenzierbar\\
    $||f_n||_\infty=\frac{1}{n}\rightarrow 0\Rightarrow \lim f_n=0$\\
    $f_n'(x)=\cos(nx)\not\rightarrow f'(x)=0$
  \end{itemize}
\end{remark}

\section{Endlichdimensionale normierte Räume}
\begin{definition}
  Ein Vektorraum $E$ (über $\K$) heißt genau dann 
  \emph{endlichdimensional\index{endlichdimensional}}, wenn
  \[\exists m\in\N \, \exists x_1,\dots,x_m\in E \, \forall x\in E\,
  \exists \alpha_1,\dots,\alpha_m\in\K\colon  x=\sum_{i=1}^{m} \alpha_ix_i\]
\end{definition}
\[\dim E \coloneqq \inf\{m| \exists x_1,\dots,x_m\in E\, \forall x\in A\,
\exists \alpha_1,\dots,\alpha_m\in\K\colon x=\sum_{i=1}^m\alpha_ix_i\}\]
Beispiel: $\R^n, \C^n$

\begin{theorem}[Satz von
  Bolzano/Weierstrass\index{Bolzano/Weierstrass!Satz von}]
  \label{satz:bw}
  Sei $K\subset\R^n$. Dann gilt: $K$ ist genau dann kompakt in
  $[\R^n,||\cdot||_\infty]$, wenn $ K$ abgeschlossen und beschränkt in
  $[\R^n,||\cdot||_\infty]$ ist.
\end{theorem}
\begin{proof}
  Der Beweis wird auf den gleichlautenden Satz in $[\R,|\cdot|]$
  zurückgeführt:
  \begin{enumerate}
    \item Aus der Tatsache, dass $K$ kompakt ist, folgt, dass es auch
      abgeschlossen und beschränkt ist.
    \item Sei $K$ abgeschlossen und beschränkt, d.h.
      \begin{enumerate}
      \item $\exists M\geq 0\, \forall x\in\K\colon ||x||_\infty\leq M$
      \item $\forall (x_n)\subset K\colon  x_n\xrightarrow{||\cdot||}
        x\in\R^n\Rightarrow x\in K$
      \end{enumerate}
  \end{enumerate}
  Betrachten den Fall $n=2$: Sei $(x_n)\subset K, x_n =(\xi_1^{(n)},
  \xi_2^{(n)}), ||x_n||_\infty=\max\{|\xi_1^{(n)}|,|\xi_2^{(n)}|\}\leq
  M (\xi_1^{(n)},\xi_2^{(n)}<\R$ beschränkt. Nach dem Satz von
  Bolzano/Weierstrass aus der Analysis~I folgt, dass es eine
  konvergente Teilfolge
  $(\xi_1^{(n_k)})\subset(\xi_1^{(n)})\colon \xi_1^{(n_k)}
  \rightarrow\xi\in\R$ gibt. Die entsprechende Teilfolge
  $(\xi_2^{(n_k)}) \subset\xi_2^{(n)}$ ist ebenfalls beschränkt und
  enthält eine konvergente Teilfolge
  $(\xi_2^{(n_k)_l})\colon (\xi_2^{(n_k)_l})\rightarrow \xi_2\in\R$. Damit
  hat die Folge $x_{(n_k)_l}=(\xi_1^{(n_k)_l},
  \xi_2^{(n_k)_l})\rightarrow x=(\xi_1,\xi_2)$. Denn
  $||x_{(n_k)_l}-x||_\infty
  =\max\{|\xi_1^{(n_k)_l}-\xi_1|,|\xi_2^{(n_k)_l}-\xi_2|\}\leq
  |\xi_1^{(n_k)_l}-\xi_1|+|\xi_2^{(n_k)_l}-\xi_2|\rightarrow 0$, d.h.
  $x_{(n_k)_l}\rightarrow x$. Somit enthält $(x_n)\subset K$ eine
  konvergente Teilfolge mit Grenzwert $x$. Da $K$ abgeschlossen ist,
  folgt, dass $x$ Element von $K$ ist und dass $K$ kompakt ist. Der
  Beweis für $n>2$ ist analog.
\end{proof}

\begin{definition}
  Sei $E$ ein Vektorraum und $||\cdot||_0,||\cdot||$ zwei Normen auf $E$.
  $||\cdot||_0$ und $||\cdot||$ heissen genau dann auf $E$ äquivalent,
  wenn 
  \[\exists c_0,c>0\,\forall x\in E\colon  ||x||_0\leq c_0||x||\qquad
  ||x||\leq c||x||_0\]
\end{definition}

\begin{theorem}
  \label{satz:VRNorm}
  Auf einem endlichdimensionalen Vektorraum $E$ über
  $\K$\footnote{$\K=\R$ oder $\K=\C$} sind sämtliche Normen
  äquivalent.
\end{theorem}
\begin{proof}
  Sei $\dim E=n$ und $\{x_1,\ldots,x_n\}$ eine Basis von $E$. Für die $x\in
  E$ existieren $\alpha_1,\ldots,\alpha_n\in\R$ mit $x = \sum_{i=1}^n
  \alpha_ix_i$. Sei $||\cdot||$ eine beliebige Norm auf $E$. Des
  weiteren definieren wir eine Norm $||\cdot||_0$ auf $E$ durch
  $||x||_0\coloneqq \sum_{i=1}^n|\alpha_i|=||\alpha||_1$ mit $\alpha=
  (\alpha_1, \ldots, \alpha_n)\in\R^n$. Es genügt nun, zu zeigen, dass
  $||\cdot||_0$ und  $||\cdot||$ äquivalent sind.
  \[||x||=\left|\left|\sum_{i=1}^n \alpha_i\cdot x_i\right|\right|
  \leq \sum_{i=1}^n |\alpha_i|\cdot ||x_i|| \leq \max_{1<i\leq n}
  ||x_i|| \sum_{i=1}^n |\alpha_i|= \left(\underbrace{\max_{1<i\leq n}
      ||x_i||}_{=c}\right)||x||_0\]
  Jetzt ist "`$||\cdot||_0\leq c_0||\cdot||$"'. Dazu betrachten wir
  folgende Funktion: $f\colon [\R^n,||\cdot||_\infty]\rightarrow\R,
  f(\alpha_1, \dots,\alpha_n)\coloneqq ||\sum_{i=1}^n \alpha_i x_i||$. Es
  gilt, dass $f$  stetig ist.\\
  Denn $|f(\alpha_1,\dots,\alpha_n)-f(\beta_1,\dots,\beta_n)|
  =||\sum_1^n (\alpha_i-\beta_i)x_i||\leq \sum_1^n |\alpha_i-\beta_i|
  \cdot ||x_i||\leq \max_{1\leq i \leq n} ||x_i|| \cdot\sum_1^n
  |\alpha_i-\beta_i|\leq n\cdot\underbrace{\max_{1\leq i\leq n}
    |\alpha_i-\beta_i|}_{=||(\alpha1,\dots,\alpha_n)-(\beta_1-\beta_n)||_\infty}$. Daraus folgt, dass $f$ stetig ist.\\
  $S=\{\alpha=(\alpha_1,\dots,\alpha_n)\in\R^n|\sum_{i=1}^n
  |\alpha_i|=1\} \subset\R^n$ ist abgeschlossen und beschränkt in
  $[\R^n,||\cdot||_\infty]$.  Denn für
  $g(\alpha_1,\dots,\alpha_n)\coloneqq \sum_{i=1}^n|\alpha_i|, g\colon 
  [\R^n,||\cdot||_\infty]\rightarrow\R$ gilt, dass $g$ stetig
  ist. Damit ist $S=g^{-1}(\{1\})$ (Urbild) abgeschlossen. $S$ ist
  beschränkt:
  $||\alpha||_\infty=||(\alpha_1,\dots,\alpha_n)||_\infty\leq\sum_{i=1}^n
  |\alpha_i|=1$ für $\alpha=(\alpha_1,\dots,\alpha_n)\in S$. Somit ist
  $S$ in $[\R^n,||\cdot||_\infty]$ kompakt nach Satz
  \ref{satz:bw}. Weil
  $f$ stetig ist, folgt, dass $f$ auf $S$ das Minimum annimmt, d.h.\\
  $\exists (\alpha_1^0,\dots,\alpha_n^0)\in S \, \forall
  (\alpha_1,\dots, \alpha_n)\in S\colon 
  0<\frac{1}{c_0}=f((\alpha_1^0,\dots,\alpha_n^0)\leq
  f(\alpha_1,\dots,\alpha_n)=||\sum_1^n \alpha_ix_i||$.  Sei $0\neq
  x\in E$ beliebig. Dann existiert $0\neq(\alpha_1,\dots,
  \alpha_n)\in\R^n:x=\sum_{i=1}^n \alpha_ix_i$. Für
  $\left(\frac{\alpha_1}{\sum_{i=1}^n |\alpha_i|},
    \frac{\alpha_2}{\sum_{i=1}^n |\alpha_i|},\dots,
    \frac{\alpha_n}{\sum_{i=1}^n |\alpha_i|}\right)\in S$ gilt
  $\frac{1}{c_0}\leq ||\sum_{k=1}^n \frac{\alpha_k}{\sum_{i=1}
    |\alpha_i|} x_k||=\frac{1}{\sum_{i=1}^n
    |\alpha_i|}||\sum_1^n\alpha_n x_k|| \Rightarrow
  ||x_0||=\sum_{i=1}^n |\alpha_i||\leq c_0 ||\sum_1^n \alpha_k
  x_k||=c_0||x||$. Für $x=0$ ist die Ungleichung ebenfalls erfüllt.
\end{proof}

\begin{theorem}
  \begin{enumerate}[(i)]
    \item Ein endlichdimensionaler normierter Raum $[E,||\cdot||]$
      über $\R$ (bzw. $\C$) ist ein Banachraum.
    \item (Bolzano/Weierstrass-Eigenschaft) Sei $K$ eine Menge eines
      endlichdimensionalen normierten Raumes $E$. Dann gilt: $K$ ist
      genau dann kompakt, wenn $K$ beschränkt und abgeschlossen ist.
  \end{enumerate}
\end{theorem}
\begin{proof}
  $x=\sum_{i=1}^n \alpha_iy_i\quad (\alpha_i\in\R)$\\
  $||x_0||\coloneqq \max_{1\leq i\leq n}|\alpha_i|=||\alpha||_\infty,\alpha=
  (\alpha_1,\dots,\alpha_n)\in\R^n$ ist eine Norm auf $E$. Nach Satz
  \ref{satz:VRNorm} existieren $c, C>0\colon c||x||_0\leq ||x||\leq C||x||_0$.
  \begin{enumerate}[(i)]
  \item Sei $x_k=\sum_{i=1}^n \alpha_i^{(k)} y_i, \alpha_i^{(k)}=
    (\alpha_1^{(k)},\dots,\alpha_n^{(k)})\in\R^n$. Es gilt $c||
    \alpha^{(k)}-\alpha^{(l)}||_\infty\leq ||x_k-x_l||\leq C
    ||\alpha^{(k)}-\alpha^{(l)}||_\infty$. Sei $(x_k)\subset E$ eine
    Cauchyfolge. Dann folgt, dass
    $(\alpha^{(k)})\subset[\R^n,||\cdot||_\infty]$ eine Cauchyfolge
    ist. Da nun $[\R^n,||\cdot||8]$ vollständig ist, gibt es ein
    $\alpha =)\alpha_1,\dots,\alpha_n)\in\R^n\colon ||\alpha^{(k)}
    -\alpha||_\infty\rightarrow 0\Rightarrow ||x_k-x||\rightarrow 0,
    x=\sum_{i=1}^n \alpha_iy_i\in E$. Also konvergiert $(x_k)$ in $E$
    gegen $x$ und es folgt, dass $E$ vollständig ist.
  \item
    \begin{itemize}
    \item["`$\Rightarrow$"'] klar, siehe Analysis I
    \item["`$\Leftarrow$"'] Definieren $f\colon [\R^n, ||\cdot||_\infty]
      \rightarrow E, f(\alpha_1,\dots,\alpha_n)\coloneqq \sum_{i=1}^n
      \alpha_i y_i, \{y_i\}$ ist eine Basis in $E$. Es gilt
      \begin{enumerate}
      \item $f$ ist bijektiv von $\R^n$ auf $E$.
      \item $f,f^{-1}$ sind stetige Funktionen nach den Ungleichungen,
        die zu Beginn des Beweises genannt sind.
      \end{enumerate}
      Sei $K\subset E$ beschränkt und abgeschlossen. $f^{-1}(K)=
      \{(\alpha_1,\dots,\alpha_n)\in\R^n\colon \sum_{i=1}^n \alpha_iy_i
      \in K\}$ ist beschränkt, da $K$ beschränkt (wegen Ungleichung
      oben) und abgeschlossen (Urbilder von abg. Mengen sind wieder
      abg.), da $f$ stetig ist. Nach Satz \ref{satz:bw} folgt:
      $f^{-1}(K)\subset [\R^n,||\cdot||_\infty]$ kompakt. Da $f$
      stetig ist, folgt $K=f(f^{-1}(K))\subset E$ kompakt.
    \end{itemize}
  \end{enumerate}
\end{proof}

Bemerkung: Es gilt sogar: Sind in einem Banachraum $E$ die beschränkten
und abgeschlossenen Mengen kompakt, so ist $E$ endlichdimensional.

\section{Stetige lineare Abbildungen (Operatoren) zwischen normierten Räumen}
\begin{definition}
  Seien $E,F$ Vektorräume über $\K$. Eine Abbildung $A\colon E\rightarrow F$
  heißt \emph{linear\index{Abbildung!lineare}}, genau dann wenn:
  \[\forall \alpha,\beta\in\K\,\forall x,y\in E\colon  A(\alpha x+\beta y)=
  \alpha Ax+\beta Ay\]
\end{definition}

Bemerkung: Lineare Abbildungen zwischen endlichdimensionalen
Vektorräumen können durch Matrizen dargestellt werden.

\begin{definition}
  Seien $E,F$ normierte Räume. Eine lineare Abbildung $A\colon E\rightarrow F$
  heißt beschränkt, genau dann wenn:
  \[\exists M\geq 0 \, \forall x\in E\colon  ||Ax||_F \leq M||x||_E\]
\end{definition}

Es gilt: $\LL(E,F)\coloneqq \{A\colon E\rightarrow F| A\text{ beschränkt}\}$ ist ein
Vektorraum. Durch $||A||\coloneqq \sup_{||x||_E\leq 1} ||Ax||_F$ wird auf $\LL(E,F)$
eine Norm (Operatorennorm\index{Operatorennorm}) erklärt.
$[\LL(E,F),||\cdot||]$ ist ein normierter Raum.\\
Ferner gilt: $\forall x\in E\colon ||Ax||_F\leq ||A||\cdot ||x||_E$. Für
$x\neq 0\colon \left.
\begin{array}{rcl}
  ||A(\frac{x}{||x||})|| & \leq & ||A||\\
  ||Ax\frac{1}{||x||}|| & = & \frac{1}{||x||}||Ax||
\end{array}\right\}\Rightarrow ||Ax||\leq ||A||\cdot||x||$

Komposition von Operatoren: $A\in\LL(E,F), B\in\LL(F,G)\Rightarrow
B\circ A\in\LL(E,G)$ und es gilt $||BA||\leq ||B||\cdot ||A||$.

\begin{theorem}
  Seien $E,F$ normierte Räume und $\dim E<\infty$. Dann ist jede
  lineare Abbildung $A\colon E\rightarrow F$ stetig (=beschränkt).
\end{theorem}
\begin{proof}
  Sei $n\coloneqq \dim E$. Wählen Basis $x_1,\dots,x_n\in E$.
  Dann $\forall x\in E \, \exists \alpha_1,\dots,\alpha_n\in\K$.
  $x=\sum_{i=1}^n \alpha_i x_i, ||x||_0=\sum_1^n |\alpha_i|$ ist eine
  äquivalente Norm. Somit
  \begin{align*}
    ||Ax_i|| & = \left|\left|A\left(\sum_1^n \alpha_i x_i\right)\right|\right|_F\\
    & =\left|\left|\sum_1^n \alpha_i Ax_i\right|\right|_F\\
    & \leq \sum_1^n |\alpha_i| \cdot ||Ax_i||\\
    & \leq \max_{1\leq i\leq n} ||Ax_i||\sum_1^n |\alpha_i|\\
    & \leq (c\max_{1\leq i\leq n} ||Ax_i||)||x||
  \end{align*}
  $\Rightarrow A$ beschränkt, d.h. $A$ ist stetig.
\end{proof}

\begin{theorem}
  Sei $E$ ein normierter Raum und $F$ ein Banachraum. Dann ist $\LL(E,F)$
  ein Banachraum.
\end{theorem}

\chapter{Differentiation}
\section{Differentiation - Beispiele und Rechenregeln}
\begin{definition}
  $E$ und $F$ seien Banachräume. Eine Funktion $f\colon D\rightarrow F,
  D\subset E$ offen, heißt in $x\in D$ differenzierbar, g.d.w.:
  \[
    \exists A\in \LL(E,F)\,\exists r(h)\,\exists\delta >0\,\forall
    ||h||\leq \delta \colon  x+h \in D\]
    \[\text{ und } f(x+h)=f(x)+Ah+r(h)
    \text{ mit } \lim_{h\rightarrow 0}\frac{r(h)}{||h||}=0
  \]
\end{definition}

Bemerkung: Die Differentiation von $f$ im Punkt $x\in D$ bedeutet eine
Approximation durch eine affive lineare Abbildung $f(x)+Ah$ mit der
Eigenschaft, dass \[\lim_{h\rightarrow 0}\frac{f(x+h)-f(x)-Ah}{||h||}=0.\]
Setzt man $\tilde{r}(h)\coloneqq \begin{cases}
  \frac{r(h)}{||h||} & 0<||h||\leq\delta\\
  0 & h=0
\end{cases}$, ist $\tilde{r}$ in $h=0$ stetig. Äquivalent zur Definition der
Differentiation von $f$ im Punkt $x$ ist die folgende:
\[f(x+h)=f(x)+Ah+||h||\tilde{r}(h)\text{ mit } \lim_{h\rightarrow 0}
\tilde{r}(h)=0\]

\begin{theorem}
  Es gilt: $A\in\LL(E,F)$ ist eindeutig bestimmt.
\end{theorem}

\begin{definition}
  Seien $E,F$ Banachräume und $f\colon D\rightarrow F, D\subset E$ offen, 
  differenzierbar in $x\in D$. Dann heißt der eindeutig bestimmte
  Operator $A\in \LL(E,F)$ mit $f(x+h)=f(x)+Ah+r(h), \lim \frac{r(h)}{||h||}
  =0$ \emph{Ableitung\index{Ableitung}} (oder \emph{Fréchet-Ableitung})
  \index{Fréchet-Ableitung} und $Ah$ \emph{Differential\index{Differential}}
  der Funktion $f$ im Punkt $x\in D$
\end{definition}

% Vorlesung vom 2004-04-28
% Differentiation

\begin{beispiel}
  $E,F$ sind Banachräume und $f\colon E\rightarrow F, f(x)=c+Ax, c\in F,
  A\in\LL (E,F)$ Dann $f'(x)=A$\\
  Beweis: $f(x+h)=c+A(x+h)=c+Ax+Ah=f(x)+Ah, r(h)=0\Rightarrow f'(x)=A$
\end{beispiel}

\begin{remark}
  Seien $E,F$ Banachräume und $f\colon D\subset E\rightarrow F$ in $D$
  differenzierbar.  Dann ist $f'$ eine Abbildung von $D$ in $\LL(E,F),
  f'\colon D\rightarrow \LL(E,F)$, d.h. die Bilder sind beschränkte lineare
  Operatoren.

  Für $E=F=\R$ gilt $\LL(\R,\R)\eqsim\R$
\end{remark}

\paragraph{Rechenregeln}
\begin{enumerate}[(i)]
\item Seien $E,F$ Banachräume und $f,g\colon D\rightarrow F, D\subset E$ offen
  und differenzierbar in $x\in D$. Dann $f+g,\alpha\cdot f, \alpha\in\R$
  mind. in $x$ differenzierbar und es gilt: $(f+g)'(x)=f'(x)+g'(x),
  (\alpha f)'(x)=\alpha f'(x)$
\item Sei $E$ ein Banachraum, $f,g\colon D\rightarrow\R, D\subset E$ offen, in
  $x\in D$ differenzierbar. Dann $f\cdot g, \frac{f}{g} (g(x)\neq 0)$
  sind in $x$ differenzierbar und es gilt $(f\cdot g)'(x)=f'(x)g(x)+
  f(x)g'(x), \left(\frac{f}{g}\right)'(x)=\frac{f'(x)g(x)-f(x)g'(x)}{(g(x))^2}$
\item Kettenregel: Seien $E,F,G$ Banachräume, $f\colon D\rightarrow F$, in $x$
  differenzierbar, $g\colon \tilde{D}\rightarrow G, \tilde{D\subset F}$ offen
  und $f(D)\subset\tilde{D}$ in $f(x)$ differenzierbar. Dann ist 
  $g \circ f$ in $x$ differenzierbar und es gilt $(g\circ f)'(x)=
  g'(f(x))f'(x), E\xrightarrow{f}F\xrightarrow{g} G$
\end{enumerate}
\begin{proof}[zu (iii)]
$f,g$ sind differenzierbar.
\begin{align*}
  f(x+h) & = f(x)+f'(x)h+||h||\tilde{r}_f(h)
  &\tilde{r}_f\xrightarrow{h\rightarrow 0} 0\\
  g(f(x)+k) & = g(f(x))+g'(f(x))k+||k||\tilde{r}_g(k)
  &\tilde{r}_g(k)\rightarrow 0\\
  (g\circ f)(x+h) & = g(f(x+h))=g(f(x)+\underbrace{f'(x)h+||h||
    \tilde{r}_f(h)}_{k})\\
  & =  g(f(x)) +g'(f(x)) (f'(x)h+||h||\tilde{r}_f(h)+||f'(x)||h\\
  &\qquad +||h|| \tilde{r}_g(f'(x)h)+||h||\tilde{r}_f(h)\\
  & = (g\circ f)(x)+g'(f(x))f'(x)h+r_{g\circ f}(h))\\
  & \text{wobei}\\
  r_{g\circ f}(h) & = ||h||g'(f(x))\tilde{r}_f(h)\\
  & \qquad +||f'(x+h)+||h|| \tilde{r}_f(h)||\cdot
  \tilde{r}_g(f'(x)h+||h||\tilde{r}_f(h))
\end{align*}
Es gilt zu zeigen:
\[\lim_{h\rightarrow 0}\frac{r_{g\circ f}(h)}{||h||}\rightarrow 0\]
\begin{align*}
  ||r_{g\circ f}(h)|| \leq & ||h||\cdot||g'(f(x))||\cdot
  ||\tilde{r}_f(h)||\\
  & \qquad +(||f'(x)||||h||+||h||
  ||\tilde{r}_f(h)||)||\tilde{r}_g(f'(x)h+||h||\tilde{r}_g(h))||\\
  \frac{||r_{g\circ f}(h)||}{||h||} \leq & ||g'(f(x))||\cdot
  ||\tilde{r}_f(h)||\\
  & \qquad +(||f'(x)||+||\tilde{r}_f(h)||)||
  \tilde{r}_g(f'(x)h+||h||\tilde{r}_g(h)) \xrightarrow{h\rightarrow 0} 0\\
  \Rightarrow& \lim \frac{r_{g\circ f}(h)}{||h||}\rightarrow 0\\
  \Rightarrow& (g\circ f)'(x)=g'(f(x))f'(x)
\end{align*}
\end{proof}

\paragraph{Richtungsableitung}
\begin{definition}
  Seien $E,F$ Banachräume und $0\neq h\in E$. Existiert für eine Funktion
  $f\colon D\rightarrow E, D\subset E$ offen, im Punkt $x\in E$ der Grenzwert
  \[\frac{\partial f}{\partial h}(x)\coloneqq \lim_{\stackrel{t\rightarrow 0}{t\in\R}} \frac{f(x+th)-f(x)}{t}\],
  so heißt $\frac{\partial f}{\partial h}(x)$ \emph{Richtungsableitung\index{Richtungsableitung}} von $f$ in $x$.
\end{definition}

\begin{theorem}
  Seien $E,F$ Banachräume und $f\colon D\rightarrow F, D\subset F$ offen, in 
  $x\in D$ differenzierbar, so ist $f$ in $x$ stetig.\\
  \textbf{Beweis}:$f(x+h)=f(x)+f'(x)h+||h||\tilde{r}_f(h)
  \xrightarrow{h\rightarrow 0} f(x)$. Daher folgt, dass $f$ in $x$ stetig.
  \qed
\end{theorem}

\begin{theorem}
  \label{satz:richtAbl}
  Seien $E,F$ Banachräume, $f\colon D\rightarrow F, D\subset E$ offen, in $x$
  differenzierbar. Dann existiert die Richtungsableitung $\frac{\partial f}{\partial h}(x)$
  für jede Richtung $h$, und es gilt $\frac{\partial f}{\partial h}(x)=f'(x)h$.\\
  \textbf{Beweis}: $f(x+th)=f(x)+f'(x)(th)+r(th)$, wobei $\frac{r(th)}{||th||}\xrightarrow{t\rightarrow 0} 0$\\
  $\frac{f(x+th)-f(x)}{t}=f'(x)h+\frac{r(th)}{t}\rightarrow f'(x)h$
  \qed
\end{theorem}

\begin{remark}
  Die Umkehrung von Satz \ref{satz:richtAbl} gilt i.A. nicht.
\end{remark}

\begin{beispiel}
$f\colon \R^2\rightarrow\R, f(x_1,x_2)\coloneqq 
\begin{cases}
  \frac{x_1x_2^2}{x_1^2+x_2^4} & (x_1,x_2)\neq (0,0)\\
  0 & (x_1,x_2)=(0,0)
\end{cases}$
Für $f$ gilt: 
\begin{enumerate}[(1)]
  \item $f$ ist in (0,0) \emph{nicht} stetig $\Rightarrow f$ in (0,0)
    nicht differenzierbar.\\
    Beweis: $(x_n)=(\frac{1}{n^2},\frac{1}{n})\rightarrow (0,0), 
    f(\frac{1}{n^2},\frac{1}{n})=\frac{\frac{1}{n^4}}{\frac{1}{n^4}
    +\frac{1}{n^4}}=\frac{1}{2}\not\rightarrow 0\Rightarrow f$ in
    (0,0) nicht stetig.
  \item $f$ besitzt in (0,0) Richtungsableitungen in jede Richtung $h\neq 0$\\
    Beweis: $\frac{f(0+th)-f(0)}{t}=\frac{1}{t}
    \frac{th_1t^2h_2^2}{t^2h_1^2+t^4h_2^4}=
    \frac{h_1 h_2^2}{h_1^2+t^2h_2^4}\xrightarrow{t\rightarrow 0}
    \frac{h_1 h_2^2}{h_1^2}=\frac{h_2^2}{h_1}, h=(h_1,h_2)$ für
    $h_1\neq 0\rightarrow 0$ für $h_1=0, h_2\neq 0$\\
    $\frac{\partial f}{\partial h}(0)=\frac{h_2^2}{h_1}$ für $h_1\neq 0$ und
     $\frac{\partial f}{\partial h}(0)=0$ für $h_1=0$. Ferner zeigt dieser 
     Ausdruck, dass $\frac{\partial f}{\partial h}(0)$ nicht linear in $h$ ist.
\end{enumerate}
\qed
\end{beispiel}

\section{Differentiation von $\R^n$-$\R^m$-Funktionen}
\subsection{Partielle Ableitung von $\R^n$-$\R$-Funktionen}
\begin{definition}
  Sei $D\subset \R^n$ offen und $f\colon D\rightarrow \R$ eine reelle Funktion.
  Existiert in $x=(x_1,\dots,x_n)\in\R^n\in D$ die Richtungsableitung
  $\frac{\partial f}{\partial e_i}(x)=\lim_{t\rightarrow 0}
  \frac{f(x+te_i)-f(x)}{t}, e_i=(0,\dots,1,\dots,0)\in\R^n$, so heißt
  $\frac{\partial t}{\partial x_i}(x)\coloneqq \frac{\partial f}{\partial e_i}(x)$
  \emph{partielle Ableitung\index{Ableitung!partielle}} von $f$ nach der
  $i$-ten Koordinate.
\end{definition}

Bemerkung: Die partielle Ableitung einer Funktion $f\colon D\rightarrow\R,D
\subset \R^n$ offen, kann man als gewöhnliche Ableitung von Funktionen einer
reellen Veränderlichen interpretieren, indem man nach der $i$-ten
Koordinate differenziert und die übrigen festhält.

Ist $f(x)=f(x_1,\dots,x_n)$, so ist $\frac{\partial f}{\partial x_i}=
\frac{f(x_1,\dots,x_i+t,x_1,\dots,x_n)-f(x_1,\dots,x_n)}{t}$. Also sind
die partiellen Ableitungen Richtungsableitungen in die $i$-te Richtung.

Beispiel: \[f(x_1,x_2)=x_1^2+x_1\sin x_2 \quad f\colon \R^2\rightarrow \R\]
\[\frac{\partial f}{\partial x_1}=2x+\sin x_2 \quad \frac{\partial f}{\partial x_2}=x_1\cos x_2\]

Die Existenz der partiellen Ableitung von $f\colon D\rightarrow \R, D\subset\R^n$
reicht i.a. nicht für die Differenzierbarkeit von $f$ aus!

Beispiel:
\[f(x_1,x_2)=
\begin{cases}
  \frac{x_1x_2^2}{x_2^2+x_2^4} & (x_1,x_2)\neq 0\\
  0 & (x_1,x_2)=0
\end{cases}\]
\[\frac{\partial f}{\partial h}(0,0)=\frac{h_2^2}{h_1} \text{ für } h_1\neq 0\wedge =0\text{ für } h_1=0\]
\[\frac{\partial f}{\partial x_1}(0,0)=0 \quad \frac{\partial f}{\partial x_2}(0,0)=0\]
Aber $f$ ist in $(0,0)$ nicht differenzierbar!

\subsection{Darstellung der Ableitung von $\R^n$-$\R^m$-Funktionen}
\begin{theorem}
  \label{satz:AblMatrix}
  Sei $D\subset\R$ offen und $f\colon D\rightarrow\R^m,f=\begin{pmatrix}
    f_1\\\vdots\\f_m\end{pmatrix}$ und $f_i\colon D\rightarrow\R$ im Punkt
  $x\in\R^n$ differenzierbar. Dann gilt für die Ableitung von $f$ die
  folgende Darstellung:
  \[f'(x)=\begin{pmatrix}\frac{\partial f_1}{\partial x_1} & \dots & \frac{\partial f_1}{\partial x_n}\\
    \vdots & & \vdots\\
    \frac{\partial f_m}{\partial x_1} & \dots & \frac{\partial f_m}{\partial x_n}
  \end{pmatrix}\]
  \textbf{Beweis}: $f'(x)=A=(a_{ij})_{\stackrel{i=1,\dots,m}{j=1,\dots,n}}$
  Dann gilt: $f(x+h)=f(x)+Ah+r(h)$ mit $\frac{r(h)}{||h||}
  \xrightarrow{h\rightarrow 0} 0$. Somit 
  $\begin{pmatrix}f_1(x+h)\\\vdots\\f_m(x+h)\end{pmatrix}=
  \begin{pmatrix}f_1(x)\\\vdots\\f_m(x)\end{pmatrix}+\begin{pmatrix}
  \sum_{k=1}^n a_{1k}h_k\\\vdots\\\sum_{k=1}^n a_{mk}h_k\end{pmatrix}
  +\begin{pmatrix}r_1(h)\\\vdots\\r_m(h)\end{pmatrix}$
  mit $\frac{r_i(h)}{||h||}\rightarrow 0, (i=1,\dots,m)$\\
  $\Rightarrow f_i(x+h)=f_i(x)+\sum_{k=1}^n a_{ik}h_k+r_i(h)$ für
  $i=1,\dots,m$\\
  $h=te_j$ mit $e_j=(0,\dots,1,\dots,0)\colon  f_i(x+te_j)=f_i(x)+
  \sum_{k=1}^n a_{ik}+\delta_{jk}+r_i(te_j)=f_i(x)+ta_{ij}+r_i(te_j)
  \Rightarrow \frac{f_i(x+te_j)-f_i(x)}{t}=a_{ij}+\frac{r_i(te_j)}{t}$\\
  $\Rightarrow \frac{\partial f}{\partial x_j}=\lim_{t\rightarrow 0} 
  \frac{f(x+te_j)-f(x)}{t}=a_{ij}$
  \qed
\end{theorem}

\begin{theorem}
  \label{satz:DiffExist}
  Sei $D\subset\R^n$ offen und $f=\begin{pmatrix}f_1\\\vdots\\f_m
  \end{pmatrix}
  \colon D\rightarrow\R^m, f_i\colon D\rightarrow\R$ eine Funktion, so dass die
  partielle Ableitung $\frac{\partial f_i}{\partial x_j}$ in $D$ 
  existieren und im Punkt $x\in D$ stetig sind, dann ist $f$ in $x$ 
  differenzierbar und es gilt die Formel aus Satz \ref{satz:AblMatrix}.\\
  \textbf{Beweis}: $f=\begin{pmatrix}f_1\\\vdots\\f_m
  \end{pmatrix}\colon D\rightarrow\R^m, D\subset\R^n$ offen, ist in $x\in D$
  differenzierbar, g.d.w. $f\colon D\rightarrow\R$ in $x\in D$ differenzierbar
  ist.\\
  Daher ist o.B.d.A. für $m=1$:\\
  $f\colon D\rightarrow\R$ Aus der Tatsache, dass $D$ offen ist, folgt, dass
  $\exists \delta>0 \colon  \stackrel{\circ}{B}(x,\delta)=\{z\in\R^n |
  ||x-z||_\infty
  <\delta\}\subset D$\\
  Sei $h\in \R^n, ||h||<\delta$. Setzen 
  \[z^{(i)}\coloneqq x+\sum_{k=1}^i h_ke_k \quad z^{(0)}\coloneqq x\]
  Es gilt $z^{(n)}=x+h$. $z^{(i)}$ und $z^{(i-1)}$ unterscheiden sich in
  der $i$-ten Koordinate. Nach dem Mittwelwertsatz der Differentialrechnung
  für differenzierbare Funktionen in einer Veränderlichen existiert ein
  $\theta_i\in [0,1]\colon f(z^{(i)})-f(z^{(i-1)})=\frac{\partial f}{\partial x_i}
  (y^{(i)})h_i$, wobei $y^{(i)}=z^{(i-1)}+\vartheta_ih_ie_i$
  {\small
    $\varphi (t)\coloneqq f(z^{(i-1)}+the_j)\, \varphi(1)=f(z^{(i)})\,\varphi (0)
    =f(z^{(i-1)})$\\
    Nach dem Mittelwertsatz existiert ein $t_0$ mit\\ $\frac{\varphi (1)-\varphi (0)}{1-0}
    =\varphi'(t_0)=\lim_{\zeta\rightarrow 0} \frac{\varphi (t_0+\zeta) + \varphi (t_0)}{\zeta}
    =\frac{f(z^{(i-1)}+(t_0+\zeta)h_ie_i)-\overbrace{f(z^{(i-1)}+t_0h_ie_i}^{=\colon y^{(i)}}}{\zeta}$\\
    $=\lim_{\zeta\rightarrow 0}\frac{f(y^{(i)}+\zeta h_ie_i)-f(y^{(i)})}{\zeta h_i}
    h_i=\frac{\partial f}{\partial x_i}(y^{(i)})h_i$
  }
  Somit ist $f(x+h)-f(x)=\sum_{i=1}^n (f(z^{(i)})-f(z^{(i-1)})=
  \sum_{i=1}^n \frac{\partial f}{\partial x_i}(y^{(i)})h_i=\sum_{i=1}^n
  \frac{\partial f}{\partial x_i}(x)h_i+\underbrace{\sum_{i=1}^n
  (\frac{\partial f}{\partial x_i}(y^{(i)})-\frac{\partial f}{\partial x_i}
  (x))h_i}_{=\colon r(h)}$\\
  Nach der Cauchy-Schwartzschen Ungleichung gilt:
  \[|r(h)|\leq \sqrt{\sum_{i=1}^n \left|\frac{\partial f}{\partial x_i}
  (x)-\frac{\partial f}{\partial x_i}(y^{(i)})\right|^2}\cdot||h||_2\]
  Daher folgt nun: $\frac{|r(h)|}{||h||_2}\leq\sqrt{\sum_{i=1}^n \left|\frac{\partial f}{\partial x_i}
  (x)-\frac{\partial f}{\partial x_i}(y^{(i)})\right|^2}\cdot||h||_2\rightarrow
  0$ für $h\rightarrow 0$, da $\frac{\partial f}{\partial x_i}$ stetig
  in $x$, geht $y^{(i)}$ gegen $x$.
  \qed
\end{theorem}

%% Vorlesung vom 2004-05-02

Die Existenz der partiellen Ableitungen von $f\colon D\subset\R^n
\rightarrow \R$ reicht i.a. \emph{nicht} für die Differenzierbarkeit von $f$!

\begin{definition}
  Sei $f\colon D\rightarrow \R, D\subset\R^n$ offen, eine reellwertige
  Funktion, so dass die partiellen Ableitungen $\frac{\partial f}{\partial x_i}$
  existieren in $x\in D$. Dann heißt:
  \[\text{grad} f(x)=\left(\frac{\partial f}{\partial x_1}(x),\dots,\frac{\partial f}{\partial x_n}(x)\right)\]
  \emph{Gradient\index{Gradient}} von $f$ an der Stelle $x$.
\end{definition}

Bemerkung: \begin{enumerate}[(i)]
  \item $f$ muss nicht notwendigerweise in $x$ differenzierbar sein!
  \item Ist $f$ in $x$ differenzierbar, so gilt: $f'(x)=\text{grad}f(x)$. Für
    die Richtungsableitung gilt dann $\frac{\partial f}{\partial h}(x)=f'(x)h
    =(\text{grad}f(x))h$.
\end{enumerate}

\begin{theorem}
  Sei $f\colon D\rightarrow\R, D\subset\R^n$ offen, in $x\in D$ differenzierbar.
  Ist $\text{grad} f(x)=0$, so verschwinden alle Richtungsableitungen in
  $x$. Ist $\text{grad} f(x)\neq 0$, so gibt es unter allen
  Richtungsableitungen $\frac{\partial f}{\partial h}(x)$ mit $||h||_2
  =1$ eine grösste, nämlich die des Gradienten $\text{grad}f(x)$ mit
  $\frac{\partial f}{\partial h}(x)=||\text{grad}f(x)||_2$.\\
  \textbf{Beweis}: $\frac{\partial f}{\partial h}(x)=(\text{grad}f(x))h$
  \begin{align*}
    \left|\frac{\partial f}{\partial h}(x)\right| & = & \left|\sum_{i=1}^n
  \frac{\partial f}{\partial x_i}(x)h_i\right|\\
  & \leq& \sqrt{\sum_{i=1}^n
  \left|\frac{\partial f}{\partial x_i}(x)\right|^2}\sqrt{\sum_{i=1}^n |h_i|^2}\\
  & = & ||\text{grad}f(x)||_2||h||_2\\
  & = & ||\text{grad}f(x)||_2 \text{ für }||h||_2=1
\end{align*}

Für $h_0\coloneqq \frac{\text{grad}f(x)}{||\text{grad}f(x)||_2}$ gilt:\\
$\frac{\partial f}{\partial
  h_0}=(\text{grad}f(x))h_0=\left(\text{grad}f(x)\right)
\left(\frac{\text{grad}f(x)}{||\text{grad}f(x)||_2}\right)=
\frac{||\text{grad}f(x)||_2^2}{||\text{grad}f(x)||_2}=||\text{grad}f(x)||_2$
\qed
\end{theorem}

Sei $f\colon D\subset\R^n\rightarrow \R$ differenzierbar. $f(a+h)=f'(a)h+r(h),
\frac{r(h)}{||h||}\rightarrow 0$
\begin{enumerate}[(i)]
  \item Für "`kleine"' $h$, d.h. $||h||$ "`klein"', ist eine Näherung
    für $f(a+h)$ die Formel
    \[f(a+h)\approx f(a)+f'(a)h=f(a)+(\text{grad}f(a))h\]
    Ausführlicher: $f(a_1+h_1,\dots,a_n+h_n)\approx f(a_1,\dots,a_n)+
    \sum_{i=1}^n \frac{\partial f}{\partial x_i}(a_i)h_i$.
    Damit wird der Unterschied $f(a+h)-f(a)$ für "`kleine"' $h$ durch
    den Ausdruck $\frac{\partial f}{\partial x_1}(a)h_1+\cdots+\frac{\partial f}{\partial x_n}(a)h_n=f'(a)h$
    annähernd gegeben. Auf dieser Formel beruht die Fehlerrechnung.
  \item Für kleine $t\in\R$ und $h\in\R$ mit $||h||_2=1$ wird der
    Unterschied $f(a+th)-f(a)\approx (\text{grad}f(x))th$ am grössten
    für $h=\frac{\text{grad}f(a)}{||\text{grad}f(a)||_2}$, d.h. die
    Richtung des Gradienten.
\end{enumerate}

\textbf{Beispiel zur Fehlerrechnung}:\\
Eine Pyramide mit quadratischer Grundfläche der Kantenlänge \unit[1]{m}
und Höhe \unit[3]{m} hat ein Volumen $V(l,h)=\frac{1}{3}l^2h=\unit[1]{m^3}$.
Gesucht ist eine Näherung für das Volumen einer Pyramide mit einer Länge
von \unit[1,03]{m} und Höhe \unit[3,06]{m}.\\
$V\colon \R^2\rightarrow \R, V(l+\Delta l,h+\Delta h)\approx V(l,h)+V'(l,h)
\begin{pmatrix}\Delta l\\ \Delta h
\end{pmatrix}
=V(l,h)+\frac{\partial V}{\partial l}(l,h)\Delta l+\frac{\partial V}{\partial h}
(l,h)\Delta h=V(l,h)+\frac{2}{3}lh\Delta l+\frac{1}{3}l^2 \Delta h$\\
$l=\unit[1]{m}, h=\unit[3]{m}, \Delta l=\unit[0,03]{m}, \Delta
h=\unit[0,06]{m}$\\
$V(l+\Delta l,h+\Delta h)\approx \frac{2}{3}\cdot 1\cdot 3\cdot
0,03+\frac{1}{3}1^2\cdot 0,06=1+0,06+0,02=1,08$\\
Der exakte Wert beträgt: $V(1,03;3,06)=1,082118$
  
\paragraph{Ein wichtiger Spezialfall der Kettenregel}
\begin{alignat*}{2}
u &\colon D\subset\R^n\rightarrow\R^m\ & g &\colon M\subset\R^m\rightarrow\R\,u(D)\subset M\\
u &=\begin{pmatrix}u_1\\ \vdots\\u_m
\end{pmatrix} & f &=g\circ u\\
f(x_1,\dots,x_n) &=g(u_1(x_1,\dots,x_n),\dots,u_m(x_1,\dots,x_n)) &
\frac{\partial f}{\partial x_k}(x) &=\sum_{i=1}^m \frac{\partial g}{\partial u_i}
(u(x))\frac{\partial u_i}{\partial x_k}(x)
\end{alignat*}

Kettenregel: $f'(x)=g'(u(x))u'(x)$
\begin{align*}
\left(\frac{\partial f}{\partial x_1}(x),\dots,\frac{\partial f}{\partial x_n}(x)\right)
& = & \left(\frac{\partial g}{\partial u_1}(u(x)),\dots,\frac{\partial g}{\partial u_m}(u(x))\right)
\begin{pmatrix}
  \frac{\partial u_1}{\partial x_1}(x) & \dots & \frac{\partial u_1}{\partial x_n}(x)\\
  \vdots & & \vdots\\
  \frac{\partial u_m}{\partial x_1}(x)& \dots & \frac{\partial u_m}{\partial x_n}(x)
\end{pmatrix}\\
& = & \left(\frac{\partial g}{\partial u_1}(u(x))\frac{\partial u_1}{\partial x_1}
(x)+\dots+\frac{\partial g}{\partial u_m}(u(x))\frac{\partial u_m}{\partial x_1}
(x),\dots,\right.\\
& & \quad\left.\frac{\partial g}{\partial u_1}(u(x))\frac{\partial u_1}{\partial x_n}(x)
+\dots+\frac{\partial g}{\partial u_m}(u(x))\frac{\partial u_m}{\partial x_n}(x)\right)\\
& \Rightarrow & \frac{\partial f}{\partial x_k}(x)=\frac{\partial g}{\partial u_1}
(u(x))\frac{\partial u_1}{\partial x_k}(x)+\dots+\frac{\partial g}{\partial u_m}
(u(x))\frac{\partial u_m}{\partial x_k} (x)
\end{align*}

\section{Mittelwert, Taylorscher Satz, lokale Extrema}
\subsection{Mittelwertsätze}
\begin{theorem}
  \label{satz:MWSreell}
  Sei $f\colon D\rightarrow \R, D\subset\R^n$ offen, auf $D$ differenzierbar,
  $x,x+h\in D$ mit $x+th\in D$ für $0\leq t\leq 1$. Dann 
  \[\exists 0<\vartheta<1\colon f(x+h)-f(x)=f'(x+\vartheta h)h\]
  \textbf{Beweis}: (Anwendung des eindimensionalen Mittelwertsatzes)
  $\varphi(t)\coloneqq f(x+th), \varphi\colon [0,1]\rightarrow \R$ ist stetig 
  differenzierbar.\\
  Kettenregel: $\varphi'(t)=f'(x+th)h$. Nach dem Mittelwertsatz gilt:
  $\frac{\varphi(1)-\varphi(0)}{1-0}=\varphi(1)-\varphi(0)=\varphi'(\vartheta)$\\
  $f(x+h)-f(x)=f'(x+\vartheta h)h$
  \qed
\end{theorem}

%Vorlesung vom 2004-05-05

\paragraph{Vorbemerkungen zum Mittelwertsatz für vektorwertige Funktionen}
\begin{enumerate}[(i)]
  \item In der Version von Satz \ref{satz:MWSreell}
    gilt der Mittelwertsatz für vektorwertige Funktionen \emph{nicht} mehr.\\
    Beispiel: $f\colon [0,2\pi]\rightarrow\R^2, f(t)=\begin{pmatrix}\cos t\\\sin t
    \end{pmatrix}$ Zu zeigen ist: $\not\exists 0<\vartheta<1\colon f(2\pi)-
    f(0)=f'(\vartheta 2\pi)2\pi$. Denn $f(2\pi)-f(0)=0, f'(t)=\begin{pmatrix}
      (\cos t)'\\(\sin t)'
    \end{pmatrix}=\begin{pmatrix}
      -\sin t\\\cos t
    \end{pmatrix},
    ||f'(t)||_2=1\Rightarrow f'(t)\neq 0\, \forall t$
  \item Ausweg: Mittelwertsatz für vektorwertige Funktionen in 
    "`Integralversionen"' formulieren.
\end{enumerate}

\begin{definition}
  Sei $f=\begin{pmatrix}f_1\\\vdots\\f_m
  \end{pmatrix}\colon  [a,b]\rightarrow \R^m$, wobei $f_i\colon [a,b]\rightarrow\R$
  riemannintegrierbar sind. Dann heißt
  \[\int_a^b f(t)dt\coloneqq \begin{pmatrix}\int_a^b
    f_1(t)dt\\\vdots\\\int_a^bf_m(t)dt
  \end{pmatrix}\]
  das $\RR$-Integral von $f$ über $[a,b]$.
\end{definition}

$f$ ist z.B. integrierbar, wenn $f$ stetig ist. Ferner: $\int_a^b
f(t)dt=0,\int_a^bf(t)dt=-\int_b^a f(t)dt$.
Analog definiert man für $A;[a,b]\rightarrow\LL (\R^n,\R^m)$ das $\RR$-Integral
als:
\[\int_a^bA(t)dt\coloneqq \left(\int_a^b a_{ij}(t)dt\right)_{\stackrel{i=1,\dots,m}{j=1,\dots,n}},
A(t)=(a_{ij}(t))\]
Ferner: $\int_a^bA(t)hdt=\left(\int_a^bA(t)dt\right)h,
h\in\R^n,h=\text{konstant}$

\textbf{Hilfssatz}: Für jede stetige Funktion $f\colon [a,b]\rightarrow\R^n$
gilt:
\[\left|\left|\int_a^bf(t)dt\right|\right|_2\leq
\int_a^b||f(t)||_2dt\]
Diese Ungleichung gilt auch für jede beliebige Norm $||\cdot||$ auf
$\R^n$\\
Beweis: Sei $u\coloneqq \int_a^b f(t)dt\in\R^n$. Dann $||u||_2^2=
<u,u>=<\int_a^b f(t)dt, u>=\int_a^b <f(t),u>dt\leq
\int_a^b ||f(t)||_2 ||u||_2dt=\left(\int_a^b ||f(t)_2
dt\right)||u||_2\Rightarrow \left|\left|\int_a^b f(t)dt\right|
\right|_2=||u||_2\leq \int_a^b ||f(t)||_2dt$
\qed

\begin{theorem}
  \label{satz:MWSint}
  Sei $f\colon D\rightarrow\R^m, D\subset \R^n$ offen, stetig differenzierbar
  und $x,x+h\in D$ mit $x+th\in D, 0\leq t\leq 1$. Dann 
  \[f(x+h)-f(x)=\left(\int_0^1 f'(x+th)dt\right)h\]
  Ferner gilt: 
  \[||f(x+h)-f(x)||_2\leq \sup_{0\leq t \leq 1}
  \underbrace{||f'(x+th)||}_{\text{Operatorennorm}}\cdot ||h||_2\]
  Die Operatorennorm ist genauer $||f'(x+th)\colon [\R^n,||\cdot||_2]
  \rightarrow[\R^m,||\cdot||_2]||$\\
  \textbf{Beweis}: $f\colon \begin{pmatrix}f_1\\\vdots\\f_m
  \end{pmatrix}, f_i\colon D\rightarrow\R$ stetig differenzierbar. Wir
  definieren $\varphi_i\colon [0,1]\rightarrow\R, i=1,\dots,m, \varphi_i(t)\coloneqq 
  f_i(x+th), \varphi_i$ stetig differenzierbar. Man wendet den 
  Hauptsatz der Differential- und Integralrechnung an: $\varphi_i(1)-
  \varphi_i(0)=\int_0^1 \varphi'_i (t)dt, \varphi'_i(t)=
  f'_i(x+th)h$. Also hat man : $f_i(x+h)-f_i(x)=\int_0^1 
  f'_i (x+th)hdt=\left(\int_0^1 f'_i(x+th)dt\right)h$\\
  $f(x+h)-f(x)=\int_0^1 \begin{pmatrix}f'_1(x+th)\\\vdots\\
    f'_m(x+th)
  \end{pmatrix}dt h=\left(\int_0^1 f(x+th)dt\right)h$\\
  Ferner: $||f(x+h)-f(x)||_2=\left|\left|\int_0^1 
  f(x+th)dt h\right|\right|\leq \left|\left|\int_0^1 
  f'(x+th)dt\right|\right|\cdot||h||_2$\\
  $\leq \int_0^1 \sup_{0\leq t\leq 1}
  ||f'(x+th)||dt||h||_2=(\sup_{0\leq t\leq 1}||f'(x+th)||)||h||_2$
  \qed
\end{theorem}

\begin{definition}
  \begin{enumerate}[(i)]
    \item Sei $E$ ein normierter Raum und $x_0,x_1,\dots,x_n\in E$. Dann
      heißt
      \[P=\bigcup_{i=1}^n \{(1-\Theta)x_{i-1}+\Theta x_i\colon 0\leq \Theta\leq 1\}\]
      \emph{Polygonzug\index{Polygonzug}} durch die Punkte $x_0,\dots,x_n$.
    \item $D\subset E$ heißt genau dann \emph{polygonzugzusammenhängend},
      wenn $\forall x,y\in D$ existiert ein Polygonzug $P\subset D$ durch
      $x_0,\dots,x_n$ mit $x_0=x, x_n=y$.
      %Zeichnungen
  \end{enumerate}
\end{definition}

\begin{theorem}
  Sei $f\colon D\rightarrow \R^m, D\subset\R^n$ offen und polygonzugzusammenhängend,
  differenzierbar mit $f'=0$ auf $D$. Dann ist $f$ konstant auf $D$.\\
  \textbf{Beweis}: Es gilt: $f$ ist stetig differenzierbar auf $D$, da
  $f'=0$. Sei $x_0\in D$ fest und $x\in D$ beliebig. Dann existiert ein
  in $D$ verlaufender Polygonzug durch $x_0,x_1,\dots,x_n\coloneqq x$.
  Aus Satz \ref{satz:MWSint} folgt> $f(x_0)=f(x_1)=\dots =f(x_n)=f(x)$.
  Also $f(x)=f(x_0)\,\forall x\in D$. Daher folgt, dass $f$ konstant ist.
  \qed
\end{theorem}

$D$ heißt \emph{Gebiet\index{Gebiet}}, wenn $D$ offen und
polygonzugzusammenhängend.

%% Vorlesung vom 2004-05-06

\subsection{Taylorsche Formel}
\paragraph{Höhere partielle Ableitungen von $\R^n$-$\R$-Funktionen}
Notation: Sei $f\colon D\rightarrow\R, D\subset\R^n$ offen, eine partiell
differenzierbare Funktion. Sind alle partiellen Ableitungen 
$\frac{\partial f}{\partial x_i}\colon D\rightarrow\R$ selbst wieder partiell
differenzierbar, so heißt $f$ zweimal differenzierbar. Man kann die
partiellen Ableitungen 2. Ordnung bilden:
\[\frac{\partial^2 f}{\partial x_j \partial x_i}\coloneqq \frac{\partial}{\partial x_j}
\left(\frac{\partial f}{\partial x_i}\right)\]
Allgemeiner definiert man durch Induktion folgendes:\\
$f\colon D\rightarrow\R, D\subset\R^n$ offen, heißt $(k+1)$-mal partiell
differenzierbar, wenn sie $k$-mal partiell differenzierbar ist und
alle partiellen Ableitungen der $k$-ter Ordnung $\frac{\partial^k f}{\partial x_{i_k}\dots\partial x_{i_2}\partial x_{i_1}}
D\rightarrow \R$ partiell differenzierbar sind.\\
Eine Funktion $f\colon D\rightarrow\R,D\subset\R^n$ offen, heißt $k$ mal
stetig differenzierbar, wenn sie $k$ mal partiell differenzierbar ist
und alle partiellen Ableitungen der Ordnung $\leq k$ stetig sind.

\begin{theorem}[Satz von Schwartz über die Vertauschbarkeit der
  partiellen Ableitungen]
  Sei $f\colon D\rightarrow\R,D\subset\R^n$ offen, zweimal stetig partiell
  differenzierbar. Dann gilt für alle 
  \[\xi\in D \text{ und } i,j=1,\dots,n:
  \frac{\partial^2 f}{\partial x_j \partial x_i}
  (\xi)=\frac{\partial^2 f}{\partial x_i \partial x_j}(\xi)\]
  \textbf{Beweis}: O.\,B.\,d.\,A.: $n=2, i=1, j=2, x_1\rightarrow x, x_2
  \rightarrow y$. Wir zeigen $\frac{\partial^2 f}
  {\partial x \partial y}(\xi,\eta)=
  \frac{\partial^2 f}{\partial y \partial x}(\xi,\eta)$ Wählen auf $\R^2$
  die Maximumnorm. Dann existiert die $\varepsilon$-Kugel
  $B_\varepsilon(\xi,\eta)\coloneqq \{(\tilde{\xi},\tilde{\eta})\in\R^2\colon 
  \max\{|\tilde{\xi}-\xi|,|\tilde{\eta}-\eta|\}<\varepsilon\}\subset D$.
  Damit: $(\xi+h,\eta+k)\in B_\varepsilon(\xi,\eta)$ für $|h|,|k|<
  \varepsilon$. Sei $0<|h|,|k|<\varepsilon$. Wir definieren $\varphi (x)\coloneqq 
  f(x,\eta+k)-f(x,\eta), \varphi\colon [\xi,\xi+h]\rightarrow\R, h>0$
  differenzierbar. Nach dem Mittelwertsatz: $\exists x_1\in]\xi,\xi+h[\colon 
  \varphi(\xi+h)-\varphi(\xi)=h\varphi'(x_1)$.
  \begin{align*}
    F(h,k) & \coloneqq  & f(\xi+h,\eta+k)-f(\xi+h,\eta)-f(\xi,\eta+k)+f(\xi,\eta)\\
    & \Rightarrow & F(h,k)=\varphi(\xi+h)-\varphi(\xi)=h\varphi'(x_1)\\
    & = & h\left[\frac{\partial f}{\partial x}(x_1,\eta+k)-
    \frac{\partial f}{\partial x}(x_1,\eta)\right]\\
    & \Rightarrow & \exists y_1\in]\eta,\eta+k[\colon 
    \frac{\partial f(x_1,\eta+k)}{\partial x}-\frac{\partial f}{\partial x}(x_1,\eta)\\
    & = & k\frac{\partial^2 f}{\partial y \partial x}(x_1,y_1)
  \end{align*}
  Also $F(h,k)=hk\frac{\partial^2 f}{\partial y \partial x}
  (x_1,y_1), x_1\in]\xi,\xi+h[, y_1\in]\eta,\eta+k[$. Nun 
  Darstellung von $F(h,k)$ mit der Funktion $\psi(y)\coloneqq f(\xi+h,y)-f(\xi)$
  in der Form $F(h,k)=\psi(\eta+k)-\psi(\eta)$\\
  Analog erhält man dann wie oben
  $\exists x_2\in]\xi,\xi+h[\quad
  y_2\in]\eta,\eta+k[\colon F(h,k)=hk\frac{\partial^2 f}{\partial x \partial y}
  (x_2,y_2)$\\
  $\stackrel{h,k\neq 0}{\Rightarrow} \frac{\partial^2 f}{\partial y \partial x}
  (x_1,y_1)=\frac{\partial^2 f}{\partial x \partial y}(x_2,y_2)
  \stackrel{h,k\rightarrow 0}{\Rightarrow} \frac{\partial^2 f}{\partial y \partial x}
  (\xi,\eta)=\frac{\partial^2 f}{\partial x\partial y}(\xi,\eta)$
  \qed
\end{theorem}

Bemerkung: Der Beweis hat gezeigt, dass es genügt, die Existenz der 
partiellen Ableitungen 2. Ordnung in einer Umgebung von $(\xi,\eta)$
und die Stetigkeit in $(\xi,\eta)$ vorauszusetzen.

\begin{Folg}
  Sei $f\colon D\rightarrow\R,D\subset\R^n$ offen, $k$ mal stetig differenzierbar.
  Dann gilt:
  \[\frac{\partial^k f}{\partial x_{i_k}\dots\partial x_{i_1}}(\xi)=
  \frac{\partial^k f}{\partial x_{i_{\pi(k)}}\dots x_{i_{\pi(1)}}}\]
  für jede Permutation $\pi\colon \{1,\dots,k\}\rightarrow\{1,\dots,k\}$\\
  Der Beweis erfolgt induktiv.
\end{Folg}

\paragraph{Taylorscher Satz} Notationen: $D\subset\R^n$ offen,\\ $C^m(D)\coloneqq 
\{f\colon D\rightarrow\R|f \text{ besitzt stetige partielle Ableitungen der
Ordnung }\leq m\}$\\
$m=0\colon C(D)\coloneqq C^0(D)$

\begin{theorem}
  Sei $D\subset\R^n$ offen, $f\in C^{m+1}(D), (m\geq 0)$ und 
  $h\coloneqq \begin{pmatrix}h_1\\\vdots\\h_n
  \end{pmatrix}\in\R^n$.
  Liegen die Punkte $\xi$ und $\xi+h$ mitsamt ihrer Verbindungsstrecke
  $\xi+th, 0\leq t\leq 1$, in $D$, so gibt es ein $\Theta$ mit $0<\Theta
  <1$, so dass
  \[f(\xi+h)=\sum_{k=0}^m \left(\frac{1}{k!}\left(h_1 
  \frac{\partial }{\partial x_1}+h_2\frac{\partial }{\partial x_2}
  +\dots+h_n\frac{\partial }{\partial x_n}\right)^k
  f(\xi)\right)\]
  \[\qquad+\frac{1}{(m+1)!}\left(h_1\frac{\partial }{\partial x_1}+\dots+
  h_n\frac{\partial }{\partial x_n}\right)^{m+1}f(\xi+\Theta h)\]
  wobei 
  \begin{align*}
    (h_1\frac{\partial }{\partial x_1}+\dots+h_n
    \frac{\partial }{\partial x_n})^k f(\xi) & \coloneqq  & 
    \sum_{i_1,\dots,i_k=1}^n 
    \frac{\partial^k f}{\partial x_{i_k}\dots\partial x_{i_1}}(\xi)
    h_{i_1}\dots h_{i_k}\\
    & = & \sum_{\alpha_1+\dots+\alpha_k}\frac{k!}{\alpha_1!\dots\alpha_n!}
    \cdot\frac{\partial^k}{\partial x_{i_n}^{\alpha_n}\dots\partial x_{i_1}^{\alpha_1}}
    (\xi)h_1^{\alpha_1}\dots h_n^{\alpha_n}
  \end{align*}
  \textbf{Beweis}: Der Beweis erfolgt für den Spezialfall $n=2\colon $
  \[f(\xi+h)=\sum_{k=0}^m\frac{1}{k!}\left(h_1
  \frac{\partial }{\partial x_1}+h_2\frac{\partial}{\partial x_2}\right)^k
  f(\xi)+\frac{1}{(m+1)!}\left(h_1\frac{\partial}{\partial x_1}+h_2
  \frac{\partial}{\partial x_2}\right)^{m+1}f(\xi+\Theta h)\]
  wobei 
  \begin{align*}
    \left(h_1\frac{\partial}{\partial x_1}+h_2
    \frac{\partial}{\partial x_2}\right)^kf(\xi) & \coloneqq  & 
    \sum_{\alpha_1+\alpha_2=k}\frac{k!}{\alpha_1!\alpha_2!}
    \frac{\partial^k}{\partial x_2^{\alpha_2} \partial x_1^{\alpha_1}}
    h_1^{\alpha_1}h_2^{\alpha_2}\\
    & = & \sum_{j=0}^k\binom{k}{j}
    \frac{\partial^k f}{\partial x_2^{k-j} \partial x_1^j}h_1^j h_2^{k-j}
  \end{align*}
  $\xi=\begin{pmatrix}
    \xi_1\\\xi_2
  \end{pmatrix}
  ,h=
  \begin{pmatrix}h_1\\h_2
\end{pmatrix}, \varphi(t)\coloneqq f(\xi+th)=f(\xi_1+th_1,\xi_2+th_2), \varphi\colon 
[0,1]\rightarrow\R$ ist $(m+1)$-mal stetig differenzierbar. Dann gilt
$\varphi^{(k)}(t)=\sum_{j=0}^n \binom{k}{j} \frac{\partial^k f}{\partial x_2^{k-j} \partial x_1^j}
  h_1^j h_2^{k-j}(\xi_1+th_1,\xi_2+th_2)$. Durch Induktion erhält man 
  folgendes:\\
  Induktionsanfang: 
  \begin{align*}
    \varphi'(t) & = & f'(\xi+th)h\\
    & = & \left(\frac{\partial f}{\partial x_1}(\xi+th)
    \frac{\partial f}{\partial x_2}(\xi+th)\right)
    \begin{pmatrix}
      h_1\\h_2
    \end{pmatrix}\\
    & = & h_1\frac{\partial f}{\partial x_1}(\xi+th)h_2
    \frac{\partial f}{\partial x_2}(\xi+th)
  \end{align*}
  für $h=1$\\
  $k\rightarrow k+1\colon $
  \begin{align*}
    \varphi^{(k+1)}(t) & = & (\varphi^{(k)}(t))'\\
    & = & \left(\sum_{j=0}^k \binom{k}{j} h_i^j h_2^{k-j}
    \frac{\partial^k f}{\partial x_1^j \partial x_2^{k-j}}(\xi+th)\right)'\\
    & = & \sum_{j=0}^k\binom{k}{j} h_1^{j+1} h_2^{k-j}
    \frac{\partial f^{k+1}}{\partial x_1^{j+1} \partial x_2^{k-j}}+
    \sum_{j=0}^k \binom{k}{j} h_1^j h_2^{k-j+1}
    \frac{\partial ^{k+1} f}{\partial x_1^j \partial x_2^{k-j+1}}(\xi+th)\\
    & = & \sum_{j=1}^{k+1} \binom{k}{j-1}h_1^j h_2^{k-j+1}
    \frac{\partial^{k+1} f}{\partial x_1^j \partial x_2^{k-j+1}}(\xi+th)\\
    & & \quad+\sum_{j=0}^k \binom{k}{j}h_1^j h_2^{k-j+1}
    \frac{\partial^{k+1}f}{\partial x_1^j \partial x_2^{k-j+1}}(\xi+th)\\
    & = & \sum_{j=0}^{k+1} \binom{k+1}{j} h_1^j h_2^{k-j+1}
    \frac{\partial^{k+1} f}{\partial x_1^j \partial x_2^{k+1-j}}(\xi+th)
  \end{align*}
  Der taylorsche Satz für Funktionen einer Variable liefert die Behauptung:\\
  $\varphi(t)=\sum_{k=0}^m \frac{\varphi^{(k)}(0)}{k!}t^k+\frac{\varphi^{(m+1)}(\Theta t)}{(m+1)!}
  t^{k+1}, 0<\Theta <1$\\
  Für $t=1\colon  f(\xi+h)=\varphi(1)=sum_{k=0}^m \frac{\varphi^{(k)}(0)}{k!}
  +\frac{\varphi^{(m+1)}(\Theta)}{(m+1)!}=\sum_{k=0}^m\frac{1}{k!}h_1
  \frac{\partial }{\partial x_1 +h_2\frac{\partial}{\partial x_2}})^kf(\xi)
  +\frac{1}{(m+1)!}(h_1\frac{\partial }{\partial x_1}+h_2\frac{\partial}{\partial x_2})^{m+1}f(\xi+\Theta h)$
  \qed
\end{theorem}

%%Vorlesung vom 2004-05-10

Für $m=1$ gilt folgender Spezialfall:\\
\textbf{Korollar}\\
Sei $D\subset \R^n$ offen, $f\in C^2(D)$ und $h=\begin{pmatrix}h_1\\\vdots\\h_n\end{pmatrix}\subset\R^n,
\xi=\begin{pmatrix}\xi_1\\\vdots\\\xi_n\end{pmatrix}\in D$. Liegen die Punkte $\xi$ und $\xi+h$ mitsamt
ihrer Verbindungsstrecke $\xi+th, 0\leq t\leq 1$ in $D$, so existiert $\Theta$ mit $0<\Theta <1$ und es gilt :
\begin{align*}
  f(\xi+h) & = & f(\xi)+\left(h_1\frac{\partial}{\partial x_1}+\dots+h_n
  \frac{\partial}{\partial x_n}\right)f(xi)+\\
  & & \quad \frac{1}{2}\left(h_1
  \frac{\partial}{\partial x_1}+\dots+h_n\frac{\partial}{\partial x_n}\right)
  f(xi)^2f(\xi+\Theta h)\\
  & = & f(\xi)+h_1\frac{\partial h}{\partial x_1}+\dots+h_n
  \frac{\partial f}{\partial x_n}(\xi)+\frac{1}{2}\sum_{j,k=1}^n
  \frac{\partial^2 f}{\partial x_k\partial x_j}(\xi+\Theta h)h_jh_k\\
  & = & f(\xi)+f'(\xi)h+\frac{1}{2}\sum_{j,k=1}^n
  \frac{\partial^2 f}{\partial x_k\partial x_j}(\xi+\Theta h)h_jh_k
\end{align*}

\begin{theorem}
  \label{satz:II36}
  Sei $D\subset \R^n$ offen und $f\in C^2(D)$. Für $B_\varepsilon(\xi)\subset D$ und alle $h\in\R^n$ mit
  $\xi +h\in D_\varepsilon(\xi)$ gilt
  \[f(\xi+h)=f(\xi)+f'(\xi)h+\frac{1}{2}\sum_{j,k=1}^n \frac{\partial^2 f}{\partial x_k \partial x_j} (\xi)
  h_jh_k+||h||_2^2\rho(h)\]
  mit $\lim_{h\rightarrow 0}\rho(h)=0$.\\
  \textbf{Beweis}: Nach dem Korollar oben $f(\xi+h)=f(\xi)+f'(\xi)h+
  \frac{1}{2} \sum_{j,k=1}^n \frac{\partial^2 f}{\partial x_j \partial x_k}
  (\xi) h_jh_k+r(h)$ mit $r(h)=\frac{1}{2}\sum_{j,k=1}^n \left[
  \frac{\partial^2 f}{\partial x_k \partial x_j}(\xi+\Theta h)-
  \frac{\partial^2 f}{\partial x_k\partial x_j}(\xi)\right]h_jh_k$.
  Somit 
  \begin{align*}
    |r(h)| & \leq & \frac{1}{2}\left(\sum_{j,k=1}^n\sqrt{\left|
    \frac{\partial^2 f}{\partial x_k \partial x_j}(\xi+\Theta h)-
    \frac{\partial^2 f}{\partial x_k \partial x_j}\right|^2}\right)
    \underbrace{\sqrt{\sum_{j,k=1}^n |h_j|^2|h_k||^2}}_{\sum_{j,k=1}^n |h_j|^2=||h||_2^2}\\
    \sum_{j,k=1}^n |h_j|^2|h_k|^2 & = & \sum_{k=1}^n \sum_{j=1}^n
    |h_j|^2|h_k|^2\\
    & = & \sum_{k=1}^n (|h_k|^2\sum_{j=1}^n |h_j|^2)\\
    & = & \left(\sum_{j=1}^n |h_j|^2)(\sum_{k=1}^n |h_k|^2\right)\\
    & = & \left(\sum |h_j|^2\right)
  \end{align*}
  Also: $\frac{|r(h)|}{||h||_2^2}\leq \frac{1}{2} \sqrt{\sum_{j,k=1}^n \left|\frac{\partial^2 f}{\partial x_k \partial x_j}
  (\xi+\Theta h)-\frac{\partial^2 f}{\partial x_k\partial x_j}(\xi)\right|}\rightarrow 0$\\
  Also $\rho(h)\coloneqq \begin{cases}
  \frac{r(h)}{||h||_2^2} & h\neq 0\\
  0 & h=0
  \end{cases}
  \rightarrow 0$
  \qed
\end{theorem}

\subsubsection{Lokale Extrema}
\begin{definition}
  Eine Funktion $f\colon D\subset \R^n\rightarrow\R$ besitzt in $x\in D$ ein
  \emph{lokales Maximum\index{Maximum!lokales}} bzw. \emph{lokales
    Minimum\index{Minimum!lokales}}, falls eine Kugel $B_\varepsilon
  (x)\subset D,\varepsilon>0$ existiert, so dass $f(x)\geq f(y)$ bzw.
  $f(x)\leq f(y)$ für alle $y\in B_\varepsilon(x)$.
\end{definition}

Tritt in dieser Definition der Fall $f(x)=f(y)$ nur für $x=y$ ein, so
spricht man von einem \emph{isoliertem lokalem Maximum
  bzw. Minimum\index{Maximum!isoliertes}\index{Minimum!isoliertes}}.
Ein lokales Extremum ist ein lokales Maximum bzw. Minimum.

\begin{theorem}
  Sei $D\subset \R^n$ offen und $f\colon D\rightarrow\R$ eine partiell
  differenzierbare Funktion. Dann gilt $f$ besitzt in $x\in D$ ein lokales
  Extremum und es folgt, dass der Gradient von $f$ an der Stelle $x=0$.
  Dies ist gleichbedeutend mit $\frac{\partial f}{\partial x_1}(x)=\dots=
  \frac{\partial f}{\partial x_1}(x)=0$
\end{theorem}
\begin{proof}
  Wir definieren $\varphi_i(t)\coloneqq f(x+te_i), i=1,\dots,n,
  e_i=\begin{pmatrix}0\\\vdots\\1\\\vdots\\0\end{pmatrix}$. $f$
  besitzt in $x$ ein lokales Extremum. Das impliziert $\varphi_i$
  haben in 0 ein lokales Extremum. Somit gilt
  $\varphi'_i(0)=0=\lim_{t\rightarrow 0} \frac{f(x+te_i)-
    f(x)}{t}=\frac{\partial f}{\partial x_i}(x)$. Also ist der
  Gradient in $f(x)=\left(\frac{\partial f}{\partial x_i}(x),\dots,
    \frac{\partial f}{\partial x_n}(x)\right)=0$
\end{proof}

\begin{definition}
  Sei $A=(a_{ij})_{i,j=1}^n$ eine symmetrische reelle $n\times n$ Matrix
  A heißt \emph{positiv definit\index{definit}}, genau dann
  wenn \[\forall x\in\R^n\backslash \{0\}\colon  \langle Ax,x\rangle >0\]
  A heißt \emph{positiv semidefinit\index{semidefinit}}, genau dann wenn
  \[\forall x\in \R^n \colon \langle Ax,x\rangle \geq 0\]
  A heißt negativ definit, genau dann wenn $-A$ positiv definit.
  \[\Leftrightarrow \forall x\in\R^n\backslash \{0\}\colon \langle Ax,x\rangle <0\]
  A heißt \emph{indefinit\index{indefinit}}, genau dann wenn
  \[\exists x,y\in\R^n\colon \langle Ax,x\rangle >0\text{ und } \langle Ay,y\rangle <0\]
\end{definition}

\paragraph{Kriterien für positiv definite Matrizen}
Eine symmetrische relle $n\times n$ Matrix $A=(a_{ij})$ ist genau dann
positiv, wenn $\exists \alpha >0\,\forall x\in\R^n\colon \langle Ax,x\rangle \geq \alpha ||x||_2^2$
oder alle Eigenwerte von $A$ sind positiv, d.h. $\lambda >0$
oder $\forall k=1,\dots,n\colon  \det\begin{pmatrix}a_{11}& \dots & a_{1k}\\
\vdots & & \vdots\\
a_{k1} & \dots & a_{kk}
\end{pmatrix}>0$\\
Beweis siehe Vorlesung Algebra I+II

\begin{definition}
  Sei $D\subset\R^n$ offen und $f\in C^2(D)$. Die \emph{Hessesche
    Matrix\index{Matrix!Hessesche}} von $f$ im Punkt $x\in D$ ist
  definiert durch:
  \[(\text{Hess}f)(x)\coloneqq \left(\frac{\partial^2 f}{\partial x_j \partial x_i}
  \right)_{i,j=1}^n\]
  Wegen $\frac{\partial^2 f}{\partial x_j \partial x_i}=
  \frac{\partial^2 f}{\partial x_i \partial x_j}$ ist $(\text{Hess} f)(x)$
  symmetrisch. Nach dem Satz \ref{satz:DiffExist} hat man
  $f''(x)=(\text{Hess}f)(x)$.
\end{definition}

Mit $f'(x)h=\langle \text{grad }f(x),h\rangle $ und $\langle f''(x)h,h\rangle =\langle \text{Hess }f(x)h,h\rangle 
=\sum_{i,j=1}^n \frac{\partial^2 f}{\partial x_j \partial x_i}h_ih_j$
kann Satz \ref{satz:II36} wie folgt beschrieben werden:\\
Sei $D\subset\R^n$ offen und $f\in C^2(D)$. Dann gilt für $B_\varepsilon
(x)\in D$ und alle $h \in\R^n$ mit $x+h\in B_\varepsilon(x)\colon  f(x+h)=f(x)
+\langle f'(x),h\rangle +\frac{1}{2}\langle f''(x)h,h\rangle +||h||^2\rho(h)$ wobei $\lim_{h\rightarrow 0}
\rho(h)=0$.

\begin{theorem}
  %II.3.8
  Sei $D\subset\R^n$ offen und $f\in C^2(D)$ mit $(\text{grad }f)(x)=f'(x)
  =0$. Dann gilt:
  \begin{enumerate}[(i)]
    \item Ist $f''(x)=(\text{Hess }f)(x)$ positiv definit, so hat $f$ in
      $x$ ein isoliertes lokales Minimum.\\
      Beweis: (Die Beweise zu (i) und (ii) können analog geführt werden.)
      $f(x+h)=f(x)+\langle f'(x),h\rangle +\frac{1}{2}\langle f''(x)h,h\rangle +||h||^2\rho(h)
      =f(x)+\frac{1}{2}\langle f''(x)h,h\rangle +||h||^2\rho(h)$\\
      Wählen $\delta>0\colon \forall h\colon ||h||_2\leq \delta\Rightarrow|\rho(h)|
      \leq \frac{\alpha}{4}$. Damit erhält man für $0<||h||_2\leq \delta\colon 
      f(x+h)=f(x)+\frac{1}{2}\langle f''(x)h,h\rangle +||h||_2^2\rho(h)\geq f(x)+
      \frac{1}{2} \langle f''(x)h,h\rangle -||h||_2^2|\rho(h)|\geq f(x)+\frac{\alpha}{2}
      ||h||_2^2-\frac{\alpha}{4}||h||_2^2=f(x)+\frac{\alpha}{4}||h||_2^2
      >f(x)$
    \item Ist $f''(x)$ negativ definit, so hat die Funktion $f$ in $x$
      ein isoliertes lokales Maximum.\\
      Beweis erfolgt analog zu (i).
    \item Ist $f''(x)$ indefinit, so besitzt $f$ in $x$ kein lokales
      Extremum.\\
      Beweis: Zeigen: In jeder $\varepsilon$-Kugel $B_\varepsilon(x)$ um
      $x$ existieren $y', y''\colon  f(y'')<f(x)<f(y')$. $f''(x)$ ist indefinit:
      $\exists \xi\in\R^n\backslash\{0\}\colon \langle f''(x)\xi,\xi\rangle =\colon \alpha>0$.
      Für kleine $|t|$ gilt: $f(x+t\xi)=f(x)+\frac{1}{2}\langle f''(x)t\xi,t\xi\rangle 
      +||t\xi||_2^2\rho(t\xi)$ und für hinreichend kleine $|t|$ gilt
      $|\rho(t\xi)|\leq\frac{\alpha}{4}\frac{1}{||\xi||_2^2}$. Also hat
      man $f(x+t\xi)=f(x)+\frac{t^2}{2}\langle f''(x)\xi,\xi\rangle +t^2||\xi||_2^2
      \rho(t\xi)=f(x+\frac{\alpha}{2}t^2+t^2||\xi||_2^2\rho(t\xi)\geq
      f(x)+\frac{\alpha}{2}t^2-t^2||\xi||_2^2|\rho(t\xi)|\geq f(x)+
      \frac{\alpha}{2}t^2-\frac{\alpha}{4}t^2=f(x)+\frac{\alpha}{4}t^2
      >f(x)$ für $0<|t|\leq\delta_0$\\
      Ebenso zeigt man: Ist $\eta\in\R^n$ ein Vektor mit $\langle f''(x)\eta,\eta\rangle 
      <0$, so gilt für genügend kleine $|t|>0\colon  f(x+t\eta)<f(x)$
  \end{enumerate}
  \qed
\end{theorem}

\paragraph{Spezialfall $n=2$}
$x\coloneqq x_1, y\coloneqq x_2$\\
Sei $D\subset\R^2$ offen, $f\in C^2(D)$ und $\text{grad } f(\xi,\eta)=0$,
d.h. $\frac{\partial f}{\partial x}(\xi,\eta)=\frac{\partial f}{\partial y}(\xi,\eta)=0$\\
$f''=\text{Hess } f=\begin{pmatrix}
  \frac{\partial^2 f}{\partial x^2} & \frac{\partial^2 f}{\partial y \partial x}\\
  \frac{\partial^2 f}{\partial y \partial x} & \frac{\partial^2 f}{\partial y^2}
\end{pmatrix}$\\
$A=\begin{pmatrix}
  a_{11}&a_{12}\\
  a_{12}&a_{22}
\end{pmatrix}
\begin{cases}
  \text{positiv definit }\Leftrightarrow a_{11}>0 & \det A =a_{11}a_{22}-a_{12}^2>0\\
  \text{negativ definit }\Leftrightarrow a_{11}<0 & \det A=a_{11}a_{22}-a_{12}^2>0
\end{cases}$

Setzen $\Delta\coloneqq \det f'' =\frac{\partial^2 f}{\partial x^2}\frac{\partial^2 f}{\partial y^2}
-\left(\frac{\partial^2 f}{\partial y \partial x}\right)^2$, so hat
\begin{enumerate}[(i)]
  \item $f$ ein isoliertes lokales Minimum in $(\xi,\eta)$, wenn 
    $\frac{\partial^2 f}{\partial x^2}>0,\Delta>0$
  \item $f$ ein isoliertes lokales Maximum in $(\xi,\eta)$, wenn
    $\frac{\partial^2 f}{\partial x^2}<0, \Delta>0$
  \item $f$ kein lokales Extremum, wenn $\Delta<0$
\end{enumerate}

\paragraph{Beispiele}
$f\colon \R^2\rightarrow\R$
\begin{enumerate}
  \item $f(x,y)=c+x^2+y^2, \text{grad }f(x,y)=\left(
    \frac{\partial f}{\partial x},\frac{\partial f}{\partial y}\right)=
    (2x,2y)$\\
    $f''(x,y)=\begin{pmatrix}
      \frac{\partial^2 f}{\partial x^2}&\frac{\partial^2 f}{\partial y \partial x}\\
      \frac{\partial^2 f}{\partial y\partial x}&\frac{\partial^2 f}{\partial y^2}
    \end{pmatrix}=
    \begin{pmatrix}
      2&0\\0&2
    \end{pmatrix},
    f''(0,0)=\begin{pmatrix}
      2&0\\0&2
    \end{pmatrix}$
    positiv definit. Somit besitzt $f$ in $(0,0)$ ein isoliertes lokales
    Minimum (sogar globales Minimum).
  \item $g(x,y)=c-x^2-y^2, \text{grad } g=(-2x,-2y), (\text{grad }g)(0,0)
    =(0,0),g''(x,y)=\begin{pmatrix}
      -2&0\\0&-2
    \end{pmatrix}, 
    -2<0, \det g''(0,0)=4\Rightarrow g$ besitzt in $(0,0)$ ein isoliertes
    lokales Maximum.
  \item $h(x,y)=c+x^2-y^2, \text{grad } h=(2x,-2y), \text{grad }(0,0)=
    (0,0), h''(x,y)=\begin{pmatrix}
      2&0\\0&-2
    \end{pmatrix}$\\
    $\det h''(0,0)=-4<0\Rightarrow h$ hat in $(0,0)$ kein
    lokales Extremum.
  \item Ist die Hessesche Matrix $f''(x,y)$ in einer Nullstelle des
    Gradienten semidefinit, so lassen sich keine allgemeinen Aussagen
    machen.
    \begin{enumerate}
      \item $f_1(x,y )=x^2+y^4, \text{grad }f_1=(2x,4y^3), f_1''(x,y)=\begin{pmatrix}
      2&0\\0&12y^2
    \end{pmatrix}$
      \item $f_2(x,y) =x^2, \text{grad }f_2=(2x,0), f_2''(x,y)=\begin{pmatrix}
      2&0\\0&0
    \end{pmatrix}$
      \item $f_3(x,y)= x^2+y^3, \text{grad }f_3=(2x,3y^2), f_3''(x,y)=\begin{pmatrix}
      2&0\\0&6y
    \end{pmatrix}$
    \end{enumerate}
    $f_i''(0,0)=\begin{pmatrix}
      2&0\\0&0
    \end{pmatrix}, i=1,2,\dots, h=\begin{pmatrix}h_1\\h_2\end{pmatrix},
      \langle f_i''(0,0)h,h\rangle =\left<\begin{pmatrix}2h_1\\0\end{pmatrix},\begin{pmatrix}
    h_1\\h_2
      \end{pmatrix}\right>=2h_1^2+0=2h_1^2\geq 0$. Somit ist $f_i''(0,0)$
      semidefinit. Es gilt:
      \begin{itemize}
    \item $f_1$ hat in $(0,0)$ ein isoliertes lokales Minimum.
    \item $f_2$ hat in $(0,0)$ lokales Minimum (kein isoliertes)
    \item $f_3$ hat in $(0,0)$ kein lokales Extremum.
      \end{itemize} 
\end{enumerate}

\paragraph{Beispiel: Methode der kleinsten Quadrate}
Sei $A=(a_{ij})_{\stackrel{i=1,\dots,m}{j=1,\dots,n}}\colon \R^n\rightarrow\R^m,
n\leq m, b=(b_i)=\begin{pmatrix}b_1\\\vdots\\b_m\end{pmatrix}\in\R^m,
  f(x_1,\dots,x_n)=\sum_{k=1}^m\left(\sum_{j=1}^n a_{kj}x_j-b_k\right)^2,
  f\rightarrow$ Minimum, $f(x)=||Ax-b||_2^2$
%Komposition der Abbildung
$\begin{CD}
  \R^n @>f>> \R\\
  @VV{g}V\\
  \R^m
\end{CD}$
  
$g(x)\coloneqq Ax-b, h(y)\coloneqq ||y||_2^2, g'(x)=A, h'(y)=\left(\frac{\partial h}{\partial y_1},
\dots,\frac{\partial h}{\partial y_n}\right)=2(y_1,\dots,y_n)=2y^T,
f'(x)=g'(g(x))g'(x)=2g(x)^Tg'(x)=2(Ax-b)^TA$
$(f'(x)^T)'=(2A^T(Ax-b))'=2A^TA, (f'(x)^T)'=f''(x)^T=f''(x)$\\
Notwendige Bedingung für Extremum: $f'(x)=2(Ax-b)^TA=0\Leftrightarrow 
f'(x)^T=2A^T(Ax-b)=0$
\[A^TAx=A^Tb\]
Man setzt voraus, dass $A$ injektiv ist. Dies bedeutet, dass $A^TA$
invertierbar ist. Denn es gilt: $A^TAx=0\Rightarrow 0=\langle A^TAx,x\rangle
=\langle Ax,Ax\rangle =||Ax||_2^2\Rightarrow Ax=0\Rightarrow x=0
\Rightarrow A^TA$ ist invertierbar. Für eine injektive Matrix $A$ gilt,
dass $f$ in $x=(A^TA)^{-1}A^Tb$ ein isoliertes lokales Minimum besitzt.
Denn $\langle f''(x)h,h\rangle =\langle 2A^TAh,h\rangle=2\langle Ah, Ah
\rangle=2||Ah||^2>0$ für $h\neq 0$

2. Lösungsweg:
$f(x)=||Ax-b|_2^2$ und $A$ injektiv:\\
$f(x+h)=\langle A(x+h)-b,A(x+h)-b\rangle=\langle Ax-b+Ah,Ax-b+Ah\rangle
=\langle Ax-b, Ax-b\rangle+\langle Ax-b,Ah\rangle + \langle Ah, Ax-b
\rangle +\langle Ah, Ah\rangle = ||Ax-b||_2^2+2\langle Ax-b,Ah\rangle+
||Ah||_2^2=f(x)+2\langle A^T(Ax-b), h\rangle +||Ah||_2^2=f(x)+||Ah||_2^2$
für $x=(A^TA)^{-1}A^Tb\Rightarrow \forall h\neq 0\colon  f(x+h)=f(x)+||Ah||_2^2
>f(x)\Rightarrow f$ besitzt in $x=(A^TA)^{-1}A^Tb$ ein absolutes isoliertes
Minimum.\\
Verallgemeinerung: $A\colon \R^n\rightarrow\R^m, n\leq m, b_k\in\R^m, 1\leq k
\leq N$\\
$f(x)=\sum_{k-1}^N ||Ax-b_k||_2^2\rightarrow$ Minimum.\\
$A$ ist injektiv $\Rightarrow x=\frac{1}{N} \sum_{k=1}^N (A^TA)^{-1}
A^Tb_k$ liegt ein absolutes isoliertes Minimum vor.

\section{Implizite Funktionen}
Eine Funktion $f\colon D\rightarrow\R^m,D\subset\R^n$ wird \emph{implizit\index{implizit}}
genannt, wenn sie durch eine Gleichung der Form
\[F(x,y)=0\]
gegeben ist, d.h. $F(x,f(x))=0\, \forall x\in D$.

Problem: Unter welchen Bedingungen an $F$ wird durch $F(x,y)=0$ eine
Funktion $y=f(x)$ definiert? Oder unter welchen Bedingungen an $F$ ist
die Gleichung $F(x,y)=0$  eindeutig nach $y$ auflösbar?

In Komponenten zerlegt bedeutet dies, das Gleichungssystem\\ $
\begin{matrix}
  F_1(x_1,\dots,x_n,y_1,\dots,y_m)=0\\
  \vdots\\
  F_m(x_1,\dots,x_n,y_1,\dots,y_m)=0,
\end{matrix}$
wobei $x=\begin{pmatrix}x_1\\\vdots\\x_n
\end{pmatrix},y=\begin{pmatrix}y_1\\\vdots\\y_m
\end{pmatrix},F=\begin{pmatrix}F_1\\\vdots\\F_m
\end{pmatrix}$
auf $D$ nach $y_1,\dots,y_m$ aufzulösen, also reellwertige 
Funktionen $f_1,\dots,f_M\colon D\rightarrow\R$ zu bestimmen, dass gilt
$F_j(x_1,\dots,x_n,f_1(x_1,\dots,x_n),\dots,f(x_1,\dots,x_n))=0, 1\leq
j\leq m, \begin{pmatrix}x_1\\\vdots\\x_n
\end{pmatrix}\in D$

Beispiele: $n=m, F(x,y)=Ay-x, A\colon \R^n\rightarrow\R^n, F\colon \R^n\times\R^n
\rightarrow\R^n$\\
$F(x,y)=0\Leftrightarrow Ay-x=0\Leftrightarrow Ay=x$. Ist $A$ invertierbar,
so gilt $y=f(x)=A^{-1}x$
\begin{enumerate}[(a)]
  \item $m=n=1\colon  F\colon \R\times\R\rightarrow\R, F(x,y)=y^3-x^2, F(x,y)=0
    \Leftrightarrow y^3-x^2=0\Leftrightarrow y^3=x^2\Leftrightarrow y=
    \sqrt[3]{x^2}$. Durch $F(x,y)=y^3-x^2=0$ wird eindeutig eine Funktion
    $y=f(x)$ definiert. Die Auflösung nach $y$ ist eindeutig
  \item $F\colon \R\times\R\rightarrow\R,F(x,y)\coloneqq x^2+y^2-1=0$\\
    Funktionen sind z.B. $y_1=f_1(x)=\sqrt{1-x^2}, y_2=f_2(x)=-\sqrt{1-x^2}$
    Durch die Gleichung $F(x,y)=x^2y^2-1=0$ wird nicht eindeutig eine
    Funktion $y=f(x)$ definiert. Auflösung nach $y$ ist nicht eindeutig
    möglich. In den meisten Fällen interessiert man sich dafür, ob durch 
    die Gleichung $F(x,y)=0$ in einer Umgebung (i.d.R. $\varepsilon$-
    Kugeln) $B_\varepsilon(\xi,\eta)$ mit $F(\xi,\eta)=0$ eine Funktion
    $y=f(x)$ mit $\eta=f(\xi)$ definiert wird (lokale Auflösbarkeit
    \index{Auflösbarkeit!lokale} von $F(x,y)=0$ nach $y$).
\end{enumerate}

Notation: 
\begin{align*}
  x &=\begin{pmatrix}x_1\\\vdots\\x_n
  \end{pmatrix} & y=\begin{pmatrix}y_1\\\vdots\\y_m
  \end{pmatrix}\\
  \begin{pmatrix}x\\y
  \end{pmatrix} &=\begin{pmatrix}x_1\\\vdots\\x_n\\y_1\\\vdots\\y_m
  \end{pmatrix}& F\colon K\rightarrow\R^m\\
  K &\subset\R^n\times\R^m & F=\begin{pmatrix}
    F_1\\\vdots\\F_m
  \end{pmatrix}\\
  F_i &\colon K\rightarrow\R & 
\end{align*}
\[F(x,y)=F(x_1,\dots,x_n,y_1,\dots,y_m)=
\begin{pmatrix}
  F_1((x_1,\dots,x_n,y_1,\dots,y_m)\\
  \vdots\\
  F_m(x_1,\dots,x_n,y_1,\dots,y_m)
\end{pmatrix}\]
Falls die Punkte existieren, gilt:
\[\frac{\partial F}{\partial x}\coloneqq \begin{pmatrix}
  \frac{\partial F_1}{\partial x_1} & \dots & \frac{\partial F_1}{\partial x_n}\\
  \vdots & & \vdots\\
  \frac{\partial F_m}{\partial x_1} & \dots & \frac{\partial F_m}{\partial x_n}
\end{pmatrix}\]
ist eine $m\times n$-Matrix und
\[\frac{\partial F}{\partial y}\coloneqq \begin{pmatrix}
  \frac{\partial F_1}{\partial y_1} & \dots & \frac{\partial F_1}{\partial y_n}\\
  \vdots & & \vdots\\
  \frac{\partial F_m}{\partial y_1} & \dots & \frac{\partial F_m}{\partial y_n}
\end{pmatrix}\]
ist eine $m\times m$-Matrix.

\begin{theorem}
  \label{satz:implFunktion}
  Sei $D\subset \R^n, G\subset\R^m$ offen und die Funktion $F\colon D\times G
  \rightarrow \R^m$ stetig differenzierbar. Ferner seien $\xi\in D$ und
  $\eta \in G$ Punkte, für die $F(\xi,\eta)=0$ und $\frac{\partial F}{\partial y}
  (\xi,\eta)$ invertierbar ist. Dann gilt:
  \begin{enumerate}[(i)]
    \item Es existiert eine offene $\delta$-Kugel $B_\delta(\xi)\subset
      D$ und eine offene $\varepsilon$-Kugel $B_\varepsilon(\eta)\subset
      G$ und genau eine stetige Funktion $f_\delta(\xi)\rightarrow
      B_\varepsilon(\eta)$ mit $f(\xi)=\eta$ und $F(x,f(x))=0\,\forall
      x\in B_\delta(\xi)$. Für jedes feste $x \in B_\delta(\xi)$ ist $f(x)$
      die einzige Lösung in $B_\varepsilon(\eta)$ mit $F(x,f(x))=0$.
    \item Es existiert eine weitere offene $\delta_1$-Kugel $B_{\delta_1}
      (\xi), \delta_1\leq \delta$ und die Funktion $f\colon B_{\delta_1}(\xi)
      \rightarrow B_\varepsilon(\eta)$ ist stetig differenzierbar auf
      $B_{\delta_1}(\xi)$ und es gilt die Formel:
      \[f'(x)=-\left(\frac{\partial F}{\partial y} (x,f(x))\right)^{-1}
      \frac{\partial F}{\partial x} (x,f(x))\]
  \end{enumerate}
  Beweis in Heuser (292-299)
\end{theorem}

Eine Bemerkung zur Formel in (ii): 
\begin{align*}
  h(x) & =F(x,f(x))&
  \begin{CD}
    B_{\delta_1}(\xi) @>>h> \R^m\\
    @VV{g}V\\
    D\times G
  \end{CD}\\
  g(x) & =\begin{pmatrix}x\\f(x)
  \end{pmatrix}& F=F(x,y)\\
  h(x) & =F(x,f(x)) & h'(x) =F'(x,f(x))g(x)\\
  F'(x,y) &=
  \left(\frac{\partial F}{\partial x}\frac{\partial F}{\partial y}\right) &
  g'(x)=\begin{pmatrix}I\\f'(x)
  \end{pmatrix}\\
  F'(x,f(x))g'(x) &=\frac{\partial F}{\partial x}(x,f(x))I+
\frac{\partial F }{\partial y}(x,f(x))f'(x)=h'(x)& h(x)=0
 \end{align*}
$\Rightarrow
h'(x)=0\Rightarrow\frac{\partial F}{\partial x}(x,f(x))+
\frac{\partial F }{\partial y}(x,f(x))f'(x)=0$\\
$f'(x)=-\left(\frac{\partial F}{\partial y}(x,f(x))\right)^{-1}
\frac{\partial F}{\partial x}(x,f(x))$.

Beispiel:
%Bild
\begin{align*}
  F(x,y) & = x^2+y^2-1 & F\colon \R\times\R\rightarrow\R\\
  \frac{\partial F}{\partial y} & = 2y \neq 0 & \text{für }y\neq 0\\
  \left(\frac{\partial F}{\partial y}\right)^{-1} & =\frac{1}{2y} &
\end{align*}

Damit ist die Gleichung $F(x,y)=x^2+y^2-1=0$ nach $y$ eindeutig in einer
offenen Umgebung von $(\xi,\eta)$ mit $F(\xi,\eta)=0$ und $\eta\neq 0$
auflösbar. In $(-1,0)$ und $(1,0)$ ist $F(x,y)=0$ nicht lokal nach $y$
auflösbar.\\
$F(x,f(x))=x^2+f(x)^2-1=0, \frac{\partial F}{\partial x}=2x$\\
$f'(x)=-\left(\frac{\partial F}{\partial y}\right)^{-1}(x,f(x))\cdot
\left(\frac{\partial F}{\partial x}\right)(x,f(x))=-\frac{1}{2f(x)}\cdot
2x=-\frac{x}{f(x)}, y>0, f(x)=\sqrt{1-x^2}, f'(x)=-\frac{x}{\sqrt{1-x^2}}$

\subsection{Umkehrsatz}
Problem: Unter welchen Bedingungen besitzt eine Funktion $f\colon D\rightarrow
\R^n, D\subset\R^n$, eine Umkehrung? Welche analytischen Eigenschaften
besitzt die Funktion $f^{-1}$?

$f(x)=Ax, A\colon \R^n\rightarrow\R^n, f(x)=Ax=y\rightarrow x=A^{-1}y,
f^{-1}(y)=A^{-1}y,f'(x)=A$

\begin{theorem}
  %II.4.2
  \label{satz:umkehrsatz}
  Sei $f\colon D\rightarrow\R^n, D\subset\R^n$ offen, stetig differenzierbar
  und in $\xi\in D$ sei $f'(\xi)$ invertierbar. Dann existiert eine
  offene Umgebung $U\in D$ von $\xi$ und eine $\varepsilon$-Kugel von
  $\eta=f(\xi)$, so dass $f|_U\colon U\rightarrow B_\varepsilon(\eta)$
  bijektiv die Umgebung $U$ auf $B_\varepsilon(\eta)$ abbildet. Die
  Umkehrung $f_U^{-1}$ von $f|_U$ ist stetig differenzierbar und für die
  Ableitung gilt:
  \[(f|_U^{-1})'(y)=f'(x)^{-1} \text{ mit } y=f(x)\quad x\in U\]
  \[(f|_U^{-1})'(f(x))=f'(x)^{-1} \quad x\in U\]
  \textbf{Beweis}:
  $F\colon D\times\R^n\rightarrow\R^n, F(x,y)\coloneqq f(x)-y=0$\\
  $F$ ist stetig differenzierbar, weil $f$ stetig differenzierbar ist,
  mit $\frac{\partial F}{\partial x}(\xi,f(\xi))=
  f'(\xi)$ und  $F(\xi,\eta)=0$ invertierbar. Satz \ref{satz:implFunktion} impliziert, dass es
  eine offene $\varepsilon$-Kugel $B_\varepsilon(\eta)$, eine offene
  $\delta$-Kugel $B_\delta(\xi)$  und genau eine stetige Funktion
  $\varphi \colon B_\varepsilon(\eta)\rightarrow B_\delta(\xi), \varphi(\eta)
  =\xi, F(\varphi(y),y)=f(\varphi(y))-y=0$ gibt. Wegen Punkt (ii) aus
  Satz \ref{satz:implFunktion} können wir $B_\varepsilon(\eta)$ so klein
  gewählt denken, dass $\varphi$ auf $B_\varepsilon(\eta)$ sogar stetig
  differenzierbar ist. Ferner gilt, da $f\colon D\rightarrow\R^n$ stetig ist,
  dass $f^{-1}(B_\varepsilon(\eta))$ offen in $\R^n$. Denn $x\in f^{-1}
  (B_\varepsilon(\eta))\stackrel{f \text{ stetig}}{\Rightarrow} \exists
  0<r<\infty\colon B_r(x)\cap D \subset f^{-1}(B_\varepsilon(\eta))
  \stackrel{D \text{ offen}}{\Rightarrow} \exists 0<r_0\leq r\colon B_{r_0}(x)
  \subset f^{-1}(B_\varepsilon(\eta))\Rightarrow f^{-1}(B_\varepsilon(\eta))$
  ist offen im $\R^n$.\\
  Für $U\coloneqq B_\delta(\xi)\cap f^{-1}(B_\varepsilon(\eta))=\{x\in B_\delta
  (\xi)\colon f(x)\in B_\varepsilon(\eta)\}$ (offen) gilt $f(U)=B_\varepsilon(\eta)$.
  Klar ist, dass $f(U)\subset B_\varepsilon(\eta)$. Wichtig zu zeigen,
  ist die Gleichheit:\\
  Sei $y\in B_\varepsilon(\eta)$. Dann gilt: $\varphi(y)\in B_\delta(\xi)$
  und $f(\varphi(y))=y\in B_\varepsilon(\eta)$. Also $\varphi(y)\in
  B_\delta(\xi)\cap f^{-1}(B_\varepsilon(\eta))=U$, d.h. $f(U)=
  B_\varepsilon(\eta)$. $f$ ist also surjektiv.\\
  Injektivität: Seien $x_1,x_2\in U\colon f(x_1)=f(x_2)=y\Rightarrow F(x_1,y)=
  F(x_2,y)=0\stackrel{\text{Satz \ref{satz:implFunktion}}}{\Rightarrow}
  x_1=x_2$. Also ist $f|_U\colon u\rightarrow B_\varepsilon(\eta)$ von $U$ auf
  $B_\varepsilon(\eta)$ bijektiv und $\varphi=f|_u^{-1}$ ist die stetig
  differenzierbare Umkehrabbildung von $f|_U$. Die Formel $(f|_U^{-1})'
  (f(x))=f'(x)^{-1}$ folgt mit der Kettenregel:\\
  $\varphi=f|_U^{-1}, \varphi(f(x))=x, \varphi'(f(x))=I\Rightarrow
  (f|_U^{-1})'(f(x))=\varphi'(f(x))f'(x)=If'(x)^{-1}$
  \qed
\end{theorem}

Bemerkungen: 
\begin{enumerate}
  \item Sei $f\colon U\rightarrow V$ eine bijektive Abbildung der offenen
    Mengen $U,V\subset\R^n$. Sind $f,f^{-1}$ stetig differenzierbar, so
    heißt $f$ ein \emph{Diffeomorphismus\index{Diffeomorphismus}}. In
    dieser Terminologie besagt der Umkehrsatz, dass die Funktion $f|_U$
    bei hinreichend kleiner Umgebung $U$ ein Diffeomorphismus ist.
  \item Der Umkehrsatz ist eine "`lokale"' Aussage, d.h. existiert für
    eine stetig differenzierbare Funktion $f\colon D\rightarrow\R^n, f(x)^{-1}$,
    so existiert i.a. nicht die "`globale"' Inverse auf ganz $D$.\\
    Beispiel: $f\colon \R^2\rightarrow\R^2, f(x,y)=\begin{pmatrix}
      e^x\cos y\\e^x\sin y
    \end{pmatrix}$. $f$ ist auf $\R^2$ stetig differenzierbar.
    $f'(x,y)=\begin{pmatrix}
      e^x \cos y & -e^x \sin y\\
      e^x \sin y & e^x \cos y
    \end{pmatrix}, f'(x,y)^{-1}=\begin{pmatrix}
      e^{-x} \cos y & e^{-x}\sin y\\
      -e^{-x}\sin y & e^{-x}\cos y
    \end{pmatrix}$\\
    Aber $f\colon \R^2\rightarrow\R^2$ ist nicht global invertierbar auf $\R^2$:
    $f(x,y)=f(x,y+2k\pi)$ mit $k\in\Z$
\end{enumerate}

\begin{theorem}
  Sei $f\colon D\rightarrow\R^n, D\subset\R^n$ offen, stetig differenzierbar
  und existiert $f'(x)^{-1}$ für jedes $x\in D$. Dann gilt:
  \begin{enumerate}[(i)]
    \item $f$ ist eine \emph{offene Abbildung\index{Abbildung!offene}},
      d.h. das Bild jeder offenen Teilmenge von $D$ ist offen im $\R^n$.\\
      Beweis: $A\subset D$ offen in $D$. Da $D$ offen ist, folgt, dass
      $A$ in $\R^n$ offen ist.
      \begin{enumerate}[1. F{a}ll]
    \item $A=\emptyset\Rightarrow f(A)=\emptyset$
    \item $a\neq\emptyset, y\in f(A)$ und $x\in A\colon f(x)=y$.\\
      Da $f'(x)$ invertierbar ist, folgt  es existiert eine offene
      Umgebung $U\subset A$  mit $x\in U$ und $f(U)\subset f(A)$
      offen (nach dem Umkehrsatz), d.h. $f(A)$ ist offen.
      \end{enumerate}
    \item Die Funktion $\varphi\colon D\rightarrow\R, \varphi(x)\coloneqq ||f(x)||$,
      besitzt kein Maximum und, falls $f(x)\neq 0$ in $D$, auch kein
      Minimum on $D$.\\
      Beweis: Annahme: $x_0\in D$ sei eine Maximalstelle von $\varphi$,
      d.h. $\forall x\in D\colon ||f(x)||\leq ||f(x_0)||$. Dann ist $f(x_0)>0$.
      Denn wäre $f(x_0)=0$, dann wäre $f=0$ auf $D$ und $f'$ wäre
      auf $D$ nirgends invertierbar.\lightning\\
      Der Umkehrsatz impliziert: $\exists B_\varepsilon(f(x_0))\subset
      f(D)$. Insbesondere gilt für $\rho=\frac{\varepsilon}{2||f(x_0)||}$\\
      $\exists x_1 \in D \, y_1=f(x_1)=f(x_0)+\rho f(x_0)=(1+\rho)f(x_0)$.
      Denn $||y_1-f(x_0)||=\rho||f(x_0)||=\frac{\varepsilon}{2}<\varepsilon$.
      Somit hat man $||f(x_1)||=(1+\rho)||f(x_0)||>||f(x_0)||$\lightning
    \item Ist $f$ injektiv, so ist $f^{-1}\colon f(D)\rightarrow\R$ stetig
      differenzierbar.\\
      Beweis: $f(D)$ ist nach (i) offen. Nach dem Umkehrsatz und da $f$
      injektiv ist, folgt $f^{-1}\colon f(D)\rightarrow\R^n$ ist stetig
      differenzierbar.
  \end{enumerate}
  \qed
\end{theorem}

\section{Extrema mit Nebenbedingungen}
Seien $f\colon X\rightarrow\R, X\subset\R^n$ offen und $g\colon X\rightarrow\R^m,
m<n$.\\
$f$ besitzt in $\xi\in X$ ein lokales Maximum bzw. lokales Minimum
unter der Nebenbedingung, $g(x)=0\colon \Leftrightarrow \xi\in N\coloneqq \{x\in X\colon 
g(x)=0\}$ und es existiert ein $B_\delta(\xi)\subset X\,\forall x\in 
B_\delta(\xi)\cap N\colon  f(x)\leq f(\xi)\text{ (lokales Maximum) bzw.}
f(x)\geq f(\xi)\text{ (lokales Minimum)}$

Problem: Gesucht sind die also die Stellen lokaler Extrema von $f$ unter
der angegebenen Nebenbedigung und die Werte, die $f$ in ihnen annimmt.\\
Setzen $x=\begin{pmatrix}y\\z
\end{pmatrix}, y=\begin{pmatrix}x_1\\\vdots\\x_m
\end{pmatrix}, z=\begin{pmatrix}x_{m+1}\\\vdots\\x_n
\end{pmatrix}\in \R^{n-m}$. Dann $g(x)=g(y,z)$. Falls $g(y,z)=0$ ($m$
Komponentengleichungen) nach $y$ auflösbar ist, d.h. $y=h(z)$ mit
$g(h(z),z)=0$, dann läuft das Problem der Extremwertbestimmung darauf
hinaus, die "`freien"' lokalen Extrema (d.h. lokale Extrema ohne
Nebenbedingungen) der Funktion $\varphi(z)=f(h(z),z)$ zu bestimmen. Ist
eine solche "`explizite"' Auflösung von $g(y,z)=0$ nach $y$ nicht 
möglich, dann hilft uns die sog. Multiplikatorenmethode.

\subsection{Lagrange Multiplikatorenmethode}
\begin{theorem}
  %II.5.1
  \label{satz:lagrange}
  Sei $X\in\R^n$ eine offene Menge, $f\colon X\rightarrow\R, g\coloneqq \begin{pmatrix}
    g_1\\\vdots\\g_m
  \end{pmatrix}\colon X\rightarrow\R^m$ seien stetig differenzierbar und $f$
  besitzt in $\xi\in X$ ein lokales Extremum unter der Nebenbedingung
  $g(x)=0$. Ferner existieren in $g'(\xi)=\begin{pmatrix}
    \frac{\partial g_1}{\partial x_1}(\xi) & \dots & \frac{\partial g_1}{\partial x_n}(\xi)\\
    \vdots & & \vdots\\
    \frac{\partial g_m}{\partial x_1}(\xi) & \dots & \frac{\partial x_m}{\partial x_n}(\xi)
  \end{pmatrix}$ eine $m$-reihige Unterdeterminante, die nicht
  verschwindet. Dann existieren $m$ Zahlen $\lambda_1,\dots,\lambda_m$
  (\emph{Lagrange Multiplikatoren\index{Lagrange Multiplikator}}), so dass
  die Gleichung
  \[f'(\xi)+\sum_{i=1}^m \lambda_ig_i'(\xi)=0\]
  besteht.
\end{theorem}
\begin{proof} O.B.d.A. sei die Determinante der Matrix 
  \begin{equation}
    \label{eq:detA}
    \det \begin{pmatrix}
    \frac{\partial g_1}{\partial x_1}(\xi) & \dots & \frac{\partial g_1}{\partial x_n}(\xi)\\
    \vdots & & \vdots\\
    \frac{\partial g_m}{\partial x_1}(\xi) & \dots & \frac{\partial x_m}{\partial x_n}(\xi)
  \end{pmatrix}\neq 0
  \end{equation}
  Seien $x=\begin{pmatrix}y\\z
  \end{pmatrix}, y=\begin{pmatrix}x_1\\\vdots\\x_m
  \end{pmatrix}, z=\begin{pmatrix}x_{m+1}\\\vdots\\x_n
  \end{pmatrix}\in \R^{n-m}, \xi=\begin{pmatrix}\eta\\\zeta
  \end{pmatrix}, \eta=\begin{pmatrix}\xi_1\\\vdots\\\xi_m
  \end{pmatrix}, \zeta=\begin{pmatrix}\xi_{m+1}\\\vdots\\\xi_n
  \end{pmatrix}$. Dann ist $f(x)=f(y,z), g(x)=g(y,z)$. Die Aussage, $f$ hat
  in $\xi$ ein lokales Extremum unter der Nebenbedingung $g(x)=0$ 
  impliziert:\\
$g(\xi)=g(\eta,\zeta)=0$ und wegen Gleichung \ref{eq:detA} ist
$\begin{pmatrix}
    \frac{\partial g_1}{\partial x_1}(\eta,\zeta) & \dots & \frac{\partial g_1}{\partial x_n}(\eta,\zeta)\\
    \vdots & & \vdots\\
    \frac{\partial g_m}{\partial x_1}(\eta,\zeta) & \dots & \frac{\partial x_m}{\partial x_n}(\eta,\zeta)
  \end{pmatrix}$.
  Nach Satz \ref{satz:implFunktion} folgt $g(y,z)=0$ ist stetig differenzierbar
  nach $y$ auflösbar, d.h.
  \begin{equation}
    \label{eq:Glb}
    \exists B_\delta(\zeta)\subset\R^{n-m}\,
  h\colon B_\delta(\zeta)\rightarrow \R^m\colon  h(\zeta)=\eta \wedge\forall
  z\in _\delta(\zeta)\colon  g(h(z),z)=0
  \end{equation}
  Ferner sei $\delta$ so klein, dass
  $\varphi(z)\coloneqq f(h(z),z)$ differenzierbar ist. Es gilt:
  \[\varphi'(\zeta)=\frac{\partial f}{\partial y}(\xi)h'(\zeta)+
  \frac{\partial f}{\partial z}(\xi)\]
  $f$ lokales Extremum in $\xi$ unter der Nebenbedingung $g(x)=0$
  impliziert, dass $\varphi'(\zeta)=0$. Also hat man
  \begin{equation}
    \label{eq:Glc}
    \frac{\partial f}{\partial y}
  (\xi)h'(\zeta)+\frac{\partial f}{\partial z}(\xi)=0
  \end{equation}
  Ausserdem hat man wegen der Gleichung \ref{eq:Glb}
  mit Satz \ref{satz:implFunktion}, dass 
 \[h'(\zeta)=-\left(\frac{\partial g}{\partial y}(\xi)\right)^{-1}
  \frac{\partial g}{\partial z}(\xi)\]
  Einsetzen in die Gleichung \ref{eq:Glc} liefert:
  $\underbrace{-\frac{\partial f}{\partial y}(\xi)
  \left(\frac{\partial g}{\partial y}(\xi)\right)^{-1}}_{\lambda^T=
  (\lambda_1,\dots,\lambda_m)}
  \frac{\partial g}{\partial z}(\xi)+\frac{\partial f}{\partial z}(\xi)
  =0$.\\
  Somit ist $\frac{\partial f}{\partial y}(\xi)+\lambda^T
  \frac{\partial g}{\partial y}(\xi)=0$ und $\frac{\partial f}{\partial z}
  (\xi)+\lambda^T\frac{\partial g}{\partial z}(\xi)=0$. Beide 
  Gleichungen liefern: $f'(\xi)+\lambda^T g'(\xi)=0\Leftrightarrow
  f'(\xi)+\sum_{i=1}^m \lambda_i g_i'(\xi)=0$
\end{proof}

\subsection{Praktische Lösungen von Extremalaufgaben}
$f\colon X\subset\R^n\rightarrow\R, g\colon X\rightarrow\R^m, m<n$\\
Man betrachtet das System der $n+m$-Gleichungen 
\[\frac{\partial f}{\partial x_k}(x)+\lambda_1
\frac{\partial g_1}{\partial x_k}(x)+\cdots+\lambda_m
\frac{\partial g_m}{\partial x_k}(x)=0\]
und 
\[g_j(x)=0\quad j=1,\dots,m\]
für die $n+m$ Unbekannten $x_1,\dots,x_n, \lambda_1,\dots,\lambda_m$,
die sich aus Satz \ref{satz:lagrange} ergeben.

Aufgabe: Seien $f\colon X\subset\R^n\rightarrow \R, g=\begin{pmatrix}
  g_1\\\vdots\\g_m
\end{pmatrix}\colon X\rightarrow \R^m$. $f$ soll unter der Nebenbedingung
$g(x)=0$ extremal werden.

\paragraph{Merkregel:}
\begin{enumerate}
  \item Man bildet die Funktion $F\colon X\times\R^m\rightarrow\R, F(x,\lambda)
    \coloneqq f(x)+\lambda^Tg(x), x=\begin{pmatrix}x_1\\\vdots\\x_n
    \end{pmatrix}, \lambda=\begin{pmatrix}\lambda_1\\\vdots\\ \lambda_m
    \end{pmatrix}$
  \item Differentiation nach $(x,\lambda)$ und Null setzen. $F'(x,\lambda)
    =0=\left(\frac{\partial F}{\partial x}, \frac{\partial F}{\partial \lambda}\right)
    =(f'(x)+\lambda^Tg'(x), g^T(x))=0\Leftrightarrow f'(x)+\lambda^T
    g'(x)=0$
\end{enumerate}

Ob in den Punkten $x=\xi$, die das obige Gleichungssystem erfüllen,
lokale Extrema vorliegen, muss tatsächlich noch überprüft werden. 
Hinreichende Bedingungen lassen sich schwer angeben. In diesem
Zusammenhang sind folgende Bemerkungen dabei nützlich:
\begin{enumerate}[(i)]
  \item $N=\{x\in X\colon g(x)=0\}$. Ist $N$ kompakt, so besitzt die Funktion
    $f|_N$ ein Maximum und ein Minimum, d.h. $f$ hat sogar ein globales
    und damit ein lokales Maximum und Minimum. 
  \item Seien $A,B\subset\R^n$ und $A\neq\emptyset$ ist kompakt und $B$ 
    ist abgeschlossen. Dann existiert $\xi\in A, \eta\in B\colon ||\xi-\eta||
    =\inf_{\stackrel{x\in A}{y\in B}} ||x-y||$\\
    Die Kompaktheit der Menge ist notwendig, denn:\\
    $A=\{(t,\sqrt{t^2-1}\colon 1\leq t\leq\infty\}, \not\exists \xi\in A,
    \eta\in B\colon ||\xi-\eta||=\inf_{\stackrel{x\in A}{y\in B}} ||x-y||$
\end{enumerate}

\begin{beispiel}
\begin{enumerate}
\item Bestimme Minima und Maxima der Funktion $f(x,y,z)=5x+y-3z$ unter
  den Nebenbedingungen: $x+y+z=0$ und $x^2+y^2+z^2=1$:
  \begin{align*}
    N & =\left\{
      \begin{pmatrix}
        x\\
        y\\
        z
      \end{pmatrix}
      \in\R^3\colon g(x,y,z)=0\right\}&
    g(x,y,z) &=
    \begin{pmatrix}
      x+y+z\\
      x^2+y^2+z^2-1
    \end{pmatrix}\\
    g &\colon \R^3\rightarrow\R^2&
    g'(x,y,z)&=
    \begin{pmatrix}
      1 & 1 & 1\\
      2x & 2y & 2z
    \end{pmatrix}
  \end{align*}
  Eine zweireihige Unterdeterminante von $g'$ auf $N$ ist $\neq 0$.\\
    $F(x,y,z,\lambda,\nu)=f(x,y,z)+\lambda(x+y+z)+\nu(x^2+y^2+z^2-1)=
    5x+y-3z+\lambda (x+y+z)+\nu(x^2+y^2+z^2-1),
    F'(x,y,z,\lambda,\nu)=0\Leftrightarrow$
    \begin{align}
      \label{1}
      \frac{\partial F}{\partial x} & = 5+\lambda+2\nu x=0\\
      \label{2}
      \frac{\partial F}{\partial y} & = 1+\lambda+2\nu y=0\\
      \label{3}
      \frac{\partial F}{\partial z} & = -3+\lambda+2\nu z=0\\
      \label{4}
      \frac{\partial F}{\partial \lambda} & = x+y+z=0\\
      \label{5}
      \frac{\partial F}{\partial \nu} & = x^2+y^2+z^2-1=0
    \end{align}
    \ref{1}, \ref{2} und \ref{3}: $3+3\lambda+2\nu(\underbrace{x+y+z}_{=0}
    )=0\Rightarrow 3+3\lambda=0\Rightarrow \lambda=-1 \Rightarrow
    \left.\begin{array}{rcl}
    4+2\nu x & = & 0\\
    2\nu y & = & 0
  \end{array}\right\}\Rightarrow \nu\neq 0, y=0\substack{\text{\ref{4},\ref{5}}}{\Rightarrow}
  \left.\begin{array}{rcl}
    x+z & = & 0\\
    x^2+y^2 & = & 1
  \end{array}\right\}\Rightarrow 2x^2=1\Rightarrow x=\pm \frac{1}{\sqrt{2}}, z=\mp\frac{1}{\sqrt{2}}$\\
  \ref{1}: $4+2\nu x=0, x=\pm\frac{1}{\sqrt{2}}, 4+\frac{2}{\sqrt{2}}\nu=0,
  \nu=\pm2\sqrt{2}$\\
  $(\frac{1}{\sqrt{2}},0,-\frac{1}{\sqrt{2}},-1,-2\sqrt{2})$\\
  Die Punkte $(\frac{1}{\sqrt{2}},0,-\frac{1}{\sqrt{2}}),
  (-\frac{1}{\sqrt{2}},0,\frac{1}{\sqrt{2}})$ erfüllen das Gleichungssystem
  \ref{1} bis \ref{5} in Verbindung mit $\lambda=-1, \nu=-2\sqrt{2}$
  bzw. $\nu=2\sqrt{2}$.\\
  Einsetzen in $f$:  $f(\frac{1}{\sqrt{2}},0,-\frac{1}{\sqrt{2}})=5\frac{1}{\sqrt{2}}
  +\frac{3}{\sqrt{2}}=\frac{8}{\sqrt{2}}=4\sqrt{2}$ und $f(-\frac{1}{\sqrt{2}}
  ,0,\frac{1}{\sqrt{2}})=-5\frac{1}{\sqrt{2}}-\frac{3}{\sqrt{2}}=-
  \frac{8}{\sqrt{2}}=-4\sqrt{2}$\\
  Die Menge $N$ ist kompakt. Da $f$ stetig ist, nimmt $f$ auf $N$ sowohl
  ihr Maximum als auch ihr Minimum an. Daher ist $4\sqrt{2}$ das
  Maximum und $-4\sqrt{2}$ das Minimum von $f$ auf $N$.\\
  Globale Extrema direkt:
  Sei 
  \begin{align*}
    N&=\left\{\begin{pmatrix}x\\y\\z\end{pmatrix}\in
      \R^3\colon \begin{matrix}x+y+z=0\\x^2+y^2+z^2=1 \end{matrix}\right\}\\
    f(x,y,z)&=5x+y-3z=\underbrace{x+y+z}_{=0}+4(x-z) \text{ auf } N
  \end{align*}
  Es gilt folgende Abschätzung: 
  \begin{align*}
    |f(x,y,z)|&=4|x-z|\leq 4(|x|+|z|)\\
    &\leq 4(\sqrt{1^2+1^2})
    \sqrt{|x|^2+|z|^2}=4\sqrt{2}(\sqrt{|x|^2+|z|^2})\\
    &\leq 4\sqrt{2}
  \end{align*}
  Also ist $-4\sqrt{2}\leq f(x,y,z)\leq 4\sqrt{2}$ mit $\begin{pmatrix}x\\y\\z
  \end{pmatrix}\in N$.
\item Sei $A=(a_{ij})_{i,j=1}^n$ eine reelle symmetrische $n\times n$-Matrix
  $(A=A^T)$. Man bestimme die Extrema $f(x)=\langle Ax,x\rangle$ unter
  der Nebenbedingung $||x||_2=1, x=\begin{pmatrix}x_1\\\vdots\\x_n
  \end{pmatrix}\in\R^n$. (Uebung)
\item Man bestimme die Extrema der Funktion $f(x)=\sum_{i=1}^n a_ix_i$
  mit $x=\begin{pmatrix}x_1\\\vdots\\x_n
  \end{pmatrix}\in\R^n, a_i>0, x_i>0$ mit der Nebenbedingung $\sum_{i=1}^n
  \frac{a_ib_1}{x_1}=1$ mit $b_1>0$.\\
  $N=\{x=\begin{pmatrix}x_1\\\vdots\\x_n
  \end{pmatrix}\in\R^n\colon x_1,\dots,x_n>0\wedge\sum_{i=1}^n \frac{a_ib_i}{x_i}
  =1\}$\\
  $g(x)=g(x_1,\dots,x_n)=\sum_{i=1}^n \frac{a_ib_i}{x_i}-1$\\
  $F(x,\lambda)=f(x)+\lambda g(x)=\sum_{i=1}^n
  a_ix_i+\lambda(\sum_{i=1}^n \frac{a_ib_i}{x_i}-1),
  F'(x,\lambda)=0\Leftrightarrow \frac{\partial F}{\partial x_i}
  =a_i+\lambda(-\frac{a_ib_i}{x_i^2}=0\Leftrightarrow
  \begin{matrix}
    a_1-\lambda\frac{a_1b_1}{x_1^2}=0\\
    \vdots\\
    a_n-\lambda\frac{a_nb_n}{x_n^2}=0
  \end{matrix}$ und $\frac{\partial F}{\partial \lambda}
  =\sum_{i=1}^n \frac{a_ib_i}{x_i}-1=0\Leftrightarrow \sum_{i=1}^n
  \frac{a_ib_i}{x_i}=1$\\
  Somit folgt $\lambda=\frac{x_1^2}{b_2}=\dots=\frac{x_n^2}{b_n}
  \Leftrightarrow x_i=\sqrt{\lambda b_i}\Rightarrow 1=\sum_{i=1}^n \frac{a_ib_i}{x_i}
  =\sum_{i=1}^n \frac{a_ib_i}{\sqrt{\lambda b_i}}=\sum_{i=1}^n
  \frac{a_i\sqrt{b_1}}{\sqrt{\lambda}} \Rightarrow \lambda=
  \left(\sum_{i=1}^n a_i\sqrt{b_i}\right)^2\Rightarrow x_k=\sqrt{b_k}
  \sqrt{\lambda}=\sqrt{b_k}\left(\sum_{i=1}^n a_i \sqrt{b_i}\right)$\\
  Für $f$ ergibt sich folgendes:\\ $f(x_1,\dots,x_n)=\sum_{k=1}^n
  a_kx_k=\sum_{k=1}^n a_k\sqrt{b_k}(\sum_{i=1}^n a_i\sqrt{b_1})=
  \left(\sum_{i=1}^n a_i\sqrt{b_i}\right)^2$\\
  $N$ ist \emph{nicht} kompakt, da $N$ nicht beschränkt ist.\\
  Behauptung: $f$ besitzt in $\xi=\left(\sqrt{b_k}\sum_{i=1}^n a_i
  \sqrt{b_i}\right)_{k=1}^n$ ein Minimum unter der Nebenbedingung $N$:
  \begin{align*}
    f(\xi) & = \left(\sum_{i=1}^n a_i\sqrt{b_i}\right)^2 =
    \sum_{i=1}^n\left(\sqrt{a_ix_i}\sqrt{\frac{a_ib_i}{x_i}}
    \right)^2\\
    & \leq \left(\sqrt{\sum_{i=1}^n(\sqrt{a_ix_i})^2}
      \sqrt{\sum_{i=1}^n(\sqrt{\frac{a_ib_i}{x_i}})^2}\right)^2\\
    & = \left(\sum_{i=1}^n a_ix_i\right)\left(\sum_{i=1}^n
      \frac{a_ib_i}{x_i}\right) = f(x)
  \end{align*} 
  für $x\in N$. Daher folgt, dass $f$ in $\xi$ 
  ein globales Minimum besitzt.
\end{enumerate}
\end{beispiel}

%% Vorlesung vom 26/28 ergaenzen

\section{Geometrische Begriffe}
\begin{definition}
  Unter einer \emph{Kurve\index{Kurve}} im $\R^n$ versteht man eine stetige
  Abbildung $f\colon I\rightarrow\R^n$, wobei $I\subset\R$ ein Intervall ist.
  Die Kurve $f$ heißt differenzierbar (bzw. stetig differenzierbar), 
  wenn $f$ differenzierbar (bzw. stetig differenzierbar) ist.
\end{definition}
\begin{definition}
  Sei $I\subset\R$ ein Intervall und $f\colon I\rightarrow\R^n$ eine
  differenzierbare Kurve. Für $t\in I$ heißt $f'(t)$ der
  \emph{Tangentialvektor\index{Tangentialvektor}} der Kurve $f$ zum
  Parameter $t$. Falls $f'(t)\neq 0$, heißt $\frac{f'(t)}{||f'(t)||_2}$
  Tangentialeinheitsvektor.
\end{definition}

\subsection{Geometrische Interpretation}
Der Tangentialvektor $f'(t)$ lässt sich als Limes von Sekanten auffassen.
Denn $f'(t)=\lim_{h\rightarrow 0} \frac{f(t+h)-f(t)}{h}$
%Zeichnung

Bemerkung: Eine Kurve $f\colon I\rightarrow\R^n$ braucht nicht injektiv zu sein.
Gilt $f(t_1)=f(t_2)=x$ für $t_1\neq t_2$, so heißt $x$ \emph{Doppelpunkt\index{Doppelpunkt}}
der Kurve $f$. In $x$ hat dann $f$ zwei i.allg. verschiedene Tangentialvektoren.

Beispiel: 
\begin{alignat*}{2}
  f&\colon \R\rightarrow\R^2 & f(t) & = \begin{pmatrix}t^2-1\\t^3-t
  \end{pmatrix}\\
  x & = t^2-1 & y & = t^3-t=t(t^2-1)\\
  y^2 & = t^2(t^2-1)^2=x^2+x^3 & f(\R) & = \left\{\begin{pmatrix}x\\y\end{pmatrix}\in\R^2\colon y^2=x^2+x^3\right\}\\
    f(-1) & = \begin{pmatrix}0\\0\end{pmatrix}=f(1) & f'(t) & = \begin{pmatrix}2t\\3t^2-1\end{pmatrix}\\
      f'(-1) & = \begin{pmatrix}-2\\2\end{pmatrix} & f'(1) & = \begin{pmatrix}2\\2\end{pmatrix}
\end{alignat*}

\begin{definition}
  Sei $f\colon I\rightarrow\R^n$ eine stetig differenzierbare Kurve. Die
  Kurve heißt \emph{regulär\index{regulär}}, falls $f'(t)\neq 0$ für alle
  $t\in I$. Ein Parameter $t\in I$ mit $f'(t)=0$ heißt \emph{singulär\index{singulär}}.
\end{definition}

Beispiel: $f\colon \R\rightarrow\R^2, f(t)=\begin{pmatrix}t^2\\t^3
\end{pmatrix}, x=t^2, y=t^3, y^2=x^3, y=\pm\sqrt{x^3}$\\
$f'(t)=\begin{pmatrix}2t\\3t
\end{pmatrix}, f'(0)=\begin{pmatrix}0\\0
\end{pmatrix}$. In $t=0$ liegt ein singulärer Punkt vor.

\begin{definition}
  \textbf{Schnittwinkel zweier Kurven}
  Seien $f\colon I_1\rightarrow\R^n, g\colon I_2\rightarrow\R^n$ zwei reguläre Kurven.
  Für $t_1\in I_1, t_2\in I_2$ gelte $f(t_1)=g(t_2)$. Unter dem
  \emph{Schnittwinkel\index{Schnittwinkel}} $\vartheta$ der Kurven $f$ und
  $g$ bei den Parametern $t_1$ bzw. $t_2$ versteht man den Winkel zwischen
  den Tangentialvektoren $f'(t_1)$ und $g'(t_2)$. Der Winkel $\vartheta$
  wird also bestimmt durch
  \[\cos \vartheta = \frac{\langle f'(t_1),g'(t_2)\rangle}{||f'(t_1)||_2||g'(t_2)||_2}\quad 0\leq\vartheta\leq\pi\]
\end{definition}

\subsection{Flächen und Tangentialebenen}
\begin{definition}
  Sei $f\colon D\rightarrow\R, D\subset\R^n$. Die Menge 
 \[\text{graph }(f)=\left\{\begin{pmatrix}x\\f(x)
  \end{pmatrix}\in\R^{n+1}\colon x\in D\right\}\]
  heißt \emph{Fläche\index{Fläche}}
  im $\R^{n+1}$.
\end{definition}
\begin{definition}
  Sei $f\colon D\rightarrow\R, D\subset\R^n$ offen und differenzierbar. Die
  Menge $T\coloneqq \left\{\begin{pmatrix}x\\y
\end{pmatrix}\in\R^{n+1}\colon x\in\R^n, y=f(\xi)+f'(\xi)(x-\xi)\right\}$ heißt
\emph{Tangentialebene\index{Tangentialebene}} von $f$ im Punkt 
$\begin{pmatrix}\xi\\f(\xi)
\end{pmatrix}$ mit $\xi\in D$.
\end{definition}

Bemerkung: 
\begin{enumerate}[(1)]
  \item Im Fall $n=1$ benutzt man den Begriff Kurve statt Fläche und
    Tangente statt Tangentialebene.
  \item Die Tangentialebene $T$ kann man sich im Punkt $(\xi, f(\xi))^T$
    wie folgt erzeugt denken:\\
    Man betrachtet folgende Kurven in $f$: 
    \begin{gather*}
      g_i(t)=(\xi_1,\dots,\xi_{i-1},t,\xi_{i+1},\dots,\xi_n,
   f(\xi_1,\dots,\xi_{i-1},t,\xi_{i+1},\dots,\xi_n))^T\\
   g_i\colon T\rightarrow\R^{n+1}\qquad g_i(\xi_i)=(f(\xi))
 \end{gather*}
    Tangentialvektoren: $g_i(\xi_i)=\begin{pmatrix}0\\\vdots\\1\\0\\\vdots\\0\\
      \frac{\partial f}{\partial x_i}(\xi)
    \end{pmatrix}$\\
    Dann: \begin{align*}
      T &=& \begin{pmatrix}\xi\\f(\xi)\end{pmatrix}+\text{span }\{g_1'(\xi),\dots,g_n'(\xi)\}\\
    &=& \left\{\begin{pmatrix}\xi\\f(\xi)\end{pmatrix}+\sum_{i=1}^n h_i g_i'(\xi)\colon  h=\begin{pmatrix}h_1\\\vdots\\h_n\end{pmatrix}\in\R^n\right\}\\
      &=& \left\{\begin{pmatrix}
        \xi+h\\
        f(\xi)+\sum_{i=1}^n h_i \frac{\partial f}{\partial x_1}(\xi)
      \end{pmatrix}\colon h\in\R^n\right\} \quad h_i=x_i-\xi_i
    \end{align*}
\end{enumerate}

\subsection{Niveauflächen}
\begin{definition}
  Sei $f\colon D\rightarrow\R, D\subset\R^n$. Dann heißt die Menge
  $\{x\in D |
  f(x)=c\}$ \emph{Niveaufläche\index{Niveaufläche}} der Funktion $f$
  zum Niveau $c$.
\end{definition}

Ein Beispiel hierfür sind Wetterkarten (Isobaren).

Bemerkung: Man kommt von einer Niveaufläche $f(x)=c_1$ zu einer 
"`unmittelbar benachbarten"' Niveaufläche $f(x)=c_2$ mit $c_2-c_1$ 
"`klein"' am schnellsten in Richtung des Gradienten:
\[c_2-c_1=f(x+h)f(x)\approx f'(x)h\]
Es gilt: 
\[\max\{|f'(x)h| | ||h||_2\leq 1\}=||f'(x)||_2\]
für $h=\frac{(f'(x)^T}{||f'(x)||_2}$ Richtung des Gradienten.

\subsection{Niveauflächen und Tangentialebenen}
\begin{theorem}
  Sei $f\colon D\rightarrow\R, D\subset\R^n$ offen, stetig differenzierbar und
  $f'(\xi)\neq 0$ in $\xi\in D$. Dann gilt: Die Tangentialebene an die
  Niveaufläche $f(x)=c$ mit $c=f(\xi)$ ist charakterisiert durch:
  \[\langle f'(\xi), x-\xi\rangle=0\]
  In Komponenten:
  \[\sum_{i=1}^n (x-\xi)\frac{\partial f}{\partial x_i}(\xi_1,\dots,\xi_n)=0\]
  \textbf{Beweis}: Sei o.\,B.\,d.\,A. $\frac{\partial f}{\partial x_n}(\xi)\neq
  0$. Dann existieren nach dem Auflösungssatz der impliziten Funktion
  eine Umgebung $U$ von $\begin{pmatrix}\xi_1\\\vdots\\\xi_{n-1}
  \end{pmatrix}$ und eine Umgebung $V$ von $\xi_n$ und $\varphi\colon 
  U\rightarrow V$ mit
  \begin{enumerate}
    \item $\varphi(\xi_1,\dots,\xi_{n-1})=\xi_n$
    \item $f(x_1,\dots,x_{n-1}, \varphi(x_1,\dots,x_n))=0\quad \forall
      \begin{pmatrix}x_1\\\vdots\\x_{n-1}
      \end{pmatrix}\in U$
  \end{enumerate}
  $T$ ist die Tangentialebene von $\varphi$ im Punkt $\begin{pmatrix}
    \tilde{\xi}\\
    \varphi(\tilde{\xi}
  \end{pmatrix}=\xi$ mit $\tilde{\xi}=\begin{pmatrix}\xi_1\\\vdots\\ \xi_{n-1}
  \end{pmatrix}$
  \[T=\left\{\begin{pmatrix}
    \tilde{x}\\
    \varphi(\tilde{\xi}+\varphi'(\tilde{\xi})(\tilde{x}-\tilde{\xi})
  \end{pmatrix}\colon \tilde{x}\in U\right\}\]
  Sei $y\in T$. Dann $y_n=\varphi(\tilde{\xi}+\varphi'(\tilde{\xi})(\tilde{y}
  -\tilde{\xi})=\xi_n-\frac{\partial f}{\partial x_n}(\xi)^{-1}
  \frac{\partial f}{\partial \tilde{x}}(\xi)(\tilde{y}-\tilde{\xi})
  \Leftrightarrow \frac{\partial f}{\partial x_n}(\xi)(y_n-\xi_n)=
  \underbrace{-\frac{\partial f}{\partial x_n}(\xi)(\tilde{y}-\tilde{\xi})}_{=\sum_{i=1}^n \frac{\partial f}{\partial x_i}(\xi)(y-\xi_i)}
  \Rightarrow \sum_{i=1}^n \frac{\partial f}{\partial x_i} (\xi)(y_i-
  \xi_i)=0$
  \qed
\end{theorem}

%%Vorlesung vom 2004-06-02

\chapter{Gewöhnliche Differentialgleichungen}
\section{Einführung}
\begin{definition}
  Sei $G\subset\R\times\R^n, f\colon G\rightarrow \R^n$ stetig. Dann heißt
  \begin{equation}
    \label{def:Diffgl}
    y'=f(x,y)
  \end{equation}
  ein System von $n$ Differentialgleichungen 1. Ordnung.

  Für $n=1$ heißt \ref{def:Diffgl} eine \emph{einfache Differentialgleichung\index{Differentialgleichung!einfache}} 1. Ordnung.

  Unter einer Lösung von \ref{def:Diffgl} versteht man eine auf einem
  Intervall $I\subset\R$ definierte differenzierbare Funktion
  \[\varphi\colon I\rightarrow\R^n\]
  mit folgenden Eigenschaften:
  \begin{enumerate}[a)]
    \item $\text{graph }\varphi\subset G, \text{graph }\varphi=\{(x,
      \varphi(x))|x\in I\}$
    \item Es gilt: $\varphi'(x)=f(x,\varphi(x))$
  \end{enumerate}
\end{definition}

In Koordinatenschreibweise:
\begin{gather*}
 y= \begin{pmatrix}y_1\\\vdots\\y_n\end{pmatrix}\qquad
f= \begin{pmatrix}f_1\\\vdots\\f_n\end{pmatrix}\\
y'= f(x,y)\Leftrightarrow\begin{matrix}
  y_1'=f_1(x,y_1,\dots,y_n)\\
  \vdots\\
  y_n'=f_n(x,y_1,\dots,y_n)
\end{matrix}
\end{gather*}

Die Lösung $\varphi(x)=\begin{pmatrix}\varphi_1(x)\\\vdots\\ \varphi_n(x)
\end{pmatrix}$ erfüllt $\varphi_i'=(f_i(x,\varphi_1(x),\dots,\varphi_n(x))$.

Bemerkungen:
\begin{enumerate}
  \item Nach dem Hauptsatz der Differential- und Integralrechnung ist
    b) äquivalent zu
    \[\varphi(x)=y_0+\int_{x_0}^x f(t,\varphi(t))dt \text{ mit } \varphi
    (x_0)=y_0\]
    Für $y'=f(x)$ erhält man als Lösung $\varphi(x)=c+\int_{x_0}^x f(t)dt,
    \varphi(x_0)=c$.
  \item Implizite Gestalt eines DGL-Systems 1 Ordnung:
    \[F(x,y,y')=0\]
    \[F\colon G\subset\R\times\R^n\times\R^n\rightarrow\R^n \text{ stetig}\]
  \item Treten in \ref{def:Diffgl} neben $x$ weitere unabhängige 
    Variable auf sowie partielle Ableitungen, so spricht man von
    \emph{partiellen Differentialgleichungen\index{Differentialgleichungen!partielle}}.\\
    Beispiel: Wärmeleitungsgleichungen:\\
    $\frac{\partial u}{\partial t}=\frac{\partial^2 u}{\partial x^2}, u=
    u(x,t)$\\
    Korteweg-deVries-Gleichungen:\\
    $\frac{\partial u}{\partial t}=\frac{\partial^3 u}{\partial x^3}+
    6u\frac{\partial u}{\partial x}$
\end{enumerate}

\paragraph{Anfangswertproblem}
Folgende Aufgabe heißt Anfangswertproblem für ein DGL-System 1.
Ordnung:\\
Sei $(x_0,y_0)\in G$.\\
Gesucht ist eine Lösung $y=\varphi(x)$ von $y'=f(x,y)$ mit $\varphi(x_0)
=y_0$.

Beispiel: $y'=f(x), f\colon I\rightarrow\R^n$ stetig, $x_0\in I, \varphi(x_0)
=y_0$\\
Integration: $\varphi(x)=y_0+\int_{x_0}^x f(t)dt$\\
$\int_{x_0}^x f(t)dt \coloneqq  \begin{pmatrix}
  \int_{x_0}^x f_1(t)dt\\
  \vdots\\
  \int_{x_0}^x f_n(t)dt
\end{pmatrix}$

Geometrische Intepretation:

%Zeichnung
Eine DGL $y'=f(x,y)$ in einem Gebiet $G$, $G\subset\R\times\R^n$, bestimmt
ein \emph{Richtungsfeld\index{Richtungsfeld}}: 
\[\{(x,y,y')\colon (x,y)\in G, y'=f(x,y)\}\]
$(x,y,y')$ heißt \emph{Linienelement\index{Linienelement}}. In jedem
Punkt $(x,y) \in G$ wird durch $y'=f(x,y)$ eine Steigung vorgegeben.

Problem: Gesucht wird eine Funktion $y=\varphi(x)$, deren Tangente im
Punkt $x,\varphi(x))$ die Richtung besitzt, die durch das Richtungsfeld
vorgeschrieben ist, d.h. die auf das Richtungsfeld passt. 

Kurven konstanten Anstiegs heissen \emph{Isoklinen\index{Isoklinen}}.

Beispiel: $y'=f(x,y)=x, G\subset\R\times\R$\\
Die Lösungen sind Parabeln: $\varphi(x)=\frac{x^2}{2}+c$

Die allgemeine Theorie der gewöhnlichen Differentialgleichungen
beschäftigt sich mit folgenden Problemstellungen für das AWP $y'=f(x,y),
\varphi(x_0)=y_0$.
\begin{enumerate}
  \item Existenz einer Lösung
  \item Eindeutigkeit der Lösung
  \item Berechnung von Lösungen
  \item Abhängigkeit der Lösung von Anfangsbedingungen (z.B. ob stetige
    Abhängigkeit vorliegt)
  \item Stabilitätsverhalten von Lösungen 
\end{enumerate}

\paragraph{Lösungsvielfalt}
Die Gesamtheit aller Lösungen 
\[L=\{y=\varphi(x)|\varphi'(x)=f(x,\varphi(x))\}\]
heißt \emph{allgemeine Lösung\index{Lösung!allgemeine}} von $y'=f(x,y)$.

Ein $\varphi\in L$ heißt \emph{spezielle Lösung\index{Lösung!spezielle}}
von $y'=f(x,y)$.

Die allgemeine Lösung kann oft durch Parameter beschrieben werden.

\section{Reduktion von Differentialgleichungssystemen höherer Ordnung auf Differentialgleichungssysteme 1. Ordnung}
\begin{definition}
  $G\subset\R\times\R^n\times\dots\times\R^n, f\colon G\rightarrow\R^n$ stetig\\
  Dann heißt
  \begin{equation}
    \label{def:DiffglHoch}
    y^{(k)}=f(x,y,y',\dots,y^{(k)})
  \end{equation}
  ein System von $n$ Differentialgleichungen $k$-ter Ordnung.
\end{definition}

Für $k=1$ erhält man Gleichung \ref{def:Diffgl} und für $n=1$ heißt
die Gleichung \ref{def:DiffglHoch} einfach Differentialgleichung $k$-ter
Ordnung.

Unter einer Lösung von \ref{def:DiffglHoch} versteht man eine Funktion
$\varphi$, die auf einem Intervall $I\subset\R$ definiert ist und $k$-mal
differenzierbar ist, mit folgenden Eigenschaften:
\begin{enumerate}[a)]
  \item $\{(x,\varphi(x),\varphi'(x),\dots,\varphi^{(k-1)}(x))|x\in I\}\subset G$
  \item $\varphi^{(k)}=f(x,\varphi(x),\dots,\varphi^{(k-1)}(x))$
\end{enumerate}

Koordinatenschreibweise: $f=\begin{pmatrix}f_1\\\vdots\\f_n
\end{pmatrix}, y=\begin{pmatrix}y_1\\\vdots\\y_n
\end{pmatrix}$, d.h. wegen Gleichung \ref{def:DiffglHoch} $\Leftrightarrow
y_i^{(k)}=f_i(x,y_1,\dots,y_n,y_1',\dots,y_n',\dots,y^{(k-1)}_1,\dots,
y^{(k-1)}_n)$

\paragraph{Reduktion von \ref{def:DiffglHoch} auf DGL-Systeme 1. Ordnung}
Man setzt $Y\coloneqq \begin{pmatrix}y_0\\y_1\\\vdots\\y_{k-1}
\end{pmatrix}\in(\R^n)^k$\\
$F(x,Y)\coloneqq \begin{pmatrix}y_1\\\vdots\\y_{k-1}\\
  f(x,y_0,\dots,y_{k-1})
\end{pmatrix}$.
Dann gilt:
\begin{enumerate}[a)] 
  \item $\varphi$ ist eine Lösung von \ref{def:DiffglHoch} 
$\Rightarrow\Phi\coloneqq \begin{pmatrix}\varphi\\ \varphi'\\\vdots\\ \varphi^{(k-1)}
\end{pmatrix}$ ist eine Lösung von 
\begin{equation}
  \label{def:DiffglEin}
   Y'=F(x,Y)
\end{equation}
Denn: Sei $\varphi\colon I\rightarrow\R^n$ eine Lösung von \ref{def:DiffglHoch},
d.h. $\varphi^{(k)}(x)=f(x,\varphi(x),\dots,\varphi^{(k-1)}(x))
\Rightarrow$
\begin{align*}
  \Phi' & = & \begin{pmatrix}\varphi'(x)\\ \varphi''(x)\\\vdots\\ \varphi^{(k)}(x)\end{pmatrix}\\
  & = & \begin{pmatrix}
  \varphi_1\\
  \vdots\\
  \varphi_{k-1}\\
  f(x,\varphi_0(x),\dots,\varphi_{k-1}(x))
\end{pmatrix}\\
  & = & F(x,\varphi_0(x),\dots,\varphi_{k-1}(x))\\
  & = & F(x,\Phi(x))
\end{align*}
  \item $\Phi$ ist eine Lösung von \ref{def:DiffglEin}. Dann ist $\varphi
    \coloneqq \varphi_0$ eine Lösung von \ref{def:DiffglEin}.\\
    Denn: Sei $\Phi$ eine Lösung von $Y'=F(x,Y)\Rightarrow \varphi_0'=
    \varphi_1 \dots$. Setze $\varphi\coloneqq \varphi_0\Rightarrow \varphi Y'=F(x,Y)Y'=F(x,Y)i_1=
    \varphi', \varphi_2=\varphi'',\dots,\varphi_{k-1}=\varphi^{(k-1)}$
    und $\varphi^{(k)}(x)=f(x,\varphi(x),\dots,\varphi^{(k-1)}(x))$. 
    Daraus folgt die Aussage.
\end{enumerate}

Fazit: Die Lösungen \ref{def:DiffglHoch} und \ref{def:DiffglEin} sind
in eineindeutiger Beziehung zueinander.

%%Vorlesung vom 2004-06-04

%%Vorlesung vom 2004-06-07

% Klausur 2004-07-10 9:00 Uhr  HS2 CZ7

\paragraph{Festlegung von $C$ durch Anfangsbedingung $\varphi(x_0)=y_0$}
Die Struktur der allgemeinen Lösung $\varphi(x)$ der inhomogenen
DGL $y'=a(x)y+b(x)$ kann auch wie folgt charakterisiert werden:\\
$\varphi(x)=C\varphi_0(x)+\varphi_{\text{inh}}(x), \varphi_0(x)=e^{\int_{x_0}^x a(t)dt}$\\
Beweis: Sei $\psi(x)$ eine Lösung des inhomogenen DGL $y'=a(x)y+b(x)$.
Wir zeigen, $\exists C\in\R\colon \psi(x)=C\varphi_0(x)+\varphi_{\text{inh}}(x)$ und
setzen $h(x)\coloneqq \psi(x)-\varphi_{\text{inh}}(x)$. Dann gilt $h'(x)=\psi'(x)
-\varphi_{\text{inh}}'(x)=a(x)\psi(x)+b(x)-(a(x)\varphi_{\text{inh}}(x)
b(x))=a(x)(\psi(x)-\varphi_{\text{inh}}(x))=a(x)h(x)\Rightarrow h(x)$
ist Lösung des homogenen DGL $y'=a(x)y$. Somit existiert ein $C\in\R \colon 
h(x)=C\varphi_0(x)$ oder $\psi(x)-\varphi_{\text{inh}}(x)=C\varphi_0(x)
\Rightarrow\psi(x)=C\varphi_0(x)+\varphi_{\text{inh}}(x)$

Beispiel: Gesucht ist die allgemeine Lösung von $y'=ay+1$.
\begin{enumerate}[1. Schr{i}tt]
  \item Berechnung der allgemeinen Lösung des homogenen DGL $y'=ay$\\
    $\varphi(x)=C\varphi_0(x)=Ce^{\int_0^x adt}=Ce^{ax}$
  \item Finden einer speziellen Lösung der inhomogenen DGL $y'=ay+1$\\
    Die erste Möglichkeit ist die Variation der Konstanten, die zweite
    ist Raten.\\
    $\varphi_{\text{inh}}(x)=-\frac{1}{a} \quad 0=\varphi_{\text{inh}}(x)
    =aa\varphi_{\text{inh}}(x)+1=a(-\frac{1}{a})+1=0$\\
    Allgemeine Lösung der inhomogenen DGL = allgemeine Lösung des
    homogenen DGL + spezielle Lösung des inhomogenen DGL
    \[\varphi(x)=Ce^{ax}-\frac{1}{a}\quad \varphi(x)=Ce^{ax}+e^{ax}-\frac{1}{a}\]
    Zur ersten Möglichkeit (Variation der Konstanten):\\
    Ansatz: $\varphi(x)=e^{ax}C$ Festlegung von $C$ durch
    Anfangsbedingung $(x)$\\
    Einsetzen in inhomogene DGL: $y'=ay+1$\\
    $\varphi'(x)=ae^{ax}C(x)+e^{ax}C'(x)=a\varphi(x)+1=ae^{ax}C(x)+1
    \Rightarrow e^{ax}C'(x)=1\Rightarrow C'(x)=e^{-ax}\Rightarrow
    C(x)-\underbrace{C(0)}_{=C}int_0^x a^{-at}dt=-\frac{1}{a}e^{-ax}+\frac{1}{a}\Rightarrow
    C(x)=C-\frac{1}{a}e^{-ax}+\frac{1}{a}$\\
    $\varphi(x)=e^{ax}C(x)=e^{ax}(C-\frac{1}{a}e^{-ax}+\frac{1}{a})=
    e^{ax}C-\frac{1}{a}+\frac{1}{a}e^{ax}$
\end{enumerate}

\subsection{Beispiele für Differentialgleichungen, die auf $y'=f(x)g(y)$
zurückgeführt werden können}
\begin{enumerate}[(a)]
  \item Die inhomogene DGL $y'=f(\frac{y}{x})$\\
    Sei $I\subset\R$ ein Intervall, $f\colon I\rightarrow\R$ stetig, $G\coloneqq \{
    (x,y)\in\R\backslash \{0\}\times \R|\frac{y}{x}\in I\}$. Dann
    heißt $y'=f(\frac{y}{x})$ homogene DGL. Es gilt, $\varphi(x)$ ist
    eine Lösung von $y'=f(\frac{y}{x})\Leftrightarrow\psi(x)=\frac{\varphi(x)}{x}$
    ist Lösung von $z'=\frac{1}{x}(f(z)-z)$.\\
    Beweis: \begin{itemize}
      \item["`$\Rightarrow$"'] Sei $\varphi$ Lösung von $y'=f(\frac{y}{x})$.
    Dann $\varphi'(x)=\frac{\varphi'(x)x=\varphi(x)}{x^2}=\frac{1}{x}
    (\varphi'(x)-\frac{\varphi(x)}{x})=\frac{1}{x}(f(\frac{\varphi(x)}{x})
    -\frac{\varphi(x)}{x})=\frac{1}{x}(f(\psi(x))-\psi(x))\Rightarrow
    \psi(x)=\frac{\varphi(x)}{x}$ ist Lösung von $z'=\frac{1}{x}
    (f(z)-z)$
      \item["`$\Leftarrow$"'] Sei $\psi$ Lösung von $z'=\frac{1}{x}
    (f(x)-x)$. Dann gilt für $\varphi(x)=\psi (x)\quad x \colon \varphi'(x)
    =\psi'(x)x+\psi(x)=\frac{1}{x}(f(\psi(x))-\psi(x))x+\psi(x)=
    f(\psi(x))-\psi(x)+\psi(x)=f(\psi(x))=f(\frac{\varphi(x)}{x})$\\
    $\varphi$ ist Lösung des DGL $y'=f(\frac{y}{x})$
    \end{itemize}
  \item Die Differentialgleichung $y''=f(y), f\colon J\rightarrow\R$ stetig\\
    Die Lösung erfolgt mit Hilfe der sog. Energiemethode:
    Sei $\varphi(x)$ Lösung von
    $y''=f(y)$. Dann Multiplikation mit $\varphi'(x)$: $\varphi''(x)
    \varphi'(x)=f(\varphi(x)\varphi'(x)\Leftrightarrow\frac{1}{2}
    \frac{d}{dx} ( (\varphi'(x)^2))=\frac{d}{dx}\int_{x_0}^x f(\varphi(z))
    \varphi'(z)dz=\frac{d}{dx}\int_{\varphi(x_0)}^{\varphi(x)} f(t)dt$\\
    Physiker setzen dann: $U(y)\coloneqq -\int_{y_0}^y f(t)dt\Leftrightarrow
    \frac{d}{dx} (\frac{1}{2}(\varphi'(x))^2+U(\varphi(x)))=0
    \Rightarrow \frac{1}{2}(\varphi'(x))^2+U(\varphi(x))=E=$konstant\\
    $y'=\pm\sqrt{2(E-U(y))}$ - Differentialgleichung mit getrennten
    Variablen
\end{enumerate}

\section{Lineare Differentialgleichungssysteme mit konstanten Koeffizienten}
\subsection{Definition}
Sei $\MM_n(\K)\coloneqq \{A=\begin{pmatrix}
  a_{11}& \dots & a_{1n}\\
  \vdots & & \vdots\\
  a_{n1} & \dots & a_{nn}
\end{pmatrix}\colon a_{ij}\in\K\}$ die Menge aller $n\times n$-Matrizen.
Dann heißt 
\begin{equation}
  \label{def:lDGL}
  y'=Ay \, y\in\R^n \, A\in\mathfrak{M}_n(\K)
\end{equation}
\emph{homogenes lineares Differentialgleichungssystem\index{Differentialgleichungssystem!homogenes lineares}} 1. Ordnung mit konstanten 
Koeffizienten. Weiter sei $b=\begin{pmatrix}b_1\\\vdots\\b_n
\end{pmatrix}\colon I\rightarrow\R^n$ eine stetige Funktion. Dann heißt
\begin{equation}
  \label{def:DGLFunkt}
  y'=Ay+b(x)
\end{equation}
ein inhomogenes lineares Differentialgleichungssystem 1. Ordnung mit
konstanten Koeffizienten. In Komponenten lautet die Gleichung 
\ref{def:DGLFunkt} wie folgt:
\[\begin{matrix}
  y_1'=a_{11}y_1+\cdots+a_{1n}y_n+b_1(x)\\
  \vdots\\
  y_n'=a_{n1}y_1+\cdots+a_{nn}y_n+b_n(x)
\end{matrix}\]

Bemerkungen: Die Funktion $f\colon \R\times\R^n\rightarrow\R^n, f(x,y)\coloneqq Ay$
ist linear in $y$. Daher stammt der Name lineare Differentialgleichung.
Im eindimensionalen Fall $n=1$ hat man die allgemeine Lösung der
homogenen Differentialgleichung $y'=ay, \varphi(x)=e^{ax}c, c\in\R$.
Mehrdimensional $n>1$ hätte man folgende Analogie: 
\[y'=Ax, \varphi(x)=e^{Ax}c, c\in\R^n\]

Die entstehen folgende Probleme:
\begin{enumerate}[(a)]
  \item Was versteht man unter $e^{Ax}$?
  \item Wie berechnet man $e^{Ax}$?
\end{enumerate}

\subsection{Operatorfunktion (Matrixfunktionen)}
\begin{definition}
  Sei $(A_k)\subset\LL(\K^n, \K^n)$ eine Folge. Die Reihe $\sum_{k=0}^\infty
  A_k$ heißt genau dann konvergent, wenn die Folge der Partialsummen
  $(\sum_{k=0}^n A_k)_{n=1}^\infty$ in $\LL(\K^n,\K^n)$ konvergent ist.
\end{definition}

Beispiel: Sei $A\in\LL(\K^n,\K^n), e^A\coloneqq \sum_{k=0}^\infty \frac{A^k}{k!}$
ist für jede Matrix $A\in\LL(\K^n,\K^n)$ konvergent. Denn $a_n=\frac{A^n}{n!}$. Die Norm ist $||a_n||=\frac{||A^n||}{n!}\leq \frac{||A||^n}{n!}
=b_n$.
\[\lim\frac{b_{n+1}}{b_n}=\lim\frac{||A||^{n+1}}{(n+1)!}\cdot\frac{n!}{||A||^n}
=\lim \frac{||A||}{n+1}=0\]

\begin{theorem}
  Sei $A=(a_{ij})_{i,j=1}^n$ konstant. Dann gilt
  \begin{enumerate}[(i)]
    \item Die allgemeine Lösung des homogenen DGL $y'=Ay$ ist
      \[\varphi(x)=e^{Ax}c\quad c\in\R^n\]
      Beweis:
      \begin{enumerate}[(a)]
    \item $\varphi(x)=e^{Ax}c$ ist Lösung von $y'=Ay\colon \varphi'(x)
      =Ae^{Ax}c=A\varphi(x)$
    \item Jede Lösung $\varphi(x)$ von $y'=Ay$ lässt sich in der
      Form $\varphi(x)=e^{Ax}c$ darstellen. Sei $\varphi$ Lösung
      von $y'=e^{Ax}y$. Zeigen, dass $c(x)\coloneqq e^{-Ax}\varphi(x)=c$
      konstant ist. $c'(x)=-Ae^{-Ax}\varphi(x)+e^{-Ax}\varphi'(x)=
      -Ae^{-Ax}\varphi(x)+e^{-Ax}A\varphi(x)=-Ae^{-Ax}\varphi(x)+
      Ae^{-Ax}\varphi(x)=0\Rightarrow c$ ist konstant. Daher folgt
      weiter $e^{Ax}c=e^{Ax}e^{-Ax}\varphi(x)=I\varphi(x)=\varphi(x)$
      \end{enumerate}
    \item Die allgemeine Lösung der inhomogenen DGL $y'=Ay+b(x)$ ist
      \[\varphi(x)=e^{Ax}c+e^{Ax}\int_{x_0}^x e^{-At}b(t)dt\]
      Beweis: Variation der Konstanten: Sei $\varphi(x)$ Lösung des
      inhomogenen DGL $y'=Ay+b(x)$. Man setzt $\varphi(x)=e^{Ax}c(x)$.
      Einsetzen in DGL: $\varphi'(x0=Ae^{Ax}c(x)+e^{Ax}c'(x)=A\varphi(x)
      b(x)=Ae^{Ax}c(x)+b(x)\Rightarrow e^{Ax}c'(x)=b(x)$. Man 
      multipliziert von links mit $e^{-Ax}$ : $e^{-Ax}e^{Ax}c'(x)=
      e^{-Ax}b(x)\Rightarrow c'(x)=e^{-Ax}b(x)$.\\
      Integration: $c(x)-\underbrace{c(x_0)}_{=c}=\int_{x_0}^x e^{-At}b(t)dt
      \Rightarrow c(x)=c+\int_{x_0}^x e^{-At}b(t)dt\Rightarrow \varphi(x)
      =e^{Ax}c(x)=e^{Ax}(c+\int_{x_0}^x e^{-At}b(t)dt)$\\
      $e^{Ax}c$ ist die allgemeine Lösung der homogenen DGL $y'=Ay$ und
      $e^{Ax}\int_{x_0}^x e^{-At}b(t)dt$ ist die spezielle Lösung der
      inhomogenen DGL $y'=Ay+b(x)$.
  \end{enumerate}
  \qed
\end{theorem}

Bemerkung: $\Phi(x)=e^{Ax}, \Phi\colon \R\rightarrow\LL(\K^n,\K^n), \Phi'(x)
=Ae^{Ax}=e^{Ax}A$\\
Man benutzt die Reihe 
\[\Phi(x)=e^{Ax}=I+Ax+\frac{A^2x^2}{2!}+\frac{A^3x^3}{3!}+\cdots
=\sum_{k=0}^\infty \frac{A^kx^k}{k!}\]
\begin{align*}
 \frac{\Phi(x+h)-\Phi(x)}{h}&=& \frac{e^{A(x+h)}-e^{Ax}}{h}\\
&=& \frac{e^{Ax+Ah}-e^{Ax}}{h}\\
&=& \frac{e^{Ax}e^{Ah}-e^{Ax}}{h}\\
&=& e^{Ax}\frac{e^{Ah}-I}{h}\\
&=& e^{Ax}\frac{1}{h}\sum_{k=1}^\infty \frac{A^kx^k}{k!}\\
&=& e^{Ax}A \sum_{k=1}^\infty\frac{A^{k-1}h^{k-1}}{k!}\\
&=& e^{Ax}A(I+\frac{Ah}{2!}+\frac{A^2h^2}{3!}+\cdots)
\xrightarrow{h\rightarrow 0} e^{Ax}A\\
&=& Ae^{Ax}
\end{align*}

Beispiel: 
\begin{align*}
  y_1' & = y_1+y_2+\cdots+y_n\\
  y_2' & = y_1+y_2+\cdots+y_n\\
  \vdots\\
  y_n' & = y_1+y_2+\cdots+y_n & \text{Gesucht ist } y_i=\varphi_i{x}
\end{align*}
Matrixschreibweise: 
\begin{align*}
  y & =
  \begin{pmatrix}
    y_1\\
    \vdots\\
    y_n
  \end{pmatrix} &
  \varphi(x) &=
  \begin{pmatrix}
    \varphi_1(x)\\
    \vdots\\
    \varphi_n(x)
  \end{pmatrix}&
  A &=
  \begin{pmatrix}
    1 & 1 & \dots & 1\\
    1 & 1 & \dots & 1\\
    \vdots & \vdots & & \vdots\\
    1 & 1 & \dots & 1\\
  \end{pmatrix}
\end{align*}
Die allgemeine Lösung ist $\varphi(x)=e^{Ax}c, c=\begin{pmatrix}
  c_1\\\vdots\\c_n
\end{pmatrix}\in\R^n$\\
Berechnung von $e^{Ax}$: $e^{Ax}=\sum_{k=0}^\infty \frac{A^kx^k}{k!}$.
Seien $e_i=\begin{pmatrix}0\\\vdots\\0\\1\\0\\\vdots\\0
\end{pmatrix}, Ae_i=\begin{pmatrix}1\\1\\\vdots\\1
\end{pmatrix}=e_1+e_2+\cdots+e_n$
\begin{align*}
A^2e_i & = Ae_1+Ae_2+\cdots+Ae_n=n(e_1+\cdots+e_n)=nAe_i\Rightarrow A^2=nA\\
A^3 & =  AA^2=AnA=nA^2=n^2A\\
A^k & =  n^{k-1}A\\
e^{Ax} &=I+\sum_{k=1}^\infty \frac{A^kx^k}{k!}=I+\sum_{k=1}^\infty
\frac{n^{k-1}x^k}{k!}A\\
&=I+\frac{A}{n}\sum_{k=1}^\infty \frac{(nx)^k}{k!}
=I+\frac{A}{n}(e^{nx}-1)\\
&\boxed{e^{Ax}=I+\frac{e^{nx}-1}{n}A}
\end{align*}

Allgemeine Lösung von $y'=Ay$ ist $\varphi(x)=e^{Ax}c=(I+\frac{e^{nx}-1}{n}
A)c$\\
Probe: $\varphi'(x)=e^{nx}Ac, A\varphi(x)=A(I+\frac{E^{nx}-1}{n}A)c=
(A+\frac{e^{nx}-1}{n}A^2)c=(A+\frac{e^{nx}-1}{n}nA)c=(A+(e^{nx}-1)A)c=
e^{nx}Ac\Rightarrow \varphi'(x)=A\varphi(x)\Rightarrow \varphi(x)=
(I+\frac{e^{nx}-1}{n}A)c$ ist die allgemeine Lösung von $y'=Ay$.

Man berechne die allgemeine Lösung des inhomogenen DGL $y'=Ay+b(x), b(x)=
\begin{pmatrix}1\\0\\\vdots\\0
\end{pmatrix}=e_1$. In Komponenten lautet die Gleichung:
\begin{align*}
  y_1' &=& y_1+\cdots+y_n+1\\
  \vdots &=& \vdots\\
  y_n' &=& y_1+\cdots+y_n
\end{align*}
Ansatz (Variation der Konstanten): $\varphi(x)=e^{Ax}c(x)$\\
$\varphi'(x)=Ae^{Ax}c(x)+e^{Ax}c'(x)=A\varphi(x)+b(x)=Ae^{Ax}c(x)+b(x),
e^{Ax}c'(x)=b(x), c'(x)=e^{-Ax}b(x)=e^{A(-x)}b(x)=(I+\frac{e^{-nx}-1}{n}
A)e_1$\\
$c(x)=c+\left(Ix-\frac{1}{n}\left(\frac{e^{-nx}}{n}+x\right)A\right)e_1$\\
Damit ergibt sich die DGL wie folgt:\\
$\varphi(x)=e^{Ax}c(x)=e^{Ax}
\left(c+\left(Ix-\frac{1}{n}\left(\frac{e^{-nx}}{n}+x\right)A\right)e_1\right)=
e^{Ax}c+e^{Ax}(Ix-\frac{1}{n}(\frac{e^{-nx}}{n}+x)A)e_1=(I+\frac{e^{-nx}-1}{n}
A)c+(I+\frac{e^{nx}-1}{n}A)(Ix-\frac{1}{n}(\frac{e^{-nx}+x}{n}+x)A)e_1=$
\[\boxed{\left(I+\frac{e^{nx}-1}{n}A\right)c+\left(Ix-\left(\frac{x}{n}+\frac{1}{n^2}\right)A\right)e_1}\]
Spezialfall $n=2$: $y=(y_1,y_2)^T, \varphi=(\varphi_1,\varphi_2)^T, A=\begin{pmatrix}1&1\\1&1
\end{pmatrix}, b(x)=e_1=(1,0)^T$\\
$\varphi(x)=(I+\frac{e^{2x}-1}{2}A)c+Ix-(\frac{x}{2}+\frac{1}{4})e_1, c=
(c_1,c_2)^T$\\
$\varphi_1(x)=c_1+\frac{e^{2x}-1}{2}(c_1+c_2)+(x-(\frac{x}{2}+\frac{1}{4}))
=\frac{e^{2x}+1}{2}c_1+\frac{e^{2x}-1}{2}c_2+\frac{x}{2}-\frac{1}{4}$\\
$\varphi_2(x)=c_2+\frac{e^{2x}-1}{2}(c_1+c_2)-\frac{x}{2}-\frac{1}{4}=
\frac{e^{2x}-1}{2}c_1+\frac{e^{2x}+1}{2}c_2-\frac{x}{2}-\frac{1}{4}$\\
Probe: $\varphi_1'(x)=e^{2x}c_1+e^{2x}c_2+\frac{1}{2}, \varphi_1(x)+
\varphi_2(x)+1=e^{2x}c_1+e^{2x}c_2-\frac{1}{2}+1\Rightarrow\varphi_1'(x)
=\varphi_1(x)+\varphi_2(x)+1$\\
$\varphi_2'(x)=e^{2x}c_1+e^{2x}c_2-\frac{1}{2}, \varphi_1(x)+\varphi_2(x)=
e^{2x}c_1+e^{2x}c_2-\frac{1}{2}\Rightarrow \varphi_2'(x)=\varphi_1(x)+
\varphi_2(x)$

\begin{definition}
  Sei $A\in\mathfrak{M}_n(\K)$. Eine matrixwertige Funktion $\Phi=
  (\varphi_1,\dots,\varphi_n)\colon \R\rightarrow\mathfrak{M}_n(\K)$ heißt
  ein \emph{Fundamentalsystem\index{Fundamentalsystem}} von Lösungen von
  $y'=Ay$, falls $\Phi(x)$ für alle $x$ invertierbar ist und die
  Matrixdifferentialgleichung $Y'=AY$ erfüllt, d.h. $\Phi'(x)=A\Phi(x)$.
  Es gilt:
  \begin{enumerate}[(1)]
    \item Jedes Fundamentalsystem $\Phi$ hat die Gestalt $\varphi(x)=
      e^{Ax}S$, wobei $S\in\mathfrak{M}_n(\K)$ invertierbar.\\
      Beweis: $\Phi(x)=e^{Ax}S, \Phi'(x)=Ae^{Ax}S=A\Phi(x)$\\
      Zeigen $S(x)=e^{-Ax}\Phi(x)$, wobei die invertierbare Matrix
      $\Phi(x)$ die DGL $Y'=AY$ erfüllt. $S'(x)=-Ae^{-Ax}\Phi(x)+e^{-Ax}
      \Phi'(x)=-Ae^{-Ax}\Phi(x)+e^{-Ax}A\Phi(x)=0\Rightarrow S'(x)=
      S=$konstant. $e^{-Ax}\Phi(x)=S\Rightarrow \Phi(x)=e^{Ax}S$. Da
      $\Phi, e^{Ax}$ invertierbar, folgt $S$ invertierbar.
    \item Die allgemeine Lösung von $y'=Ay$ ist $\varphi(x)=\Phi(x)c, c
      \in\K^n$\\
      Beweis: $\varphi(x)=\Phi(x)c=e^{Ax}Sc$ ist Lösung von $y'=Ay$. Zu
      zeigen ist $\varphi(x)$ Lösung von $y'=Ay$, so exitiert $c\in\K^n\colon 
      \varphi(x)=e^{Ax}Sc$. Setzen $c(x)=S^{-1}e^{-Ax}\varphi(x)$. Dann
      gilt $c'(x)=S^{-1}Ae^{-Ax}\varphi+S^{-1}e^{-Ax}\varphi(x)=S^{-1}
      Ae^{-Ax}\varphi(x)-S^{-1}e^{-Ax}A\varphi(x)=0\Rightarrow c(x)=x=$konstant.
      $c=S^{-1}e^{-Ax}\varphi(x)\Rightarrow\varphi(x)=e^{Ax}Sc$
      \qed
  \end{enumerate}
\end{definition}

\paragraph{Berechnung von $\Phi(x)=e^{Ax}S$}
\begin{align*}
  \Phi(x)&=& (\varphi_1(x),\dots,\varphi_n(x))\\
\varphi_i(x)&=& e^{Ax}Se_i\\
e_i&=& (0,\dots,0,1,0,\dots,0)^T
\end{align*}
Es gilt:
\begin{theorem}
  Die Matrix $\MM_n(\C)$ besitzt die Eigenwerte $\mu_1,\dots,\mu_p,
  \lambda_1,\dots,\lambda_q$ und das System $\{v_{10}, v_{20},\dots,
  v_{p0},v_{11},\dots,v_{r_11},\dots,v_{12},\dots,v_{r_22},
  \dots, v_{1q},\dots,v_{r_qq}\}, p+r_1+\cdots+r_q=n$ von Eigenvektoren
  und Hauptvektoren (Wurzelvektoren), d.h. 
  \begin{align*}
    (A-\mu_1I)v_{10}&=& 0,\dots, (A-\mu_pI)v_{p0}=0\\
    (A-\lambda_1I)v_{11}&=& 0, (A-\lambda_1I)v_{21}=v_{11},\dots,
    (A-\lambda_1I)v_{r_11}=v_{(r_1-1)1}\\
    \vdots\\
    (A-\lambda_q I)v_{1q}&=& 0, (A-\lambda_q I)v_{2q}=v_{1q},\dots,
    (A-\lambda_qI)v_{r_qq}=v_{(r_q-1)q}
  \end{align*}
  Dann wird mit $\varphi_{10}(x)=e^{\mu_1x}v_{10},\dots,\varphi_{p0}(x)=
  e^{\mu_rx}v_{p0}$
  \[\varphi_{ei}(x)=e^{\lambda_ix}\left(v_{ei}+xv_{(e-1)i}+\frac{x^2}{2!}v_{(e-2)i}
  +\cdots+\frac{x^{l_i-1}}{(l_i-1)!}v_{1i}\right)\quad l=1,\dots,r_1,i=1,..,q \]
  ein Fundamentalsystem von Lösungen von $y'=Ay$ gegeben, d.h. die Matrix
  $\Phi(x)=(\varphi_{10}(x), \varphi_{20}(x),\dots,\varphi_{p0}(x), 
  \varphi_{11}(x),\dots, \varphi_{r_11}(x),\dots,\varphi_{1q}(x),\dots,
  \varphi_{r_qq}(x))$ erfüllt die DGL $Y'=AY$ und ist für jedes $x$
  invertierbar. Die allgemeine Lösung von $y'=Ay$ ist $\varphi(x)=\Phi(x)
  c, c\in\K^n$ oder $\varphi(x)=c_{10}\varphi_{10}(x)+\cdots+c_{p0}\varphi_{p0}(x)
  +c_{11}\varphi_{11}(x)+\cdots+c_{r_11}\varphi_{r_11}(x)+\cdots+
  c_{1q}\varphi_{1q}(x)+\cdots+c_{r_qq}\varphi_{r_qq}(x)$\\
  \textbf{Beweis}: 
  \begin{enumerate}[(1)]
    \item Betrachten für $J$ eine Diagonalmatrix $J=D=\begin{pmatrix}
    \mu_1 & & 0\\
     & \ddots & \\
    0 & & \mu_n
      \end{pmatrix}$. Dann gilt: Die Spalten von $S$ sind dann Eigenvektoren 
      von $A$. Denn für $e_1$ hat man $ASe_i=SJe_i=S\mu_ie_i=\mu_iSe_i,
      Av_i=\mu_iv_i, v_i\coloneqq Se_i$.\\
      $\Phi(x)e_i=e^{Ax}Se_i=Se^{Jx}e_i=Se^{\mu_ix}e_i=e^{\mu_ix}Se_i=
      e^{\mu_ix}v_i$\\
      $\Phi(x)=(e^{\mu_1x}v_1,\dots,e^{\mu_nx}v_n)$
      \[\varphi(x)=\Phi(x)(c_1e_1+\cdots+c_ne_n)=c_1\Phi(x)e_1+\cdots+
      c_n\Phi(x)e_n=c_1e^{\mu_1x}v_1+\cdots+c_ne^{\mu_nx}v_n\]
      ist allgemeine Lösung von $y'=Ay$.
    \item Jede Matrix $A\in\MM_n(\K)$ kann nach einem Satz der linearen
      Algebra in eine Jordanmatrix $J=S^{-1}AS$ transformiert werden. Es
      ist $J=\begin{pmatrix}
    J_0 & & & \\
    & J_1 &  & \\
    & & \ddots & \\
    & & & J_q
      \end{pmatrix}$ blockdiagonal mit einem diagonalen Block $J_0=
      \begin{pmatrix}
    \mu_1 & & 0\\
    & \ddots & \\
    0 & & \mu_p
      \end{pmatrix}$ und Jordanblöcken $J_i=
      \begin{pmatrix}
      \lambda_i & 1 & 0 & 0 & \dots & 0\\
      0 & \lambda_i & 1 & 0 & \dots & 0\\
      0 & 0 & \lambda_i & 1 & \dots & 0\\
      \vdots & & & & & \\
      0 & \dots & & & \lambda_1 & 1\\
      0 & \dots & & & 0 & \lambda_i
    \end{pmatrix}$ der Größe $r_i\geq 2$. Die Zahlen $\mu_1,
    \dots,\mu_p, \lambda_1,\dots,\lambda_q$ sind dabei die nicht
    notwendigerweise verschiedenen
    Eigenwerte von $A$. Ferner hat man $p+r_1+\cdots+r_q=n$ und
    $e^{Jx}=\begin{pmatrix}
      e^{J_0x} & & 0\\
      & \ddots & \\
      0 & & e^{J_qx}
    \end{pmatrix}$\\
    Wie ist die Lösung von $e^{J_ix}$? Man setzt $J_i=J=
    \begin{pmatrix}
      \lambda & 1 & 0 & 0 & \dots & 0\\
      0 & \lambda & 1 & 0 & \dots & 0\\
      \vdots & & & & & \\
      0 & \dots & & & & \lambda
    \end{pmatrix}, J=\lambda I+N, N=\begin{pmatrix}
      0 & 1 & 0 & \dots & 0\\
      0 & 0 & 1 & \dots & 0\\
      \dots & & & & 1\\
      0 & \dots & & & 1
    \end{pmatrix}$\\
    $e^{Jx}=e^{\lambda Ix+Nx}=e^{\lambda Ix}+e^{Nx}=e^{\lambda x}e^{Nx}$\\
    $\varphi_l(x)=e^{Ax}Se_l=Se^{Ix}e_l=Se^{\lambda x}(e_l+e_{l-1}+\cdots+
    \frac{x^{l-1}}{(l-1)!}e_1)=e^{\lambda x}(Se_l+xSe_{l-1}+\cdots+
    \frac{x^{l-1}}{(l-1)!}Se_1)$\\
    $v_i=Se_i\colon  \varphi_l(x)=e^{\lambda x}(v_l+xv_{l-1}+\cdots+
    \frac{x^{l-1}}{(l-1)!}v_1)$
    Es gilt 
    \begin{align*}
      Ne_1=0, Ne_2=e_1, Ne_3=e_2, & \dots &, Ne_l=e_{l-1}, 2\leq l\leq r\\
      N^2e_1=0, N2e_2=Ne_1=0, N2e_3=Ne_2=e_1, & \dots & , N^2e_l=Ne_{l-1}=e_{l-2}\\
      N^ke_1=N^ke_2=\dots=N^ke_k=0 & & N^ke_l=e_{l-k}\\
      N^{r-1}e_1=\dots=N^{r-1}e_{r-1}=0 & & N^{r-1}e_r=e_1, N^r=0
    \end{align*}
    $e^{Nx}e_l=\sum_{k=0}^{r-1} \frac{x^kN^ke_l}{k!}=Ie_l+xNe_l+
    \frac{x^2}{2!}N^2e_l+\cdots+\frac{x^{r-1}}{(r-1)!}N^{r-1}e_l=
    e_l+xe_{l-1}+\frac{x^2}{2!}e_{l-2}+\cdots+\frac{x^{l-1}}{(l-1)!}e_1$
    Dabei ist $\lambda$ der Eigenwert von $A$ und die Eigenvektoren und
    Wurzelvektoren erfüllen die Gleichungen $(A-\lambda I)v_1=0, (A-
    \lambda I)v_2=v_1,\dots,(A-\lambda I)v_l=v_{l-1},\dots,
    (A-\lambda I)v_r=v_{r-1}$. Denn $AS=SJ$ impliziert: $ASe_1=SJe_1=
    S\lambda e_1=\lambda Se_1\Leftrightarrow (A-\lambda I)v_1=0$ und
    $ASe_l=SJe_l=S(\lambda e_l+e_{l-1})=\lambda Se_l+Se_{l-1}\Leftrightarrow
    (A-\lambda I)v_l=v_{l-1}, 2\leq l \leq r$
  \end{enumerate}
  \qed
\end{theorem}

Bemerkung: Sei $A\in\MM_n(\K)$ und sei $S\in\MM_n(\K)$ invertierbar.
Dann gilt für $J\coloneqq S^{-1}AS$ die Formel $e^{Ax}S=Se^{Jx}$. Denn $J^2=
(S^{-1}AS)^2=S^{-1}ASS^{-1}AS=S^{-1}A^2S$ und somit ist $e^{Jx}=
\sum_{k=0}^\infty \frac{J^kx^k}{k!}=\sum_{k=0}^\infty \frac{S^{-1}ASx^k}{k!}
=S^{-1}(\sum_{k=0}^\infty \frac{A^kx^k}{k!})S=S^{-1}e^{Ax}S\Leftrightarrow
e^{Ax}S=Se^{Jx}$.

Beispiel: 
\begin{align*}
  y_1'&=& 3y_1\\
  y_2'&=& y_2-y_3\\
  y_3'&=& y_2+3y_3\\
  y&=& \begin{pmatrix}y_1\\y_2\\y_3\end{pmatrix}, y'=Ay\\
  A&=& \begin{pmatrix}
    3 & 0 & 0\\
    0 & 1 & -1\\
    0 & 1 & 3
  \end{pmatrix}\\
  y&=& \varphi(x)=\begin{pmatrix}\varphi_1(x)\\ \varphi_2(x)\\ \varphi_3(x)
  \end{pmatrix}
\end{align*}

\begin{enumerate}[1. Schr{i}tt]
  \item Bestimmung der Eigenwerte von $A$\\
    $\det(\lambda I-A)=\det\begin{pmatrix}
      \lambda-3 & 0 & 0\\
      0 & \lambda-1 & 1\\
      0 & -1 & \lambda-3
    \end{pmatrix}=(\lambda-3)\det\begin{pmatrix}
      \lambda-1 & 1\\
      -1 & \lambda-3
    \end{pmatrix}=(\lambda-3)( (\lambda-1)(\lambda-3)+1)=(\lambda-3)(\lambda^2
    -4\lambda+4)=(\lambda-3)(\lambda-2)^2$\\
    $\lambda_1$ ist drei und $\lambda_2$ ist ein zweifacher Eigenwert.
  \item Bestimmung von Eigenvektoren und Wurzelvektoren\\
    Zu $\lambda=3$ existiert nur ein Eigenvektor:
    \begin{align*}
      \psi_1(x)&=& e^{\lambda_1 x}w_1=e^{3x}w_1, (A-\lambda_1 I)w_1=(A-3I)w_1=0\\
      \psi_2(x)&=& e^{\lambda_2x}w_2=e^{2x}w_2, (A-\lambda_2I)w_2=(A-2I)w_2=0\\
      \psi_3(x)&=& e^{\lambda_2x}(w_3+xw_2)=e^{2x}(w_3+xw_2)\\
      & & \qquad(A-\lambda_2I)w_3=(A-2I)w_3=w_2\\
      (A-3I)w_1&=& \begin{pmatrix}
    0 & 0 & 0\\
    0 & -2 & -1\\
    0 & 1 & 0
      \end{pmatrix}\begin{pmatrix}
    w_{11}\\w_{21}\\w_{31}
      \end{pmatrix}=\begin{pmatrix}
    0\\0\\0
      \end{pmatrix}
    \end{align*}
    Daher folgt: $w_{11}$ ist beliebig, $-2w_{21}-w_{31}=0$ und 
    $w_{21}=0$. Setzen $w_{11}=1$ und errechnen $w_{21}=w_{31}=0$. Damit
    ist $w_1=\begin{pmatrix}1\\0\\0\end{pmatrix}$ ein Eigenvektor zum
    Eigenwert $\lambda_1=3$.
    \[\boxed{\psi_1(x)=e^{3x}w_1=e^{3x}\begin{pmatrix}1\\0\\0
    \end{pmatrix}=\begin{pmatrix}e^{3x}\\0\\0
    \end{pmatrix}}\]
    ist Lösung von $y'=Ay$.
    \[(A-2I)w_2=\begin{pmatrix}
      1 & 0 & 0\\
      0 & -1 & -1\\
      0 & 1 & 1
    \end{pmatrix}\begin{pmatrix}
      w_{12}\\w_{22}\\w_{32}
    \end{pmatrix}=\begin{pmatrix}0\\0\\0\end{pmatrix}\]
    Aus der Gleichung $w_{12}=0, -w_{22}-w_{32}=0=w_{22}+w_{32}$ folgt,
    dass $w_2=\begin{pmatrix}0\\1\\-1\end{pmatrix}$ ein Eigenvektor ist.
    \[\boxed{\psi_2(x)=e^{2x}w_2=e^{2x}\begin{pmatrix}0\\1\\-1
    \end{pmatrix}=\begin{pmatrix}0\\e^{2x}\\-e^{2x}
    \end{pmatrix}}\]
    \[(A-2I)w_3=w_2=\begin{pmatrix}
      1 & 0 & 0\\
      0 & -1 & -1\\
      0 & 1 & 1
    \end{pmatrix}\begin{pmatrix}
      w_{13}\\w_{23}\\w_{33}
    \end{pmatrix}=w_2=\begin{pmatrix}
      0\\1\\-1
    \end{pmatrix}\]
    $w_{13}=0, -w_{23}-w_{33}=1, w_{23}+w_{33}=-1\Rightarrow w_{13}=0,
    w_{23}=-1, w_{33}=0$\\
    Somit ist $w_3=\begin{pmatrix}
      0\\-1\\0
    \end{pmatrix}$ ein Eigenvektor.
    \[\boxed{\begin{aligned}
      \psi_3(x)=e^{2x}(w_3+xw_2)&=e^{2x}\left(\begin{pmatrix}0\\-1\\0
      \end{pmatrix}+x\begin{pmatrix}0\\1\\-1
      \end{pmatrix}\right)\\
      =e^{2x}\begin{pmatrix}0\\x-1\\-x
      \end{pmatrix}&=\begin{pmatrix}0\\(x-1)e^{2x}\\-xe^{2x}
      \end{pmatrix}
    \end{aligned}}\]
    Fundamentalmatrix: 
    \[\Phi(x)=(\psi_1(x),\psi_2(x),\psi_3(x)=\begin{pmatrix}
      e^{3x} & 0 & 0\\
      0 & e^{2x} & (x-1)e^{2x}\\
      0 & -e^{2x} & -xe^{2x}
    \end{pmatrix}\]
    Probe:  Zeigen $Y=\Phi(x)$ erfüllt Matrixdifferentialgleichung 
    $Y'=AY$:\\
    $\Phi'(x)=\begin{pmatrix}
      3e^{3x} & 0 & 0\\
      0 & 2e^{2x} & (2x-1)e^{2x}\\
      0 & -2e^{2x} & -(2x+1)e^{2x}
    \end{pmatrix}$,\\ $A\Phi(x)=\begin{pmatrix}
      3 & 0 & 0\\
      0 & 1 & -1\\
      0 & 1 & 3
    \end{pmatrix}\begin{pmatrix}
      3 & 0 & 0\\
      0 & 1 & -1\\
      0 & 1 & 3
    \end{pmatrix}=\begin{pmatrix}
      3e^{3x} & 0 & 0\\
      0 & 2e^{2x} & (2x-1)e^{2x}\\
      0 & -2e^{2x} & -(2x+1)e^{2x}
    \end{pmatrix}\Rightarrow \Phi'(x)=A\Phi(x)$\\
    Allgemeine Lösung von $y'=Ay$: $\varphi(x)=\Phi(x)c, c\in\R^3$\\
    $\varphi(x)=\Phi(x)\begin{pmatrix}c_1\\c_2\\c_3
    \end{pmatrix}=c_1\varphi(x)e_1+c_2\varphi(x)e_2+c_3\varphi(x)e_3=
     c_1\psi(x)e_1+c_2\psi(x)e_2+c_3\psi(x)e_3$\\
     In Komponenten: 
     \begin{align*}
       \varphi(x)&=& \begin{pmatrix}
       \varphi_1(x)\\ \varphi_2(x)\\ \varphi_3(x)
     \end{pmatrix}\\
     &=& c_1\begin{pmatrix}e^{3x}\\0\\0
     \end{pmatrix}+c_2\begin{pmatrix}0\\e^{2x}\\-e^{2x}
     \end{pmatrix}+c_3\begin{pmatrix}0\\(x-1)e^{2x}\\-xe^{2x}
     \end{pmatrix}\\
     &=& \begin{pmatrix}c_1e^{3x}\\c_2e^{2x}+c_3(x-1)e^{2x}\\
       -c_2e^{2x}-c_3xe^{2x}
     \end{pmatrix}
     \end{align*}
     $y_1=\varphi_1(x)=c_1e^{3x}, y_2=\varphi_2(x)=c_2e^{2x}c_3(x-1)e^{2x},
     y_3=\varphi_3(x)=-c_2e^{2x}-c_3xe^{2x}$
\end{enumerate}

%%zweites Beispiel einfuegen

\section{Der Existenz- und Eindeutigkeitssatz von Picard-Lindelöf}
Man betrachtet das DGL $y'=f(x,y), y=\begin{pmatrix}y_1\\\vdots\\y_n
\end{pmatrix}, f=\begin{pmatrix}f_1\\\vdots\\f_n
\end{pmatrix}$. In Komponenten:
\begin{align*}
  y_1'&=& f_1(x,y_1,\dots,y_n)\\
  \vdots\\
  y_n'&=& f_n(x,y_1,\dots,y_n
\end{align*}

\subsection{Lipschitzbedingung}
\begin{definition}
  Sei $G\subset\R\times\R^n, f\colon G\rightarrow\R^n$ stetig.
  \begin{enumerate}[(a)]
    \item $f$ genüge in $G$ einer \emph{Lipschitzbedingung\index{Lipschitzbedingung}}
      \[\exists L\geq 0\,\forall(x,y),(x,\tilde{y})\in G\colon  ||f(x,y)-f(x,\tilde{y})||\leq L||y-\tilde{y}||\]
      (Genauer: $f=f(x,y)$ genüge in $G$ bzgl. $y$ einer Lipschitzbedingung)
    \item $f$ genüge in $G$ \emph{lokal} einer Lipschitzbedingung
      \[\forall (a,b)\in G\,\exists \text{Umgebung } U \text{ von } (a,b)
      \text{und } f \text{ genügt in } G\cap U \text{ einer Lipschitzbedingung}\]
  \end{enumerate}
\end{definition}

\paragraph{Hinreichendes Kriterium für Lipschitzbedingung}
Sei $G\subset\R\times\R^n$ offen und $f\colon G\rightarrow\R^n, f=f(x,y),
y=\begin{pmatrix}y_1\\\vdots\\y_n\end{pmatrix}$ \emph{stetig} partiell
differenzierbar. Dann genügt $f$ in $G$ lokal einer Lipschitzbedingung.\\
Beweis: $(a,b)\in G\colon \exists r>0$, so dass $U\coloneqq \{(x,y)\in\R\times\R^n\colon 
|x-a\leq r, ||y-b||\leq r\}\subset G$. $U$ ist in $\R\times\R^n$
abgeschlossen und beschränkt und somit also kompakt. Somit ist wegen
Stetigkeit von $\frac{\partial f}{\partial y}=\begin{pmatrix}
  \frac{\partial f_1}{\partial y_1} & \dots & \frac{\partial f_1}{\partial y_n}\\
  \vdots & & \vdots\\
  \frac{\partial f_n}{\partial y_1} & \dots & \frac{\partial f_n}{\partial y_n}
\end{pmatrix}$ auf $U$: $L\coloneqq \sup\{\left|\left|\frac{\partial f}{\partial y}
(x,y)\right|\right|\colon (x,y)\in U\}<\infty$.\\
Nach dem Mittelwertsatz %Satz II.3.2
gilt:
\[f(x,y)-f(x,\tilde{y})=\left(\int_0^1 \frac{\partial f}{\partial y}
(x,y+t(\tilde{y}-y))dt\right)(\tilde{y}-y)\]
Daher folgt: 
\begin{align*}
 ||f(x,y)-f(x,\tilde{y})||_2&=& ||\int_0^1\frac{\partial f}{\partial y}
(x,y+t(\tilde{y}-y))dt)(\tilde{y}-y)\\
& \leq& \int_0^1||\frac{\partial f}{\partial y}
(x,y+t(\tilde{y}-y)))(\tilde{y}-y)||_2dt\\
&\leq & \int_0^1 \left|\left|\frac{\partial f}{\partial y} (x,y+t(\tilde{y}-y))
\right|\right|||\tilde{y}-y||_2dt\\
&\leq & \int_0^1\underbrace{\left|\left|\frac{\partial f}{\partial y}
(x,y+t(\tilde{y}-y))\right|\right|}_{\leq L\,\forall (x,z)\in U}dt
||\tilde{y}-y||_2\\
&\leq & L\int_0^1 1dt||\tilde{y}-y||_2=L||\tilde{y}-y||_2
\end{align*}
Da auf endlichdimensionalen Räumen die Normen äquivalent sind, erhalten
wir unter der Ausgangsnorm $||\cdot||$: $||f(x,y)-f(x,\tilde{y}||\leq
\tilde{L}||\tilde{y}-y||$.
\qed

\subsection{Satz von Picard-Lindelöf}
\begin{theorem}
  Sei $G\subset\R\times\R^n$ offen und $f\colon G\rightarrow\R^n$ stetig, die
  lokal einer Lipschitzbedingung genügt. Dann gilt, dass für alle $(a,c)
  \in G$ ein $\varepsilon>0$ existiert und genau eine Lösung $\varphi\colon 
  [a-\varepsilon,a+\varepsilon]\rightarrow\R^n$ vom 
  Anfangswertproblem $y'=f(x,y)$ mit $\varphi(a)=c$.\\
  \textbf{Beweis}:  
  \begin{enumerate}[1. Schr{i}tt]
    \item Raum der stetigen Funktionen\\
      Sei $I$ ein abgeschlossenes und beschränktes Intervall (=kompakt).
      $\mathcal{C}(I,\R^n)\coloneqq \{\varphi\colon I\rightarrow\R^n\colon \varphi\text{ stetig}\},
      ||\varphi||\coloneqq \sup_{x\in I}||\varphi(x)||_2$. Der Raum $[\CC(I,\R^n),
      ||\cdot||]$ ist ein vollständiger normierter Raum. Sei $I_\varepsilon
      \coloneqq [a-\varepsilon,a+\varepsilon], \varepsilon>0$. Wählen $\varepsilon,r>0$
      so, dass $U=\{(x,y)\in I_\varepsilon\times\R^n\colon  ||y-c||_2\leq r\}
      \subset G$ und $f$ auf $U$ einer Lipschitzbedingung genügt, d.h.
      $\exists L\geq 0\,\forall (x,y),(x,\tilde{y})\in U\colon ||f(x,y)-f(x,
      \tilde{y})||_2\leq ||y-\tilde{y}||_2$. $U$ ist kompakt und $f$
      stetig auf $U$. Man setzt $B_r^\varepsilon(c)\coloneqq \{\varphi\in\CC(
      I_\varepsilon,\R^n)\colon ||\varphi-c||\leq r\}$ (ist i.a. nicht kompakt).
      $B_r^\varepsilon$ ist als abgeschlossene Kugel $\CC(I_\varepsilon,
      \R^n)$ ein vollständiger metrischer Raum mit der Metrik $(d(
      \varphi,\psi)=||\varphi-\psi||)$.
    \item Kontrahierende Abbildung\\
      Wir definieren die Abbildung 
      \[T\colon B_r^\varepsilon(c)\rightarrow\CC(I_\varepsilon,\R^n)\]
      durch den Ansatz $(T\varphi)(x)\coloneqq c+\int_a^x
      f(t,\varphi(t))dt$.
      \begin{enumerate}
    \item Es gilt die Abschätzung
      \begin{align*}
    ||(T\varphi)(x)-c||_2&=& \left|\left|\int_a^x f(t,\varphi(t))dt\right|\right|_2\\
    &\leq & \left|\int_a^x ||f(t,\varphi(t))||_2dt\right|\\
    & \leq & |x-a|M\leq \varepsilon M\quad \forall x\in I_\varepsilon
      \end{align*}
      Hieraus folgt: 
      \[\boxed{\forall \varphi\in B_r^\varepsilon(c)\colon ||T\varphi-
      c||=\sup_{x\in I_\varepsilon}||(T\varphi)(x)-c||_2\leq \varepsilon M}\]
      \item
    \begin{align*}
      ||(T\varphi)(x)-(T\tilde{\varphi})(x)||_2&=& \left|\left|\int_a^x
      (f(t,\varphi(t))-f(t,\tilde{\varphi}(t)))dt\right|\right|_2\\
      &\leq & \left|\int_a^x \underbrace{||f(t,\varphi(t))-f(t,\tilde{\varphi}(t)))||_2}_{L||\varphi-\tilde{\varphi}||}
      dt\right|\\
      &\leq & L|x-a|||\varphi-\tilde{\varphi}||\\
      &\leq & \varepsilon L ||\varphi-\tilde{\varphi}||\quad x\in I_\varepsilon
    \end{align*}
    \[\Rightarrow\boxed{\forall \varphi,\tilde{\varphi}\in
    B_r^\varepsilon(c)\colon ||T\varphi-T\tilde{\varphi}||\leq\varepsilon L
    ||\varphi-\tilde{\varphi}||}\]
    \end{enumerate}
    Man wählt $\varepsilon>0$ so, dass $\varepsilon\leq \min\{
    \frac{r}{M},\frac{1}{2L}\}$. Dann gilt:
    \begin{enumerate}
      \item $T(B_r^\varepsilon(c))\subset B_r^\varepsilon(c)$
      \item $\forall \varphi,\tilde{\varphi}\in B_r^\varepsilon(c)\colon 
    ||T\varphi-T\tilde{\varphi}||\leq \frac{1}{2}||\varphi-\tilde{\varphi}||$
    \end{enumerate}
  \item Anwendung des Banachschen Fixpunktsatzes\\
    Man setzt $X\coloneqq B_r^\varepsilon(c)$ (vollständiger metrischer Raum)
    und $T\colon X\rightarrow X$ ist kontrahierend. Nach dem Banachschen
    Fixpunktsatzes existiert genau ein $\varphi\in X=B_r^\varepsilon(c)\colon 
    T\varphi=\varphi$.
  \end{enumerate}
  Der Hauptsatz der Differential- und Integralrechnung impliziert
  $\varphi'(x)=f(x,\varphi(x))$ und $\varphi(a)=c$.
  \qed
\end{theorem}

Beispiele für Anfangswertprobleme:
\begin{enumerate}[(a)]
  \item $y'=\sqrt[3]{y^2}, y=\varphi(a)=c, f=f(x,y)=\sqrt[3]{y^2}, f\colon 
    \R\times\R\rightarrow\R$
    \begin{enumerate}[1. F{a}ll]
      \item $a\in\R,c\neq 0\colon \varphi(a)=c$\\
    $\frac{\partial f}{\partial y}(x,y)=\frac{2}{3}y^{\frac{2}{3}-1}
    =\frac{2}{3}y^{-\frac{1}{3}}\Rightarrow f$ erfüllt lokal eine
    Lipschitzbedingung in $\R\times(\R\backslash\{0\})$. Nach dem
    Satz von Picard-Lindelöf folgt, dass das Anfangswertproblem
    eindeutig lösbar ist. Berechnung der Lösung:
    \[\varphi'(x)=\sqrt[3]{(\varphi(x))^2}=\frac{\varphi'(x)}{\sqrt[3]{(\varphi(x))^2}}=1\]
    Integration: 
    \[\int_a^x \frac{\varphi'(t)}{\sqrt[3]{\varphi(t)^2}}dt=\int_a^x
    dt=x-a\]
    \[\begin{split}
      \int_a^x \frac{\varphi'(x)dt}{\sqrt[3]{\varphi(t)^2}}
    \begin{bmatrix}
      u=\varphi(t)\\
      du=\varphi'(t)dt
    \end{bmatrix}=\int_{c=\varphi(a)}^{\varphi(x)}\frac{du}{\sqrt[3]{u^2}}
    =\int_u^{\varphi(x)} u^{-\frac{2}{3}}du\\
    \qquad=3u^{\frac{1}{3}}|_c^{\varphi(x)}
    =3\left( (\varphi(x))^{\frac{1}{3}}-c^{\frac{1}{3}}\right)=x-a
        \end{split}\]
    \[\boxed{\varphi(x)=\frac{1}{27}(x+3\sqrt[3]{c}-a)^3}\]
    Bemerkung: Die Lösung ist sogar auf $I=\R$ definiert.
      \item $y=\varphi(a)=0, c=0$\\
    $\varphi_0(x)=0$ ist eine Lösung des Anfangswertproblems.\\
    $\varphi_a(x)=\frac{1}{27}(x-a)^3$ ist ebenfalls eine Lösung des
    Anfangswertproblems. Ferner ist auch für $a_0<a<a_1, \varphi(x)=
    \begin{cases}
      \varphi_{a_0}(x)=\frac{1}{27}(x-a_0)^3 & x\leq a_0\\
      0 & a_0<x<a_1\\
      \varphi_{a_1}(x)=\frac{1}{27}(x-a_1)^3 & x\geq a_1
    \end{cases}$ eine Lösung des Anfangswertproblems. Damit ist das
    Anfangswertproblem für kein $a\in \R$ mit $\varphi(a)=0$ 
    eindeutig lösbar.
    \end{enumerate}
\end{enumerate}

\subsection{Das Picard-Lindelöfsche Iterationsverfahren anhand eines Beispiels}
$y'=f(x,y), y=\varphi(x), y=\varphi(a)=c, \varphi'(x)=f(x,\varphi(x))=
\int_a^x \varphi'(t)dt=\int_a^x f(t,\varphi(t))dt$

Iterationsprozedur: $\varphi_{n+1}=(T\varphi_n)(x)=c+\int_a^x
f(t,\varphi_n(t))dt$\\
Der Startwert ist $\varphi_0=c$.\\
Beispiel: $y'=y, y=\varphi(0)=c$ Die Lösung ist $\varphi(x)=ce^x$. Mit
Hilfe des Iterationsverfahrens wird ebenfalls die Lösung ermittelt:
$f(x,y)=y, |f(x,y)-f(x,\tilde{y})|=|y-\tilde{y}|$\\
$f$ genügt einer Lipschitzbedingung mit $L=1$. Damit führt das
Iterationsverfahren zu genau einer Lösung mit $\varphi(0)=c$.
\begin{align*}
  \varphi_{n+1}&=& c+\int_a^x f(t,\varphi_n(t))dt\\
  \varphi_1(x)&=& c+\int_0^x f(t,\varphi_0(t))dt=c+\int_0^x 
  \varphi_0(t)dt=c+\int_0^x cdt=c+cx\\
  \varphi_2(x)&=& c+\int_0^x \varphi_1(t)dt=c+\int_0^x c(1+t)dt=
  c(1+x+\frac{x^2}{2})\\
  \vdots\\
  \varphi_k&=& c(1+x+\frac{x^2}{2!}+\cdots+\frac{x^k}{k!})
\end{align*}
Induktion: $k\rightarrow k+1$: \\
$\varphi_{k+1}(x)=c+\int_0^x \varphi_k(t)dt=c+c\int_0^x (1+t+\frac{t^2}{2!}
+\cdots+\frac{t^k}{k!})dt=c+c(t+\frac{t^2}{2!}+\cdots+\frac{t^{k+1}}{(k+1)!})|_0^x=
c+c(x+\frac{x^2}{2}+\cdots+\frac{x^{k+1}}{(k+1)!})=c(1+x+\frac{x^2}{2}
+\cdots+\frac{x^{k+1}}{(k+1)!})$\\
$\varphi(x)=\lim_{n\rightarrow\infty} \varphi_n(x)=c\lim\sum_{k=0}^n
\frac{x^k}{k!}=c\sum_{k=0}^\infty \frac{x^k}{k!}=ce^x$

\section{Lösungstheorie linearer Differentialgleichungsysteme 1.~Ordnung}
$y'=A(x)y+b(x), A(x)=(a_{ij}(x))_{i,j=1}^n, b(x)=\begin{pmatrix}
  b_1(x)\\\vdots\\b_n(x)
\end{pmatrix}$

\subsection{Existenz- und Eindeutigkeitssatz}
\begin{theorem}
  %Satz III.5.1.1
  Sei $I\subset\R$ ein offenes Intervall und $A\colon I\rightarrow\MM_n(\K), b\colon 
  I\rightarrow\K^n$ stetige Abbildungen. Dann gilt: 
  \[\forall x_n\in I\,\forall c\in\K^n\,\exists^1 \text{Lösung }
  \varphi\colon I\rightarrow\K^n\colon  y'=A(x)y+b(x), \varphi(x_0)=c\]
  \textbf{Beweis}: Setzen $f(x,y)=A(x)y+b(x)$. Man zeigt, dass für jedes
  kompakte Intervall $J\subset I$ ein $L\geq 0$ existiert mit $\forall x\in J\,
  \forall y,\tilde{y}\in\K^n\colon  ||f(x,y)-f(x,\tilde{y})||\leq
  L||y-\tilde{y}||$\\
  $A(x)=(a_{ij}(x))$ ist stetig. Daher ist auch $a_{ij}(x)$ stetig. Aus
  der Tatsache, dass $J$ kompakt ist, folgt $M_J\coloneqq \max_{i,j=1,\dots,n}
  \sup_{x\in J} |a_{ij}(x)|<\infty$. Für $y=\begin{pmatrix}y_1\\\vdots\\y_n
  \end{pmatrix}, \tilde{y}=\begin{pmatrix}\tilde{y_1}\\\vdots\\\tilde{y_n}
  \end{pmatrix}$ gilt:
  \begin{align*}
   ||f(x,y)-f(x,\tilde{y})||_1&=& ||A(x)y-A(x)\tilde{y}||_1
  =\sum_{i=1}^n|\sum_{j=1}^n a_{ij}(x)(y_j-\tilde{y_j})|\\
  & \leq& \sum_{i=1}^n\sum_{j=1}^n |a_{ij}(x)||y_j-\tilde{y_j}|\leq nM_J
  \sum_{i=1}^n |y_j-\tilde{y_j}|\\
  &=& nM_j||y-\tilde{y}||_1
  \end{align*}
    Da die $||\cdot||_1$ äquivalent zur Ausgangsnorm $||\cdot||$ ist, 
  erhält man mit einer weiteren Konstanten $\alpha\geq 0$ die 
  Abschätzung $||f(x,y)-f(x,\tilde{y})||\leq\alpha nM_J||y-\tilde{y}||$.
  Nach Existenz und Eindeutigkeitssatz von Picard-Lindelöf existiert ein
  offenes Intervall $\tilde{J}\subset J$ und $x_0\in \tilde{J}$ und das
  AWP $y'=A(x)y+b(x), y=\varphi(x_0)=c$ ist eindeutig lösbar. Ferner
  kann man zeigen, dass die Lösung des AWP eindeutig auf $J$ und weiter
  auf das gesamte Intervall $I$ fortgesetzt werden  kann (siehe Forster
  Analysis II).
  \qed
\end{theorem}

\subsection{Lösungstheorie}
Dazu wird $\LL_h$ für homogene Lösungen eingeführt: $\LL_h\coloneqq \{\varphi\colon I
\rightarrow\K^n\colon  \varphi \text{Lösung von } y'=A(x)y\}$\\
$\LL_{inh}\coloneqq \{\varphi\colon I\rightarrow\K^n\colon  \varphi \text{Lösung von } y'=A(x)
y+b(x)\}$

\begin{theorem}
  \label{satz:LTheorie}
  Es gelten folgende Aussagen:
  \begin{enumerate}[(i)]
    \item $\varphi_1,\varphi_2\in\LL_h\Rightarrow c_1\varphi_1+c_2\varphi_2
      \LL_h, c_1,c_2\in \K$\\
      Beweis: $\varphi_1,\varphi_2\in\LL_h$, d.h. $\varphi_i(x)=A(x)
      \varphi_i(x), i=1,2 \Rightarrow (c_1\varphi_1(x)+c_2\varphi_2(x))'
      =c_1\varphi_1'(x)+c_2\varphi_2'(x)=c_1A(x)\varphi_1(x)+c_2A(x)
      \varphi_2(x)=A(x)(c_1\varphi_1(x)+c_2\varphi_2(x))$
    \item $\varphi\in\LL_h, \psi\in\LL_{inh}\Rightarrow \varphi+\psi\in\LL_{inh}$\\
      Beweis: $\varphi\in\LL_h, \psi\in\LL_{inh}\Rightarrow\varphi'(x)=
      A(x)\varphi(x),\psi'(x)=A(x)\psi(x)+b(x)\Rightarrow(\varphi(x)+
      \psi(x))'=\varphi'(x)+\psi'(x)=A(x)\varphi(x)+A(x)\psi(x)+b(x)=
      A(x)(\varphi(x)+\psi(x)+b(x))\Rightarrow\varphi+\psi\in\LL_{inh}$
    \item $\psi_1,\psi_2\in\LL_{inh}\Rightarrow\psi_1-\psi_2\in\LL_h$\\
      Beweis: $\psi_1,\psi_2\in\LL_{inh}, \psi_i'(x)=A(x)\psi_i(x)+b(x),
      i=1,2\Rightarrow(\psi_1(x)-\psi_2(x))'=\psi_1'(x)-\psi_2'(x)=A(x)
      \psi_1(x)+b(x)-(A(x)\psi_2(x)+b(x))=A(x)(\psi_1(x)-\psi_2(x))
      \Rightarrow\psi_1-\psi_2\in\LL_h$
      \qed
  \end{enumerate}
\end{theorem}
  
\subsection{Lineare Abhängigkeit und Unabhängigkeit}
\begin{definition}
  \begin{enumerate}[(i)]
    \item $k$ stetige Funktionen $\varphi_1,\dots,\varphi_k\in\CC(I,\K^n)$
      heissen \emph{linear unabhängig}, g.\,d.\,w.:
      \[\forall \alpha_1,\dots,\alpha_k\in\K (\sum_{i=1}^k \alpha_i\varphi_i
      =0\Rightarrow \alpha_1=\cdots=\alpha_k=0\]
    \item $k$ stetige Funktionen $\varphi_1,\dots,\varphi_k\in\CC(I,\K^n)$
      heissen \emph{linear abhängig}, g.\,d.\,w.:
      \[\exists\alpha_1,\dots,\alpha_k\in\K\colon \sum_{i=1}^k \alpha_i\varphi_i
      =0\wedge\sum_{i=1}^k|\alpha_i|>0\]
  \end{enumerate}
\end{definition}

Bemerkung: $\sum_{i=1}^k \alpha_i\varphi_i=0\colon \forall x \in I\colon  \sum_{i=1}^k
\alpha_i\varphi_i(x)=0$

\begin{theorem}
  \label{satz:linAbh}
  \begin{enumerate}[(a)]
    \item Für $k$ Lösungen $\varphi_1,\dots,\varphi_k\in\LL_h$ sind
      folgende Aussagen äquivalent:
      \begin{enumerate}[(i)]
    \item $\varphi_1,\dots,\varphi_k$ sind linear unabhängig über
      $\K$.
    \item $\exists x_0\in I\colon \varphi_1(x_0),\dots,\varphi_k(x_0)\in
      \K^n$ sind linear unabhängige Vektoren über $\K$.
    \item $\forall x\in I\colon  \varphi_1(x),\dots,\varphi_k(x)\in\K^n$
      sind linear unabhängige Vektoren über $\K$.
      \end{enumerate}
      \textbf{Beweis}: Der Beweis von (iii) nach (ii) nach (i) ist 
      trivial. Zu zeigen ist daher noch die Richtung von (i) nach (iii).
      Hier erfolgt der Beweis indirekt. Seien $\varphi_1,\dots,\varphi_k
      \in\LL_h$. Annahme: $\exists x_0\in I\colon  \varphi_1(x_0),\dots,
      \varphi_k(x_0)$ sind linear abhängig, d.h. $\exists\alpha_1,\dots,
      \alpha_k\in\K\colon \sum_{i=1}^k |\alpha_i|>0\wedge \sum_{i=1}^k \alpha_i
      \varphi_i(x_0)=0$. Es gilt $\varphi=\sum_{i=1}^k \alpha_i
      \varphi_i\in\LL_h$ mit $\varphi(x_0)=\sum_{i=1}^k \alpha_i\varphi_i
      (x_0)=0$. Wegen des Existenz- und Eindeutigkeitssatz von
      Picard-Lindelöf des AWP $y'=A(x)y, y=\varphi(x_0)=0$ folgt
      $\varphi=0$ ist die einzige Lösung des AWP, d.h. $\forall x\in I\colon 
      \varphi(x)=\sum_{i=1}^k \alpha_i\varphi_i(x)=0\Rightarrow
       \varphi_1,\dots,\varphi_k$ sind linear abhängig. \lightning zu (i)
    \item $\dim \LL_h=n$\\
      \textbf{Beweis}: Man zeigt zuerst, dass die Dimension größer oder
      gleich $n$ ist: Für die Einheitsvektoren $e_1,\dots,e_n\in\K^n$
      existieren Lösungen $\varphi_1,\dots,\varphi_n\in\LL_h$ mit 
      $\varphi_i(x_0)=e_i$. Da $e_1,\dots,e_n$ linear unabhängige
      Vektoren in $\K$ sind, sind auch die Lösungen $\varphi_1,\dots,
      \varphi_n$ linear unabhängig nach dem Punkt (a)(ii) dieses
      Satzes. Somit gilt $\dim\LL_h\geq n$.\\
      Zu zeigen ist nun, dass die Dimension kleiner gleich $n$ ist:
      Annahme: $\psi_1,\dots,\psi_{n+1}\in\LL_h$ seien linear
      unabhängige Lösungen. Dann sind die $n+1$ Vektoren aus dem
      Körper $\K$ $\psi_1(x_0),
      \dots, \psi_{n+1}(x_0)$ linear unabhängig. \lightning zu
       $\dim\K^n=n$
  \end{enumerate}
  \qed
\end{theorem}

Bemerkung: Sind $\varphi_1,\dots,\varphi_k$ keine Lösungen des
homogenen DGL $y'=A(x)y$, d.h. $\varphi_1,\dots,\varphi_k\notin\LL_k$,
so ist Satz \ref{satz:linAbh} i.a. falsch. 
Beispiel:
\[\varphi_1=\varphi_1(x)=\begin{pmatrix}x\\0
\end{pmatrix}\quad \varphi_2=\varphi_2(x)=\begin{pmatrix}x^2\\0
\end{pmatrix}\quad \varphi_1,\varphi_2\in \CC\left( 0,2),\R^2 \right)\]
sind linear unabhängig. Denn $\alpha_1\varphi_1(x)+\alpha_2\varphi_2
(x)=0$ und $\alpha_1\varphi_1+\alpha_2\varphi_2=0$ und es folgt:
\begin{align*}
  0&=& \alpha_1\varphi_1(\frac{1}{2})+\alpha_2\varphi_2(\frac{1}{2})=
  \alpha_1\begin{pmatrix}\frac{1}{2}\\0
  \end{pmatrix}+\alpha_2\begin{pmatrix}\frac{1}{4}\\0
  \end{pmatrix}=\begin{pmatrix}\frac{\alpha_1}{2}+\frac{\alpha_2}{4}\\0
  \end{pmatrix}\\
  0&=& \alpha_1\varphi_1(1)+\alpha_2\varphi_2(1)=\alpha\begin{pmatrix}1\\0
  \end{pmatrix}+\alpha_2\begin{pmatrix}1\\0
  \end{pmatrix}=\begin{pmatrix}\alpha_1+\alpha_2\\0
  \end{pmatrix}\\
  & \Rightarrow & \frac{\alpha_1}{2}+\frac{\alpha_2}{4}=0\wedge\alpha_1
  +\alpha_2=0\\
  & \Rightarrow & \alpha_1=\alpha_2=0\\
  & \Rightarrow & \varphi_1,\varphi_2\in\CC( (0,2),\R^2)
\end{align*}
sind linear unabhängig. Aber $\varphi_1(1)=\varphi_2(1)=\begin{pmatrix}
  1\\0
\end{pmatrix}$, d.h. (a)(iii) ist nicht erfüllt.

\begin{definition}
  Ein Lösungsfundamentalsystem der Differentialgleichung 
  \[y'=A(x)y \quad  A(x)\in\MM_n(\K)\]
  sind $n$ linear unabhängige Lösungen $\varphi_1,\dots,
  \varphi_n\in\LL_h$. Schreibt man $\varphi_i(x)=\begin{pmatrix}
    \varphi_{1i}(x)\\\vdots\\ \varphi_{ni}(x)
  \end{pmatrix}$, so heißt $\Phi=(\varphi_1,\dots,\varphi_n)=
  \begin{pmatrix}
    \varphi_{11} & \varphi_{12} & \dots & \varphi_{1n}\\
    \vdots & \vdots & & \vdots\\
    \varphi_{n1} & \varphi_{n2} & \dots & \varphi_{nn}
  \end{pmatrix}$ \emph{Fundamentalmatrix\index{Fundamentalmatrix}} von
  $y'=A(x)y$.
\end{definition}

Bemerkungen:
\begin{enumerate}[(a)]
  \item Nach Satz \ref{satz:linAbh} gilt: $\varphi_1,\dots,\varphi_n$
    linear unabhängig, g.d.w. $\exists x_0\in I\colon \det\Phi(x_0)\neq
    0\Leftrightarrow\forall x \in I\colon \det \Phi(x)\neq 0$
  \item Ist $\Phi=(\varphi_1,\dots,\varphi_n)$ ein Lösungsfundamentalsystem
    von $y'=A(x)y$, so lässt sich die allgemeine Lösung von $y'=A(x)y$ 
    in der Form
    \[\varphi(x)=\Phi(x)c, c\in \K^n, c=\begin{pmatrix}c_1\\\vdots\\c_n
    \end{pmatrix}\text{ oder } \varphi(x)=c_1\varphi_1(x)+\cdots+c_n\varphi_n(x)\]
    schreiben. Man kann $\Phi$ selbst als Lösung der folgenden
    Matrix-DGL $Y'=A(x)Y$ auffassen.
\end{enumerate}

\subsection{Die inhomogene Differentialgleichung $y'=A(x)y+b(x)$}
\begin{theorem}
  Sei $I\subset\R$ ein offenes Intervall und $A\colon I\rightarrow\MM_n(\K),
  b\colon I\rightarrow\K^n$ stetig. Dann gilt für $\psi_0\in\LL_{inh}\colon \LL_{inh}
  =\psi_0+\LL_h\coloneqq \{\psi_0+\varphi\colon \varphi\in\LL_j\}$, d.h. $\psi(x)=\psi_0
  (x)+\varphi(x)+c, c\in\K^n$, wobei $\Phi$ eine Lösungsfundamentalmatrix
  ist.\\
  Allgemeine Lösung des inhomogenen DGL ist die allgemeine Lösung der
  homogenen DGL plus einer speziellen Lösung der inhomogenen DGL.\\
  \textbf{Beweis}: 
  \begin{enumerate}[1. Schr{i}tt]
    \item Zu zeigen ist $\LL_{inh}\subset\psi_0+\LL_h$. Sei $\psi\in\LL_{inh}$.
      Daraus folgt nach Satz \ref{satz:LTheorie} $\psi-\psi_0\in\LL_h
      \Rightarrow\exists\varphi\in\LL_h\colon \psi-\psi_0=\varphi$.
    \item Zu zeigen ist $\psi_0+\LL_h\subset\LL_{inh}$. Sei $\psi\in\psi_0
      +\LL_h$, d.h. $\exists\varphi\in\LL_h\colon \psi=\psi_0+\varphi
      \Rightarrow\psi\in\LL_{inh}\Rightarrow\psi_0+\LL_h\in\LL_{inh}$
  \end{enumerate}
  \qed
\end{theorem}

\subsubsection{Lösen der inhomogenen DGL $y'=A(x)y+b(x)$ mit der Methode
der Variation der Konstanten}
Sei $\Phi=(\varphi_1,\dots,\varphi_n)$ ein Lösungsfundamentalsystem von
$y'=A(x)y$. Dann gilt für die allgemeine Lösung von $y'=A(x)y\colon \varphi(x)
=\Phi(x), c\in\K^n$.\\
Variation der Konstanten: Der Ansatz ist $\psi(x)=\Phi(x)c(x)$. Man muss
nun differenzieren: $\psi'(x)=\Phi'(x)c(x)+\Phi(x)c'(x)=A(x)\Phi(x)c(x)
+\Phi(x)c'(x)=A(x)\psi(x)+\Phi(x)c'(x)=A(x)\psi(x)+b(x)\Rightarrow
\Phi(x)c'(x)=b(x)$. Da ein $\Phi^{-1}(x)$ für alle $x\in I$ existiert,
folgt $c'(x)=\Phi^{-1}(x)b(x)\Rightarrow c(x)-c(x_0)=\int_{x_0}^x
\Phi^{-1}(t)b(t)dt\Rightarrow c(x)=c+\int_{x_0}^x \Phi^{-1}(t)b(t)dt$
\[\Rightarrow \psi(x)=
\Phi(x)c(x)=\Phi(x)c+\int_{x_0}^x \Phi^{-1}(t)b(t)dt\]

Allgemeine Lösung der inhomogenen DGL:
\[\boxed{\psi(x)=\Phi(x)c+\Phi(x)\int_{x_0}^x \Phi^{-1}(t)b(t0)dt}\]

Beispiel: 
\begin{align*}
  y_1'&=& \frac{1}{2x}y_1-\frac{1}{2x^2}+1, x>0\\
  y_2'&=& y_1+x
\end{align*}
Gesucht ist die allgemeine Lösung des inhomogenen DGL mit $y=(y_1,y_2)^T$
und $A(x)=\begin{pmatrix}
  \frac{1}{2x} & -\frac{1}{2x^2}\\
  1 & 0
\end{pmatrix}, b(x)=(1,x)^T$.

Ansatz: 
\begin{align*}
  y_2&=& y_2(x)x^\alpha, \alpha\in\R\\
  y_1(x)&=& y_2'(x)=\alpha x^{\alpha-1}
\end{align*}
Einsetzen in die erste Gleichung: 
\begin{align*}
  y_1'(x)&=& \alpha(\alpha-1)x^{\alpha-2}=\frac{1}{2x}\alpha x^{\alpha-1}
  -\frac{1}{2x^2}x^a\\
  &\Rightarrow & \alpha(\alpha-1)x^{\alpha-2}=\left(\frac{\alpha}{2}-
  \frac{1}{2}\right)x^{\alpha-2}, \forall x>0\\
  & \Rightarrow & \alpha(\alpha-1)=\frac{\alpha}{2}-\frac{1}{2}\\
  & \Rightarrow & \alpha^2-\frac{3}{2}\alpha+\frac{1}{2}=0\\
  & \Rightarrow & \alpha_{1,2}=\frac{3}{4}\pm\sqrt{\frac{9}{16}-\frac{1}{2}}
  =\frac{3}{4}\pm\frac{1}{4}\\
  & \Rightarrow & \alpha_1=1\wedge\alpha_2=\frac{1}{2}
\end{align*}
$\alpha=1\colon  \varphi_1(x)=(1,x)^T$ und $\alpha=\frac{1}{2}\colon \varphi_2(x)=
\begin{pmatrix}\frac{1}{2}x^{-\frac{1}{2}}\\x^{\frac{1}{2}}
\end{pmatrix}$. Daher sind $\varphi_1,\varphi_2$ linear unabhängig: Denn
für $\Phi(x)=(\varphi_1(x),\varphi_2(x))=\begin{pmatrix}
  1&\frac{1}{2}x^{-\frac{1}{2}}\\
  x& x^{\frac{1}{2}}
\end{pmatrix}$ gilt $\det \Phi(x)=x^{\frac{1}{2}}-\frac{1}{2}xx^{-\frac{1}{2}}
=x^{\frac{1}{2}}-\frac{1}{2}x^{\frac{1}{2}}=\frac{1}{2}x^{\frac{1}{2}}
\neq 0$ für $x>0$. Damit ist $\Phi(x)$ ist Fundamentalmatrix und es gilt
für die allgemeine Lösung
\[\varphi(x)=\Phi(x)c=\begin{pmatrix}
  1 & \frac{1}{2}x^{-\frac{1}{2}}\\
  x & x^{\frac{1}{2}}\begin{pmatrix}x-1\\0
\end{pmatrix}
\end{pmatrix}\begin{pmatrix}c_1\\c_2
\end{pmatrix}=\begin{pmatrix}
  c_1+\frac{c_2}{2}x^{-\frac{1}{2}}\\
  c_1x+c_2x^{\frac{1}{2}}
\end{pmatrix}=c_1\varphi_1(x)+c_2\varphi_2(x)\]
Im zweiten Schritt erfolgt wieder die Variation der Konstanten. Dies
liefert: $\psi_0(x)=\Phi(x)\int_1^x\Phi^{-1}(t)b(t)dt$. Es gilt
\[\Phi^{-1}(x)=\begin{pmatrix}
  2 & -\frac{1}{x}\\
  -2x^{\frac{1}{2}} & 2x^{-\frac{1}{2}}
\end{pmatrix}\]
\[\int_1^x \Phi^{-1}(t)b(t)dt=\int_1^x \begin{pmatrix}
  2 & -\frac{1}{t}\\
  -2t^{\frac{1}{2}} & 2t^{-\frac{1}{2}}
\end{pmatrix}\begin{pmatrix}1\\t
\end{pmatrix}dt=\int_1^x \begin{pmatrix}1\\0
\end{pmatrix}dt=\begin{pmatrix}x-1\\0
\end{pmatrix}\]
\[\psi(x)=\Phi(x)\begin{pmatrix}x-1\\0
\end{pmatrix}=\begin{pmatrix}
  1 & \frac{1}{2}x^{-\frac{1}{2}}\\
  x & x^{\frac{1}{2}}
\end{pmatrix}\begin{pmatrix}x-1\\0
\end{pmatrix}=\begin{pmatrix}x-1\\x^2-x
\end{pmatrix}\]
ist die spezielle Lösung des inhomogenen DGL.

Allgemeine Lösung des inhomogenen DGL:
\[\psi(x)=\varphi(x)c+\psi_0(x)=\begin{pmatrix}
  c_1+\frac{c_2}{2}x^{-\frac{1}{2}}+x-1\\
  c_1x+c_2x^{\frac{1}{2}}+x^2-x
\end{pmatrix}\]
In Komponenten: $y_1=y_1(x)=c_1+\frac{c_2}{2}x^{-\frac{1}{2}}+x-1$ und
$y_2=y_2(x)=c_1x+c_2x^{\frac{1}{2}}+x^2-x$

\section{Lineare Differentialgleichungen $n$-ter Ordnung}
\subsection{Lösungstheorie}
Übertragung der Resultate über lineare DGL 1.~Ordnung auf lineare
DGL $n$-ter Ordnung. Sei $I\subset\R$ ein Intervall, $a_k, f\in\CC(I,\K)$
seien stetige Funktionen zwischen $0\leq k\leq n-1$. Dann heißt
$L(y)\coloneqq y^{(n)}+a_{n-1}(x)y^{(n-1)}+\cdots+a_1(x)y'+a_0(x)y=f(x)$ 
\emph{homogene lineare Differentialgleichung $n$-ter Ordnung\index{Differentialgleichung!homogene}\index{Differentialgleichung!lineare}},
falls $f=0$. Ansonsten heißt es inhomogen. $L$ heißt
\emph{linearer Differentialausdruck\index{Differentialausdruck!linearer}},
d.h. $L(c_1y_1+c_2y_2)=c_1L(y_1)+c_2L(y_2)$.

\begin{theorem}
  \begin{enumerate}[(i)]
    \item Sei $\LL_h\coloneqq \{\varphi\colon I\rightarrow \K\colon L(\varphi)=0\}$ die Menge
      der Lösungen des homogenen DGL. Dann ist $\dim \LL_h=n$
    \item Sei $\LL_{inh}\coloneqq \{\varphi\colon I\rightarrow\K\colon L(\varphi)=f(x)\}$
      die Menge der Lösungen der inhomogenen DGL. Dann gilt für ein 
      $\psi_0\in\LL_{inh}\colon \LL_{inh}=\psi_0+\LL_h$.
    \item $n$-Lösungen $\varphi_1,\dots,\varphi_n\in\LL_h$ der homogenen
      DGL sind genau dann linear unabhängig, wenn $\exists x_0\in I\colon 
      W(x)\footnote{heißt Wronskideterminante\index{Wronskideterminante}}\coloneqq \det\begin{pmatrix}
	\varphi_1(x) & \dots & \varphi_n(x)\\
	\varphi_1'(x) & & \varphi_n'(x)\\
	\vdots & & \vdots\\
	\varphi_1^{(n-1)}(x) & \dots & \varphi_n^{(n-1)}(x)
      \end{pmatrix}\neq 0\Leftrightarrow \forall x \in I\colon W(x)\neq 0$
  \end{enumerate}
  \textbf{Beweis}: Die DGL $L(y)=f(x)$ ist äquivalent zu dem inhomogenen
  DGL-System 1.~Ordnung $y_0\coloneqq y$.
  \begin{alignat*}{2}
    y_0' & = y_1 & y_0' & = y_1\\
    y_1' & = y_2 & y_0''& =y_2\\
    \vdots & & \vdots\\
    y_{n-2}' & = y_{n-1} & y_0^{(n-1)} & = y_{n-1}\\
    y_{n-1}' & = -a_0(x)y_0-a_1(x)y_1-& \cdots a_{n-1}(x)y_{n-1}+f(x)
  \end{alignat*}
  Jeder Lösung $\varphi\colon I\rightarrow\K$ von $L(y)=f(x)$ entspricht einer
  Lösung $y=\begin{pmatrix}y_0\\y_1\\\vdots\\y_{n-1}
  \end{pmatrix}=\begin{pmatrix}\varphi\\ \varphi'\\\vdots\varphi^{(n-1)}
  \end{pmatrix}\colon I\rightarrow\K^n$ des Systems oben. Damit folgen die
  obenstehenden Behauptungen aus den Sätzen %III.5.2.1, III.5.2.2, III.5.3.1
\end{theorem}

\begin{definition}
  Eine Basis $\varphi_1,\dots,\varphi_n\in\LL_h$ der homogenen DGL
  $L(y)=0$ heißt \emph{Lösungsfundamentalsystem\index{Lösungsfundamentalsystem}}.
  Also: Allgemeine Lösung von $L(y)=0\colon  \varphi(x)=c_1\varphi_1(x)+
  c_2\varphi_2(x)+\cdots+c_n\varphi_n(x)$ 
\end{definition}

Beispiel: $y''-\frac{1}{2x}y'+\frac{1}{2x^2}y=0$ besitzt die Lösungen
$\varphi_1(x)=x, \varphi_2(x)=\sqrt{x}$. Es gilt $\varphi_1,\varphi_2$
sind linear unabhängig. Denn $W(x)=\det\begin{pmatrix}
  \varphi_1(x) & \varphi_2(x)\\
  \varphi_1'(x) & \varphi_2'(x)
\end{pmatrix}=\det\begin{pmatrix}
  x & \sqrt{x}\\
  1 & \frac{1}{2\sqrt{x}}
\end{pmatrix}=\frac{1}{2}x\frac{1}{\sqrt{x}}-\sqrt{x}=-\frac{1}{2}\sqrt{x}\neq=0$. Somit ist $\{\varphi_1,\varphi_2\}$ ein Lösungsfundamentalsystem.
Allgemeine Lösung: $\varphi(x)=c_1\varphi_1(x)+c_2\varphi_2(x)=c_1x+
c_2\sqrt{x}$

\paragraph{Bestimmung einer speziellen Lösung von $L(y)=f(x)$ mit der
Methode der Variation der Konstanten}
\begin{enumerate}[1. Schr{i}tt]
  \item $L(y)=f(x)$ auf ein DGL-System 1.~Ordnung umschreiben und
    Methode der Variation der Konstanten für DGL-System 1.~Ordnung
    benutzen:\\
    Sei $\Phi(x)=\begin{pmatrix}
      \varphi_1(x) & \dots & \varphi_n(x)\\
      \varphi_1'(x) & & \varphi_n'(x)\\
      \vdots & & \vdots\\
      \varphi_1^{(n-1)}(x) & \dots & \varphi_n^{(n-1)}
    \end{pmatrix}$ Fundamentalsystem zum zugehörigen DGL-System.
  \item Ansatz: $\psi(x)=\Phi(x)c(x)$. 
    \begin{align*}
      \psi'(x)&=& \Phi'(x)c(x)\\
      &=& A(x)\psi(x)+\begin{pmatrix}0\\\vdots\\0\\f(x)
      \end{pmatrix}\\
      &=& A(x)\Phi(x)c(x)+\begin{pmatrix}0\\\vdots\\0\\f(x)
      \end{pmatrix}\\
      \Phi(x)c'(x)&=& b(x)=\begin{pmatrix}0\\\vdots\\0\\f(x)
      \end{pmatrix}\\
      \text{wobei}\\
      A(x)&=& 
      \begin{pmatrix}
	0 & 1 & 0 & \dots & 0\\
	0 & 0 & 1 & \dots & 0\\
	\vdots\\
	0 & 0 & 0 & \dots & 1\\
	-a_0(x) & -a_1(x) & -a_2(x) & \dots & -a_{n-1}(x)
      \end{pmatrix}\\
    \end{align*}
    Oder in Komponenten $\sum_{i=1}^n c_i'(x)\varphi_i^{(k)}(x)=0$
    für $k=0,\dots,n-2$
  \item Berechnung der $c_i'(x)$ mit Cramerscher Regel\\
    $c_i'(x)=\frac{W_i(x)}{W(x)}, W_i(x)=\det
    \begin{pmatrix}
      \varphi_1(x) & \dots & \varphi_{i-1}(x) & 0 & \varphi_{i+1}(x) & \dots\\
      \varphi_1'(x) & \dots & \varphi_{i-1}'(x) & 0 & \varphi_{i+1}'(x) & \dots\\
      \vdots & & \vdots & \vdots & \vdots& \\
      \varphi_1^{(n-1)}(x) & \dots & \varphi_{i-1}^{(n-1)}(x) & 0 & \varphi_{i+1}^{(n-1)} & \dots
    \end{pmatrix}$\\
    Integration: $c_i(x)=\int_{x_0}^x \frac{W_i(t)}{W(t)}dt$\\
    Spezielle Lösung von $L(y)=f(x)\colon  \psi_0(x)=\sum_{i=1}^n c_i(x)
    \varphi_i(x)$, wobei $c_i(x)=\int_{x_0}^x \frac{W_i(t)}{W(t)}dt$\\
    Das Anfangswertproblem 
    \[L(y)=f(x), \varphi(x_0)=y_0, \varphi'(x_0)
    =y_1,\dots,\varphi^{(n-1)}(x_0)=y_{n-1}, x_0\in I \]
    hat genau eine
    Lösung.
\end{enumerate}

\subsection{Reduktion der Ordnung einer Differentialgleichung $L(y)=0$ bei Kenntnis einer Lösung}
Ansatz: $\psi(x)=\varphi(x)u(x)$, wobei $L(\varphi(x))=0$.\\
Demonstration der Methode anhand einer linearen Differentialgleichung
2.\,Ordnung:
\begin{equation}
  \label{eq:Red}
  y''+a(x)y'+b(x)=0
\end{equation}
Sei $\varphi\neq 0$ eine Lösung von Gleichung \ref{eq:Red}.\\
Einsetzen in DGL:\\
$\varphi u''+(2\varphi'+a(x)\varphi)u'+\underbrace{u(\varphi''+a(x)
\varphi'+b(x)\varphi)}_{=0}=0\Leftrightarrow u''+\left( \frac{2\varphi'}{\varphi}
+a(x)\right)u'=0$. Setzen $v\coloneqq u'$. Dann ist
\begin{equation}
  \label{eq:Redv}
\boxed{v'+\left( \frac{2\varphi'}{\varphi}+a(x)\right)v=0}
\end{equation}
eine lineare DGL 1.\,Ordnung. Es gilt: Ist $v\neq 0$ Lösung der
Gleichung \ref{eq:Redv}, so ist $\psi(x)=\varphi(x)u(x)$, wobei
$u(x)=\int_{x_0}^x v(t)dt$, eine von $\varphi$ unabhängige Lösung von
$y''+a(x)y'+b(x)y=0$. Denn es gilt 
\begin{align*}
  W(x)&=& \det
\begin{pmatrix}
  \varphi(x) & \psi(x)\\
  \varphi'(x) & \psi'(x)
\end{pmatrix}=\det
\begin{pmatrix}
  \varphi(x) & \varphi(x)u(x)\\
  \varphi'(x) & \varphi'(x)u(x)+\varphi(x)u'(x)
\end{pmatrix}\\
&=& \varphi\varphi'u+\varphi^2u'-\varphi\varphi'u=\varphi^2u'\\
&=& \varphi^2v\neq0
\end{align*}
\qed
\subsection{Praktisches Vorgehen beim Lösen von linearen DGL 2.~Ordnung mit nichtkonstanten Koeffizienten}
\[L(y)=y''+a(x)y'+b(x)y=f(x)\]
Der Lösungsweg ist wie folgt:
\begin{enumerate}[1.\,Schr{i}tt]
  \item Finden einer Lösung der homogenen DGL $L(y)=0$ durch
    Potenzreihenansatz.
    \[\varphi(x)=\sum_{k=-\infty}\infty a_kx^k \quad \varphi(x)=x^\alpha, \alpha\in\R\]
    $a(x)$ und $b(x)$ müssen ebenfalls in Potenzreihen entwickelt werden.
  \item Reduktion der Ordnung von $L(y)=0$ auf eine DGL 1.~Ordnung
  \item Berechnung einer Lösung der inhomogenen DGL (beispielsweise mit
    Variation der Konstanten oder auch Raten)
\end{enumerate}

\subsection{Lineare Differentialgleichungen $n$-ter Ordnung mit konstanten Koeffizienten}
\[L(y)=y^{(n)}+a_{n-1}y^{(n-1)}+\cdots+a_1y'+a_0y=f(x)\]
wobei $a_i$ konstant ist.

\begin{theorem}
  Besitzt das Polynom $P_L(\lambda)\coloneqq \lambda^n+a_{n-1}\lambda^{n-1}+\cdots+
  a_1\lambda+a_0$ die paarweise voneinander verschiedenen Nullstellen
  $\lambda_k\in\C, k=1,\dots,s$ mit den Vielfachheiten $n_k, 1\leq k\leq s$.
  Dann besitzt die homogene DGL $L(y)=0$ ein Lösungsfundamentalsystem
  aus folgenden Funktionen
  \[\varphi_{km}(x)\coloneqq x^me^{\lambda_kx}\quad m=0,1,\dots,n_k-1\quad k=1,\dots,s\]
\end{theorem}
\begin{proof}
  \begin{enumerate}[1. Schr{i}tt]
  \item Man zeigt, dass $\varphi_{km}(x)=x^me^{\lambda_kx}$ 
    Lösungen von $L(y)=0$ sind.\\
    Ansatz: $\varphi(x)\coloneqq e^{\lambda x}$. Dann gilt $\varphi^{(k)}(x)=
    \lambda^ke^{\lambda x}$.
    \[L(\varphi(x))=(\lambda^n+a_{n-1}\lambda^{n-1}+\cdots+a_1\lambda
    +a_0)e^{'\lambda x}=0\]
    Die obige Gleichung ist genau dann 0, wenn 
    \[P_L(\lambda)\coloneqq \lambda^n+a_{n-1}\lambda^{n-1}+\cdots+a_1\lambda
    +a_0=0\] Somit sind $\varphi_k(x)=e^{\lambda_k x}$ Lösungen von
    $L(y)=0$,
    wobei $\lambda_k$ Nullstellen von dem Polynom $P_L$ sind.\\
    Sind alle Nullstellen von $P_L$ einfach, d.h. $n_k=1,
    k=1,\dots,n$, so bilden die Funktionen $\varphi_k(x)=e^{\lambda_k
      x}, k=1,\dots,n$, bereits ein Fundamentalsystem. Ein Problem
    besteht bei mehrfachen
    Nullstellen. Dazu berechnet man $L(x^me^{\lambda x})$:\\
    $L(x^me^{\lambda x})=L\left( \frac{\partial^m}{\partial \lambda^m}
      (e^{\lambda x})\right)$\\
    Vertauschung der Differentiation (nach Satz von Schwartz):
    $=\frac{\partial^m}{\partial \lambda^n}L(e^{\lambda x})=
    \frac{\partial^m}{\partial \lambda^m} (P_L(\lambda)e^{\lambda
      x})$.  Ist $\lambda=\lambda_j$ eine $n_j$-fache Nullstelle von
    $P_L, P_L(\lambda)=\prod_{k=1}^s (\lambda-\lambda_k)^{n_k}$, dann
    gilt $\frac{\partial^m}{\partial \lambda^m}(P_L(\lambda)e^{\lambda
      x})= 0$ für $m=0,1,\dots,n_j-1$. Denn $P_L(\lambda)=Q_j(\lambda)
    (\lambda-\lambda_j)^{n_j}, Q_j(\lambda)=\prod_{k=1,k\neq j}^s
    (\lambda-\lambda_j)^{n_k}$.\\
    Leibnitzsche Regel:
    \begin{align*}
      \frac{\partial^m}{\partial \lambda^m} (P_L(\lambda)e^{\lambda
        x}) 
      &= \sum_{k=0}^m \binom{m}{k} \frac{\partial^k}{\partial \lambda^k}
      (P_L(\lambda)) \frac{\partial^{m-k}}{\partial \lambda^{m-k}}
      (e^{\lambda k}, \frac{\partial^m}{\partial
        \lambda^m}(P_L(\lambda))\\
      &= \frac{\partial^m}{\partial\lambda^m}( (\lambda-\lambda_j)^{n_j}
      Q_j(\lambda))\\
      &=\sum_{k=0}^m \frac{\partial^k}{\partial \lambda^k}
      ((\lambda-\lambda_j)^{n_j} \frac{\partial^{m-k}}{\partial\lambda^{m-k}}
      (Q_j(\lambda)), \frac{\partial^k}{\partial\lambda^k}
      (\lambda-\lambda_j)^{n_j}\\
      &=n_j(n_j-1)\ldots (n_j-k+1)(\lambda-\lambda_j)^{n_j-k}\\
      &\Rightarrow \frac{\partial^k}{\partial\lambda^k}
      ((\lambda-\lambda_j)^{n_j})\\
      & =0
    \end{align*}
    Somit ist $\frac{\partial^m}{\partial\lambda^m}(P_L(\lambda)) =0$
    für $m=0,1,\dots,n_j-1$ und $\frac{\partial^m}{\partial\lambda^m}
    (P_L(\lambda)e^x)=0$ für $m=0,1,\dots,n_j-1$ und $j=1,\dots,s$.
  \item Die $\varphi_{km}(x)=x^me^{\lambda_k x}, m=0,1,\dots,n_k-1,n=
    n_1+\cdots+n_s, k=1,\dots,s$ sind stets linear unabhängig.
    \begin{lemma}
      Seien $\lambda_1,\dots,\lambda_r\in\C$ verschiedene Zahlen und
      $P_1,\dots,P_r$ Polynome auf einem offenen Intervall $I\subset\R$.
      Dann gilt:
      \[\sum_{j=1}^r P_j(x)e^{\lambda_j x}=0\,\forall x\in I \Rightarrow
      P_1=P_2=\cdots=P_r=0\] Beweis durch Induktion: $r=1\colon 
      P_1(x)e^{\lambda_1x}=0\,\forall
      x\in I\Rightarrow P_1(x)=0\,\forall x\in I\Rightarrow P_1=0$.\\
      Induktionsschritt mit $(r-1)\Rightarrow r$: Sei $\sum_{j=1}^r
      P_j(x) e^{\lambda_j x} = 0$. Damit folgt $\sum_{j=1}^{r-1}
      P_j(x) e^{(\lambda_j-\lambda_r)x}+P_r(x)=0$. Sei nun $m$ der
      Grad des Polynoms plus 1. Dann gilt folgendes (nach m-maliger
      Differentiation nach $x$):
      \begin{align*}
        0&=\frac{\partial^m}{\partial x^m} \left( \sum_{j=1}^{r-1}
          P_j(x) e^{(\lambda_j-\lambda_r)x} + P_r(x) \right)\\
        &= \frac{\partial^m}{\partial x^m} \left( \sum_{j=1}^{r-1}
          P_j(x)
          e^{(\lambda_j-\lambda_r)x}\right)\\
        &=\sum_{j=1}^{r-1} \frac{\partial^m}{\partial x^m} (P_j(x)
        e^{(\lambda_j-\lambda_r)x})\\
        &= \sum_{j=1}^{r-1} Q_j(x) e^{(\lambda_j-\lambda_r)x}\\
        &\text{wobei } Q_j-(\lambda_j-\lambda_r)^mP_j(x)+R_j(x)
      \end{align*}
      $R_j$ ist ebenfalls ein Polynom. Aus der Induktionsvoraussetzung
      folgt nun: $Q_j(x)=0\,\forall x\in I$,
      d.h. $Q_1=Q_2=\cdots=Q_{r-1}=0 \Rightarrow P_j=R_j=0,
      j=1,\dots,r-1\Rightarrow 0=\sum_{j=1}^r P_j(x)e^{\lambda_j
        x}=P_r(x)e^{\lambda_rx}\Rightarrow P_r=0$ auf $I$.
    \end{lemma}
    Jetzt zur linearen Unabhängigkeit von
    $\varphi_{jk}(x)=x^ke^{\lambda_j x}$ mit $k=0,1,\ldots,n_j-1,
    j=1,\ldots,s$ gilt für alle $x\in\R$:
    \begin{align*}
      \sum_{j=1}^s \sum_{k=0}^{n_j-1} c_{jk} \varphi_{jk}(x) &=
      \sum_{j=1}^s \sum_{k=0}^{n_j-1} c_{jk}x^ke^{\lambda_jx}\\
      &= \sum_{j=1}s\left( \sum_{k=0}^{n_j-1} c_{jk}x^k
      \right)e^{\lambda_jx} =0
  \end{align*}
  Nach dem Lemma folgt $c_{jk}=0$.
  \end{enumerate}
\end{proof}

\paragraph{Praktisches Vorgehen anhand eines Beispiels}
Man finde die allgemeine reelle Lösung der DGL $x+2\mu x+\omega_0^2x=0$
($\omega_0>0, \mu\geq 0$) der gedämpften Schwingung. Man sucht die
Lösungen der Form $t^me^{\lambda_kt}$.\\
Ansatz: $\varphi(t)=e^{\lambda t}, \varphi'(t)=\lambda e^{\lambda t},
\varphi''(\lambda^2e^{\lambda t})$ Einsetzen in DGL $L(\varphi(t))=
(\lambda^2+2\mu\lambda+\omega_0^2)e^{\lambda t}=0\Leftrightarrow\lambda^2
+2\mu\lambda+\omega_0^2$. Nullstellen: $\lambda=-\mu\pm\sqrt{\mu^2-\omega_0^2}$.
\begin{enumerate}[1.\,F{a}ll]
  \item $0\leq \mu<\omega_0\colon  \lambda_{1,2}=-\mu\pm i\omega, \omega=
    \sqrt{\omega_0^2-\mu^2}>0$\\
    Lösungsfundamentalsystem: $\varphi_1(t)=e^{\lambda_1t}=e^{-\mu t}
    e^{i\omega t}, \varphi_2(t)=e^{\lambda_2 t}=e^{-\mu t}e^{-i\omega t}$\\
    $e^{i\omega t}=\cos(\omega t) +i \sin(\omega t)$. Betrachten
    $\begin{matrix}
      \psi_1(t) &=& \Re \varphi_1(t)=e^{-\mu t}\cos (\omega t)\\
      \psi_2(t)&=& \Im \varphi_2(t)=e^{-\mu t}\sin(\omega t)
    \end{matrix}$. Es gilt $L(\psi_1(t))=L(\psi_2(t))=0$. Nun ist noch
    zu zeigen, dass $\{\psi_1,\psi_2\}$ ein Lösungsfundamentalsystem ist:
    \begin{align*}
      \det
      \begin{pmatrix}
        \psi_1(t) & \psi_2(t)\\
        \psi_1'(t) & \psi_2'(t)
      \end{pmatrix}
      &= \det
      \begin{pmatrix}
        e^{-\mu t}\cos(\omega t) & e^{-\mu t}\sin(\omega t)\\
        -\mu e^{-\mu t}\cos(\omega t)&
        -\mu e^{-\mu t}sin(\omega t)\\
        \qquad -e^{-\mu t}\omega\sin(\omega t)& \qquad+e^{-\mu
          t}\omega \cos(\omega t)
      \end{pmatrix}\\
      &= -\mu e^{-2\mu t}\cos(\omega t)\sin(\omega t)+\omega e^{-2\mu
        t}\cos^2 (\omega t)\\
      &\qquad +\mu e^{-2\mu t}\cos(\omega t)\sin(\omega t)+\omega
      e^{-2\mu t}\sin^2(\omega t)\\
      &= \omega e^{-2\mu t}\neq 0
  \end{align*}
\item $\mu=\omega_0$: Nullstellen $\lambda_1=\lambda_2=-\mu$. Damit ist
  $\varphi_1(t)= e^{-\mu t}, \varphi_2(t)=te^{-\mu t}$ ein Fundamentalsystem.
\item $\mu>\omega_0$: Dann ist $\lambda_1=-+\sqrt{\mu^2-\omega_0^2}, 
  \lambda_2=-\mu-\sqrt{\mu_2-\omega_0^2}<0$. Man setzt: $\mu_j\coloneqq -\lambda_j
  >0, j=1,2$. Dann ist $\varphi_1(t)=e^{\lambda_1t}=e^{-\mu_1t},
  \varphi_2(t)=e^{\lambda_2t}e^{-\mu_2t}$ ist Fundamentalsystem.
\end{enumerate}
Zusammenfassend hat man für die allgemeine Lösung von $x''+2\mu x'+
\omega_0^2x=0$:
\begin{align}
  \varphi(t)&=& c_1e^{-\mu t}\cos(\omega t)+c_2e^{-\mu t}\sin (\omega t)\\
  \varphi(t)&=& c_1e^{-\mu t}+c_2te^{-\mu t} \text{ für } \mu=\omega_0\\
  \varphi(t)&=& c_1e^{-\mu_1 t}+c_2e^{-\mu_2t}\text{für }\omega_0<\mu\\
  & & \qquad \mu_1=-\lambda_1=+\mu-\sqrt{\mu^2-\omega_0^2}\notag
\end{align} 

%% Vorlesung vom 2004-07-02

\begin{theorem}
  %Satz IV.3.1
  Sei $G\subset\R^n$ ein Gebiet\index{Gebiet} und $f\colon G\rightarrow\R^n$
  ein Gradientenfeld. Dann erhält man alle Skalarfelder 
  (Stammfunktionen) $\Phi\colon G\rightarrow\R$ von $f$, d.h. $f=\text{ grad}
  \Phi$, in der Form
  \[\Phi=\Phi_0+c \qquad c\in\R\]
  mit $f=\text{ grad}\Phi_0$.\\
  \textbf{Beweis}: Aus $f=\text{ grad} \Phi_0\Rightarrow\text{ grad}
  \Phi=\text{ grad}\Phi_0+c=\text{ grad}\Phi_0=f$. Umgekehrt sei $f=
  \text{ grad}\Phi=\text{ grad}\Phi_0\Rightarrow\text{ grad} (\Phi-\Phi_0)
  =0\Rightarrow(\Phi-\Phi_0)'=0$. Da $g$ ein Gebiet ist, folgt $\Phi-
  \Phi_0=c$.
  \qed
\end{theorem}

\begin{theorem}
  %VI.3.2
  Sei $G\subset\R^n$ ein Gebiet und $f\colon G\rightarrow\R^n$ ein stetiges
  Vektorfeld. Dann gilt, dass $f$ genau dann ein Gradientenfeld ist,
  $\int_\gamma f(x)gx$ wegunabhängig ist.\\
  \textbf{Beweis}: 
  \begin{itemize}
    \item["`$\Rightarrow$"'] Sei $f=\text{ grad}\Phi=\Phi'$. Seien 
      $A,B\in G$ zunächst zwei Punkte, die durch einen stetig differenzierbaren
      Weg $\gamma\colon [a,b]\rightarrow\R^n$ mit $\gamma(a)=A$ und $\gamma(b)=
      B$ verbunden sind. Dann ist: $\int_\gamma f(x)dx=\int_a^b f(\gamma
      (t))\gamma'(t)dt=\int_a^b \Phi'(\gamma(t))\gamma'(t)dt=\int_a^b
      \frac{d}{dt} (\Phi(\gamma(t)))dt=\Phi(\gamma(b))-\Phi(\gamma(a))=
      \Phi(A)-\Phi(B)$.\\
      Sieen $A,B\in G$ beliebige und $\gamma$ ein stückweise stetig
      differenzierbarer Weg, der $A$ und $B$ verbindet. Ein solcher
      existiert, da $G$ polygonzugzusammenhängend ist. Also $\gamma=
      \gamma_1\oplus\gamma_2\oplus\cdots\oplus\gamma_n$, wobei $\gamma_k$ stetig
      differenzierbar. Damit ist $\int_\gamma\text{ grad}\Phi(x)dx=
      \sum_{k=1}^n \int_{\gamma_k}\text{ grad}\Phi(x)dx$.
    \item["`$\Leftarrow$"'] Sei $\xi\in G$ und $B_\varepsilon(\xi)\subset
      G$ eine offene $\varepsilon$-Kugel. Für beliebige $h\in\R^n$ mit
      $\xi+h\in B_\varepsilon(\xi)$ ist $\sigma(t)=\xi+th\in B_\varepsilon
      (\xi)$ für $0\leq t\leq 1$. Setzen $\Phi(x)\coloneqq \int_A^x f(y)dy, A\in G$
      fest, $x\in G$ beliebig. Dann ist $\Phi(\xi+h)-\Phi(\xi)=\int_A^{\xi+h}
      f(y)dy-\int_A^\xi f(y)dy=\int\xi^{\xi+h} f(y)dy=\int_\sigma f(y)dy
      =\int_0^1 f(\sigma(t))\sigma'(t)dt=\int_0^1 f(\xi+th)hdt$. Ferner
      hat man $\int_\sigma f(\xi)dy=\int_0^1 f(\xi)\sigma'(t)dt=\int_0^1
      f(\xi)hdt=f(\xi)h$. Somit hat man $|\Phi(\xi+h)-\Phi(\xi)-f(\xi)h|
      =|\int_\sigma f(y)-f(\xi))dy|\leq \max_{y\in \{\xi+th\colon 0\leq t\leq 1}
      ||f(y)-f(\xi)||_2 L(\sigma)$. Da $f$ stetig ist, folgt $\max_{y\in \{\xi+th\colon 0\leq t\leq 1}
      ||f(y)-f(\xi)||_2\xrightarrow{h\rightarrow 0} 0$. Damit gilt
      $f(\xi)=\Phi(\xi)=\text{ grad}\Phi(\xi)$.
  \end{itemize}
  \qed
\end{theorem}

Folgerung: Es gilt $\int_\gamma \text{grad} \Phi dx=\Phi(B)-\Phi(A),
\gamma(a)=A,\gamma(b)=B$ für jeden stetig differenzierbaren Weg $\gamma$
in einem Gebiet $G$ und Anfangspunkt $A$ und Endpunkt $B$ und jedes
stetig differenzierbare Skalarfeld $\Phi$.

Ein praktisches Differenzierbarkeitskriterium dafür, dass ein 
Vektorfeld ein Gradientenfeld ist:
\begin{enumerate}[(i)]
  \item Notwendiges Kriterium\\
    Sei $f\colon 
    \begin{pmatrix}
      f_1\\\cdots\\f_n
    \end{pmatrix}\colon G\rightarrow\R^n$ ein stetig differenzierbares
    Gradientenfeld auf einer offenen Menge $G$. Dann gilt notwendigerweise:
    $\frac{\partial f_j}{\partial x_k}=\frac{\partial f_k}{\partial x_j},
    k_{xj}=1,\dots,n$. (Integrabilitätskriterien)\\
    Beweis: (Schwartzscher Satz): $f=\text{ grad }\Phi=\Phi'$, da $f$
    stetig differenzierbar. Damit ist $\Phi$ zweimal stetig differenzierbar.
    Wegen dem Schwatzschen Satz folgt nun, $\frac{\partial f_j}{\partial x_k}
    =\frac{\partial^2 \Phi}{\partial x_k\partial x_j}=\frac{\partial^2 \Phi}{\partial x_j \partial x_k}
    =\frac{\partial f_k}{\partial x_j}$. Dann ist $f$ ein 
    Gradientenfeld.
  \item Hinreichende Bedingungen\\
    Sei $G\subset\R^n$ eine offene und sternförmige Menge\index{Menge!sternförmig},
    d.h. $\exists a \in G\,\forall x \in G\,\forall t\in[0,1]\colon a+tx\in G$,
    und $f=
    \begin{pmatrix}
      f_1\\\cdots\\f_n
    \end{pmatrix}\colon G\rightarrow\R^n$ ein stetig differenzierbares
    Vektorfeld mit $\frac{\partial f_j}{\partial x_k}=\frac{\partial f_k}{\partial x_j},
    j,k=1,\dots,n$. Dann ist $f$ ein Gradientenfeld, d.h. $\exists\Phi\colon 
    G\rightarrow\R\colon f=\text{ grad }\Phi$.\\
    Beweis: Sei o.\,B.\,d.\,A. $a=0, \sigma(t)=tx$, wobei $t$ zwischen 0 und
    1 liegt. $\Phi(x)$ sei $\int_\sigma f(y)dy$.
    \begin{align*}
    \Phi(x) &=\int_0^1 f(tx)xdt=\int_0^1 \sum_{j=1}^n f_j(tx)x_jdt\\
    \frac{\partial \Phi(x)}{\partial x_k} &= \int_0^1
    \frac{\partial}{\partial x_k} (f(tx)x)dt\\
    &= \int_0^1\frac{\partial}{\partial x_k} \left(\sum_{j=1}^n f_j
      (tx) x_j\right) dt \sum_{j1}^n \frac{\partial}{\partial x_k}
    (f_j(tx)x_j) dt\\
    &= \sum_{j=1}^n \left( \frac{\partial f_j(tx)}{\partial x_k} x_j +
      f_j(tx) \frac{\partial x_j}{\partial x_k}\right)\\
    &=f_k(tx)+ \sum_{j=1}^n \frac{\partial f_j(tx)}{\partial x_k}
    x_j=f_k(tx)+ \sum_{j=1}^n \frac{\partial f_j(tx)}{\partial u_k}
    \frac{\partial u_k}{\partial x_k} x_j\\
    &= f_k(tx)+\sum_{j=1}^n \frac{\partial f_j(tx)}{\partial
      u_k}tx_j = f_k(tx)+\sum_{j=1}^n \frac{\partial f_k(tx)}{\partial
      u_j}tx_j\\
    &= \frac{d}{dt}(tf_k(tx))\\
    &\text{Somit ist } \frac{\partial\Phi(x)}{\partial x_k}
    =\int_0^1 \frac{d}{dt} (ff_k(tx))dt=f_k(x)
  \end{align*}
\end{enumerate}

\subsection{Praktische Bestimmung von $\Phi$}
Sei o.B.d.A. $f=\text{ grad }\Phi, \Phi=\Phi(x_1,x_2), f_1=
\frac{\partial \Phi}{\partial x}, f_2=\frac{\partial \Phi}{\partial x_2}$. 
\begin{enumerate}
  \item Man wählt einen Polygonzug $\gamma$ in Richtung der Koordinatenachsen
    in $G$. $\Phi(x)=\int_a^x f(y)dy$ mit $a=(a_1,a_2)$ und $x=(x_1,x_2)$.
    $\Phi(x)=\int_\gamma f(y)dy=\int_{\gamma_1} f(y)dy+\int_{\gamma_2}
    f(y)dy$ mit $\gamma=\gamma_1\oplus\gamma_2, \gamma_1(t)=(t,a_2),
    \gamma_2(t)=(x_1,t)$. 
    
\end{enumerate}

%Vorlesung vom 2004-07-05 ergaenzen

\printindex
\end{document}
