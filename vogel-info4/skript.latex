% TODO:
%   * eine Umgebung für Schreibweisen/Notationen
%   * Algorithmen in eine eigene Umgebung und einheitlich formatieren
%   * einen Abstract -- Kurzzusammenfassung des Inhalts

% Einige zusätzliche Informationen für rubber
%  rubber erkennt nicht, dass die Datei weg kann, daher sagen wir es ihm
% rubber: clean $base.thm
%  rubber soll nach Änderungen an der Datei nochmal bauen
% rubber: watch $base.thm
% rubber: makeidx.tool      xindy
% rubber: makeidx.language  german-din

\documentclass[halfparskip*,german,draft,twoside]{scrreprt}

\usepackage[l2tabu]{nag}  % nag überprüft den Text auf verältete Befehle
                          % oder solche, die man nicht in LaTeX verwenden
                          % soll -- l2tabu-Checker in LaTeX

\usepackage{tabularx}
\usepackage{longtable}
\usepackage{ifthen}

\usepackage{makeidx}
\usepackage[final]{graphicx}
\usepackage{color}
\usepackage[draft=false,colorlinks,bookmarksnumbered,linkcolor=blue,breaklinks]{hyperref}
\usepackage[latin1]{inputenc}
% \usepackage{nicefrac}

% Schrift, die als serifen-Schrift (normale Text) verwendet wird
\usepackage{lmodern}		% Latin Modern
% \usepackage{type1ec}		% cm-super
\usepackage[T1]{fontenc}        % T1-Schriften verwenden -- besser für PDFs
\usepackage{textcomp}           % wird benötigt, damit der \textbullet
                                % für itemize in lmodern gefunden wird.

\usepackage[intlimits,leqno]{amsmath}
\usepackage[all,warning]{onlyamsmath}  % warnt bei Verwendung von nicht
                                       % amsmath-Umgebungen z.\,B. $$...$$
\usepackage{amssymb}     % wird für \R, \C,... gebraucht
\usepackage{fixmath}     % ISO-konforme griech. Buchstaben
\usepackage{mathtools}

\usepackage[amsmath,thmmarks,hyperref]{ntheorem}
\usepackage{xspace}
\usepackage{slashbox}

\usepackage{paralist}
\usepackage{ngerman}
\usepackage{svn}
%\usepackage{wasysym}  % \lightning
\usepackage{ellipsis}    % Korrektur für \dots
\usepackage{fixltx2e}
\usepackage[final]{microtype} % Verbesserung der Typographie

% Damit auch die Zeichen im Mathemode in Überschriften fett sind
% <news:lzfyyvx3pt.fsf@tfkp12.physik.uni-erlangen.de>
\addtokomafont{sectioning}{\boldmath}

% \newtheoremstyle{break}{3pt}{3pt}{}{}{\bfseries}{}{\newline}{}

\theoremstyle{break}
\theorembodyfont{\normalfont}
\theoremheaderfont{\normalfont\bfseries}
\theoremnumbering{arabic}
\newtheorem{satz}{Satz}[chapter]
\newtheorem{bemerk}{Bemerkung}[chapter]
\newtheorem{defini}{Definition}[chapter]
\newtheorem{bsp}{Beispiel}[chapter]
\newtheorem{festl}{Festlegung}[chapter]

\theoremstyle{nonumberbreak}
\newtheorem{fakt}{Fakt}

\theoremheaderfont{\scshape}
\theorembodyfont{\normalfont}
\theoremsymbol{\ensuremath{_\blacksquare}}
% \theoremsymbol{q.\,e.\,d.}
\newtheorem{proof}{Beweis:}

\newcommand*{\satzautorefname}{Satz}
\newcommand*{\bemerkautorefname}{Bemerkung}
\newcommand*{\definiautorefname}{Definition}
\newcommand*{\bspautorefname}{Beispiel}
\newcommand*{\festlautorefname}{Festlegung}
\newcommand*{\faktautorefname}{Fakt}
\renewcommand*{\subsectionautorefname}{Abschnitt}
\renewcommand*{\subsubsectionautorefname}{Abschnitt}

% \setdefaultenum{(1)}{(a)}{i.}{A.}
\pagestyle{headings}

\newcommand*{\N}{\mathbb{N}}
\newcommand*{\Z}{\mathbb{Z}}
\newcommand*{\PP}{\mathbb{P}}
\newcommand*{\Prr}{\PP\mathrm{r}}  % The command \Pr already exist
\newcommand*{\Pa}{\PP\mathrm{a}}
\newcommand*{\TM}{\ensuremath{\mathcal{TM}}}
\newcommand*{\help}[1]{\textcolor{green}{help: #1}}
\newcommand*{\todo}[1]{\textcolor{red}{todo: #1}}
\newcommand*{\listlinebreak}{\mbox{}\vspace{-\parskip}}
\newcommand*{\algokeyword}[1]{\underline{\texttt{#1}}\xspace}

% Zum Markieren von wichtigen Begriffen. Diese sollen hervorgehoben
% und in den Index aufgenommen werden.
\newcommand*{\highl}[2][]{\textbf{\boldmath{#2}}%
  \ifthenelse{\equal{#1}{}}{\index{#2}}{\index{#1}}%
}

% Befehl für die Darstellung der Gliederungsüberschriften im Index
\newcommand*{\lettergroup}[1]{\minisec{#1}}

\newcommand*{\obda}{o.\,B.\,d.\,A.\xspace}
\newcommand*{\sonst}{\text{sonst}}
\newcommand*{\leerz}{\ifthenelse{\boolean{mmode}}%
			       {\text{\textvisiblespace}}%
			       {\textvisiblespace}}
% \newcommand{\ndef}{\ifthenelse{\boolean{mmode}}%
% 			       {\text{n.\,def.}}%
% 			       {n.\,def.\xspace}}
\newcommand*{\ndef}{\ifthenelse{\boolean{mmode}}%
 			       {\perp}%
 			       {$\perp$\xspace}}
% \newcommand*{\gdw}{\ifthenelse{\boolean{mmode}}%
% 			       {\Leftrightarrow}%
% 			       {$\Leftrightarrow$\xspace}}
% \newcommand*{\gdwdef}{\ifthenelse{\boolean{mmode}}%
% 			       {:\Leftrightarrow}%
% 			       {$:\Leftrightarrow$\xspace}}
\newcommand*{\gdw}{\ifthenelse{\boolean{mmode}}%
			       {\mspace{8mu}gdw\mspace{8mu}}%
			       {$gdw$\xspace}}
\newcommand*{\gdwdef}{\ifthenelse{\boolean{mmode}}%
			       {\mspace{8mu}gdw_{def}\mspace{8mu}}%
			       {$gdw_{def}$\xspace}}

\renewcommand*{\vdash}{\mathrel{|\mkern-4mu-}\mathrel{\mkern-10mu-}}
\DeclarePairedDelimiter{\abs}{\lvert}{\rvert}

\renewcommand*{\epsilon}{\varepsilon}
\renewcommand*{\mod}{\bmod}

\newcounter{schritt}
\newenvironment*{schritte}%
	       {\begin{list}{\textit{\underline{\arabic{schritt}.\,Schritt:}}}%
		      {\usecounter{schritt}%
			\settowidth{\labelwidth}{\textit{\underline{99.\,Schritt:}}}%
			\setlength{\leftmargin}{1cm}%
			\setlength{\itemindent}{4mm}%
			\addtolength{\itemindent}{\labelwidth}%
			\addtolength{\itemindent}{-\leftmargin}%
		      }}%
	       {\end{list}}


\newenvironment*{mdescription}%
	        {\renewcommand*{\descriptionlabel}[1]%
			      {\hspace\labelsep\normalfont ##1}%
		 \begin{description}}%
		 {\end{description}}
\newenvironment*{auflistung}[1][\linewidth]%
               {\tabularx{#1}{r@{\;\ldots\;}X}}%
               {\endtabularx}

\makeindex

\SVN $LastChangedRevision$
\SVN $LastChangedDate$

\begin{document}

\title{Grundlagen der theoretischen Informatik}
\author{Dr.\,Jörg Vogel}
\date{SS 2003}
\maketitle

\pdfbookmark[0]{Inhaltsverzeichnis}{inhaltsverzeichnis}
\tableofcontents

\clearpage
\pdfbookmark[0]{Auflistung der Sätze}{theoremlist}
\chapter*{Auflistung der Theoreme}

\pdfbookmark[1]{Sätze}{satzlist}
\section*{Sätze}
\theoremlisttype{optname}
\listtheorems{satz}

\pdfbookmark[1]{Definitionen und Festlegungen}{definilist}
\section*{Definitionen und Festlegunden}
% \theoremlisttype{all}
\listtheorems{defini,festl}

\clearpage
\chapter*{Vorwort}

{\itshape
  Dieses Dokument wurde als Skript für die auf der
  Titelseite genannte Vorlesung erstellt und wird jetzt im Rahmen des
  Projekts
  "`\href{http://uni-skripte.lug-jena.de/}
  {Vorlesungsskripte der Fakultät für Mathematik}
  \href{http://uni-skripte.lug-jena.de/}{und Informatik}"'
  weiter betreut. Das
  Dokument wurde nach bestem Wissen und Gewissen angefertigt. Denoch
  garantiert weder der auf der Titelseite genannte Dozent, die Personen,
  die an dem Dokument mitgewirkt haben, noch die
  Mitglieder des Projekts für dessen Fehlerfreiheit. Für etwaige Fehler
  und dessen Folgen wird von keiner der genannten Personen eine Haftung
  übernommen. Es steht jeder Person frei, dieses Dokument zu lesen, zu
  verändern oder auf anderen Medien verfügbar zu machen, solange ein
  Verweis auf die Internetadresse des Projekts
  \url{http://uni-skripte.lug-jena.de/}
  enthalten ist.

  Diese Ausgabe trägt die Versionsnummer~\SVNLastChangedRevision\ und ist
  vom \SVNDate. Eine (mögliche) aktuellere Ausgabe ist auf der Webseite
  des Projekts verfügbar.

  Jeder ist dazu aufgerufen, Verbesserungen, Erweiterungen und
  Fehlerkorrekturen für das Skript einzureichen bzw. zu melden oder diese
  selbst einzupflegen -- einfach eine E-Mail an die
  \href{mailto:uni-skripte@lug-jena.de}{Mailingliste
  \texttt{<uni-skripte@lug-jena.de>}} senden. Weitere Informationen
  sind unter der oben genannten Internetadresse verfügbar.

  Hiermit möchten wir allen Personen, die an diesem Skript mitgewirkt
  haben, vielmals danken:
  \begin{itemize}
   \item \href{mailto:joerg@alea.gnuu.de}{Jörg Sommer
    \texttt{<joerg@alea.gnuu.de>}} (2005)
  \end{itemize}
}

\chapter{Berechenbarkeit}
\section{Was ist ein Algorithmus?}

1935 formulierte Alan Turing folgende Frage: "`Gibt es eine
\emph{effektive Prozedur}, die das Hilbertsche Problem löst?"'

\begin{description}
 \item[Hilbert'sche Problem:] Gegeben sei eine Menge von
  prädikaten-logischen Formeln und eine weitere Formel $F$. Ist $F$ eine
  Folgerung aus der Menge der gegebenen Formeln?
 \item[\textnormal{Umformulierung:}] Ist eine gegebene Formel erfüllbar
  oder nicht?
\end{description}

Das Problem von Turing war, dass es bis 1935 keine Präzisierung dessen
gab, was ein solches Verfahren ("`effektive Prozedur"') ist, obwohl es
schon seit jahrtausenden Rechenverfahren gab.

Beispiele für solche Verfahren:
\begin{itemize}
 \item Grundrechenarten für mehrstellige Zahlen
 \item Lösungsverfahren für Gleichungen
  \begin{itemize}
   \item lineare Gleichungen
   \item Polynome
   \item Differentialgleichungen
   \item Diophantische Gleichungen
  \end{itemize}
 \item Konstruktionsverfahren
  \begin{itemize}
   \item regelmäßiges 17-Eck
  \end{itemize}
 \item Rezepturen\ldots
  \begin{itemize}
   \item \ldots für Speißen
   \item \ldots für Arzeneimittel
   \item \ldots für Parfüme
  \end{itemize}
\end{itemize}

allen Rezepturen ist gemeinsam:
\begin{itemize}
 \item wohlbestimmte Menge an Ausgangsstoffen
 \item Folge exakter Handlungsanweisungen
 \item $\rightarrow$ Produkt
\end{itemize}
den Rechenverfahren ist gemeinsam:
\begin{itemize}
 \item wohldefinierte Menge von Ausgangsgrößen
 \item Folge von Rechenschritten
 \item $\rightarrow$ Resultat
\end{itemize}

Dies liefert einen ersten Ansatz für die Formulierung:
\begin{center}
  Eingabe $\xrightarrow{\hspace{1.5cm}}$
  {\setlength{\fboxsep}{5mm}\fbox{Algorithmus}}
  $\xrightarrow{\hspace{1.5cm}}$ Ausgabe\\
\end{center}

Ein konkretes Beispiel für einen Algorithmus ist der Euklidische
Algorithmus. Dazu später mehr.

\begin{defini}\label{def:5}
  Für zwei natürliche Zahlen $x$ und $y$ bezeichnet \highl[mod@$\mod$]{$x \mod y$} diejenige
  natürliche Zahl, die als \highl{Rest \textnormal{bei der} ganzzahligen Division} mit dem
  Dividenden $x$ und dem Divisor $y$ bleibt.
\end{defini}

Frage: Ist diese Festlegung sinnvoll? Was ist das Resultat?

\begin{satz}\label{satz:1}
  Für je zwei natürliche Zahlen $x$ und $y$ gibt es zwei eindeutig
  bestimmte Zahlen $q$ und $r$ mit folgenden Eigenschaften:
  \begin{itemize}
   \item $x = qy+r$
   \item $0 \leq r < y$
  \end{itemize}
\end{satz}

\begin{bemerk}
  \autoref{satz:1} rechtfertigt die folgende Bezeichnung:
  \begin{enumerate}
   \item $q = x \div y$
   \item $r = x\mod y$
  \end{enumerate}
\end{bemerk}

\highl{Euklidischer Algorithmus} -- informal
\begin{mdescription}
 \item[Eingabe:] zwei natürliche Zahlen $a$ und $b$
 \item[Ausgabe:] $r_{k-1}$
\end{mdescription}
\begin{schritte}
 \item Bestimmt $r = a \mod b$\\
  Falls $r=0$, dann gib $b$ aus, sonst gehe zum nächsten Schritt.
 \item Bestimme $r_{2} = b \mod r$\\
  Falls $r_{2} = 0$, dann gebe $r$ aus, sonst gehe zum nächsten Schritt.
 \item Bestimmt $r_{3} = r \mod r_{2}$\\
  Falls $r_{3} =0$, dann gebe $r_{2}$ aus, sonst gehe zum nächsten Schritt.
 \item Wiederhole das Verfahren solange, bis ein Wert $r_{k}=0$
  erreicht wird und gib den Wert $r_{k-1}$ aus.
\end{schritte}

\highl{Euklidischer Algorithmus} -- formal
\begin{enumerate}
 \item $a_{0}=a; a_{1} = b; i=0$
 \item \algokeyword{while} $a_{i+1} \ne 0$ \algokeyword{do}
 \item \quad $a_{i+2} = a_{i}$ \algokeyword{mod} $a_{i+1}$
 \item \quad $i=i+1$
 \item \algokeyword{return} $a_{i}$
\end{enumerate}

Zwei Fragen ergeben sich aus dieser Definition
\begin{enumerate}
 \item Ist die Ausgabe $a_{i}$ bzw. $r_{k-1}$ tatsächlich der größte
  gemeinsame Teiler der Zahlen $a$ und $b$? -- Ist das gegebene Verfahren
  \emph{korrekt}?
 \item Liefert das Verfahren das Resultat in einer praktikablen Zeit? --
  Ist das gegebene Verfahren \emph{effizient}?
\end{enumerate}
In unserem Fall lassen sich beide Fragen mit \emph{ja}
beantworten.

Eigenschaften von Algorithmen:\nopagebreak
\begin{itemize}
 \item endliche Beschreibung
 \item endlicher Datenbereich
 \item beschränkte Menge von Anfangs-Grundoperationen
 \item schrittweise Ausführung (bzw. endliche Parallelität)
 \item endliche Dauer jeder Grundoperation
 \item Determiniertheit -- zu jedem Zeitpunkt steht fest, welches der
  nächste Schritt ist
 \item Terminierung -- das Verfahren endet
\end{itemize}

\textbf{\large mathematische Formalisierung des Algorithmenbegriffs}

verschiedene Zugänge:
\begin{description}
 \item[Termersetzungssysteme]\listlinebreak
  \begin{itemize}
   \item Turing-Maschine (A.\,Turing, 1936) -- \autoref{cha:1}
   \item Post'sche Systeme (M.\,Post, 1943)
   \item Markovalgorithmen (M.\,Markov, 1951)
  \end{itemize}
 \item[algebraischer Zugang]\listlinebreak
  \begin{itemize}
   \item partiell-rekursive Funktionen (Kleene, Herbrand, Gödel, 1936)
    -- \autoref{cha:2}
   \item $\lambda$-definierbare Funktionen (Church, 1936)
  \end{itemize}
 \item[theoretische Modelle]\listlinebreak
  \begin{itemize}
   \item Registermaschinen (Sheperson, 1964)
  \end{itemize}
\end{description}

\begin{satz}[Hauptsatz der Algorithmentheorie]
  Alle verschiedene Formalisierungen des Algorithmenbegriffs sind äuqivalent.
\end{satz}

\begin{satz}[These von Church]\label{satz:church}
  Alle Algorithmenbegriffe beschreiben die Klasse der im intuitiven Sinne
  berechenbaren Funktionen!
\end{satz}

\chapter{Turing-Maschinen}\label{cha:1}
\section{Wörter und Sprachen}\label{sec:1}

Eine endliche Menge $\Sigma$, z.\,B. $\Sigma=\{a_{1},a_{2}, \ldots,
a_{n}\}$, bezeichnet man als \highl{Alphabet}. Ein Element des Alphabets
$x\in\Sigma$ nennt man \highl{Buchstabe}. Jede endliche Folge
$x_{1}\ldots x_{m}$ von Buchstaben aus $\Sigma$ heißt \highl{Wort} über
dem Alphabet $\Sigma$. Die Anzahl $m$ der Buchstaben eines Wortes $w$
heißt \highl{Länge des Wortes} und wird mit $\abs{w}$ bezeichnet.

Eine besondere Rolle spielt das "`\highl{leere Wort}"' der Länge null --
also kein Buchstabe. Die Bezeichnung dafür ist $\lambda$
\index{lambda@$\lambda$} oder $\epsilon$. \index{epsilon@$\epsilon$}

$\Sigma^{\ast}$ bezeichnet die \highl{Menge aller endlichen Wörter}
(inkl.~$\lambda$). Angenommen die Buchstaben $a_{1},\ldots,a_{n}$ von
$\Sigma$ sind geordnet $a_{1} < a_{2} < \ldots < a_{n}$. Dann ergibt sich
hieraus eine \highl{kanonische Ordnung} für $\Sigma^{\ast}$.
\begin{align*}
  w_{1}< w_{2} \gdwdef& \abs{w_{1}} < \abs{w_{2}} \text{ oder}\\
  & (w_{1} = wx_{1}w_{1}', w_{2}=wx_{2}w_{2}' \wedge x_{1} < x_{2})
\end{align*}
oder in Worten ausgedrück: wenn $w_{1}$ und $w_{2}$ die gleiche Länge
haben, dann ist der erste Buchstabe von links, in dem sich $w_{1}$ und
$w_{2}$ unterscheiden, in $w_{1}$ kleine als der in $w_{2}$. Die
Reihenfolge von $\Sigma^{\ast}$ heißt auch \highl{quasilexikographische
Reihenfolge}

Es sei $\Sigma$ ein Alphabet. Dann bezeichnet
\begin{align*}
  \Sigma^{0} &:= \{\lambda\}\\
  \Sigma^{1} &:= \Sigma\\
  \Sigma^{n+1} &:= \{ wx\colon w\in\Sigma^{n},  x\in\Sigma \}\\
  \Sigma^{\ast} &= \bigcup_{n=0}^{\infty} \Sigma^{n}\\
  \Sigma^{+} &:= \Sigma^{\ast}\setminus \{\lambda\}
\end{align*}

Für zwei Wörter $u,v\in\Sigma^{\ast}$ mit $u=x_{1}\ldots x_{m}$ und
$v=y_{1} \ldots y_{n}$ bezeichnet die \highl{Konkatenation}
(Hintereinanderschreibung) $u\cdot v$ (oder $uv$) das Wort $x_{1}\ldots
x_{m}y_{1}\ldots y_{n}$.

Für ein Wort $w\in\Sigma^{\ast}$ mit $w=x_{1}\ldots x_{m}$ bezeichnet man
das Wort $w^{R}=x_{m}x_{m-1}\ldots x_{1}$ als \highl{Spiegelwort}.

Man bezeichnet $L\subseteq \Sigma^{\ast}$ als \highl{formale Sprache}.
Für zwei Sprachen $L_{1},L_{2}\subseteq \Sigma^{\ast}$ ist die
\highl{Konkaternation} $L_{1}\cdot L_{2} := \{ u\cdot v\colon u\in L_{1}, v\in
L_{2}\}$. Für eine Sprache $L\subseteq \Sigma^{\ast}$ ist die
\highl{Spiegelsprache} $L^{R}$ definiert durch $\{w^{R}\colon w\in L\}$.

Für ein Wort $w\in\Sigma^{\ast}$ sind die \highl{Potenzen} von $w$
gleichermaßen definiert:
\begin{align*}
  w^{0} &:=\lambda\\
  w^{1} &:=w\\
  w^{n+1} & := w^{n}\cdot w
\end{align*}
Die $n$-te Pozenz ist also das Wort, das durch $n$-fache
Hintereinanderschreibung entsteht.

Für eine Sprache $L\subseteq \Sigma^{\ast}$  sind die \highl{Potenzen}
von $L$ folgendermaßen definiert:
\begin{align*}
  L^{0} &:= \{\lambda\}\\
  L^{1} &:= L\\
  L^{n+1} &:= L^{n}\cdot L
\end{align*}
Die $n$-te Potenz einer Sprache besteht also aus all denjenigen Wörtern,
die das $n$-fache Produkt irgendwelcher Wörter aus $L$ sind.

Für eine Sprache $L\subseteq \Sigma^{\ast}$ bezeichnet
\begin{gather*}
  L^{\ast}:= \bigcup_{n=0}^{\infty} L^{n}
\end{gather*}
die \highl{Kleene-Hülle} von $L$.

\subsection{Spezielle Alphabete}
\begin{align*}
  \Sigma_{latein} &:= \{ a,b,c,\ldots,x,y,z \}\\
  \Sigma_{dezi} &:= \{ 0,\ldots,9 \}\\
  \Sigma_{bool} &:= \{ 0,1\}\\
  \Sigma_{Tastatur} &:= \{
     a,\ldots,z,A,\ldots,Z,0,\ldots,9,-,+,:,\ldots\} \cup \{ \leerz \}
\end{align*}
\textbf{Achtung:} Es gilt $\abs{\leerz}=1$!

\begin{bemerk}
  Jeder Roman ist ein Wort über dem Alphabet $\Sigma_{Tastatur}$.
\end{bemerk}

Wir definieren für Wörter $w\in \Sigma_{bool}^{\ast}$ der Form
$x_{1}\ldots x_{n}$ die Funktion
\begin{gather*}
  No_{2}(w)\colon \Sigma_{bool}^{\ast} \rightarrow \N,
  w \mapsto \sum_{i=1}^{n}x_{i} 2^{n-i}
\end{gather*}

Das kürzeste Wort~$w$ mit der Eigenschaft $No_{2}(w)=n$ heißt
\highl{Binärdarstellung} von $n$. Schreibweise: $bin(n) := w$.

Für Wörter $w\in\Sigma_{dezi}^{\ast}$ definieren wir analog:
\begin{gather*}
  No_{10}(w) := \sum_{i=1}^{n} x_{i} 10^{n-i}
\end{gather*}
und die \highl{Dezimaldarstellung} $dezi(n)$ als das kürzeste Wort $w$
mit $No_{10}(w) := n$.

Eine Abbildung $f\colon\Sigma^{\ast} \rightarrow \Delta^{\ast}$ heißt
\highl{Homomorphismus} von $\Sigma^{\ast}$ in $\Delta^{\ast}$ \gdwdef für
alle Wörter $u,v\in\Sigma^{\ast}$ gilt: $f(u\cdot v) = f(u)\cdot f(v)$.

\section{Der Begriff der Turing-Maschine}

Zunächst eine informale Beschreibung der Bestandteile einer Turing-Maschine:
\begin{itemize}
 \item Ein nach rechts und links unendliches Arbeitsband
  (\highl{Turing-Band}), das in Felder (Zellen) unterteilt ist.
 \item In jeder Zelle kann ein Buchstabe eines gegebenen
  Alphabets~$\Sigma$ stehen oder die Zelle ist leer.

  Bezeichnung für eine leere Zelle: $\Box$

  Beispiel für $\Sigma = \Sigma_{latin}$
  \todo{Beispiel des Turing-Bandes}
 \item Auf dem Band agiert ein Lese-Schreib-Kopf.
 \item Dieser Kopf steht auf genau einer Zelle des Bandes und kann in
  einem Takt den Inhalt dieser Zelle lesen und überschreiben.
 \item Ein endliches Gedächtnis steuert diesen Arbeitskopf und kann einen
  von endlich vielen inneren Zuständen annehmen.
 \item In Abhängigkeit vom gelesenen Symbol und dem inneren Zustand wird
  eine Aktion ausgeführt.
 \item Eine solche Aktion hat drei Bestandteile:\listlinebreak
  \begin{itemize}
   \item neues Symbol schreiben
   \item neuen inneren Zustand annehmen
   \item Bewegung des Kopfes um eine Zelle
  \end{itemize}
\end{itemize}

\begin{defini}[Formale Beschreibung der Turing-Maschine]
  Eine \highl{Turing-Maschine} $M$ ist gegeben durch ein Sextupel
  $M=(Q,\Sigma,\Gamma, \delta, q_{0}, F)$ mit den Elementen\\
  \begin{auflistung}
    $Q$& eine endliche Menge (Zustandsmenge)\\
    $\Sigma$& ein endliches Alphabet (Eingabealphabet)\\
    $\Gamma$& ein endliches Alphabet (Arbeitsalphabet), wobei
       $\Sigma\subseteq\Gamma$\\
    $\delta$ & Überführungsfunktion $Q\times \Gamma \rightarrow Q\times
       \Gamma\times\{L,0,R\}$ (links, stehen, rechts)\\
    $q_{0}\in Q$& Startzustand\\
    $F\subseteq Q$& Finalzustände
  \end{auflistung}
\end{defini}

Vereinbarung: \highl{Blanksymbol} $\Box\in\Gamma\setminus\Sigma$
(damit die Turing-Maschine die Enden der Eingabe erkennen kann) und
$Q\cap\Gamma=\emptyset$ (dies ist für die Definition einer Konfiguration
(\autoref{def:6}) erforderlich).

\begin{bsp}
  Beispiel einer aktuellen Situation einer Turing-Maschine.

  \todo{bild einfügen}

  Es sei $\delta(q,b) = (q', a, R)$. Damit ist die neue Situation:

  \todo{bild einfügen}
\end{bsp}

\begin{bemerk}
  Dieser Übergang heißt \highl{Takt} der Maschine.
\end{bemerk}

\begin{defini}\label{def:6}
  Es ein $M=(Q,\Sigma,\Gamma,\delta,q_{0},F)$ eine Turing-Maschine. Eine
  \highl{Konfiguration} von $M$ ist ein Wort $\alpha\cdot q\cdot\beta\in
  \Gamma^{\ast}\times Q\times\Gamma^{\ast}$. Dabei bezeichnet $q\in Q$
  den aktuellen Zustand der Maschine und
  $\alpha\cdot\beta\in\Gamma^{\ast}$ die aktuelle Bandinschrift der
  Maschine.
\end{defini}

\begin{bemerk}
  Zu jedem Zeitpunkt sind höchstens endlich viele Symbole veschieden vom
  Blanksymbol. Damit beschreibt eine Konfiguration eine Momentansituation
  von $M$.
\end{bemerk}

\begin{bsp}
  $K_{1} = aqbba$ und $K_{2}=aaq'ba$. Der Lese-Schreib-Kopf befindet sich
  auf der ersten Zelle des "`rechten Teils"' von $\beta$.
\end{bsp}

\begin{defini}
  Wir definieren auf der Menge der Konfigurationen eine zweistellige
  Relation
  \begin{gather*}
    \vdash \subseteq (\Gamma^{\ast}\cdot Q\cdot\Gamma^{\ast})
       \times (\Gamma^{\ast}\cdot Q\cdot\Gamma^{\ast})\\[1.5ex]
    a_{1}a_{2}\ldots a_{m} \underbrace{q}_{\mathclap{\in Q}}
    b_{1}b_{2}\ldots b_{n} \vdash
    \begin{cases}
      a_{1}a_{2}\ldots a_{m}cq'b_{2}\ldots b_{n}&: \delta(q,b_{1}) =
      (q',c,R)\\
      a_{1}a_{2}\ldots a_{m}q'cb_{2}\ldots b_{n}&: \delta(q,b_{1}) =
      (q',c,0)\\
      a_{1}a_{2}\ldots q'a_{m}cb_{2}\ldots b_{n}&: \delta(q,b_{1}) =
      (q',c,L)
    \end{cases}
  \end{gather*}

  Zwei Sonderfälle:
  \begin{enumerate}
   \item Der Lese-Schreib-Kopf steht am rechten Rand und bewegt sich nach
    rechts:
    \begin{gather*}
      a_{1}\ldots a_{m}qb_{1} \mapsto a_{1}\ldots a_{m}cq'\Box
    \end{gather*}
    falls $\delta(q,b_{1}) = (q',c,R)$.
   \item Der Lese-Schreib-Kopf steht am linken Rand und bewegt sich nach
    links:
    \begin{gather*}
      qb_{1}b_{2} \ldots b_{n} \mapsto q'c\Box b_{2} \ldots b_{n}
    \end{gather*}
    falls $\delta(q,b_{1}) = (q',c,L)$.
  \end{enumerate}
\end{defini}

\begin{defini}
  Es sei $M$ eine Turing-Maschine und es seien $K_{1}, K_{2}$ zwei Konfigurationen
  von $M$.

  \begin{enumerate}
   \item $K_{2}$ ist \highl{unmittelbare Nachfolgekonfiguration} von
    $K_{1}$ \gdwdef $K_{1} \vdash K_{2}$.
   \item $K_{2}$ ist eine \highl{Folgekonfiguration} von $K_{1}$
    \gdwdef $K_{2}=K_{1}$ oder es existiert eine endliche Folge
    $K_{1}', K_{2}',\ldots,K_{m}'$ mit $K_{1} = K_{1}' \vdash K_{2}',
    K_{2}' \vdash K_{3}', \ldots, K_{m-1}' \vdash K_{m}' = K_{2}$.

    Schreibweise: $K_{1}\vdash^{\ast} K_{2}$
  \end{enumerate}
\end{defini}

\begin{bemerk}
  $\vdash^{\ast}$ ist eine reflexive und transitive Hülle von $\vdash$.
\end{bemerk}

\begin{defini}
  Die \highl{Startkonfiguration} der Turing-Maschine $M$ bei der Eingabe
  $w\in\Sigma^{\ast}$ ist $q_{0}w = Start-Konf_{M}(w)$. Jede
  Konfiguration von $M$ der Form $\alpha q_{F} \beta$ heißt
  \highl{Endkonfiguration} (oder \highl{Finalzustand}), falls $q_{F}\in
  F$.
\end{defini}

\subsection{Beispiele für Turing-Maschinen}
\begin{bsp}\label{bsp:1}
  $L=\{w\in\{a,b\}^{\ast} \colon w^{R}=w\}$ ist die Menge aller
  \highl{Palindrome} über $\{a,b\}$.

  Ziel: Konstruktion einer Turing-Maschine $M$, die $L$ im folgenden Sinne erkennt:
  \begin{enumerate}
   \item $w\in L$, dann löscht $M$ die Eingabe $w$, schreibt ein "`a"'
    und stoppt im Finalzustand.
   \item $w\in\{a,b\}^{\ast}\setminus L$, dann löscht $M$ diese Eingabe
    $w$, schreibt ein "`b"' und stoppt im Finalzustand.
  \end{enumerate}

  Zustände:\\
  \begin{auflistung}
    $q_{0}$& Startzustand\\
    $q_{a}$& merke sich "`a"' und Kopf läuft nach rechts\\
    $q_{b}$& merke sich "`b"' und Kopf läuft nach rechts\\
    $q_{a}'$& testet "`a"' und Kopf läuft nach links\\
    $q_{b}'$& testet "`b"' und Kopf läuft nach links\\
    $q_{+}$& Test positiv\\
    $q_{-}$& Test negativ\\
    $q_{F}$& Finalzustand
  \end{auflistung}
  $\Sigma = \{a,b\}$\\
  Zustandsüberführungsfunktion $\delta$:\\
  \begin{tabular}{*{3}{c|}c}
    \backslashbox{$Q$}{$\Gamma$}& $a$ & $b$& $\Box$ \\
    \hline
    $q_{0}$& $(q_{a},\Box, R)$& $(q_{b},\Box, R)$& $(q_{F},a, 0)$\\
    $q_{a}$& $(q_{a},a, R)$& $(q_{b},b, R)$& $(q_{a}',\Box, L)$\\
    $q_{b}$& $(q_{b}, a, R)$& $(q_{b}, b, R)$& $(q_{b}', \Box, L)$\\
    $q_{a}'$& $(q_{+}, \Box, L)$& $(q_{-}, \Box, L)$& $(q_{F}, a, 0)$\\
    $q_{b}'$& $(q_{-}, \Box, L)$& $(q_{+}, \Box, L)$& $(q_{F}, a, 0)$\\
    $q_{+}$& $(q_{+}, a, L)$& $(q_{+}, b, L)$& $(q_{0}, \Box, R)$\\
    $q_{-}$& $(q_{-}, \Box, L)$& $(q_{-}, \Box, L)$& $(q_{F}, b, 0)$\\
    $q_{F}$& $(q_{F}, a, 0)$& $(q_{F}, b, 0)$& $(q_{F}, \Box, 0)$
  \end{tabular}

  Die Überführungsfunktion ist stets eine \highl{totaldefinierte
  Fuktion}! Das bedeutet, es gibt keine undefinierten Situationen oder
  bildlich gesprochen, keine der Tabellenzellen ist leer! Wenn
  ein Finalzustand erreicht wird, stoppt die Maschine (von außen
  betrachtet) bzw. ist in einer Endlosschleife (von innen betrachtet).
\end{bsp}

\begin{bsp}
  Wir konstruieren eine Maschine $M$, die die Sprache $L=\{a^{n}b^{n}:
  n\geq 1\} \subseteq \{a,b\}^{\ast}$ erkennt.

  $M$ arbeitet in zwei Etappen:
  \begin{enumerate}%[1.\,{Etappe}]
   \item $M$ testet, ob die Eingabe von der Form $a^{i}b^{j}$ ist.
   \item $M$ testet, ob $i =j$ ist.
  \end{enumerate}

  \begin{longtable}{r@{\;\ldots\;}p{.75\linewidth}}
    $q_{0}$& \parbox[t]{\linewidth}{
	       falls "`a"' gelesen wird: Bewegung nach rechts\\
	       falls "`b"' gelesen wird: Übergang in $q_{1}$\\
	       falls "`$\Box$"' gelesen wird: "`Fehler"'
	     }\\
    $q_{1}$& \parbox[t]{\linewidth}{
    	       falls "`a"' gelesen wird: "`Fehler"'\\
    	       falls "`b"' gelesen wird: Bewegung nach rechts\\
    	       falls "`$\Box$"' gelesen wird: Übergang in $q_{2}$
    	     }\\
    $q_{2}$& \parbox[t]{\linewidth}{
    	       löscht das rechteste "`b"': Übergang in $q_{3}$\\
    	       lese "`a"' oder "`$\Box$"': "`Fehler"'
    	     }\\
    $q_{3}$& Bewegung nach links bis zum ersten $\Box$: Übergang in $q_{4}$\\
    $q_{4}$& \parbox[t]{\linewidth}{
    	       streiche das "`a"': Übergang zu $q_{5}$\\
    	       falls "`b"' oder "`$\Box$"': "`Fehler"'
    	     }\\
    $q_{5}$& \parbox[t]{\linewidth}{
    	       testet, ob der "`Rest"' das leere Wort ist: Fianlzustand $q_{7}$\\
    	       lesse "`a"' oder "`b"': Übergang zu $q_{6}$
    	     }\\
    $q_{6}$& Bewegung nach rechts bis zum ersten $\Box$: Übergang zu $q_{2}$\\
    $q_{7}$& Finalzustand
  \end{longtable}
  \begin{tabular}{c|ccc}
    & $a$ & $b$ & $c$\\
    \hline
    $q_{0}$ & $(q_{0}, a, R)$ & $(q_{1}, b, R)$&
	 $(q_{0},\Box,0)^{\star}$\\
    $q_{1}$& $(q_{1},a,0)^{\star}$ & $(q_{1}, b, R)$& $(q_{2}, \Box, L)$\\
    $q_{2}$& $(q_{2},a,0)^{\star}$ & $(q_{3}, \Box, L)$& $(q_{2}, \Box,
	 0)^{\star}$\\
    $q_{3}$& $(q_{3},a,L)$ & $(q_{3}, b, L)$& $(q_{4}, \Box, R)$\\
    $q_{4}$& $(q_{5},\Box,R)$ & $(q_{4}, b, 0)^{\star}$& $(q_{4}, \Box,
	 0)^{\star}$\\
    $q_{5}$& $(q_{6},a,R)$ & $(q_{6}, b, R)$& $(q_{7}, \Box, 0)$\\
    $q_{6}$& $(q_{6},a,R)$ & $(q_{6}, b, R)$& $(q_{2}, \Box, L)$\\
    $q_{7}$& $(q_{7},a,0)$ & $(q_{7}, b, 0)$& $(q_{7}, \Box, 0)$\\
  \end{tabular}\\
  \textit{$^{\star}$: Für diese Zustände stoppt die Maschine mit "`Fehler"'.}

  Es gilt: $M$ erreicht bei Eingabe $w$ den Finalzustand~$q_{7}$
  \gdw $w\in L$.
\end{bsp}

\section{Exkurs über Zahlenfunktionen}
Es sei $b>1\in\N$ \highl{Basis}

\subsection{\texorpdfstring{$b$}{b}-näre Zahlendarstellung}
Ziffern $\{0,1,\ldots,b-1\}$

Fakt: Jede natrüliche Zahl $n\geq0$ besitzt eine eindeutige Darstellung
der Form
\begin{gather*}
  m=x_{m}b^{m}+ x_{m-1}b^{m-1} + \ldots + x_{2}b^{2} + x_{1}b+x_{0}
\end{gather*}
wobei $x_{m},\ldots,x_{0}\in\{0,\ldots,b-1\}$ und $x_{m}\ne0$ sind.

Schreibweise: $bnaer(n) = x_{m}x_{m-1}\ldots x_{2}x_{1}x_{0}$

$bnaer \colon \N \rightarrow \{0,1,\ldots,b-1\}^{\ast}$ ist eine eindeutige,
aber nicht bijektive Abbildung.

speziell: $b=2$ mit den Ziffern $\{0,1\}$ heißt binär; z.\,B.: $bin(17)
=10001$, aber $010001\in\{0,1\}^{\ast}$ ist kein Bild der Abbildung.

\subsection[\texorpdfstring{$b$}{b}-adische Darstellung]%
	   {$\boldsymbol{b}$-adische Darstellung}\label{sec:bad}
Ziffern $\{1,2,\ldots,b\}$

\begin{fakt}
  jede natürliche Zahl $n>0$ besitzt eine eindeutige Darstellung der Form
  \begin{gather*}
    n=y_{n}b^{n}+ y_{n-1}b^{n-1}+\ldots + y_{1}b^{1} + y_{0}
  \end{gather*}
  wobei $y_{n},y_{n-1},\ldots,y_{0}\in\{1,2,\ldots,b\}$
\end{fakt}

Schreibweise: $bad(m) = y_{n}y_{n-1}\ldots y_{0}$, $bad(0) = \lambda$.

Die Abbildung $bad \colon \N\rightarrow\{1,2,\ldots,b\}^{\ast}$ ist eine
Bijektion.

speziell: $b=2$ dyadisch; $dya\colon \N \rightarrow \{1,2\}^{\ast}$ ist
injektiv und surjektiv; z.\,B.: $dya(17) = 1121$

\section{Turing-Berechenbarkeit}
Sei $M= (Q,\Sigma,\Gamma,\delta, q_{0}, F)$ eine Turing-Maschine. Ferner seien
$\Box,\#\in\Gamma, \Delta\subseteq\Gamma\setminus\{\Box\},
\Sigma\subseteq \Gamma\setminus\{\Box,\#\}$ und $n>0$.

Eine Turing-Maschine $M$ \highl{berechnet} eine ($n$-stellige) Funktion
$f\colon\bigl(\Sigma^{\ast}\bigr)^{n} \rightarrow \Delta^{\ast}$, falls gilt:
\begin{enumerate}
 \item Für $(w_{1},w_{2},\ldots,w_{n})\in \bigl(\Sigma^{\ast}\bigr)^{n}$
  sei $f$ definiert und für die Startkonfiguration\\
  $q_{0}w_{1}\#w_{2}\#\ldots\#w_{n}$ gilt:
  \begin{gather*}
    q_{0}w_{1}\#w_{2}\#\ldots\#w_{n} \vdash^{\ast}
    q_{F}f(w_{1},w_{2},\ldots,w_{n})
  \end{gather*}
  mit $q_{F}\in F$.
 \item Falls $f$ für $(w_{1},w_{2},\ldots,w_{n})\in
  \bigl(\Sigma^{\ast}\bigr)^{n}$ \highl{nicht definiert} (Symbol:
  \ndef) ist, dann ausgehend von $q_{0}w_{1}\#w_{2}\#\ldots\#w_{n}$,
  stoppt $M$ nicht oder $M$ stoppt \emph{nicht} in einem Finalzustand.
\end{enumerate}

\begin{defini}
  Eine \highl{Wortfunktion} $f\colon \bigl(\Sigma^{\ast}\bigr)^{n} \rightarrow
  \Delta^{\ast}$ heißt \highl{Turing-berechenbar} \gdwdef es eine
  Turing-Maschine $M$ gibt, die $f$ berechnet.
\end{defini}

\begin{defini}\label{def:1}
  Eine \highl{Zahlenfunktion} $g\colon\N^{n}\rightarrow\N$ heißt
  \highl{Turing-berechenbar} \gdwdef $g$ bei dyadischer
  Codierung $f_{g}$ ($f_{g}$ ist eine Wortfunktion $\{1,2\}^{\ast}
  \rightarrow \{1,2\}^{\ast}$) Turing-brechenbar ist, d.\,h.
  \begin{gather*}
    f_{g}(y_{1}, y_{2}, \ldots, y_{n}) = dya\Bigl(g
    \bigl(dya^{-1}(y_{1}), \ldots, dya^{-1}(y_{n}) \bigr) \Bigr)
  \end{gather*}
\end{defini}

\begin{defini}\label{def:2}
  Eine Sprache $L\subseteq\Sigma^{\ast}$ heißt
  \highl{Turing-entscheidbar} \gdwdef die
  \highl{charakteristische Funktion} $\chi_{L}$ Turing-berechenbar ist
  \begin{gather*}
    \chi_{L}(w) = \begin{cases}
		 1&\colon w\in L\\
		 0&\colon w\notin L
	       \end{cases}
  \end{gather*}
\end{defini}

\begin{defini}\label{def:3}
  Eine Sprache $L\subseteq \Sigma^{\ast}$ heißt
  \highl{Turing-semientscheidbar} \gdwdef die
  \highl{partielle charakteristische Funktion} $\chi_{L}^{p}$
  Turing-berechenbar ist
  \begin{gather*}
    \chi_{L}^{p}(w) = \begin{cases}
			1&\colon w\in L\\
			\ndef&\colon w\notin L
		      \end{cases}
  \end{gather*}
\end{defini}

\begin{defini}\label{def:4}
  Eine Sprache $L\subseteq\Sigma^{\ast}$ heißt \highl{Turing-aufzählbar}
  \gdwdef eine total definierte Turing-berechenbare
  Funktion $f\colon\Sigma^{\ast} \rightarrow_{t}\Sigma^{\ast}$ existiert, so dass
  $f(\Sigma^{\ast}) = L$.
\end{defini}

\begin{bemerk}
  $f$ könnte z.\,B. die folgende Abbildung machen
  \begin{gather*}
    f(w) =
       \begin{cases}
         w & \colon w\in L\\
         u & \colon w\notin L
       \end{cases}
  \end{gather*}
  $u$ ist dabei ein bekanntes festes Wort aus $L$. Dies könnte z.\,B.
  $\lambda$ sein, falls $\lambda\in L$.
\end{bemerk}

\subsection{Normierte Startsituation}
\begin{itemize}
 \item Definition trifft keine Aussage über das Verhalten einer Turing-Maschine für
  Eingaben, die nicht von der erwarteten Form sind. Es ist nicht geklärt,
  was passiert, wenn Zeichen $\notin \Sigma\cup\Gamma$ auf dem Band
  stehen.
 \item Jede Turing-Maschine berechnet für jede natürliche Zahl $n>0$ eine
  $n$-stellige Funktion.
\end{itemize}

\subsection{partielle Funktionen}
Als berechenbare Funktionen werden auch solche angesehen, die nicht
überall definiert sind.

\begin{bsp}
  Wir definieren für $\Sigma=\{1,2\}$ die Turing-Maschine $M =(\{q_{0},
  q_{F}\}, \Sigma, \Sigma\cup\{\Box\}, \delta, q_{0}, \{q_{F}\})$
  \begin{align*}
    \delta(q_{0},1) &= (q_{0}, 1, R) &\delta(q_{F}, 1) &= (q_{F}, 1,0)\\
    \delta(q_{0},2) &= (q_{0}, 2, R) &\delta(q_{F}, 2) &= (q_{F}, 2,0)\\
    \delta(q_{0},\Box) &= (q_{0}, \Box, R) &\delta(q_{F}, \Box) &=
	 (q_{F}, \Box,0)
  \end{align*}
  $\delta(q_{F},\ast)$ ist die Verfollständigung der
  Überführungsfunktion, obwohl $q_{F}$ nie erreicht wird.

  $M$ berechnet die \highl[Funktion!nirgends definierte]{"`nirgends definierte"' Funktion}
  $f\colon\Sigma^{\ast} \rightarrow\Sigma^{\ast}$
  \begin{align*}
    f(w) = \ndef &&\forall w\in\Sigma^{n}
  \end{align*}
  Dies gilt für den Definitionsbereich $D\ne\emptyset$ und damit
  $f(D)=\emptyset$
\end{bsp}

\subsection{Wortfunktionen}
Die Abbildung $bad\colon \N\rightarrow\{1,2,\ldots,b\}^{\ast}$ (für eine
Basis $b>1$) aus \autoref{sec:bad} ist eine Bijektion zwischen den Zahlen und den Wörten.
Diese Bijektion erlaubt eine natürliche Zahl $n$ mit dem Wort
$bad(n)$ und schließlich die Menge $\N$ mit $\{1,2,\ldots,b\}^{\ast}$
zu identifizieren.

Jedes Alphabet $\Sigma$ mit $k$~Buchstaben kann durch Umbennen in
$\{1,2,\ldots,k\}$ übersetzt werden und damit kann $\Sigma^{\ast}$ mit
$\N$ identifiziert werden.

\begin{bsp}
  Eine Turing-Maschine, die die Nachfolgerfunktion dyadischer Darstellung
  berechnet:\\
  $\Sigma=\{1,2\}, \Gamma=\{1,2,\Box\}$\\
  \begin{auflistung}[0.4\linewidth]
    $q_{0}$& Startzustand\\
    $q_{U1}$& Übertrag 1\\
    $q_{U0}$& Übertrag 0\\
    $q_{F}$& Finalzustand
  \end{auflistung}
  \begin{tabular}{c|ccc}
    $\delta$& $1$& $2$ & $\Box$\\
    \hline
    $q_{0}$ & $(q_{0}, 1, R)$& $(q_{0}, 2, R)$& $(q_{U1}, \Box, L)$\\
    $q_{U1}$ & $(q_{U0}, 2, L)$& $(q_{U1}, 1, L)$& $(q_{F}, 1, 0)$\\
    $q_{U0}$ & $(q_{U0}, 1, L)$& $(q_{U0}, 2, L)$& $(q_{F}, \Box, R)$\\
    $q_{F}$ & $(q_{F}, 1, 0)$& $(q_{F}, 2, 0)$& $(q_{F}, \Box, 0)$
  \end{tabular}
\end{bsp}

Wir haben in \autoref{def:1} die Festlegung getroffen:
Eine Zahlenfunktion $g\colon\N^{n} \rightarrow\N$ heißt
Turing-berechenbar \gdwdef die Wortunktion $f$
Turing-berechenbar ist:
\begin{gather*}
  f\colon \big(\{1,2\}^{\ast}\big)^{n} \rightarrow \{1,2\}^{\ast}, f(y_{1},\ldots,y_{n}) =
  dya\Bigl(g\bigl(dya^{-1}(y_{1}), \ldots,dya^{-1}(y_{n}) \bigr)\Bigr)
\end{gather*}

Eine "`großzügigere"' Definition der Berechenbarkeit wäre die folgende:
\begin{defini}
  Eine Zahlenfunktion $g\colon\N^{n}\rightarrow\N$ heißt
  \highl{Turing-berechenbar} \gdwdef zwei natürliche
  Zahlen $b_{1},b_{2} >1$ und eine Turing-berechenbare Funktion
  \begin{gather*}
    h\colon (\{1,\ldots,b_{1}\}^{\ast})^{n} \rightarrow
    \{1,\ldots,b_{2}\}^{\ast}, (z_{1}, \ldots,z_{n}) \mapsto
    b_{2}ad\Bigl( g \bigl(b_{1}ad^{-1}(z_{1}), \ldots,
    b_{1}ad^{-1}(z_{n}) \bigr) \Bigr)
  \end{gather*}
  existieren.
\end{defini}

\begin{mdescription}
 \item[Frage:] Führen diese zwei verschiedenen
  Definitionen auf zwei verschiedene Arten von Berechenbarkeit?
 \item[Wir zeigen:] Falls $h$
  Turing-berechenbar ist, dann folgt daraus, dass auch $f$
  Turing-berechenbar ist. Beide Definitionen sind also gleichwertig.
  \begin{align*}
    f(y_{1},\ldots,y_{n}) &= dya\Bigl( g \bigl(dya^{-1}(y_{1}),\ldots,
       dya^{-1}(y_{n}) \bigr)\Bigr)\\
    &= dya\biggl( \underbrace{b_{2}ad^{-1}\Bigl( \underbrace{h\bigl(
       \underbrace{b_{1}ad(
       \underbrace{dya^{-1}
         (\underbrace{y_{1}}_{\mathclap{\in\{1,2\}^{\ast}}})}_{\in \N} )
       }_{\in\{1,\ldots,b_{1}\}^{\ast}},
       \ldots, b_{1}ad(dya^{-1}(y_{n})) \bigr)}_{\in\{1,\ldots,b_{2}\}^{\ast}}
        \Bigr)}_{\in\N} \biggr)\\
    &= \bigl(b_{2}ad^{-1} \circ dya \bigr) h( (dya^{-1}\circ
       b_{1}ad)(y_{1}), \ldots, (dya^{-1}\circ b_{1}ad)(y_{n}) )
  \end{align*}
\end{mdescription}

\begin{fakt}\mbox{}\\
  \begin{tabularx}{.9\linewidth}{XcX}
    \parbox{\linewidth}{\centering $(b_{2}ad^{-1} \circ dya)$} & &
       \parbox{\linewidth}{\centering $(dya^{-1}\circ b_{1}ad)$}\\
    & und & \\
    Umrechnung von $b_{2}$-adischer in dyadische Darstellung
       && Umrechnung von dyadischer in $b_{1}$-adishe Darstellung\\
    \multicolumn{3}{c}{sind "`einfach"' durch Turing-Maschinen berechenbar.}
  \end{tabularx}
\end{fakt}

\begin{bemerk}[Verkettung von Funktionen]
  zur Verkettung von Funktionen:
  \begin{center}
    \input{verkettung.pdf_t}\\
    $c = g(b) = g(f(a)) = (f\circ g)(a)$
  \end{center}

  Es gilt: $(a,c) \in f\circ g \gdwdef \exists b\in B\colon
  (a,b)\in f, (b,c)\in g$
\end{bemerk}

\begin{description}
 \item[Fazit:] Es gibt \emph{einen} Begriff der Turing-Berechenbarkeit für Wort-
  und Zahlenfunktionen, unabhängig von der Darstellung.
\end{description}

\begin{defini}
  \TM\index{TM@\TM} ist die \highl[Klasse!Turing-ber.\,Fkt.]{Klasse aller
  Turing-berechenbarer Funktionen}.
  \begin{gather*}
    \TM = \{f\colon\N^{n}\rightarrow\N \big| f \text{ ist
    Turing-berechenbar}\}
  \end{gather*}
\end{defini}

\subsection{Entscheidbarkeit, Semientscheidbarkeit und Aufzählbarkeit}\label{sec:5}
Alle diese Begriffen sind zurückgeführt auf die Berechenbarkeit gewisser
Funktionen und damit spezielle Formulierungen der Berechenbarkeit.

\subsubsection{Beziehungen zwischen den Begriffen}
\begin{mdescription}
 \item[1.\,Beobachtung:] Die Sprache
  $L\subseteq\Sigma^{\ast}$ ist Turing-entscheidbar \gdw
  $\overline{L}=\Sigma^{\ast}\setminus L$ ist Turing-entscheidbar

  \hspace{2cm}\input{t-entsch1.pdf_t}
 \item[2.\,Beobachtung:] Die Sprache
  $L\subseteq\Sigma^{\ast}$ ist Turing-entscheidbar \gdw
  die Sprache $L$ und die Komplementsprache $\overline{L}$
  Turing-semientscheidbar sind.

  \hspace{2cm}\input{t-entsch2.pdf_t}
 \item[3.\,Beobachtung:] Eine Sprache $L\subseteq\Sigma^{\ast}$ ist
  Turing-semientscheidbar \gdw $L$ ist aufzählbar.

  $\Leftarrow$ Wenn eine Sprache aufzählbar ist, dann gibt es eine
  Turing-Maschine $M_{aufz}$, die die Funktion $f(\Sigma^{\ast})=L$
  berechnet (\autoref{def:4}). Eine Turing-Maschine $M_{semi}$ kann für
  eine Eingabe $w$ alle Wörter der Sprache $L$ von $M_{aufz}$ erzeugen
  lassen und vergleicht, ob die Eingabe $w$ dabei ist. Findet sie diese,
  stoppt $M_{semi}$ mit 1, andernfalls ist die Ausgabe undefiniert. Damit
  berechnet $M_{semi}$ genau die partielle charakteristische Funktion
  $\chi_{L}^{p}$ (\autoref{def:3}).

  $\Rightarrow$ Umgekehrt existiere eine Turing-Maschine $M_{semi}$, die
  für eine Eingabe $w$ entscheidet, ob diese zu $L$ gehört. $M_{semi}$
  kann zur Bestimmung, ob ein Wort $u\in L$ ist, 1,2,3,\ldots viele
  Schritte benötigen. Man lässt aber $M$ höchstens $k$~Schritte machen
  und gibt ein festes (bekanntes) $a\in L$ aus, falls $M$ nicht nach
  $k$~Schritten gestoppt hat. Einer Eingabe $w$ wiederum lässt sich
  eineindeutig ein Paar $(u, k) \in \Sigma^{\ast}\times\N$
  zuordnen\footnote{Ein $u$ kann durch seine Stellung in $\Sigma^{\ast}$
  als Zahl $j(u)$ repräsentiert werden. Weiterhin lässt sich jedes
  $u_{i}\in\Sigma^{\ast}$ mit einer Zahl $i\in\N$ identifizieren und das
  Paar $(i,k)\in\N\times\N$ lässt sich durch Diagonalisierung mit einer
  Zahl $j(u)$ identifizieren -- DML: Gleichmächtigkeit von $\Z$ und
  $\N$.}.

  Damit kann man eine Turing-Maschine $M_{aufz}$ konstruieren, die für
  ein Wort $w\in\Sigma^{\ast}$ das Paar $(u, k)\in\Sigma^{\ast}\times\N$
  bestimmt und prüft, ob $M_{semi}(u)$ nach $k$~Takten stoppt. Ist dies
  der Fall, gibt $M_{aufz}$ $u$ aus, ansonsten $a$. $M_{aufz}$ gibt also
  nur Wörter aus $L$ aus -- die Funktion, die $M_{aufz}$ berechnet ist
  total.

  Für ein Wort $u\in L$ stoppt $M_{semi}$ nach einer endlichen Anzahl
  $k$ an Takten, d.\,h. es gibt ein Paar $(u,k)$ und damit ein
  $w\in\Sigma^{\ast}$, für das die Maschine $M_{aufz}$ das Wort $u$
  ausgibt. $M_{aufz}$ gibt also (irgendwann) jedes Wort aus $L$ aus --
  Vollständigkeit.
\end{mdescription}

\subsection{Turing-Maschinen als Akzeptoren und Erkenner}\label{sec:2}
Eine Sprache $L$ ist Turing-entscheidbar \gdw
$\chi_{L}$ ist Turing-berechenbar (vgl. \autoref{def:2}), d.\,h. falls eine
Eingabe $w\in\Sigma^{\ast}$ zu $L$ gehört, endet die Berechnung einer Turing-Maschine
in der Konfiguration $\Box q_{F}1\Box$ und falls $w\notin L$ endet die
Berechnung in $\Box q_{F}0\Box$.

Wir definieren neue Finalzustände (einer neuen Turing-Maschine):
\begin{itemize}
 \item
  aus der Konfiguration $\Box q_{F}1\Box \vdash \Box q_{+}\Box\Box$,
  $q_{+}$ heißt \highl{akzeptierender Zustand} (wobei das Turing-Band
  leer ist)
 \item
  aus der Konfiguration $\Box q_{F}0\Box \vdash \Box q_{-}\Box\Box$,
  $q_{-}$ heißt \highl{ablehnender Zustand} (wobei das Turing-Band
  leer ist)
\end{itemize}
Eine solche Turing-Maschine (ohne Ausgabe) heißt \highl{Erkenner} der Sprache $L$ mit
dem akzeptierenden Finalzustand $q_{+}$ und dem ablehnenden Finalzustand
$q_{-}$.

$L$ ist Turing-semientscheidbar \gdw $\chi_{L}^{p}$ ist
berechenbar (vgl. \autoref{def:3}).

Gleichermaßen definieren wir einen akzeptierenden Zustand $q_{+}$ als denjenigen
Finalzustand von $\Box q_{F}1\Box\vdash \Box q_{+}\Box\Box$. Es gibt
jedoch keinen ablehnenden Zustand. Eine solche Turing-Maschine heißt \highl{Akzeptor}
der Sprache $L$.

\section{Techniken zur Programmierung von Turing-Maschinen}
\subsection{Endliche Sprache mit schnellem Zugriff}

Die Daten einer endlichen Datenmenge $D$ können durch folgenden Trick in
das "`Gedächtnis"' der Turing-Maschine eingeführt werden:
\begin{gather*}
  Q_{neu} = Q_{alt} \times D
\end{gather*}

\begin{bemerk}\label{bem:1}
  Dies ist keine Änderung des bisherigen Begriffs Turing-Maschine, sondern lediglich
  eine \emph{Modifikation}, die eine Konstruktion wahrnimmt!
\end{bemerk}

\begin{bsp}
  Für $w\in\Sigma^{\ast}$ bezeichnet $\abs{w}$ die Länge von $w$, d.\,h. $w$
  hat $\abs{w}$ viele Buchstaben. (vgl. Beginn von \autoref{sec:1})

  Wir betrachten die folgende Sprache
  \begin{gather*}
    L= \{w=w_{1}w_{2}\ldots w_{\abs{w}}\colon w_{1} \ne w_{j}, j=2,\ldots,\abs{w}\}
    \subseteq \Sigma^{\ast}
  \end{gather*}

  Wir konstruieren folgende Turing-Maschine $M$:
  $\Sigma=\{a,b,c\}, \Gamma = \Sigma\cup\{\Box\}$\\
  $Q_{neu} =\{q_{1},q_{2},q_{3}\}\times \Gamma$\\
  Startzustand: $[q_{0}, \Box]$\\
  Finalzustand: $[q_{F}, \Box]$\\
  Überführungsfunktion:
  \begin{align*}
    \delta( [q_{0}, X], X) &= ([q_{1}, X], \Box, R) &X\in\{a,b,c\}\\
    \delta( [q_{0}, \Box], \Box) &= ([q_{F}, \Box], \Box, 0)
       &\text{(Finalzustand)}\\
    \delta( [q_{1}, X], Y) &= ([q_{1}, X], \Box, R) &X,Y\in\{a,b,c\},
       X\ne Y\\
    \delta( [q_{1}, X], \Box) &= ([q_{1}, \Box], \Box, 0)
       &\text{(Finalzustand)}\\
    \delta( [q_{1}, X], X) &= ([q_{2}, \Box], X, R) &X\in\{a,b,c\}\\
    \delta( [q_{2}, \Box], X) &= ([q_{2}, \Box], X, L) &\text{($M$ stoppt
       nicht)}\\
  \end{align*}
  $M$ ist ein Akzeptor für $L$.
\end{bsp}

\subsection{Turing-Bänder mit mehreren Spuren -- Mehrspurmaschinen}
\begin{mdescription}
 \item[informell:] Das Turing-Band ist in mehrere Zeilen
  bzw. Spuren unterteilt
 \item[formal:]
  \begin{gather*}
    \Gamma_{neu} = \Sigma \cup \Gamma_{alt}^{(k)} = \Sigma \cup
       (\Gamma_{alt}\times\ldots \times\Gamma_{alt})
  \end{gather*}
  Dabei ist $\Box^{k}$ das neue Blanksymbol
\end{mdescription}

\begin{bemerk}
  Analog zu \autoref{bem:1} ist dies keine Änderung des Begriffs Turing-Maschine.
\end{bemerk}

\begin{bsp}[Addition mehrstelliger Zahlen in dyadischer
  Darstellung]\mbox{}\\
  \begin{tabular}{r}
    1221\\
    1221\\
    \hline
    12122
  \end{tabular}

  Eingabe: $\Box dya(x)\# dya(y)\Box$\\
  $\Sigma = \{1,2,\#\}$

  \begin{enumerate}
   \item Initialisierung: $k=3$ (3 Spuren)
    \begin{align*}
      b\in\Sigma &\mapsto (b,\Box,\Box)\\
      \Box &\mapsto (\Box,\Box,\Box)
    \end{align*}

    wir erhalten als Bandinhalt:
    \begin{gather*}
      \begin{array}{ccccc}
	\Box&dya(x) & \#& dya(y) & \Box\\
	\Box&\Box\ldots\Box& \Box & \Box\ldots\Box & \Box\\
	\Box&\Box\ldots\Box& \Box & \Box\ldots\Box & \Box
      \end{array}
    \end{gather*}
   \item Übertragung von $dya(y)$ in die 2.\,Spur:
    \begin{gather*}
      \begin{array}{ccc}
	\Box&dya(x) & \Box\\
	\Box&dya(y) & \Box\\
	\Box&\Box\ldots\Box & \Box
      \end{array}
    \end{gather*}
   \item Stellenweise Addition:
    \begin{gather*}
      \begin{array}{ccc}
	\Box&dya(x) & \Box\\
	\Box&dya(y) & \Box\\
	\Box&dya(x+y) & \Box
      \end{array}
    \end{gather*}
   \item Normierung auf eine Spur
    $(\gamma_{1}, \gamma_{2}, \gamma_{3}) \mapsto \gamma_{3}$
  \end{enumerate}
\end{bsp}

\begin{bsp}[Multipikation mehrstelliger Zahlen in dyadischer Darstellung]
  Bei der Multiplikation zweier Faktoren $x$ und $y$ benötigt das
  herkömmliche Verfahren $\lfloor\log_{2} y\rfloor$ viele Zeilen --
  also nicht konstant viele!

  \begin{tabular}[t]{r}
    $1221\cdot 1$\\
    \hline
    1221
  \end{tabular}\hfill
  \begin{tabular}[t]{r}
    $1221\cdot 2$\\
    \hline
    12122
  \end{tabular}\hfill
  \begin{tabular}[t]{r}
    $1221\cdot 11$\\
    \hline
    1221\\
    1221\phantom{1}\\
    \hline
    111111
  \end{tabular}\hfill
  \begin{tabular}[t]{r}
    $1221\cdot 12$\\
    \hline
    12122\\
    1221\phantom{2}\\
    \hline
    121212
  \end{tabular}\hfill
  \begin{tabular}[t]{r}
    $1221\cdot 21$\\
    \hline
    1221\\
    12122\phantom{1}\\
    \hline
    212121
  \end{tabular}\hfill
  \begin{tabular}[t]{r}
    $1221\cdot 111$\\
    \hline
    1221\\
    1221\phantom{1}\\
    1221\phantom{11}\\
    \hline
    1121211
  \end{tabular}

  Die Idee ist aber, den erste Faktor $x$ mit jeder Stelle des zweiten
  Faktors $y$ einzeln zu multiplizieren und die Ergebnisse aufzusummiert.

  \begin{enumerate}
   \item Initialisierung: $k=4$ Spuren
   \item Frage: $y=0$? $\rightarrow$ ja: gehe zu 3.; nein: gehe zu 4.
   \item Lösche den Bandinhalt und stoppe
   \item 2.\,Spur Zwischenergebnis $x$ mal letzte Ziffer von $y$.
   \item Frage: hat $y$ ein weiteres Bit? $\rightarrow$ ja: gehe zu 6.;
    nein: gehe zu 9.
   \item 3.\,Spur Zwischenergebnis $x$ mal aktuelles Bit von $y$.
   \item 4.\,Spur Zwischenergebnis 2.+3.\,Spur
   \item Übertrage das Zwischenergebnis Summe 2.+3.\,Spur in die 2.\,Spur
    und lösche die 3. und 4. Spur, gehe zu 5.
   \item Normierung: Das Ergbenis $dya(x+y)$ steht in der 2.\,Spur und
    wird in eine Spur zurückübersetzt
  \end{enumerate}
\end{bsp}

\subsection{Mehrbandmaschninen}
$k$ sei fixiert, $k$-Band-Turing-Maschine
\begin{mdescription}
 \item[informell:] $k$\,Bänder mit \emph{je} einem Kopf
 \item[formell:] $\delta\colon Q\times \Gamma^{k} \rightarrow Q\times
  \Gamma^{k}\times\{L,0,R\}^{k}$
\end{mdescription}

\begin{bemerk}
  Dies ist eine Erweiterung der bisherigen Definition der Turing-Maschine. \help{Wieso
  das auf einmal? Weil sich die Abbildungsfunktion geändert hat. Vorher
  wurden die Mengen $Q$ und $\Gamma$ immer nur uminterpretiert, jetzt
  wird richtig was geändert.}
\end{bemerk}

\begin{bsp}
  $k=2, L= \{w\in\{a,b\}^{\ast}\colon w =w^{R}\}$

  Wir wissen bereits aus \autoref{bsp:1}, dass $L$ Turing-entscheidbar
  durch eine gewöhnliche (1-Band-) Turing-Maschine ist.

  Idee:\listlinebreak
  \begin{enumerate}
   \item $q_{0}$ läuft an das rechte Ende der Eingabe, $\rightarrow q_{1}$
   \item $q_{1}$ liest die Eingabe von rechts nach links und kopiert sie
    buchstabenweise auf das 2.\,Band, $\rightarrow q_{2}$
   \item $q_{2}$ bewegt den Kopf auf Band\,2 an das linke Ende,
    $\rightarrow q_{3}$
   \item $q_{3}$ vergleicht beide Bandinhalte buchstabenweise; stets
    Übereinstimmung $\rightarrow$ akzeptiere; irgendwo Unterschied
    $\rightarrow$ ablehnen
  \end{enumerate}
\end{bsp}

\begin{satz}
  Jede Sprache $L\subseteq \Sigma^{\ast}$, die von einer $k$-Band-Turing-Maschine
  entschieden werden kann, kann auch von einer gewöhnlichen (1-Band-)
  Turing-Maschine entschieden werden.

  \begin{proof}
    Es sei $M$ eine $k$-Band-Turing-Maschine, die die Sprache $L\subseteq
    \Sigma^{\ast}$ entscheidet. (Schreibweise: $L(M)=L$: $M$ entscheidet
    $L$)

    Wir konstruieren eine 1-Band-Turing-Maschine $M'$, die die Arbeit von $M$
    nachvollzieht, d.\,h. "`simuliert"'. (Beweis durch Simulation) $M'$
    vollzieht die Arbeit von $M$ mit ihren Mitteln nach. Das Arbeitsband
    von $M'$ ist unterteilt in $(2k+1)$\,Spuren. Die Spuren
    $1,3,\ldots,2k-1$ enthalten Inhalte der Bänder $1,2,\ldots,k$ von
    $M$. Die Spuren $2,4,\ldots,2k$ markieren die Kopfposition auf den
    Bändern $1,2,3,\ldots,k$ von $M$. Die Spur~$2k+1$ enthält eine linke
    und eine rechte Endmarke, die das am weitesten links bzw. rechts
    liegene Feld eines der Bänder markiert.

    \textbf{Ausgangssituation\ldots}
    \begin{description}
     \item[\ldots von $M$:]\mbox{}\\
      \begin{tabular}{*{6}{c}@{\qquad}r}
	$\Box$& $w_{1}$ &$w_{2}$& \ldots &$w_{n}$&$\Box$& 1.\,Band\\
	&$\uparrow$\\
	$\Box$& $\Box$ & \multicolumn{2}{c}{\ldots} &$\Box$&$\Box$& 2.\,Band\\
	&$\uparrow$\\
	\multicolumn{6}{c}{\vdots}&\multicolumn{1}{c}{\vdots}\\
	$\Box$& $\Box$ & \multicolumn{2}{c}{\ldots} &$\Box$&$\Box$& $k$.\,Band\\
	&$\uparrow$
      \end{tabular}
      Startzustand: $q_{0}$
     \item[\ldots von $M'$:]
      $\Box w_{1} w_{2} \ldots w_{n} \Box$\qquad einzigstes Band,
      Startzustand $q_{0}'$
    \end{description}

    \begin{enumerate}
     \item \textbf{Initialisierung} (Einrichten der Spuren):\\
      \begin{tabular}{l@{\quad}*{6}{c}}
	1.& $\Box$& $w_{1}$ &$w_{2}$& \ldots &$w_{n}$&$\Box$\\
	2.&$\Box$&$\blacktriangle$&$\Box$&\ldots&$\Box$&$\Box$\\
	3.&$\Box$& $\Box$ & \multicolumn{2}{c}{\ldots} &$\Box$&$\Box$\\
	4.&$\Box$&$\blacktriangle$&$\Box$&\ldots&$\Box$&$\Box$\\
	5.&$\triangleright$& $\Box$ & \multicolumn{3}{c}{\ldots} &$\triangleleft$\\
	&$\uparrow$
      \end{tabular}\qquad$(k=2)$
     \item \textbf{Simulation}: um einen Schritt der Arbeit von $M$
      nachzuvollziehen, führt $M'$ folgende Schritte aus:
      \begin{enumerate}
       \item der Kopf von $M'$ bewegt sich von links nach rechts und
	merkt sich für jedes Band von $M$ das aktuelle gelesene Symbol.
	Am rechten Rand kennt $M'$ den aktuellen Zustand und die aktuell
	gelesenen Symbole und kann damit gemäß der Überführungsfunktion
	$\delta$ von $M$ einen neuen aktuellen Zustand $q_{t+1}$ von $M$
	und $k$ neue Buchstaben (von $M$) und $k$ Bewegungen der Köpfe
	bestimmen.
       \item Der Kopf von $M'$ bewegt sich von rechts nach links und
	überschreibt die Buchstaben in den markierten Feldern gemäß
	$\delta$, verschiebt die Kopfmarkierungen gemäß $\delta$ und
	erreicht die linke Endmarke. Falls hierbei eine Zelle, die eine
	der beiden Endmarken enthält, beschriftet wird, wird die Marke um
	ein Feld nach links bzw. rechts verschoben, so dass der
	Arbeitsbereich von $M'$ stets zwischen den Endmarken liegt.

	Damit erreicht $M'$ eine normierte Zwischensituation und der
	nächste Schritt von $M$ kann simuliert werden.

	$M'$ akzeptiert eine Eingabe $w$ \gdw $M$ diese
	Eingabe akzeptiert.
      \end{enumerate}
     \item \textbf{Normierung} (Band aufräumen)
    \end{enumerate}
  \end{proof}
\end{satz}

\subsection{Unterprogramme}
\begin{defini}
  Unterprogramme sind eigenständige Turing-Maschinen, die in größere Turing-Maschinen eingebaut sind.
  \begin{itemize}
   \item Ein Teil der Zustände von $M$ und des Arbeitsspeichers von $M$
    sind für das Unterprogramm reserviert.
   \item In gewissen Situationen der Hauptprogramms werden Daten an ein
    Unterprogramm übergeben, dort behandelt und wieder zurück an das
    Hauptprogramm übergeben.
  \end{itemize}
\end{defini}

\begin{bsp}[Multiplikation von natürlichen Zahlen in unärer Darstellung]
  \begin{description}
   \item[Eingabe:] der Form $1^{n}\#1^{m}$
    \begin{gather*}
      \Box \underbrace{1\ldots1}_{n-\text{mal}}\# \underbrace{1\ldots1}_{m-\text{mal}}\Box
    \end{gather*}
   \item[Resultat:] $1^{n\cdot m}$
   \item[Idee:] Kopiere ersten Block ($1^{n}$) so oft, wie es der zweite
    Block angibt. Konstruiere eine 3-Band-Turing-Maschine
    \begin{center}
      \begin{tabular}{ll}
	1.\,Band: &Eingabe\\
	2.\,Band: &2.\,Block ($1^{m}$)\\
	3.\,Band: & Ergebnis
      \end{tabular}
    \end{center}

    Wir beschreiben die Arbeit der Maschine:\\
    \begin{auflistung}
      $q_{0}$& Überlaufen des ersten Blocks $\rightarrow$ $q_{1}$\\
      $q_{1}$& Überlaufen des zweiten Blocks nach rechts und kopiere
	 Inhalt auf das zweite Band (lösche ihn auf dem ersten Band)
	 $\rightarrow$ $q_{2}$\\
      $q_{2}$& falls auf dem zweiten Band ein Strich gelesen wird, dann
	 gehe zu $q_{u}$, falls ein $\Box$ gelesen wird, gehe zu $q_{3}$\\
      $q_{u}$& kopiere den Inhalt des ersten Bandes auf das dritte Band
	 $\rightarrow$ $q_{u}'$\\
      $q_{u}'$& gehe mit den Köpfen in die Ausgangsposition $\rightarrow$
	 $q_{2}$\\
      $q_{3}$& Normierung -- Resultat auf das erste Band schreiben
	 und Aufräumen $\rightarrow$ $q_{F}$\\
      $q_{0}$--$q_{3}$& Turing-Maschine mit Startzustand $q_{0}$, Finalzustand $q_{F}$\\
      $q_{u},q_{u}'$& Unterprogramm, Startzustand $q_{u}$, Finalzustand
	 $q_{u}'$, eingebettet in große Turing-Maschine
    \end{auflistung}
  \end{description}
\end{bsp}

\subsection{Komposition von Turing-Maschinen}
\subsubsection{Transitionsdiagramme}

\begin{bsp}
  Am Beispiel einer Turing-Maschine, die binär eine Eins addiert. Zustände der
  Maschine werden als Knoten in einem Diagramm dargestellt. Die
  Überführungsfunktion mittels bewerteter Kanten.
  \begin{center}
    \input{transition.pdf_t}\\
    \textit{Die Maschine "`$i:=i+1$"'}
  \end{center}
  Dieser (Mega-)Knoten lässt sich in ein weiteres Transitionsdiagramm
  (einer größeren Turing-Maschine) einsetzen.
\end{bsp}

\begin{bsp}
  Eine Turing-Maschine, die testet, ob der Bandinhalt "`0"' ist oder nicht (binäre
  Darstellung)
  \begin{center}
    \input{transition2.pdf_t}\\
    \textit{Die Maschine "`$i=0$"'}
  \end{center}
  Die Anschlüsse für dieses Unterprogramm (Knoten) führen in den
  Startzustand und verlassen die Endzustände.
\end{bsp}

\subsubsection{Hintereinanderschalten von Turing-Maschinen}
Es seien $M_{i}=(Q_{i}, \Sigma, \Gamma_{i}, \delta_{i}, q_{0_{i}}, F_{i})$
($i=1,2$) zwei Turing-Maschinen. \obda $Q_{1}\cap Q_{2}=\emptyset$. Die Turing-Maschine
$M=(Q_{1}\cup Q_{2}, \Sigma, \Gamma_{1}\cup \Gamma_{2}, \delta,
q_{0_{1}}, F_{2})$ realisiert ein hintereinanderschalten von $M_{1}$ und $M_{2}$.
Dabei gilt:
\begin{gather*}
  \delta = \delta_{1}\cup\delta_{2}\cup\{(q_{1},a) \mapsto (q_{0_{2}},
  a', 0)\colon q_{1}\in F_{1}, a\in\Gamma_{1}, a'\in\Gamma_{2}\}
\end{gather*}

\begin{description}
 \item[Notation:] $start \rightarrow M_{1} \rightarrow M_{2} \rightarrow
  stopp$ oder $M:= M_{1}\,;\,M_{2}$
\end{description}

\begin{bsp}
  \begin{gather*}
    \underbrace{start \rightarrow \fbox{i:=i+1} \rightarrow \fbox{i:=i+1}
      \rightarrow stopp}_{i:=i+2}
  \end{gather*}
\end{bsp}

\begin{bsp}[Fallunterscheidung]
  \begin{gather*}
    \delta = \delta_{1}\cup \delta_{2}\cup \{(q_{+}, a) \mapsto
       (q_{0_{1}}, a', 0)\} \cup \{(q_{-}, a) \mapsto (q_{0_{2}}, a',
       0)\} \\
    start \rightarrow M_{0} \rightarrow \fbox{i=0?}
    \begin{cases}
      q_{+} \rightarrow M_{1} \rightarrow \ldots \rightarrow stopp\\
      q_{-} \rightarrow M_{2} \rightarrow \ldots \rightarrow stopp
    \end{cases}\\
    M := M_{0};\ \text{\algokeyword{if}}\ i=0\
       \text{\algokeyword{then}} \ M_{1}\
       \text{\algokeyword{else}}\ M_{2}
  \end{gather*}
\end{bsp}

\begin{bsp}[while-Schleifen]
  \mbox{}
  \begin{center}
    \input{while.pdf_t}\\
    \textit{Maschine "`\algokeyword{while} $i\ne0$
      \algokeyword{do} $M$"'}
  \end{center}
\end{bsp}

\section{Rechenzeit und Speichersplatz}

\begin{defini}
  Es sei $M=(Q, \Sigma, \Gamma, \delta, q_{0}, F)$ eine Turing-Maschine und
  $w\in\Sigma^{\ast}$ eine Eingabe.
  \begin{align*}
    time_{M}(w) &:=
       \begin{cases}
	 \text{\parbox{.4\textwidth}{Anzahl der Rechenschritte von $M$
	 bei der Eingabe $w$}}&
	 \text{falls $M$ bei $w$ stoppt}\\
	 \ndef& $M$\text{ stoppt nicht}
       \end{cases}\\
    space_{M}(w) &:=
       \begin{cases}
	 \text{\parbox{.4\textwidth}{Anzahl der vom Kopf besuchten Zellen
	 des Arbeitsbandes}}&
	 \text{falls $M$ bei $w$ stoppt}\\
	 \ndef& $M$\text{ stoppt nicht}
       \end{cases}
  \end{align*}
  Damit ist $time_{M}\colon \Sigma^{\ast} \rightarrow \N,
  space_{M}\colon\Sigma^{\ast} \rightarrow \N$.
  \begin{align*}
    TIME_{M}(n) &:=
       \begin{cases}
	 \max\limits_{\abs{w}\leq n} time_{M}(w)& time_{M}(w)
         \text{ definiert}\\
	 \ndef& $M$\sonst
       \end{cases}\\
    SPACE_{M}(n) &:=
       \begin{cases}
	 \max\limits_{\abs{w}\leq n}space_{M}(w)&space_{M}(w)
         \text{ ist definiert}\\
	 \ndef& $M$\sonst
       \end{cases}
  \end{align*}
  $TIME_{M}: \N\rightarrow\N$ ist die maximale Anzahl an Rechenschritten,
  die benötigt wird, um ein Wort ein Länge $n$ zu berechnen.
  Analog ist $SPACE_{M}:\N\rightarrow\N$ der maximale Speicherplatz, der
  für die Berechnung eines Wortes der Länge $n$ benötigt wird.
\end{defini}

\begin{defini}
  Es sei $t\colon\N \rightarrow_{t}\N$ und $s\colon\N\rightarrow_{t}\N$ zwei (total
  definierte) Zahlenfunktionen. Eine Funktion $f\colon\N\rightarrow\N$ ist
  \highl{Turing-berechenbar mit der Zeitschranke} $t$ und der
  \highl{Speicherplatzbeschränkung} $s$, falls es eine Turing-Maschine $M_{t}$ und eine
  Turing-Maschine $M_{s}$ gibt, so dass $TIME_{M_{t}} \leq t$ und $SPACE_{M_{s}}\leq s$.

  Es sei $L\subseteq \Sigma^{\ast}$ eine formale Sprache. $L$ ist
  \highl{Turing-erkennbar mit der Zeitbeschränkung} $t$ und der
  \highl{Speicherplatzbeschränkung} $s$ \gdw ein
  Erkenner $M_{t}$ (Turing-Maschine ohne Ausgabe;
  s.\,\autoref{sec:2}) und ein Erkenner $M_{s}$ existieren, die
  folgende Bedingungen erfüllen:
  \begin{gather*}
    M_{t}(w\in L)= q_{+}, M_{t}(w\notin L) = q_{-}, TIME_{M_{t}} \leq t\\
    M_{s}(w\in L)= q_{+}, M_{s}(w\notin L) = q_{-}, SPACE_{M_{s}} \leq s\\
  \end{gather*}
\end{defini}

\begin{satz}
  Jede Sprache $L\subseteq \Sigma^{\ast}$, die von einer Mehrband-Turing-Maschine $M$
  mit der Zeitbeschränkung $t$ und der Speicherplatzbeschränkung $s$
  enschieden werden kann, kann auch von einer 1-Band-Turing-Maschine $M_{1}$ mit der
  Zeitbeschränkung $O(s\cdot t)$ und der Platzbeschränkung $O(s)$
  entschieden werden.

  \begin{gather*}
    \mathcal{P} = \{L\colon \exists p, p \text{ ist Polynom}, TIME_{M} \leq p\}
  \end{gather*}
  $\mathcal{P}$ sind alle die Sprachen, die sich von einer Turing-Maschine in
  Polynomialzeit entscheiden lassen.
\end{satz}

\chapter{Partiell-rekursive Funktionen}\label{cha:2}

Bisher haben wir zur Charakterisierung von Berechenbarkeit
(Turing-)Maschinen, die Funktionen mit Hilfe eines Algorithmus'
berechnen, betrachtet. Jetzt wollen wir einen algebraischen Ansatz
betrachten, der auf einer Menge von Gundfunktionen, die (indutuitiv)
berechenbar sind, und Schemata, die aus "`einfachen"' Funktionen neue
"`komplexe"' Funktionen konstruieren, aufbaut.

\begin{bsp}[Modulo-Funktion]\label{bsp:2}
  $\mod\colon\N\times\N \rightarrow\N$\\
  $\mod(a,b) =$ Rest bei der ganzzahligen Division von $a$ und $b$\\
  $\mod(a,0) = \mod(0,b) = \mod(0,0) = 0$

  Für $b\ne0$ lässt sich die Funktion rekursiv auf folgende Weise
  berechnen:
  \begin{gather*}
    \mod(a,b) = \text{\algokeyword{if} } a < b
    \text{ \algokeyword{then} } a \text{ \algokeyword{else}} \mod(a-b, b)
  \end{gather*}

  Vergleiche mit \autoref{def:5}
\end{bsp}

Das zugrundeliegende Schema ist folgendes:
\begin{itemize}
 \item für eine endliche Menge $A\subseteq \N$ sind die Werte der
  Funktion bekannt (mittels anderer einfacherer Funktionen berechenbar)
 \item für den "`großen"' Rest werden die Funktionswerte durch Werte
  der Funktion an früheren Stellen $B_{n}$ (mittels anderer
  einfacher Funktionen) bestimmt.
\end{itemize}

In unserem \autoref{bsp:2} sind dies: $A=\{0,\ldots,b-1\}, B_{n}=\{n-b\}$.

Ein besonders einfacher Fall liegt vor, wenn $A=\{0\}$ und
$B_{n}=\{n-1\}$.

\section{Primitiv-rekursive Funktionen}
\begin{festl}
  Wir beschränken uns \obda auf Zahlenfunktionen $f\colon\N^{k}\rightarrow\N$.
\end{festl}

\begin{bemerk}
  Eine echte Einschränkung für diesen Abschnitt ist, dass wir nur total
  definierte Funktionen betrachten.
\end{bemerk}

\begin{defini}[Grundfunktionen]\index{Grundfunktionen} \label{def:8}
  \begin{description}
   \item[Projektion]\index{Projektion}
    \begin{align*}
      I_{j}^{n}(x_{1},\ldots,x_{n}) = x_{j}
      &&\bigl((x_{1},\ldots,x_{n})\in\N^{n}, n\geq1, 1\leq j\leq n\bigr)
    \end{align*}
    Die Menge aller Projektionen $\{I_{j}^{n}\colon n>0, 1\leq j \leq n\}$
   \item[Konstanten]
    \begin{align*}
      C_{k}^{n}(x_{1},\ldots,x_{n}) = k
      &&\bigl((x_{1},\ldots,x_{n})\in\N^{n}, n\geq1, k\geq 0)
    \end{align*}
    Die Menge aller Konstanten $\{C_{k}^{n}\colon n\geq 1, k\geq 0\}$
   \item[Nachfolgerfunktion]
    \begin{align*}
      N(x) = x+1 &&(x\in\N)
    \end{align*}
  \end{description}

  $\mathcal{G}$\ldots ist die Menge aller \highl{Grundfunktionen}.
\end{defini}

\begin{bemerk}\label{bem:3}
  Alle Grundfunktionen sind Turing-berechenbar!
\end{bemerk}

\begin{defini}[Einsetzungsprinzip]\index{Einsetzungsprinzip}
  Gegeben seien eine Funktion $h\!\colon\N^{m}\rightarrow\N$ und eine Menge von
  Funktionen $g_{i}\!\colon\N^{n}\rightarrow\N$ ($i=1,\ldots,m$). Die Funktion
  $f\!\colon\N^{n}\rightarrow\N$ geht aus den Funktionen $h$ und $g_{i}$ durch
  Einsetzung hervor \gdwdef
  \begin{gather*}
    f(x_{1},\ldots,x_{n}) = h(g_{1}(x_{1},\ldots,x_{n}),\ldots,
    g_{m}(x_{1},\ldots,x_{n}))
  \end{gather*}
  Schreibweise: $f=SUB^{m}(h; g_{1},\ldots,g_{m})$

  Es sei $F\subseteq\{f\colon\N^{n}\rightarrow\N, n\geq0\}$ eine Menge von
  (Zahlen-)Funktionen. $F$ heißt \highl{abgeschlossen bezüglich des
  Schemas der Einsetzung} \gdwdef jede Funktion, die durch
  Einsetzung von Funktionen aus $F$ hervorgeht, gehört zu $F$.
\end{defini}

\begin{figure}
  \centering
  \input{n-einsetzung.pdf_t}
  \parbox{10cm}{\caption{$M_{f}$ als Komposition aus $M_{h}$ und
    $M_{g_{1}},\ldots,M_{g_{m}}$ zur Nachbildung des "`Schemas der
    Einsetzung"'}}
  \label{fig:3}
\end{figure}

\begin{bemerk}\label{bem:4}
  Die Klasse der Turing-berechenbaren Funktionen $\TM$ ist
  abgeschlossen bezüglich des Schemas der Einsetzung! \autoref{fig:3}
\end{bemerk}

\begin{defini}[Schema der primitiven Rekursion]
  Eine Funktion $f\colon\N^{n}\rightarrow\N$ geht aus den Funktionen
  $g\colon\N^{n-1}\rightarrow\N$ und $h\colon\N^{n+1}\rightarrow\N$ durch
  \highl{primitive Rekursion} hervor \gdwdef
  \begin{align*}
    \forall x_{1},\ldots,x_{n-1},y\colon f(x_{1},\ldots,x_{n-1},0) &=
       g(x_{1},\ldots,x_{n-1})\\
    f(x_{1},\ldots,x_{n-1},y+1) &= h(x_{1},\ldots,x_{n-1}, y,
       f(x_{1},\ldots,x_{n-1},y))
  \end{align*}
  Schreibweise: $f=PR(g,h)$

  $F$ heißt abgeschlossen bzgl. primitiver Rekursion
  \gdwdef jede Funktion, die sich durch primitive
  Rekursion aus den Funktionen aus $F$ ergibt, selbst zu $F$ gehört.
\end{defini}

\begin{bemerk}\label{bem:5}
  Die Klasse der Turing-berechenbaren Funktionen $\TM$ ist abgeschlossen
  bzgl. primitiver Rekursion.
\end{bemerk}

\begin{bsp}\label{bsp:7}
  Die Addition $plus\colon\N\times\N\rightarrow\N$ geht aus den
  Grundfunktionen durch primitive Rekursion und Einsetzung hervor.
  \begin{align*}
    plus(x,0) &= x = I_{1}^{1}(x)\\
    plus(x,y+1) &= x+(y+1) = (x+y) +1 = plus(x,y)+1 =
       N\bigl(plus(x,y)\bigr)
    \intertext{Da $h$ für $PR$ eine dreistellige Funktion seien muss,
      wenden wir nochmal das Schema der Einsetzung an:}
    plus(x,y+1) &= N\bigl( I_{3}^{3}(x,y,plus(x,y)) \bigr)
  \end{align*}
  $plus(x,y+1)$ lässt sich durch das Schema der Einsetzung
  $SUB^{1}(N;I^{3}_{3})$ durch $h\colon\N^{3} \rightarrow N$ ersetzen. Für die
  Funktion $plus$ gilt also: $plus = PR\bigl(I_{1}^{1},
  SUB^{1}(N;I_{3}^{3})\bigr)$.
\end{bsp}

\begin{defini}[primitiv-rekursive Funktionen]
  % Das \protect vor dem \Prr ist notwendig, da \index sonst die
  % Zeichenkette \@Prr in den Indexdatei schreibt, was xindy wiederum
  % nicht gefällt, da @ eine besondere Bedeutung hat.
  % http://www.listserv.dfn.de/cgi-bin/wa?A2=ind0205&L=tex-d-l&D=0&T=0&P=29773
  Die \highl{Klasse $\protect\Prr$ der primitiv-rekursiven Funktionen} ist die kleinste
  Klasse von Funktionen $\{f\colon\N^{n}\rightarrow\N \big| n\geq0\}$ mit folgenden
  Eigenschaften:
  \begin{enumerate}
   \item Die Grundfunktionen $\mathcal{G}$ liegen in $\Prr$. ($\mathcal{G}\subseteq\Prr$)
   \item $\Prr$ ist abgeschlossen bzgl. der Einsetzung.
   \item $\Prr$ ist abgeschlossen bzgl. der primitiven Rekursion
  \end{enumerate}

  Die Klasse der primitiv-rekursiven Funktionen lässt sich damit als
  algebraische Hülle schreiben:
  \begin{gather*}
    \Prr = \Gamma_{\{SUB,PR\}}(G)
  \end{gather*}
  Dabei steht $SUB$ für $SUB = \{SUB^{m}\colon m\in\N\}$
\end{defini}

\begin{bemerk}
  Alle primitiv-rekursiven Funktionen sind Turing-berechenbar!
\end{bemerk}

\begin{description}
 \item[Frage:] Sind alle Funktionen, die total definiert und berechenbar
  sind, primitiv-rekursiv?
\end{description}

\section{Die Ackermann-Funktion}\label{sec:4}
F.\,W.\,Ackermann definierte 1928 die folgende Funktion, die total
definiert und berechenbar ist, aber von der gezeigt wurde, dass sie nicht
primitiv-rekursiv ist!

Wir benutzen folgende Form: $A\colon\N^{2}\rightarrow\N$
\begin{align*}
  A(0,y) &:= y+1\\
  A(x+1, 0) &:= A(x,1)\\
  A(x+1, y+1) &:= A(x, A(x+1, y))
\end{align*}

\begin{bemerk}
  Dieses Definitionsschema enthält eine doppelte Rekursion, die dazu
  führt, dass die Funktion \emph{exorbitant} schnell wächst!
\end{bemerk}

\begin{bsp}
  \begin{align*}
    A(1,0) &= A(0,1) = 2\\
    A(1,1) &= A(0, A(1,0)) = A(0,2) = 3\\
    A(1,2) &= A(0, A(1,1)) = A(0,3) = 4\\
    \mathbf{A(1,y)} &\mathrel{\mathbf{=}}\mathbf{y+2}\\
    A(1,y+1) &= A(0, A(1,y)) = A(0,y+2) = (y+2) +1 = (y+1) +2
       \displaybreak[1]\\
    A(2,0) &= A(1,1) = 1+2 = 3\\
    A(2,1) &= A(1, A(2,0)) = A(1,3) = 3+2 = 5\\
    A(2,2) &= A(1, A(2,1)) = A(1,5) = 5+2 = 7\\
    \mathbf{A(2,y)} &\mathrel{\mathbf{=}}\mathbf{2y+3}\\
    A(2,y+1) &= A(1, A(2,y)) = A(1,2y+3) = 2y+3+2 = 2(y+1) +3
       \displaybreak[1]\\
    A(3,0) &= A(2,1) = 2\cdot 1+3 = 5\\
    A(3,1) &= A(2, A(3,0)) = A(2,5) = 2\cdot5+3 = 13\\
    A(3,2) &= A(2, A(3,1)) = A(2,13) = 2\cdot13+3 = 29\\
    A(3,3) &= A(2, A(3,2)) = A(2,29) = 2\cdot29+3 = 61\\
    \mathbf{A(3,y)} &\mathrel{\mathbf{=}}\mathbf{2^{y+3}-3}\\
    A(3,y+1) &= A(2, A(3,y)) = A(2, 2^{y+3}-3) = 2\cdot(2^{y+3}-3)+3 =
       2^{(y+1)+3}-3\displaybreak[1]\\
    A(4,0) &= A(3,1) = 2^{1+3}-3\\
    A(4,1) &= A(3,A(4,1)) = A(3,2^{16}-3) = 2^{2^{16}}-3\\
    A(4,2) &= A(3,A(4,2)) = A(3, 2^{2^{16}}-3) = 2^{2^{2^{16}}}-3\\
    \mathbf{A(4,y)} &\mathrel{\mathbf{=}}\mathbf{2^{2^{\cdots^{2}}}
       \raisebox{1mm}{\big\}}y\text{\textbf{-mal}} -3}\displaybreak[1]\\
    A(5,0) &= A(4,1) = 2^{16}-3\\
    A(5,1) &= A(4, A(5,0) ) = A(4, 2^{16}-3)
  \end{align*}
\end{bsp}

\begin{satz}
  Die Ackermannfunktion ist (intuitiv) berechenbar, aber nicht
  primitiv-rekursiv.

  \begin{proof}
    Die Idee des Beweises ist folgende Beobachtung:  Setzt man die
    Definition der Ackermann-Funktion wiederholt in die allgemeine Form
    ein (\autoref{eq:5}), so sieht man, dass die Anzahl der ineinander
    geschachtelten Rekursionen von den Parametern $x$ und $y$ abhängt.
    Mit Primitiver-Rekursion kann man jedoch nur einfache Rekursion (mit
    konstanter Schachtelungstiefe) erreichen.

    \begin{gather}\label{eq:5}
      A(x+1, y+1) = A(x, A(x+1, y)) = A\big(x, A(x, A(x+1, y-1)) \big) =\\
      A\big(x, A\big(x, A(x A(x+1, y-2)) \big) \big)
    \end{gather}

    % Idee: Definition einer Folge von Funktionen $f_{n}:
    % \N\rightarrow\N$
    % \begin{align*}
    %   f_{0}(y) &= y+1\\
    %   f_{n+1}(0) &= f_{n}(1)\\
    %   f_{n+1}(y+1) &= f_{n}(f_{n+1}(y))\\
    %   \intertext{mit dem Effekt}
    %   f_{n+1}(y+1) &= f_{n}(f_{n+1}(y)) = f_{n}(f_{n}(f_{n+1}(y-1))) =
    %      \ldots\\
    %   \intertext{von $y$ ineinander geschachtelten Rekursionen}
    % \end{align*}\help{Wieso kann das nicht prim.-rek. sein?}
  \end{proof}
\end{satz}

Haben $\Prr = \Gamma_{\{SUB,PR\}}(G)$, d.\,h. jede primitiv-rekursive
Funktion lässt sich darstellen aus den Grundfunktionen und endlich oft
nötiger Anwendung des Schemas der Einsetzung und des Schemas der
primitiven Rekursion.

Für jede konkrete Funktion ergibt sich eine konkrete Darstellung mit
einer festen Anzahl von Einsetzungen und primitiven Rekursionen.

\begin{bemerk}\label{bem:2}
  Jede primitiv-rekursive Funktion lässt sich durch einen Ausdruck
  endlicher Länge über einem gegebenen Alphabet beschreiben:
  \begin{gather*}
    \Sigma = \{I,C,N, |, \#, ), ,, (, x, SUB, PR\}
  \end{gather*}
\end{bemerk}

\begin{bsp}
  Hatten: $plus= PR(I_{1}^{1}, SUB^{1}(N, I^{3}_{3}))$ es ergibt sich:
  \begin{gather*}
    plus = PR(I\#|\#|\#,SUB\#|\#(N,I\#|||\#|||\#))
  \end{gather*}
  Dies ist ein Wort über dem Alphabet $\Sigma$.
\end{bsp}

\textbf{Konsequenz}:\\
Eine solche Darstellung zeigt:
\begin{enumerate}
 \item $\Prr$ ist abzählbar unendlich
 \item $\Prr$ ist effektiv nummerierbar (durch systematisches
  nummerieren der Wörter über $\Sigma$)
\end{enumerate}

Dies hat folgende weitere Konsequenzen:\\
Es sei $\phi_{0}, \phi_{1}, \phi_{2},\ldots$ eine Nummerierung aller
einstelligen primitiv-rekursiven Funktionen. Wir definieren durch
\emph{Diagonalisierung} eine Funktion $\psi$
\begin{gather*}
  \psi(n) = \phi_{n}(n)+1\qquad(n\in\N)
\end{gather*}
Es ist leicht einzusehen, dass $\psi$ zwar (intuitiv) berechenbar,
aber nicht primitiv-rekursiv ist.

Ann.: $\psi\in\Prr$ Dann müsste $\psi$ zu $\phi_{n}$ gehören und es
existiert ein $k\in\N$ mit $\psi=\phi_{k}$. Dies führt aber zu einem
Widerspruch: $\phi_{k}(k) = \psi(k) = \phi_{k}(k)+1$.

\section{\texorpdfstring{$\mu$}{\textmu}-rekursive Funktionen}

Programmiersprachen mit Schleifen:
\begin{gather*}
  \text{\algokeyword{while} } Bedingung
  \text{ \algokeyword{do} } Anweisung \text{ \algokeyword{end}}
\end{gather*}
wollen solche Schleifen simulieren

\begin{defini}
  Es sei $g\colon\N^{n+1}\rightarrow\N$ eine Funktion mit $n>0$. Die Funktion
  $f\colon\N^{n}\rightarrow\N$ entsteht aus $g$ durch das Schema der
  \highl[mu-Rekursion@$\mu$-Rekursion]{$\mu$-Rekursion} \gdwdef für alle
  $(x_{1},\ldots,x_{n})\in\N^{n}$ gilt:
  \begin{gather*}
    f(x_{1},\ldots,x_{n}) =
    \begin{cases}
      \min\{t\in\N\colon g(x_{1},\ldots,x_{n},t)=0\}&
      \text{\parbox[t]{.35\linewidth}{falls ein solches
      $t$ existiert und $\forall 0\leq y\leq t$ $g(x_{1},\ldots,x_{n},y)$
      definiert ist}}\\
      \ndef&\sonst
    \end{cases}
  \end{gather*}
\end{defini}
Schreibweise: $f=\mu R(g)$

Damit gilt: Wenn $g$ berechenbar ist, dann ist auch $f$ berechenbar.

als Schleife:\\
\verb|t := 0|\\
\verb|while |$g(x_{1},\ldots,x_{n}, t)\ne0$\verb| do t := t+1 end|

\begin{defini}\label{def:9}
  \begin{enumerate}
   \item Eine Klasse $\PP$ von Funktionen heißt abgeschlossen
    bzgl. $\mu$-Rekursion \gdwdef für alle
    $g\in\PP$ ist $f=\mu R(g)\in\PP$.
   \item Die \highl[Klasse!part.-rek.\,Fkt]{Klasse $\PP$ der
    partiell-rekursiven Funktionen} \index{P@$\PP$|see{Klasse!part.-rek.\,Fkt}}
    ist die kleinste Klasse, die $\Prr$
    umfasst und abgeschlossen bzgl. $\mu$-Rekursion ist. Anders
    dargestellt: $\PP=\Gamma_{\{\mu R\}}(\Prr)$
  \end{enumerate}
\end{defini}

Äquivalent hierzu ist die folgende Definition:
\begin{defini}
  Die Klasse $\PP$ ist die kleinste Klasse, die $\mathcal{G}$ umfasst und
  die abgeschlossen bzgl. Einsetzung, primitiver-Rekursion und
  $\mu$-Rekursion ist. Anders dargestellt:
  $\PP=\Gamma_{\{SUB,PR,\mu R\}}(\mathcal{G})$
\end{defini}

\begin{bemerk}
  Dabei werden das Schema der Einsetzung und das Schema der primitiven
  Rekurision für partiell-definierte Funktionen erweitert.
\end{bemerk}

\begin{bsp}
  \begin{gather*}
    d(m,n) = \begin{cases}
	       \frac{n}{m}&\text{falls Teiler existiert}\\
	       \ndef& \sonst
	     \end{cases}
  \end{gather*}
  Zunächst zeigen wir, dass die Signumfunktion, Potenzfunktion und die
  Betragsfunktion primitiv-rekursiv sind.

  \begin{gather*}
    sgn\colon \N\rightarrow\N; n \mapsto
       \begin{cases}0&\colon n=0\\1&\colon n>0\end{cases}\\
    exp\colon\N^{2}\rightarrow\N; (m,n)\mapsto m^{n}; (0,0)\mapsto1\\
    ab\colon\N^{2}\rightarrow\N; (m,n)\mapsto \abs{m-n}
  \end{gather*}

  \begin{align*}
    sgn(0) &= 0 = C_{0}^{0}\\
    sgn(n+1) &= 1 = h(n, sgn(n)) = C_{1}^{2}(n, sgn(n))\\
    sgn &= PR(C_{0}^{0}, C_{1}^{2})
  \end{align*}

  Die Darstellung ist jedoch nicht eindeutig und so wäre auch folgende
  möglich:
  \begin{align*}
    sgn(0) &= I_{1}^{1}(C_{0}^{0})\\
    sgn(n+1) &= C_{1}^{1}(I_{1}^{2}(n,n))\\
    sgn &= PR(SUB^{1}(I_{1}^{1}, C_{0}^{0}), SUB^{1}(C_{1}^{1}, I_{1}^{2}))
  \end{align*}

  Die Abstandsfunktion lässt sich aus anderen primitiv-rekursive
  Funktionen zusammensetzen und ist somit selbst primitiv-rekursiv
  \begin{gather*}
    ab(x,y) = \abs{x-(y+1)} = sgn(a-b)\cdot(a-b) + sgn(b-a)\cdot(b-a)
  \end{gather*}

  % \begin{align*}
  %   exp(x,0) &= C_{1}^{1}(x)\\
  %   exp(x,y+1) &= x^{y+1} = x^{y}\cdot x
  % \end{align*}

  Damit ist $f\colon\N^{3}\rightarrow\N$ primitiv-rekursiv
  \begin{align*}
    f(k,m,n) &= \abs{k\cdot m-n}^{sgn(m)}\\
    \intertext{setzen $f$ in $\mu R(f)$ ein:}
    [\mu R(f)](m,n) &=
       \begin{cases}
	 \mu k(\abs{k\cdot m-n}=0)&\colon \text{falls ein solches $k$ existiert
	 und $m\ne0$}\\
	 \ndef&\colon\sonst
       \end{cases}\\
    &= \begin{cases}
	 \mu k(k\cdot m=n)&\colon \text{falls ein solches $k$ existiert}\\
	 \ndef&\colon\sonst
       \end{cases}\\
    &= \begin{cases}
	 \frac{n}{m}&\colon \text{falls $m$ ein Teiler von $n$ ist, $m\ne0$}\\
	 \ndef&\colon\sonst
       \end{cases}\\
    &= d(m,n)
  \end{align*}
\end{bsp}

\begin{bsp}\label{bsp:5}
  Die Funktion $wurz\colon\N\rightarrow\N$ ist partiell-rekursiv
  \begin{gather*}
    wurz(n) := \begin{cases}
		 \sqrt{n}&\colon\sqrt{n}\in\N\\
		 \ndef&\colon\sonst
	       \end{cases}
  \end{gather*}

  Wir betrachten folgende zweistellige Funktion $h$
  \begin{align*}
    h(m,n) &= \abs{m-n^{2}}&&h\in\Prr\\
    \intertext{Wir bestimmen $\mu R(h)$:}
    [\mu R(h)](m) &=
       \begin{cases}
	 \mu n(\abs{m-n^{2}}=0)&\colon\exists n\\
	 \ndef&\colon\sonst
       \end{cases}\\
    &= \begin{cases}
	 \sqrt{m}&\colon\sqrt{m}\in\N\\
	 \ndef&\colon\sonst
       \end{cases}\\
    &= wurz(m)
  \end{align*}
  Also ist $wurz = \mu R(h)$
\end{bsp}

\begin{bsp}\label{bsp:6}
  Die Funktion $ganzwurz\colon\N\rightarrow\N$ ist partiell-rekursiv
  \begin{align*}
    ganzwurz(m) = gw(m) = \lfloor\sqrt{m}\rfloor&&(m\in\N)
  \end{align*}
  Es gilt:
  \begin{align*}
    gw(m) = n &\Leftrightarrow n\leq\sqrt{m}< n+1\\
    &\Leftrightarrow n^{2} \leq m < (n+1)^{2}
  \end{align*}
  Also gilt:
  \begin{align*}
    gw(m) &= \mu n(m < (n+1)^{2})\\
    &= \mu n(\abs{(m+1)-(n+1)^{2}}=0)
  \end{align*}
  Weiter gilt: $gw(m) = wurz(m)$ falls $wurz(m)$ definiert ist und $gw$
  ist total definiert. Damit ist $gw$ eine \highl{Fortsetung} von $wurz$ und $gw$
  ist partiell-rekursiv (sogar primitiv-rekursiv)
\end{bsp}

\begin{satz}\label{satz:7}
  Jede partiell-rekursive Funktion lässt sich darstellen als ein Term, der
  die Symbole für die Grundfunktion, die Schemata $SUB, PR, \mu R$, sowie
  weitere notwendige Hilfssymbole enthält.

  Vergleiche das Alphabet $\Sigma$ für primitiv-rekursive Funktionen in
  \autoref{bem:2} und füge "`$\mu R$"' als neues Symbol hinzu!

  Die kanonische (quasilexikographische) Auflistung aller dieser Terme
  liefert eine \emph{effektive Nummerierung} aller partiell-rekursiven
  Funktionen. $\PP$ ist also aufzählbar und abzählbar unendlich.
\end{satz}

\section{Allgemein-rekursive Funktionen}

Die Funktion $wurz\in\PP$ aus \autoref{bsp:5} und ist partiell (definiert). Die
Funktion $gw\in\PP$ aus \autoref{bsp:6}, total (definiert). Die Fortsetzung von $wurz$
ist $gw$: $gw\big|_{D wurz} = wurz$

\begin{defini}
  Eine partiell-rekursive Funktion $f\in\PP$ heißt \highl{allgemein-rekursiv}
  \gdwdef $f$ total definiert ist.

  $\Pa$\index{Pa@$\Pa$|see{Klasse!allg.-rek.\,Fkt.}} bezeichnet die
  \highl[Klasse!allg.-rek.\,Fkt.]{Klasse aller allgemein-rekursiven
  Funktionen}.
\end{defini}

Wenn $\mathbb{F}$\index{$\mathbb{F}$} die Menge aller Zahlenfunktionen
bezeichnet, dann gilt:
\begin{gather*}
  \emptyset \subseteq \Prr \subseteq \Pa \subseteq
  \PP \subseteq \mathbb{F}
\end{gather*}

\begin{satz}
  Alle Inklusionen sind echt:
  \begin{gather*}
    \begin{matrix}
      \emptyset &\subsetneq& \Prr &\subsetneq& \Pa &\subsetneq&
      \PP &\subsetneq& \mathbb{F}\\
      &1.&&2.&&3.&&4.
    \end{matrix}
  \end{gather*}

  \begin{proof}
    \begin{enumerate}
     \item z.\,B. ist $nachfolger\in\Prr$ --- \autoref{def:8}
     \item Ackermann-Funktion --- \autoref{sec:4}
     \item $wurz\in\PP\setminus\Pa$ --- \autoref{bsp:5}
     \item Es gibt Funktionen aus $\mathbb{F}\setminus\PP$, die nicht
      berechenbar sind:

      Wir wissen aus \autoref{satz:7}, dass $\PP$ eine effektive Numerierung
      besitzt, d.\,h. es gibt höchstens abzählbar unendlich
      viele partiell-rekursive Funktionen. Aber es gibt überabzählbar
      viele Zahlenfunktionen, z.\,B. ist bereits $\{0,1\}^{\N}$
      überabzählbar.
    \end{enumerate}
  \end{proof}
\end{satz}

\begin{bemerk}
  Da nicht jede partiell-rekursive Funktion partiell ist, ist
  $\mu$-rekursive Funktion eine alternative Bezeichnund.

  Da nicht jede primitiv-rekursive Funktion primitiv ist, ist
  induktiv-rekursive Funktion eine alternative Bezeichnung.
\end{bemerk}

Dennoch bleibt die Frage offen, ob \emph{jede} partiell-rekursive Funktion zu
einer allgemein-rekursiven Funktion fortgesetzt werden kann.

Dazu betrachten wir die folgende Diagonalisierung der partiell-rekursiven
Funktionen:\\
$\phi_{0},\phi_{1},\phi_{2},\ldots$ ist eine Nummerierung der
partiell-rekursiven Funktionen, die sich aus einer Auflistung aller
zugehörigen Terme ergibt. Wir definieren nun die folgende Funktion
\begin{gather*}
  \psi(n) := \phi_{n}(n) +1 =
  \begin{cases}
    \phi_{n}(n)+1&\colon \text{falls } \phi_{n}(n)\text{ definiert ist}\\
    \ndef&\colon\sonst
  \end{cases}
\end{gather*}
$\psi$ ist eine berechenbare Funktion, d.\,h. $\psi$ kommt in der Liste
$\phi_{n}$ vor. Nehmen wir an $\psi$ hat den Index $k$, also
$\psi=\phi_{k}$. Dies führt uns jedoch zu dem Problem:
\begin{gather*}
  \phi_{k}(k) = \psi(k) = \phi_{k}(k)+1 =
  \begin{cases}
    \phi_{k}(k)+1&\colon \text{falls } \phi_{k}(k)\text{ definiert ist}\\
    \ndef&\colon\sonst
  \end{cases}
\end{gather*}
als dessen Konsequenz nur gelten kann, dass $\psi$ an der Stelle $k$ nicht
definiert seien kann. $\psi(n)\in\PP$ ist also an min. einer Stelle $k$ nicht
definiert und somit nicht allgemein-rekursiv ($\notin\Pa$).
\help{Damit ist doch keine Aussage über die Fortsetzung gemacht}

Die Eigenschaft partiell-rekursiv sein zu können, ist unverzichtbar
für die Definition von Berechenbarkeit. Dies führt zu einer negativen
Antwort unserer Frage.

Es sei $\phi_{l}$ eine Nummer irgendeiner allgemein-rekursiven Funktion.
Dann gilt: $\psi(l)$ ist definiert und hat den Wert $\psi(l) =
\phi_{l}(l)+1$ und es gilt $\psi(l)\ne\phi_{l}(l)$. Also gilt
$\psi\ne\phi_{l}$ und $\phi_{l}$ ist \emph{keine} Fortsetzung von
$\psi$.

\begin{fakt}
  Nicht jede partiell-rekursive Funktion kann zu einer
  allgemein-rekursiven Funktion fortgesetzt werden!
\end{fakt}

\begin{satz}
  Die Menge $\Pa$ der allgemein-rekursiven Funktionen besitzt
  keine effektive Nummerierung!

  \begin{proof}
    (durch Diagonalisierung) Annahme: es existiert eine Liste
    $f_{0},f_{1},f_{2},\ldots$ über allgemein-rekursive Funktionen. Dann
    wäre auch die total berechenbare Funktion $g(n) = f(n)+1$ in der
    Liste enthalten und es gäbe einen Index $m$ mit $g=f_{m}$. Dies führt
    jedoch zu einem Widerspruch (\autoref{eq:6}), als dessen Konsequenz
    nur gelten kann, dass es eine solche Liste -- eine effektive
    Nummerierung -- nicht gibt.
    \begin{gather}\label{eq:6}
      f_{m}(m) = g(m) = f_{m}(m)+1
    \end{gather}
  \end{proof}
\end{satz}

Frage: Kann man eine nicht berechenbare Funktion aus $\mathbb{F}\setminus
\PP$ angeben?

Erinnern wir uns zurück: Eine Sprache $L\subseteq\Sigma^{\ast}$ heißt
entscheidbar \gdw die charakteristische Funktion $\chi_{L}$ berechenbar
ist. (\autoref{def:2}) Die Menge $\Pa$ der allgemein-rekursiven
Funktionen ist nicht aufzählbar und damit ist nach \autoref{sec:5} die
Menge nicht entscheidbar. Die charakteristisch Funktion der
allgemein-rekursiven Funktionen ist also nicht berechenbar
\begin{gather}\label{eq:7}
  \chi_{\Pa} \colon \N \rightarrow \N\qquad
     \chi_{\Pa}(n) = \begin{cases}1\colon \text{die Turing-Maschine
                       $TM_{n}$ aus $\PP$ ist total ($\in\Pa$)}\\
                       0\colon \text{sonst}
                     \end{cases}
\end{gather}

Gibt es ein anschauliches Beispiel einer partiell-rekursiven (d.\,h.
berechenbaren) Funktion, von der es nicht offensichtlich ist, dass sie
selbst oder eine ihrer Fortsetzungen nicht primitv-rekursiv ist?

% Ein Kandidat für eine solche Funktion wird jetzt beschrieben.
% Ausgangspunkt ist die ungewisse Vermutung:
\begin{quote}
  Für jede natürliche Zahl $n\geq1$ führt die wiederholte Anwendung
  folgender Regel nach endlich vielen Schritten auf die Zahl 1:
  \begin{gather*}
    n \mapsto
    \begin{cases}
      \frac{n}{2} & n \text{ ist gerade}\\
      3n+1& n \text{ ist ungerade}
    \end{cases}
  \end{gather*}
\end{quote}

Ein Beispiel hierzu:
\begin{align*}
  1&\\
  2& \mapsto 1\\
  3& \mapsto 10 \mapsto 5 \mapsto 16 \mapsto 8 \mapsto 4 \mapsto 2 \mapsto
     1\\
  4& \mapsto 2 \mapsto 1\\
  5& \mapsto 16 \mapsto 8 \mapsto 4 \mapsto 2 \mapsto 1\\
  6& \mapsto 3 \mapsto \ldots\\
  7& \mapsto 22 \mapsto 11 \mapsto 34 \mapsto 17 \mapsto 52 \mapsto 26
     \mapsto 13 \mapsto 40 \mapsto 20 \mapsto 10 \mapsto 5 \mapsto \ldots\\
  8& \mapsto 4 \mapsto\ldots \\
  9& \mapsto 28 \mapsto 14 \mapsto 7\mapsto\ldots \\
  10& \mapsto 5\mapsto\ldots
\end{align*}

Wir fassen alle Zahlen, für die diese Vermutung zutrifft als Menge $B =
\{n\in\N_{+}\colon \text{ Vermutung trifft für $n$ zu}\}$ zusammen. Nun ist die
Frage: Ist $B=\N_{+}$?

Die einmalige Anwendung der Regel entspricht folgender Funktion
\begin{gather*}
  f (n) =
    \begin{cases}
      \frac{n}{2} & n \text{ ist gerade}\\
      3n+1& n \text{ ist ungerade}
    \end{cases}
\end{gather*}
$f$ ist definiert durch primitiv-rekursive Funktionen mittels
Fallunterscheidung! Deshalb ist auch $f$ primitiv-rekursiv.

Die $t$-malige Anwendung der Regel wird durch die folgende Funktion
beschrieben
\begin{align*}
  g(n, 0) &= n && I_{1}^{1}(n)\\
  g(n,t+1) &= f(g(n,t)) = f'(n, t, g(n,t)) &&SUB(f',I_{3}^{3})
\end{align*}
$g$ ist also eine primitv-rekursive Funktion mit $PR(I_{1}^{1},
SUB(f',I_{3}^{3}))$.

Wir definieren nun
\begin{gather*}
  h(n) =
  \begin{cases}
    \mu t(g(n,t) = 1) &\colon \text{ein solches $t$ existiert}\\
    \ndef &\colon\sonst
  \end{cases}
\end{gather*}
$h$ ist partiell-rekursiv und für den Definitionsbereich gilt: $D_{n}=B$.
Aber es gibt keine Beschreibung von $h$ (oder einer Fortsetzung) als
primitv-rekursive Funktion \help{Woran sieht man das?}
\begin{gather*}
  g(n,t) = 1 \gdw g(n,t) -1 = 0
\end{gather*}

\subsection{Eigenschaften primitiv-rekursiver Funktionen}
\begin{satz}[stückweise definierte Funktionen]
  Es seien folgende Funktionen primitiv-rekursiv
  \begin{align*}
    f_{1},\ldots,f_{k},f_{k+1}\colon\N^{n} \rightarrow \N\\
    \text{und } g_{1},\ldots,g_{k} \colon\N^{n} \rightarrow \N
  \end{align*}
  und es sei die folgende Bedingung erfüllt: Es gibt \emph{keine} Tupel
  $(x_{1},\ldots,x_{n})\in\N^{n}$ mit der Eigenschaft, dass für jedes
  $j\ne i$ $g_{i}(x_{1},\ldots,x_{n})=0$ \emph{und}
  $g_{j}(x_{1},\ldots,x_{n})=0$ (d.\,h. für jedes Tupel ist höchstens
  eine Funktion $g_{i}=0$).

  Dann ist die Funktion $h\colon\N^{n}\rightarrow\N$ mit
  \begin{gather*}
    h(x_{1},\ldots,x_{n}) =
    \begin{cases}
      f_{1}(x_{1},\ldots,x_{n}) &\colon g_{1}(x_{1},\ldots,x_{n})=0\\
      f_{2}(x_{1},\ldots,x_{n}) &\colon g_{2}(x_{1},\ldots,x_{n})=0\\
      \vdots\\
      f_{k}(x_{1},\ldots,x_{n}) &\colon g_{k}(x_{1},\ldots,x_{n})=0\\
      f_{k+1}(x_{1},\ldots,x_{n}) &\colon \sonst
    \end{cases}
  \end{gather*}
  primitiv-rekursiv.
\end{satz}

\begin{satz}[obere Schranken]
  Es seien $g\colon\N^{n+1}\rightarrow_{t} \N$ und $h\colon\N^{n}\rightarrow\N$
  primitiv-rekursiv. Ferner sei $f=\mu R(g)$ die durch $\mu$-Rekursion
  aus $g$ entstehende Funktion mit der Eigenschaft, dass für alle
  $(x_{1},\ldots,x_{n})\in\N^{n}$ gilt:
  \begin{gather*}
    f(x_{1},\ldots,x_{n}) \leq h(x_{1},\ldots,x_{n})
  \end{gather*}
  (d.\,h. $f$ ist für alle Tupel $(x_{1},\ldots,x_{n})$ definiert und es
  gilt die Ungleichung).

  Dann ist $f$ primitiv-rekursiv!
\end{satz}

\begin{satz}[Simultane Rekursion]
  Es seien $g_{1},g_{2}\colon \N^{n-1}\rightarrow_{t}\N$ und $h_{1},h_{2}\colon
  \N^{n+2}\rightarrow_{t}\N$ primitiv-rekursiv.

  Dann sind auch die Funktionen $f_{1},f_{2}\colon\N^{n}\rightarrow\N$ mit
  \begin{align*}
    f_{1}(x_{1},\ldots,x_{n-1}, 0) &= g_{1}(x_{1},\ldots,x_{n})\\
    f_{2}(x_{1},\ldots,x_{n-1}, 0) &= g_{2}(x_{1},\ldots,x_{n})\\
    \text{und } f_{1}(x_{1},\ldots,x_{n-1},y+1) &=
       h_{1}(x_{1},\ldots,x_{n-1}, f_{1}(x_{1},\ldots,x_{n-1},y),
       f_{2}(x_{1},\ldots,x_{n-1},y))\\
    f_{2}(x_{1},\ldots,x_{n-1},y+1) &= h_{2}(x_{1},\ldots,x_{n-1},
       f_{1}(x_{1},\ldots,x_{n-1},y), f_{2}(x_{1},\ldots,x_{n-1},y))
  \end{align*}
  primitv-rekursiv.
\end{satz}

\begin{satz}[Wertverlaufsfunktionen]
  Es sei $A=\{0,1,\ldots,l\}$ und ferner sei
  $B_{n}\subseteq\{0,\ldots,n-1\}$ mit der Eigenschaft $\abs{B_{n}}=k$.
  Ferner sei $g_{0},\ldots,g_{l}\colon\N^{n-1}\rightarrow_{t}\N$ und
  $h\colon\N^{n+k}\rightarrow_{t}\N$ primitv-rekursiv.

  Dann ist auch die Funktion $f\colon\N^{n} \rightarrow_{t} \N$ mit
  \begin{align*}
    f(x_{1},\ldots,x_{n-1},0) &= g_{0}(x_{1},\ldots,x_{n-1})\\
    \vdots\\
    f(x_{1},\ldots,x_{n-1},l) &= g_{l}(x_{1},\ldots,x_{n-1})\\
    f(x_{1},\ldots,x_{n-1},y+1) &= h(x_{1},\ldots,x_{n-1}, y,
       z_{1},\ldots,z_{k})\\
    z_{1} &= f(x_{1},\ldots,x_{n-1},y_{1})\\
    \vdots\\
    z_{k} &= f(x_{1},\ldots,x_{n-1},y_{k})\\
    B_{y+1} &= \{y_{1},\ldots,y_{k}\}
  \end{align*}
  primitiv-rekursiv.
\end{satz}

\begin{bsp}[Fibonacci-Zahlen]\listlinebreak
  \begin{align*}
    F(0) &= F(1) = 1\\
    F(n+1) &= F(n)+F(n-1)&&n \geq 2\\[1.5ex]
    A &= \{0,1\}, B_{n}= \{n-2, n-1\colon n\geq 2\}\\
    F(0) &= F(1) = C_{1}^{0}\\
    F(n+1) &= h(n, F(n), F(n-1))
  \end{align*}

  Für $h$ ist noch zu zeigen, dass $h$ primitiv-rekursiv ist. Der Beweis
  ist analog dem für $plus$ in \autoref{bsp:7}:
  \begin{align*}
    h(a,b,c) &= b+c\\
    h(a,b,0) &= b\\
    h(a,b,c+1) &= N\bigl(I_{4}^{4}(a,b,c, h(a,b,c)) \bigr)
  \end{align*}
  $F$ ist primitiv-rekursiv!
\end{bsp}

\section{Partiell-rekursive und Turing-berechenbare Funktionen}

\begin{satz}
  Jede partiell-rekursive Funktion ist Turing-berechenbar, d.\,h.
  $\PP\subseteq\TM$.

  \begin{proof}
    $\PP$ ist laut \autoref{def:9} die kleinste Klasse, die die
    Grundfunktionen umfasst und abgeschlossen bzgl. $SUB,PR$ und $\mu R$
    ist. Zeigen wir also, dass diese auch Turing-berechenbar sind:
    \begin{enumerate}
     \item Nach \autoref{bem:3} ist jede Grundfunktion Turing-berechenbar:
      $\mathcal{G}\subseteq\TM$.
     \item Nach \autoref{bem:4} ist $\TM$ abgeschlossen bzgl. der
      Einsetzung:
      falls $g_{1},\ldots,g_{m}\colon\N^{n}\rightarrow_{t}\N$ und
      $h\colon\N^{m}\rightarrow_{t}\N$ Turing-berechenbar sind, dann ist auch
      $f\colon\N^{n}\rightarrow_{t}\N$ mit $f(x_{1},\ldots,x_{n}) =
      h\bigl(g_{1}(x_{1},\ldots,x_{n}),\ldots,
      g_{m}(x_{1},\ldots,x_{n})\bigr)$ Turing-berechenbar!

     \item Nach \autoref{bem:5} ist $\TM$ abgeschlossen bzgl. Primitiver-Rekursion,
      d.\,h. falls $g\colon\N^{n-1} \rightarrow_{t}\N$ und
      $h\colon\N^{n+1}\rightarrow_{t}\N$ Turing-berechenbar sind, dann ist
      auch $f\colon\N^{n}\rightarrow\N$ mit
      \begin{align*}
	f(x_{1},\ldots,x_{n-1},0) &= g(x_{1},\ldots,x_{n-1})\\
	f(x_{1},\ldots,x_{n-1},y+1) &= h\bigl(x_{1},\ldots,x_{n-1}, y,
	   f(x_{1},\ldots,x_{n-1},y)\bigr)
      \end{align*}
      Turing-berechenbar.

      Es sei $M_{g}$ (bzw. $M_{h}$) eine Turing-Maschine, die die
      Funktion $g$ (bzw. $h$) berechnet. $M_{g}(x_{1},\ldots,x_{n-1})$
      bezeichnet im Folgenden das Resultat der Berechnung von $M_{g}$ bei Eingabe
      $(x_{1},\ldots,x_{n-1})$.

      Wir beschreiben folgende Turing-Maschine für die Eingabe
      $(x_{1},\ldots,x_{n-1},y)$:\\
      \underline{begin} (Eingabe: $x_{1},\ldots,x_{n-1},y$)
      \begin{enumerate}
       \item $t:=0$
       \item $z:= M_{g}(x_{1},\ldots,x_{n-1})$
       \item \underline{while} $t\ne y$ \underline{do}
       \item \quad $z:= M_{h}(x_{1},\ldots,x_{n-1}, t,z)$
       \item \quad $t:= t+1$
       \item \underline{end}
       \item \underline{return} $z$
      \end{enumerate}
      \underline{end}

      Die so beschriebene Turing-Maschine berechnet $f$!

     \item \TM ist abgeschlossen bzgl. $\mu$-Rekursion, d.\,h. falls
      $g\colon \N^{n+1} \rightarrow \N$ Turing-berechenbar ist, dann ist auch
      $f\colon \N^{n} \rightarrow \N$ Turing-berechenbar, wobei
      \begin{gather*}
        f(x_{1},\ldots,x_{n}) = \mu t \bigl( g(x_{1},\ldots,x_{n})=0 \bigr)
      \end{gather*}

      \underline{begin} (Eingabe: $x_{1},\ldots,x_{n}$)
      \begin{enumerate}
       \item $t:= 0$
       \item $z:= M_{g}(x_{1},\ldots,x_{n},t)$
       \item \underline{while} $z\ne0$ \underline{do}
       \item \quad $t:= t+1$
       \item \quad $z := M_{g}(x_{1},\ldots,x_{n},t)$
       \item \underline{end}
       \item \underline{return} $t$
      \end{enumerate}
      \underline{end}
    \end{enumerate}
  \end{proof}
\end{satz}

\begin{satz}
  Jede Turing-berechenbare Funktion ist partiell-rekursiv. $\TM\subseteq\PP$

  \begin{proof}
    Die Idee dabei ist, die Arbeitsweise von Turing-Maschinen durch
    primitiv- bzw. partiell-rekursive Funktionen "`zu beschreiben"'.

    Es sei $M = (Q,\Sigma, \Gamma, \delta, q_{0}, F)$ eine
    Turing-Maschine.

    Das Arbeitsalphabet $\Gamma = \{\Box, a_{1}, a_{2},\ldots,a_{m-1}\}$
    wird interpretiert (indetifiziert) mit der Zahlenmenge
    $\{0,1,2,\ldots,m-1\}$ des $m$-nären Systems.

    \begin{description}
     \item[\underline{Schreibweise:}] $Konf_{M}(w,t)$ bezeichnet die
      Konfiguration (Bandinschrift, Kopfposition, Zustand) von $M$ bei
      Eingabe $w$ nach dem Takt $t$ und wird beschrieben durch
      \begin{gather*}
        \underbrace{y_{l}\ldots y_{2}y_{1}}_{\text{linker Teil}}
           \underbrace{x_{0}q}_{\text{Zustand}}
           \underbrace{x_{0}x_{1}\ldots x_{k}}_{\text{rechter Teil}}
      \end{gather*}
    \end{description}

    Die Berechnung von $M$ bei Eingabe $w$ wird
    vollständig durch die Folge von Konfigurationen beschrieben.
    \begin{gather*}
      Konf_{M}(w,0) \vdash Konf_{M}(w,1) \vdash Konf_{M}(w,2) \vdash
         \ldots \vdash Konf_{M}(w,t)
    \end{gather*}
    Dabei ist $K_{0}=Start_{M}(w)$ die Startkonfiguration, $K_{t}$
    eine Finalkonfiguration und $K_{i} \vdash K_{i+1}$ gemäß $\delta$.

    Wir definieren:
    \begin{align*}
      Z(w,t) = q\\
      R(w,t) = \sum_{0}^{k} x_{i}m^{i}\\
      L(w,t) = \sum_{0}^{l} y_{i}m^{i}
    \end{align*}

    Damit ist die Konfiguration $Konf_{M}(w,t)$ mit Hilfe der drei
    Funktionen $Z,R$ und $L$ vollständig beschrieben.
    Die Beschreibung der Bandinschrift ist auf diese Weise eindeutig!


    Mithilfe von simultaner Rekursion zeigen wir jetzt noch, dass die
    definierten Funktionen (sogar) primitiv-rekursiv sind.

    Anfang:
    \begin{align*}
      Z(w,0) &= q_{0}\\
      R(w,0) &= \sum_{0}^{n} w_{i}m^{i}&&w=w_{1}w_{2}\ldots w_{n}\\
      L(w,0) &= 0
    \end{align*}

    Schritt an der Stelle $t\rightarrow t+1$:\\
    es sei $Z(w,t) = q$ der aktuelle Zustand und das aktuelle Symbol
    $x=R(w,t) \mod m$. Ferner sei
    \begin{gather*}
      \delta(q,x) = q'x'\begin{cases}
                          \text{nach rechts}\\
                          \text{stehen bleiben}\\
                          \text{nach links}
                        \end{cases}
    \end{gather*}

    Damit lässt sich ein Schritt der Überführungsfunktion auf die folgende
    Weise nachbilden:
    \begin{align*}
      Z(w, t+1) &= q'\\
      R(w,t+1) &= \begin{cases}
                   R(w,t) \div m&\colon \text{nach rechts}\\
                   R(w,t) - x +x'&\colon \text{stehenbleiben}\\
                   \big(R(w,t) - x +x'\big)m+y_{0} &\colon\text{nach links}
                 \end{cases}\\
      L(w,t+1) &= \begin{cases}
                   L(w,t)m + x' &\colon \text{nach rechts}\\
                   L(w,t)&\colon \text{stehenbleiben}\\
                   L(w,t) \div m &\colon\text{nach links}
                  \end{cases}\\
    \end{align*}

    Wir definieren:
    \begin{gather*}
      stopp_{M}(w) := \mu t \bigl( Z(w,t)\in F\bigr)
    \end{gather*}
    \begin{enumerate}[1{.\,Fall}]
     \item Ein solches $t$ existiert nicht, d.\,h. $M$ stoppt bei
      Eingabe $w$ nicht.

      Dann ist $stopp_{M}(w)= \ndef$.
     \item Ein $t$ existiert, d.\,h. $M$ stoppt und $stopp_{M}(w)$ ist
      definiert.
    \end{enumerate}
    Die Funktion $stopp_{M}$ ist partiell-rekursiv.

    Wir definieren weiterhin:
    \begin{gather*}
      Res_{M}(w) = R(w, stopp(w))
    \end{gather*}
    Damit gilt: Das Ergebnis der Berechnung von $M$ bei Eingabe $w$ ist
    $Res_{M}(w)$ \gdw ein Ergebnis existiert.

    Damit haben wir gezeigt, dass jede Turing-berechenbare Funktion $f$ eine
    Darstellung der folgenden Form mit den primitiv-rekursiven Funktionen
    $Z, L$ und $R$ und einer $\mu$-Rekursion besitzt:
    \begin{gather*}
      f(w) = Res_{M}(w) = R(w, \mu t \bigl(Z(w,t) \in F\bigr) )
    \end{gather*}
    \end{proof}
\end{satz}

\begin{bemerk}
  Der Beweis hängt wesentlich davon ab, dass $\div$ und $\mod$
  primitiv-rekursiv sind.
\end{bemerk}
Dazu die nun folgende Herleitung.

Es seien $f\colon\N^{n+1} \rightarrow_{t} \N$ und $g\colon\N^{n} \rightarrow_{t}
\N$ primitiv-rekusiv. Ferner gelte
\begin{align*}
  \forall (x_{1},\ldots,x_{n})\in\N^{n} \exists y \leq
     q(x_{1},\ldots,x_{n})&&(f(x_{1},\ldots,x_{n})=0)
\end{align*}

Dann ist eine Funktion $h\colon \N^{n}\rightarrow\N$ primitiv-rekursiv, wobei
\begin{gather*}
  h(x_{1},\ldots,x_{n}) = \mu y\bigl( f(x_{1},\ldots,x_{n},y) =0\bigr)
\end{gather*}

\begin{proof}
  Hilfsfunktion $h'\colon \N^{n+1} \rightarrow \N$
  \begin{align*}
    h'(x_{1},\ldots,x_{n},z) &= \mu y(y\leq z \wedge
       f(x_{0},\ldots,x_{n},y) = 0)\\
    &:= \sum_{i=0}^{z} sgn \bigl( \prod_{j=0}^{i}
       f(x_{1},\ldots,x_{n},j) \bigr)
  \end{align*}

  $h'$ ist primitiv-rekursiv und es gilt:
  \begin{gather*}
    h(x_{1},\ldots,x_{n}) = h'\bigl(x_{1},\ldots,x_{n},
       g(x_{1},\ldots,x_{n})\bigr)
  \end{gather*}
  Also ist auch $h$ primitiv-rekursiv!
\end{proof}

\underline{Anwendung:}
\index{div@$\div$}
\begin{gather*}
  x \div y = \mu z\big( (x+1) - (z+1) y =0 \big)\\
\end{gather*}
Ausnahme: $x \div 0 := 0$
\begin{center}
  % \tabularnewline verwendet wegen <news:85u0grhhhi.fsf@lola.goethe.zz>
  \begin{tabular}{*{2}{>{\centering}p{2cm}|}|>{\centering}p{2cm}}
    x\quad & y\quad & z\tabularnewline
    \hline
    11 & 4 & 2\tabularnewline
    12 & 4 & 3\tabularnewline
    13 & 4 & 3
  \end{tabular}
\end{center}
und damit
\index{mod@$\mod$}
\begin{gather*}
  x \mod y = x-y (x\div y)
\end{gather*}

\subsection{Eigenschaften partiell-rekursiver Funktionen}
\begin{satz}[Kleene'scher Normalformsatz]
  Jede ($n$-stellige) partiell-rekursive Funktion $f$ besitzt die
  Darstellung der Form
  \begin{gather*}
    f(x_{1},\ldots,x_{n}) = g \big(\mu y(h(x_{1},\ldots,x_{n},y) = 0) \big)
  \end{gather*}
  mit primitiv-rekursiven Funktionen $g\colon \N\rightarrow_{t}\N$ und $h\colon
  \N^{n+1} \rightarrow_{t} \N$
\end{satz}

\begin{satz}[Parametrisierungssatz]
  Jede ($n$-stellige) partiell-rekursive Funktion $f$ besitzt eine
  Darstellung der Form
  \begin{gather*}
    f = \big\{ \big(g_{1}(t), g_{2}(t), \ldots, g_{n}(t), g_{n+1}(t)
       \big) \colon t\in\N \big\}
  \end{gather*}
  mit (einstelligen) primitiv-rekursiven Funktionen
  $g_{1},\ldots,g_{n+1}\colon \N \rightarrow_{t}\N$ oder $f$ ist nirgends
  definitert.
\end{satz}

\chapter{Formale Sprachen und formale Grammatiken}

Unverzichtbare Bestandteile höherer Programmiersprachen sind:
\begin{itemize}
 \item Wertzuweisung
 \item Bedingungen testen
 \item Fallunterscheidung
 \item Schleifen
\end{itemize}
Rein von der Intuition her, können all diese Bestandteile (von
Programmen) durch spezielle Turing-Maschinen realisiert werden. Das
bedeutet: alles was sich mit solchen \highl{Programmiersprachen}
berechnen lässt, kann auch von Turing-Maschinen berechnet werden und ist
damit auch partiell-rekursiv.

\highl{Programmiersprachen} sind "`künstliche"' Sprachen (formale
Sprachen) mit der gemeinsamen Eigenschaft, dass ihre Syntax durch exakte
Regeln definiert ist.
Das heißt für jede Zeichenkette ist es wohl definiert, ob sie ein Wort
(Programm) in der gegebenen formalen Sprache darstellt oder nicht.

Solche formalen Sprachen werden durch formale Grammatiken definiert.
Damit wird der Begriff der formalen Grammatik zu einer weiteren
mathematischen Präzesierung des Begriffs Algorithmus.

Grammatiken erzeugen Wörter. Wir wollen aber Funktionen
berechnen! Eine Grammatik berechnet eine Funktion, indem sie ihren
Graphen erzeugt.

Es sei $f\colon\Sigma^{\ast} \rightarrow \Delta^{\ast}$ eine Funktion (die
durch eine Turing-Maschine berechnet wird). Dann lässt sich eine
Grammatik konstruieren, die die folgende Sprache erzeugt:
\begin{gather*}
  \{ (u,v)\colon u\in\Sigma^{\ast}, v\in\Delta^{\ast} \wedge f(u) = v\}
\end{gather*}
Dies ist gerade der Graph von $f$.

\section{Grammatiken und Sprachen vom Typ-0}
\begin{defini}
  Eine "`\highl[Grammatik!Typ-0]{Typ-0-Grammatik}"' oder einfach nur
  Grammatik genannt ist ein Viertupel $G=(N, T, S, P)$ mit\\
  \begin{auflistung}
   $N$& ist ein endliches (nichtleeres) Alphabet -- Menge der
    \highl{Nichtterminale} oder \highl{Variablen}\\
   $T$& ist ein endliches (nichtleeres) Alphabet mit $N\cap
    T=\emptyset$ -- Menge der \highl{Terminale}\\
   $S$& $S\in N$ ist das \highl{Startsymbol}\\
   $P$& $P\subseteq (N\cup T)^{\ast} \times (N\cup T)^{\ast}$ ist eine
    endliche Menge von Paaren der Form $(p,q)$, wobei $p\notin T^{*}$
    (d.\,h. $p$ enthält mindestens ein Nichterminal).

    $P$ ist die Menge der \highl{Produktionen} oder \highl{Regeln} von $G$.

    \begin{description}
     \item[\underline{Schreibweise:}] $p \rightarrow q$
    \end{description}
  \end{auflistung}
\end{defini}

Nun stellt sich die Frage, wie mit Hilfe dieser Regeln Wörter erzeugt
werden können. Ein Ansatz ist die folgende Idee: Falls ein Wort
$w=w_{l}pw_{r}$ bereits (irgendwie) erzeugt ist und es eine Regel
$p\rightarrow q$ gibt, dann wird $w' = w_{l}qw_{r}$ erzeugt. Beginnen werden wir mit dem
Startsymbol $S$.

\begin{defini}\label{def:10}
  Es sei $G=(N,T,S,P)$ eine Grammatik.

  \begin{enumerate}
   \item Ein Wort $w'$ heißt \highl[ableitbar!in einem Schritt]{in einem
    Schritt} aus einem Wort $w$ \highl{ableitbar} \gdwdef es zwei Wörter
    $w_{l}$ und $w_{r}$ gibt, die das Wort $w$ bilden als
    $w=w_{l}pw_{r}$, eine Produktion $p\rightarrow q$ exsistiert und es
    gilt $w' = w_{l}qw_{r}$

    \begin{description}
     \item[\underline{Schreibweise:}] $w \rightarrow w'$
    \end{description}

   \item Ein Wort $v$ heißt \highl{ableitbar} aus einem Wort $u$
    \gdwdef es eine Folge von Wörtern
    $w_{0},w_{1},\ldots,w_{n}$ mit $w_{0}=u, w_{n}=v$ und
    entsprechende Produktionen $w_{i}\rightarrow w_{i+1}$ für
    $i=0,\ldots,n-1$ gibt.

    Eine solche Folge heißt \highl{Ableitung der Länge $n$}

    \begin{description}
     \item[\underline{Schreibweise:}] $u \rightarrow ^{\ast} v$
    \end{description}

   \item Die von dieser Typ-0-Grammatik $G$ erzeugte
    \highl[Sprache!Typ-0]{Typ-0-Sprache} ist gegeben durch
    \begin{gather*}
      L(G) := \{ w\in T^{\ast}\colon S \rightarrow ^{\ast} w\}
    \end{gather*}
    Eine Sprache $L$ heißt Typ-0-Sprache \gdwdef eine
    Grammatik $G$ mit $L(G) =L$ exsistiert.
   \item $CH(0) = \{ L\colon L\ \text{ist Typ-0-Sprache} \}$ ist die
    \highl[Klasse!Typ-0-Sprachen]{Klasse der Typ-0-Sprachen}.
  \end{enumerate}
\end{defini}

\begin{bsp}\label{bsp:3}
  \begin{align*}
    G &= (N,T,S,P)\\
    N &= \{ S,R,L \}\\
    T &= \{ a, \# \}\\
    P &= \{ S \rightarrow \#aL\#, &&\text{Regel 1}\\
    &=\quad aL \rightarrow Laa, &&\text{Regel 2}\\
    &=\quad \#L \rightarrow \#R, &&\text{Regel 3}\\
    &=\quad \#L \rightarrow \#, &&\text{Regel 4}\\
    &=\quad Ra \rightarrow aaR, &&\text{Regel 5}\\
    &=\quad R\# \rightarrow L\#, &&\text{Regel 6}\\
    &=\quad R\# \rightarrow \#\} &&\text{Regel 7}
  \end{align*}

  Konkrete Beispiele für Ableitungen:
  \begin{align*}
    S &\rightarrow \#aL\# && \text{Regel 1}\\
    \#aL\# &\rightarrow \#Laa\# && \text{Regel 2}\\
    \#Laa\# &\rightarrow \#aa\# && \text{Regel 4}\\
    \intertext{$\Rightarrow \#aa\#\in L(G)$}
    \#Laa\# &\rightarrow \#Raa\# && \text{Regel 3}\\
    \#Raa\# &\rightarrow \#aaRa\# && \text{Regel 5}\\
    \#aaRa\# &\rightarrow \#aaaaR\# && \text{Regel 5}\\
    \#aaaaR\# &\rightarrow \#aaaa\# && \text{Regel 7}\\
    \intertext{$\Rightarrow \#aaaa\#\in L(G)$}
    \#aaaaR\# &\rightarrow \#aaaaL\# && \text{Regel 6}\\
    \#aaaaL\# &\rightarrow \#aaaLaa\# && \text{Regel 2}\\
    \ldots
  \end{align*}

  \begin{gather*}
    L(G) = \{ \#\underbrace{a\ldots a}_{2^{i}}\#\colon i\in\N, i\geq 1\}
  \end{gather*}
\end{bsp}

Grammatiken erzeugen Sprachen, häufig werden die Eigenschaften von Sprachen
als Eigenschaften von Grammatiken nachgewiesen! Diese Nachweise werden
vereinfacht, falls es gelingt die Produktionen zu vereinfachen:
durch \highl{Normalformen}.

\begin{defini}
  Eine Grammatik $G=(N,T,S,P)$ ist in
  \highl[Chomski-NF!Typ-0]{Chomski-Normalform vom Typ-0}
  \index{Normalform!Grammatik|see{Chomski-NF}} \gdwdef
  \begin{enumerate}
   \item $P$ enthält höchstens eine Regel der Form $p\rightarrow\lambda$
    ($\lambda$: leeres Wort)
   \item alle Produktionen haben eine der folgenden Formen
    \begin{enumerate}
     \item $X\rightarrow YZ$ \label{enu:NF0-1}
     \item $XY \rightarrow Z$ \label{enu:NF0-2}
     \item $X \rightarrow a$ \label{enu:NF0-3}
    \end{enumerate}
    wobei $X,Y,Z\in N, a\in T\cup\{\lambda\}$.
  \end{enumerate}
\end{defini}

\begin{bemerk}
  Diese Einschränkung ist drastisch! Auch unsere Beispielgrammatik aus
  \autoref{bsp:3} erfüllt diese Einschränkung nicht.
\end{bemerk}

\begin{defini}
  Zwei Grammatiken $G_{1}$ und $G_{2}$ sind \highl{äquivalent}
  \gdwdef $L(G_{1}) = L(G_{2})$
\end{defini}

\begin{satz}\label{satz:2}
  Zu jeder Grammatik $G$ vom Typ-0 gibt es eine äquivalente
  Normalformgrammatik vom Typ-0.

  \begin{proof}
    Der Beweis ist konstruktiv und beschreibt einen Algorithmus, wie man
    aus einer gegebenen Grammatik $G$ eine äquivalente
    Normalformgrammatik $G'$ erzeugt. Der Algorithmus vollzieht sich in
    folgenden Globalschritten und wird in \autoref{bsp:4} an der
    Grammatik aus \autoref{bsp:3} illustriert.

    \begin{schritte}
     \item Alle Terminalsymbole sollen nur noch in Regeln der Form
      % skript-check aus
      \ref{enu:NF0-3} auftreten. Dazu wird:
      % skript-check an
      \begin{itemize}
       \item für jedes Terminalsymbol $t\in T$ ein Nichtterminalsymbol
        $t'\in N_{1}$ definiert,
       \item jede Regel $(p\rightarrow q) \in P$ wird durch $(p'\rightarrow
        q') \in P_{1}$ ersetzt, indem alle Terminale $t$ in $p$ und
        $q$ durch $t'$ ersetzt werden und so die neuen $p'$ und $q'$
        entstehen und
       \item eine neue Regel $t' \rightarrow t$ ($\forall t\in T$) neu
        aufgenommen werden.
      \end{itemize}

      Die so beschriebene Grammatik bezeichnen wir mit $G_{1}=(N_{1}, T,
      S, P_{1})$

     \item Wenn es mehrere Regeln der Form $p\rightarrow \lambda$ gibt,
      wird ein neues Nichtterminal~$L$ eingeführt, alle diese Regeln
      durch $p\rightarrow L$ ersetzt und eine neue Regel $L\rightarrow
      \lambda$ hinzugefügt.

     \item Nun sollen alle Regeln $p\rightarrow q$, die aus mehr als
      einem Symbol bestehen, so umgewandelt werden, dass sie entweder von
      % skript-check aus
      Form~\ref{enu:NF0-1} oder \autoref{enu:NF0-2} sind.
      % skript-check an

      Dazu wird für jede Regel (die nicht schon von der
      % skript-check aus
      Form~\ref{enu:NF0-1} oder \ref{enu:NF0-2} ist) ein neues
      % skript-check an
      Nichtterminal $B\in N_{2}$ definiert und die alte Regel $p
      \rightarrow q$ durch zwei neue Regeln ersetzt: $p \rightarrow B,
      B\rightarrow q$.

      Das Ergebnis ist die Grammatik $G_{2} = (N_{2}, T, S, P_{2})$.

     \item Als nächster Schritt soll die Längenbeschränkung realisiert
      werden. Dabei betrachten wir Regel $p\rightarrow q \in P_{2}$, für die
      ($\abs{p}>2$ und $\abs{q}=1$) oder ($\abs{p}=1$ und $\abs{q}>2$)
      ist. Es sei $X\rightarrow Y_{1}Y_{2}\ldots Y_{n}$ und $n>2$ die
      Form von $p\rightarrow q$.

      Wir definieren neue Nichtterminale $D_{1},D_{2},\ldots,D_{n-2}$ und
      ersetzen $p\rightarrow q$ durch die Regeln
      \begin{gather*}
        X\rightarrow Y_{1}D_{1}, D_{1} \rightarrow Y_{2}D_{2}, D_{2}
           \rightarrow Y_{3}D_{3},\ldots,D_{n-3} \rightarrow
           Y_{n-2}D_{n-2}, D_{n-2} \rightarrow Y_{n-1}Y_{n}
      \end{gather*}

      Falls $X_{1}X_{2}\ldots X_{n} \rightarrow Y$ die Form von
      $p\rightarrow q$ ist, dann definieren wir neue Nichtterminale
      $E_{1}, E_{2},\ldots,E_{n-2}$ und ersetzten $p\rightarrow q$ durch
      \begin{gather*}
        X_{1}X_{2} \rightarrow E_{1}, E_{1}X_{3} \rightarrow E_{2},
           E_{2}X_{4} \rightarrow E_{3}, \ldots,E_{n-3} X_{n-1}
           \rightarrow E_{n-2}, E_{n-2} X_{n} \rightarrow Y
      \end{gather*}

     \item Alle Regeln der Form $X \rightarrow Y$, die also auf
      \emph{beiden} Seiten nur ein Terminal oder Nichtterminal stehen
      haben, werden nun noch durch je zwei neue Regeln $X \rightarrow VW$
      und $VW \rightarrow Y$ ersetzt, wobei $X,Y\in N_{4}$.
    \end{schritte}
  \end{proof}
\end{satz}

\begin{bsp}\label{bsp:4}
  An einem Beispiel wollen wir nun den Algorithmus aus \autoref{satz:2}
  an der Grammatik aus \autoref{bsp:3} nachvollziehen.

  \begin{schritte}
   \item
    \begin{align*}
      G_{1} &= (N_{1}, T, S, P_{1})\\
      N_{1} &= N\cup \{A,Z\} = \{ S,R,L,A,Z \}\\
      P_{1} &= \{ S \rightarrow ZALZ, &&\text{Regel 1}\\
      &=\quad AL \rightarrow LAA, &&\text{Regel 2}\\
      &=\quad ZL \rightarrow ZR, &&\text{Regel 3}\\
      &=\quad ZL \rightarrow Z, &&\text{Regel 4}\\
      &=\quad RA \rightarrow AAR, &&\text{Regel 5}\\
      &=\quad RZ \rightarrow LZ, &&\text{Regel 6}\\
      &=\quad RZ \rightarrow Z, &&\text{Regel 7}\\
      &=\quad Z \rightarrow \#,\\
      &=\quad A \rightarrow a \}\\
      L(G_{1}) &= \{ \#a^{m}\#\colon m = 2^{n}, n\geq 1\} = L(G)
    \end{align*}
   \item Dieser Fall tritt bei unserer Beispielgrammatik nicht auf.
   \item
    \begin{align*}
      G_{2} &= (N_{2}, T, S, P_{2})\\
      N_{2} &= N_{1}\cup \{B_{1}, B_{2}, B_{3}, B_{4}\}\\
      P_{2} &= \{ S \rightarrow ZALZ, &&&&\text{Regel 1}\\
      &=\quad AL \rightarrow B_{1}, & B_{1} &\rightarrow LAA, &&\text{Regel 2}\\
      &=\quad ZL \rightarrow B_{2}, &B_{2} &\rightarrow ZR, &&\text{Regel 3}\\
      &=\quad ZL \rightarrow Z, &&&&\text{Regel 4}\\
      &=\quad RA \rightarrow B_{3}, &B_{3} &\rightarrow AAR, &&\text{Regel 5}\\
      &=\quad RZ \rightarrow B_{4}, &B_{4} &\rightarrow LZ, &&\text{Regel 6}\\
      &=\quad RZ \rightarrow Z, &&&&\text{Regel 7}\\
      &=\quad Z \rightarrow \#,\\
      &=\quad A \rightarrow a \}
    \end{align*}
   \item
    \begin{align*}
      G_{3} &= (N_{3}, T, S, P_{3})\\
      N_{3} &= N_{2}\cup \{D_{1}, B_{2}, E_{1}, E_{2}\}\\
      P_{3} &= \{ S \rightarrow ZD_{1}, D_{1} \rightarrow AD_{2}, &D_{2}
         &\rightarrow LZ, &&&&\text{Regel 1}\\
      &=\quad AL \rightarrow B_{1}, & B_{1} &\rightarrow LE_{1}, &E_{1}
         &\rightarrow AA, &&\text{Regel 2}\\
      &=\quad ZL \rightarrow B_{2}, &B_{2} &\rightarrow ZR, &&&&\text{Regel 3}\\
      &=\quad ZL \rightarrow Z, &&&&&&\text{Regel 4}\\
      &=\quad RA \rightarrow B_{3}, &B_{3} &\rightarrow AE_{2}, &E_{2}
         &\rightarrow AR, &&\text{Regel 5}\\
      &=\quad RZ \rightarrow B_{4}, &B_{4} &\rightarrow LZ, &&&&\text{Regel 6}\\
      &=\quad RZ \rightarrow Z, &&&&&&\text{Regel 7}\\
      &=\quad Z \rightarrow \#,\\
      &=\quad A \rightarrow a \}
    \end{align*}
   \item Dieser Fall tritt bei unserer Beispielgrammatik nicht auf.
  \end{schritte}

  Wir haben jetzt zu der Grammatik $G$ eine äquivalente Grammatik $G_{3}$
  in Chomski-Normalform vom Typ-0 konstruiert.
\end{bsp}

Wie bereits erwähnt werden Grammatiken für höhere
\highl{Programmiersprachen} eingesetzt. Sie dienen der Definition der
\highl{Syntax} der Sprache. Zur Prüfung der syntaktischen Korrektheit
eines Programms stellt sich die Frage, ob das gegebene Programm
tatsächlich den Regeln der Grammatik entspricht. Gilt also:
\begin{gather*}
  P\in L(G)
\end{gather*}
Diese Frage bezeichnet man als das \highl{Wortproblem}. Sie ist
gleichwertig zu der Frage nach einem \highl{Parser} \footnote{Parser:
effizienter Algorithmus, der nachweist, ob $P$ Programm ist ($\in L(G)$)
oder nicht ($\notin L(G)$)} für die Grammatik~$G$.

Für Grammatiken vom Typ-0 gibt es trotz der Einschränkungen keinen
Parser, d.\,h. es gibt Grammatiken vom Typ-0, für die \emph{kein}
Algorithmus existiert, der entscheidet, ob für eine Eingabe $w$ gilt:
$w\in L(G)$ oder $w\notin L(G)$. Typ-0-Grammatiken sind sowohl aus
theoretischer wie aus praktischer Sicht zu allgemein.

\subsection[Beziehungen zwischen Typ-0-Grammatiken und Turing-Maschinen]%
           {Beziehungen zwischen dem Leistungsvermögen von
             Typ-0-Grammatiken und Turing-Maschinen}
\label{sec:3}

\begin{satz}\label{satz:6}
  Falls $L\subseteq \Sigma^{\ast}$ Turing-aufzählbar ist, dann existiert
  eine Typ-0-Grammatik $G$ mit $L(G) = L$.

  \begin{proof}
    Wenn $L$ Turing-aufzählbar ist, dann existiert (nach \autoref{def:4})
    eine Turing-Maschine $M$ mit $M(\Sigma^{\ast})=L$. Dazu können wir
    eine Turing-Maschine $M'$ konstruieren: $Acc(M')=L$. Ausgehend von
    $M'$ konstruieren wir eine Grammatik $G$, die alle Wörtet erzeugt,
    die von $M'$ akzeptiert werden.

    Es sei $\Sigma^{\ast}= \{\lambda=w_{0},
    w_{1},\ldots \}$ die \highl{kanonische}
    (\highl{quasilexikographische}) Auflistung von $\Sigma^{\ast}$. Für
    eine Eingabe $u$ simuliert die neue Turing-Maschine $M'$ die
    Maschine $M$ auf die folgende Weise:

    $M'$ vollzieht die Berechnungen von $M$ für die Eingabe $w_{0},
    w_{1}, w_{2}, \ldots$ nach und vergleicht jedes (Zwischen-)Ergebnis
    $M(w_{0}), M(w_{1}), M(w_{2}),\ldots$ mit der Eingabe $u$. Falls
    für ein $i$ gilt: $M(w_{i}) = u$, dann löscht $M'$ den gesamten
    Bandinhalt und geht in den einzigsten akzeptierenden Finalzustand
    $q_{+}$.

    Dann gilt:
    \begin{align*}
      u\in L &\gdw \exists i\colon M(w_{i}) = u\\
      &\gdw M'\ \text{stoppt bei Eingabe $u$}\\
      &\gdw M'\ \text{akzeptiert die Eingabe $u$ (mit
         leerem Band und Finalzustand $q_{+}$)}\\
      &\gdw u\in Acc(M')
    \end{align*}

    \obda fordern wir:
    \begin{itemize}
     \item der Startzustand $q_{0}$ kommt nur in der Anfangskonfiguration
      vor,
     \item eine neues Symbol $\#$ wird an das rechte Ende der Eingabe
      gesschrieben und
     \item das Turingband rechts von $\#$ wird nicht benutzt.
    \end{itemize}
    $M''$ sei eine so modifizierte Turing-Maschine.
    \begin{align*}
      Start-M''(u) &= q_{0}u_{1}u_{2}\ldots u_{k}\# && u=u_{1}\ldots u_{k}\\
      Acc_{M''}(u) = \begin{cases}q_{+}&\colon u\in L\\\ndef&\colon\sonst\end{cases}
    \end{align*}

    Ziel ist es nun eine Typ-0-Grammatik $G$ zu konstruieren, die
    ausgehend von der akzeptierenden Konfiguration $q_{+}$ von $M''$ jede
    mögliche Startkonfiguration $q_{0}u_{1}\ldots u_{k}\#$ und damit $L$
    durch "`Rückwärtsrechnung"' erzeugt.

    Wir beschreiben eine solche Grammatik in drei Schritten:
    \begin{schritte}
     \item Erzeugung der akzeptierenden Konfiguration mit ausreichend
      vielen Blanksymbolen $\Box$:
      \begin{gather*}
        S\rightarrow q_{+}, q_{+} \rightarrow q_{+}\Box, q_{+}
           \rightarrow\Box q_{+}
      \end{gather*}
      (erzeugen damit $\Box^{i}q_{+}\Box^{j}, i,j\in\N$)

     \item "`Rückwärtsrechnung"'
      \begin{enumerate}
       \item falls $\delta(q,a) = (q', a', R)$, dann erstelle die Regel
        $a'q' \rightarrow qa$
       \item falls $\delta(q,a) = (q', a', L)$, dann erstelle die Regel
        $q'ba' \rightarrow baq$ ($\forall b\in\Gamma$)
       \item falls $\delta(q,a) = (q', a', 0)$, dann erstelle die Regel
        $q'a' \rightarrow qa$
      \end{enumerate}

      Mithilfe dieser Regeln lässt sich für jede Konfiguration $k$ von
      $M''$ eine Vorgängerkonfiguration $k^{-}$ mit $k^{-} \vdash_{M''} k$
      erzeugen. Als Zwischenergebnis erhalten wir Konfigurationen der
      Form $\Box\Box\ldots \Box q_{0}u_{1}\ldots u_{k}\#$, wobei
      $u_{1}\ldots u_{k}\in L$
     \item Die Schlussregel soll noch die $\Box, q_{0}$ und $\#$ löschen:
      \begin{gather*}
        \Box q_{0} \rightarrow q_{0}, q_{0}a \rightarrow aq_{0} (\forall
           a\in\Sigma), q_{0}\# \rightarrow \lambda
      \end{gather*}
    \end{schritte}

    Als Endergebnis erhalten wir: $u_{1}\ldots u_{n}\in L$, also $L(G)=L$.
  \end{proof}
\end{satz}

Das Pendant zum vorherigen Satz liefert der nächste:
\begin{satz}\label{satz:5}
  Jede Sprache $L\subseteq \Sigma^{\ast}$, die durch eine Typ-0-Grammatik
  erzeugt werden kann, ist auch Turing-aufzählbar.

  \begin{proof}
    Es sei $G=(N,T,S,P)$ die Grammatik vom Typ-0 (in Normalform) mit
    $L(G) =L$. Jede solche Grammatik erzeugt einen \highl{markieren
    Arbeitsbaum} für $L(G)$. Es sei $S\rightarrow ^{\ast} u$.
    Die direkten Nachfolgeableitungen $Succ$\index{Succ@$Succ$} für ein
    $u$ ($S\rightarrow ^{\ast} u$) sind
    \begin{gather*}
      Succ(u) = \{ v\colon u\rightarrow v\}
    \end{gather*}

    Gründe für $v\in Succ(u)$:
    \begin{itemize}
     \item an mehreren Stellen in $u$ ist eine Regel aus $P$ anwendbar
      (z.\,B. Regel $a\rightarrow b$ bei $aca$ kann zu $bca$ oder $acb$
      führen) oder
     \item an ein und derselben Stelle sind verschiedene Regeln anwendbar
      (z.\,B. Regeln $a\rightarrow b$ und $a\rightarrow c$ bei $da$ können
      zu $db$ oder $dc$ führen)
    \end{itemize}

    Deshalb:
    \begin{itemize}
     \item nummerieren wir die Regeln aus $P$ -- fixiert
     \item nummerieren wir von links nach rechts alle Stellen in $u$,
      an denen eine Regel anwendbar ist
    \end{itemize}

    Damit ergeben sich Paare $(r,s)$ für einen Schritt $u\rightarrow v$,
    die besagen: $v$ ergibt sich aus $u$ (in einem Schritt), indem an der
    Stelle $s$ die Regel $r$ angewendet wird. Schreibweise:
    $u\xrightarrow{(r,s)} v$.

    Definieren induktiv:
    \begin{align*}
      Succ^{0}(\{S\}) &= \{ S\}\\
      Succ^{k+1}(\{S\}) &= Succ\bigl( Succ^{k}(\{S\})\bigr)
    \end{align*}

    Damit gilt: $u\in Succ^{k}(\{S\})$ \gdw $u$ ist in
    $k$~Schritten aus $S$ ableitbar ($S\rightarrow ^{k}u$).

    Und weiterhin gilt:
    \begin{gather*}
      L = \Big( \bigcup_{k=0}^{\infty} Succ^{k}(\{S\}) \Big)\cap T^{\ast}
    \end{gather*}
    Das heißt $w\in L \gdw w\in T^{\ast} \wedge \exists k\colon
    w\in Succ^{k}(\{S\})$

    \highl{markierter Ableitungsbaum} von $G$:
    \begin{description}
     \item[Knotenmenge $V$:]
      \begin{gather*}
        V = \bigcup_{k=0}^{\infty} Succ^{k}(\{S\})
      \end{gather*}
     \item[Kantenmenge $E$:] für jedes $u\in V$ und alle $v\in
      Succ(\{u\})$ ziehen wir eine Kante $u\rightarrow v$ mit der Marke
      $(r,s)$, falls $u\xrightarrow{(r,s)} v$.
    \end{description}

    Dieser Baum ist abzählbar und eingeteilt in Schichten
    $Succ^{0}(\{S\}), Succ^{1}(\{S\}),\ldots$
    \todo{Skizze einfügen}

    Es sei $w\in L(G)$ (vergleiche Skizze). Wir konstruieren eine
    Turing-Maschine, die eine Eingabe $w$ genau dann akzeptiert, wenn
    $w\in L(G)$, und anderenfalls nicht stoppt.

    Die Turing-Maschine $M$ arbeitet bei Eingabe $w$ prinzipell so: $M$
    durchmustert den Ableitungsbaum Schicht für Schicht (Breitensuche)
    solange, bis sie die Eingabe findet. Die Markierung der Kanten im
    Baum ermöglicht die Orientierung der Maschine. Eine Eingabe wird
    genau dann gefunden, wenn $w\in L(G)$. In diesem Fall akzeptiert $M$
    die Eingabe.
    \begin{gather*}
      w\in Acc(M)
    \end{gather*}
  \end{proof}
\end{satz}

\begin{defini}
  Da Typ-0-Sprachen von Turing-Maschinen aufgezählt werden können,
  bezeichnet man die \highl{Klasse der Typ-0-Sprachen} auch mit $RE$
  (recursive enumerable). $RE = CH(0)$ (vgl. \autoref{def:10})
\end{defini}
\section{Grammatiken und Sprachen vom Typ-1}\label{sec:Gr+S-T1}

Ausgangspunkt für unsere kommenden Überlegungen ist, dass das Wortproblem
für Sprachen vom Typ-0 unlösbar ist.

\begin{defini}[Typ-1-Grammatik]
  Eine Grammatik $G=(N,T,S,P)$ heißt \highl[Grammatik!Typ-1]{Typ-1-Grammatik} oder vom
  \highl[Grammatik!Erweiterungstyp]{Erweiterungstyp} oder
  \highl[Grammatik!nicht verkürzend]{nicht verkürzend}
  \gdwdef
  \begin{itemize}
   \item für alle Regeln $(p\rightarrow q)\in P$ gilt:
    \begin{gather*}
      \abs{p} \leq \abs{q}\ \text{oder}\ p\rightarrow q\ \text{ist}\ 
         S\rightarrow \lambda
    \end{gather*}
   \item Falls $S\rightarrow\lambda\in P$, dann kommt $S$ auf keiner rechten
    Seite einer Regel vor.
  \end{itemize}

  Eine Sprache $L\subseteq\Sigma^{\ast}$ ist vom
  \highl[Sprache!Typ-1]{Typ-1} \gdwdef es eine
  Typ-1-Grammatik $G$ mit $L(G)=L$ gibt.

  $CH(1)$\index{CH1@$CH(1)$|see{Klasse!Typ-1-Sprachen}} bezeichnet die
  \highl[Klasse!Typ-1-Sprachen]{Klasse aller Typ-1-Sprachen}.
\end{defini}

\begin{defini}[Typ-1-Normalform-Grammatik]
  Eine Typ-1-Grammatik $G=(N,T,S,P)$ ist
  \highl[Grammatik!Typ-1-Normalform]{Typ-1-Normalform}
  \gdwdef in $P$ kommen nur Regeln der folgenden Form vor
  (außer $S\rightarrow\lambda$, falls $\lambda\in L(G)$):
  \begin{enumerate}
   \item $X\rightarrow YZ$,
   \item $XY\rightarrow UV$ oder
   \item $X\rightarrow a$
  \end{enumerate}
  für $U,V,X,Y,Z\in N$ und $a\in T$
\end{defini}

\begin{satz}
  Zu jeder Typ-1-Grammatik $G$ gibt es eine äquivalente
  Typ-1-Normalform-Grammatik $G'$ mit $L(G)=L(G')$.

  \begin{proof}
    (Beweis ist konstruktiv)
    \todo{aus Übung ergänzen}
  \end{proof}
\end{satz}

Eine weitere wichtige Grammatikklasse ist die folgende
\begin{defini}[kontextsensitive Grammatik]
  Eine Grammatik $G=(N,T,S,P)$ heißt
  \highl[Grammatik!kontextsensitiv]{kontextsensitiv}
  \gdwdef alle Regeln haben die Form:
  \begin{itemize}
   \item $uAv \rightarrow uwv$ oder
   \item $S \rightarrow \lambda$
  \end{itemize}
  wobei $A\in N$ und $w\in(N\cup T)^{+}$ und $u,v\in(N\cup T)^{\ast}$.

  Falls $S\rightarrow \lambda$ eine Regel ist, dann kommt $S$ auf keiner
  rechten Seite einer Regel vor.
\end{defini}

\begin{bsp}[für eine kontextsensitive Grammatik]
  \begin{align*}
    G &=(N,T,S,P)\\
    N &= \{S, S', A, A', B, B'\}\\
    T &= \{a,b\}\\
    P &= \{ S\rightarrow\lambda, S\rightarrow S', S'\rightarrow ABS',
       AB\rightarrow A'B,\\
    &\qquad A'B \rightarrow A'A, A'A \rightarrow BA, BA
       \rightarrow B'A,\\
    &\qquad B'A \rightarrow B'B, B'B \rightarrow AB,
       A\rightarrow a, B\rightarrow b\}
  \end{align*}

  Einerseite ist $G$ kontextsensitiv, andererseits ist $G$ \emph{beinahe}
  Typ-1-Normalform (eine Ausnahme).

  Frage: Welche Sprache wird von dieser Grammatik überhaupt erzeugt?
  Ansatz: $S' \rightarrow ABS'$ ersetzen durch $S' \rightarrow AC$ und $C
  \rightarrow BS'$.
\end{bsp}

\begin{satz}\index{Grammatik!kontextsensitiv}
  Zu jeder kontextsensitiven Grammatik $G$ gibt es eine äquivalente
  Typ-1-Grammatik $G'$ mit $L(G)=L(G')$ und umgekehrt
\end{satz}

\begin{defini}
  Man bezeichnet die \highl{Klasse der Typ-1-Sprachen} auch mit
  $CS=CH(1)$.
\end{defini}

\begin{satz}
  Für Sprachen vom Typ-1 ist das \highl{Wortproblem} lösbar! Das heißt,
  zu \emph{jeder} Grammatik $G$ (vom Typ-1 oder kontextsensitiv) gibt es
  einen Algorithmus, der entscheidet, ob für eine Eingaben $w$ gilt:
  \begin{gather*}
    w\in L(G)\ \text{oder}\ w\notin L(G)
  \end{gather*}
\end{satz}

Die \highl[Sprachen!kontextsensitiv]{kontextsensitiven Sprachen} sind für
die Praxis die bedeutendste Sprachklasse! Alle Programmiersprachen sind
kontextsensitiv!

Aber: Das \highl{Wortproblem} ist für kontextsensitive Sprachen zwar
lösbar, jedoch i.\,a. \emph{nicht effizient}!

Deshalb werden Programmiersprachen i.\,a. nicht durch rein-kontextsensitive
Grammatiken beschrieben, sondern durch weiter vereinfachte Grammatiken
bis auf "`Ausnahmen"': z.\,B. im "`linken Kontext"' muss für jeden
Bezeichner zuvor der Typ deklariert sein.

\section{Grammatiken und Sprachen vom Typ-2}\label{sec:Gr+S-T3}

Da wir mit Typ-1-Grammatik das Wortproblem lösen können, steht nun die
Frage nach einem effizienten Parser.

\begin{defini}
  Eine Grammatik $G=(N,T,S,P)$ ist vom \highl[Grammatik!Typ-2]{Typ-2}
  oder \highl[Grammatik!kontextfrei]{kontextfrei} \gdwdef
  alle Regeln sind von der Form $A \rightarrow w$ wobei $A\in N$ und
  $w\in(T\cup N)^{\ast}$ -- auf der linken Seite steht genau ein
  Nichtterminal.

  Eine Sprache $L\subseteq\Sigma^{\ast}$ heißt
  \highl[Sprache!kontextfrei]{kontextfrei} oder vom
  \highl[Sprache!Typ-2]{Typ-2}, falls eine kontextfreie Grammatik $G$ mit
  $L(G) =L$ existiert.

  $CH(2) =CF$\index{CH2@$CH(2)$|see{Klasse!kontextfreie Sprachen}} bezeichnet
  die \highl[Klasse!kontextfreie Sprachen]{Klasse der kontextfreien
  Sprachen}.
\end{defini}

Klar ist: $CH(2) \subseteq CH(0)$ und $CH(1) \subseteq CH(0)$, aber gilt
auch $CH(2)\subseteq CH(1)$?

An zwei Beispielen zeigen wir, dass nicht jede kontextfreie Grammatik
kontextsensitiv ist.

\begin{bsp}
  Eine kontextfreie Sprache ist die Menge alle korrekten
  Klammerausdrücke, die sogenannte \highl{Dyck-Sprache} $D_{2}$.
  \index{D2@$D_{2}$|see{Dyck-Sprache}}
  \begin{gather*}
    (()())\in D_{2},\qquad ((()))\in D_{2},\qquad ())()\notin D_{2}
  \end{gather*}
  \begin{align*}
    T &= \{ (,) \}\\
    N &= \{ S\}\\
    P & = \{ S \rightarrow (S), S \rightarrow SS, S\rightarrow \lambda \}
  \end{align*}

  Diese Grammatik ist nicht vom Typ-1, weil $S$ auf einer rechten Seite
  auftaucht, obwohl es die Regel $S\rightarrow\lambda$ gibt!
\end{bsp}

\begin{bsp}
  Die Menge aller \highl{Palindrome} $PAL = \{w\in\Sigma^{\ast}\colon
  w=w^{R}\}$.
  \begin{align*}
    T &= \{ a,b\}\\
    N&=\{S\}\\
    P&=\{S \rightarrow aSa, S\rightarrow bSb, S\rightarrow \lambda,
       S\rightarrow a, S\rightarrow b\}
  \end{align*}

  Auch diese Grammatik ist nicht kontextsensitiv.
\end{bsp}

\begin{satz}
  Zu jeder kontextfreien Grammatik gibt es eine
  \highl[Grammatik!$\lambda$-freie]{$\lambda$-freie Grammatik}
  \footnote{"`$\lambda$-frei"' bedeutet, es gibt keine Regel der Form
    $w\rightarrow\lambda$} $G'$, die  kontextfrei ist und für die gilt:
  $L(G') = L(G) \setminus\{ \lambda\}$.

  \begin{proof}
    Wir nehmen an, die Grammatik hat die Regeln
    \begin{align*}
      A &\rightarrow \lambda\\
      C &\rightarrow A_{1}AA_{2}\\
      C &\rightarrow A_{1}A_{2}
    \end{align*}

    Wir definieren $M_{i}$ induktiv als die Menge der Nichtterminale, die
    nach $i$ Ableitungsschritten in das leere Wort überführt werden.
    $A\in M_{i} \gdw A \rightarrow ^{i}\lambda$
    \begin{align*}
      M_{1} &= \{ A\in N\colon (A\rightarrow\lambda)\in P\}\\
      M_{i+1} &= M_{i}\cup \{ B\in N\colon (B\rightarrow u)\in P\ \text{mit}\ 
         u\in M_{i}\}
    \end{align*}
    Damit gilt: Für alle $i=1,2,\ldots$ ist stets $M_{i}\subseteq N$.
    Also existiert ein Grenzwert $k$ mit $M_{k}=M_{k+1}=M_{k+2}=\ldots$ Es gilt
    dann $A\in M_{k} \gdw A\rightarrow ^{\ast}\lambda$.

    Damit können wir folgende Regelmenge $P'$ definieren:
    \begin{multline*}
      P' = P\setminus \{ A\rightarrow \lambda\colon (A\rightarrow\lambda)\in
         P\} \cup \{ C\rightarrow u'\colon u'\ne\lambda \wedge \exists
         (C\rightarrow u)\in P \wedge\\
      \text{$u'$ entsteht durch weglassen min. eines Symbols aus $M_{k}$} \}
    \end{multline*}
  \end{proof}
\end{satz}

\begin{bsp}
  Nehmen wir an, wir haben die Regel $C\rightarrow
  A_{1}A_{2}A_{3}A_{4}A_{5}$ und es gilt
  \begin{gather*}
    A_{i}\in N,\quad A_{2},A_{3},A_{4}\in M_{k},\quad A_{1},A_{5}\notin M_{k}
  \end{gather*}
  Dann werden folgende Regeln zusätzlich aufgenommen:
  \begin{align*}
    C &\rightarrow A_{1}A_{3}A_{4}A_{5}\\
    C &\rightarrow A_{1}A_{2}A_{4}A_{5}\\
    C &\rightarrow A_{1}A_{2}A_{3}A_{5}\\
    C &\rightarrow A_{1}A_{4}A_{5}\\
    C &\rightarrow A_{1}A_{3}A_{5}\\
    C &\rightarrow A_{1}A_{2}A_{5}\\
    C &\rightarrow A_{1}A_{5}
  \end{align*}

  Fallunterscheidung:
  \begin{enumerate}[1{.\,Fall:}]
   \item $\lambda\notin L(G)$. Dann gilt: $L(G')=
    L(G)\setminus\{\lambda\} = L(G)$ und damit ist $G'$ äquivalent (und
    $\lambda$-frei) zu $G$
   \item $\lambda\in L(G)$. Wir konstruieren $G''$ durch folgende Angaben:
    \begin{gather*}
      N''= N\cup\{S''\},\quad P''=P'\cup \{S'' \rightarrow \lambda,
         S''\rightarrow S\}
    \end{gather*}
  \end{enumerate}
  Insgesamt erhalten wir: $L(G') = L(G)\setminus \{\lambda\}$,
  $G'=(N,T,S,P')$.

  Dann gilt: $G''=(N'',T,S'',P'')$ und $L(G'') = L(G)\cup\{\lambda\}
  =L(G)$ und $G''$ ist kontextsensitiv.
\end{bsp}

Damit haben wir:
\begin{satz}
  Jede \highl[Sprache!kontextfrei]{kontextfreie Sprache} ist
  \highl[Sprache!kontextsensitiv]{kontextsensitiv}. (obwohl nicht jede
  kontextfreie Grammatik kontextsensitiv ist.)
\end{satz}

Dies bedeutet für die \highl{Chomsky-Hierarchie}:
\begin{itemize}
 \item $CH(0) = RE$\ldots die Klasse der \highl[Sprache!rek.-aufzählb.]
  {rekursiv-aufzählbaren Sprachen}
  \index{$CH(0)$|see{Sprache!rek.-aufzählb.}}
  \index{$RE$|see{Sprache!rek.-aufzählb.}}
 \item $CH(1) = CS$\ldots die Klasse der \highl[Sprache!kontextsensitiv]
  {kontextsensitiven Sprachen} \index{$CH(1)$|see{Sprache!kontextsensitiv}}
  \index{$CS$|see{Sprache!kontextsensitiv}}
 \item $CH(2) = CF$\ldots die Klasse der \highl[Sprache!kontextfrei]
  {kontextfreien Sprachen} \index{$CH(2)$|see{Sprache!kontextfrei}}
  \index{$CF$|see{Sprache!kontextfrei}}
\end{itemize}
\begin{gather*}
  CF\subseteq CS \subseteq RE
\end{gather*}

\begin{defini}\label{def:7}
  Eine kontextfreie Grammatik $G=(N,T,S,P)$ ist in
  \highl[Normalform!Typ-2-Grammatik]{Normalform für Typ-2-Grammatiken}
  \gdwdef
  \begin{itemize}
   \item falls $\lambda\in L(G)$, dann (und nur dann) gilt die Regel
    $S\rightarrow\lambda$,
   \item $S$ tritt in keiner rechten Seite einer Regel auf und
   \item außer der $\lambda$-Regel haben alle Regeln die Form:
    \begin{align*}
      A&\rightarrow BC\ \text{oder}&&A,B,C\in N\\
      A&\rightarrow a&& a\in T\\
    \end{align*}
  \end{itemize}
\end{defini}

\begin{satz}
  Zu jeder kontextfreien Grammatik $G$ gibt es eine äquivalente
  kontextfreie Grammatik $G'$ in Normalform!
\end{satz}

\underline{Beobachtung:} Falls $w \in L(G')$ und $\abs{w}>1$ ist, dann
gibt es in $G'$ eine Ableitung von $w$ der Länge $2n-1$. Diese Beobachtung
ist Grund dafür, dass das \highl[Wortproblem!kontextfreie
Sprachen]{Wortproblem} für kontextfreie Sprachen effizient lösbar ist!

Ausgangspunkt ist das Wort $w=w_{1}\ldots w_{n}\in L$
\begin{enumerate}
 \item $w_{n}$ muss aus einem Nichtterminal $A_{n}$ entstanden sein;
  altes Wort: $w'=w_{1}\ldots w_{n-1}A_{n}$ \label{enu:6}
 \item $w_{n-1}$ muss aus einem Nichtterminal $A_{n-1}$ entstanden sein;
  altes Wort: $w''=w_{1}\ldots w_{n-2}A_{n-1}A_{n}$ \label{enu:5}
 \item $A_{n-1}$ und $A_{n}$ müssen aus einem Nichtterminal $A'_{n}$
  entstanden sein; altes Worts: $w'''=w_{1}\ldots w_{n-2}A'_{n}$
 \item Mit dem Wort $w'''$ können wir wieder zu \autoref{enu:5} gehen.
\end{enumerate}

Um ein Wort der Form $w=w_{1}\ldots w_{n-1}A_{n}$ um einen Buchstaben zu
verkürzen ($w'=w_{1}\ldots w_{n-2}'A_{n}$) braucht es zwei Schritte. Für
das gesamte Worte also $2(n-1)$ Schritte um ein Nichtterminal -- das
Startsymbol -- zu erreichen. Ein zusätzlicher Schritt (\autoref{enu:6})
ist noch notwendig, um das Ausgangswort in diese Form zu bringen.

\begin{satz}
  Zu jeder kontextfreien Grammatik $G$ gibt es einen \emph{effizienten}
  Algorithmus, der entscheidet, ob eine Eingabe $w\in L(G)$ ist oder
  nicht.
\end{satz}

Was heißt effizient?
\begin{itemize}
 \item Laufzeit z.\,B. des Algorithmus' von Kasany/Younger: $O(n^{3})$
  für eine vollständige Sprachanalyse
 \item Laufzeitredurzierung durch "`schnelle Matrixmultiplikation"' von
  Solovay/Strassen: $O(n^{\log_{2}7})$
 \item offene Frage: Gibt es einen Algorithmus in $O(n^{2})$?
\end{itemize}

Das \highl{Wortproblem} in der \highl{Chomski-Hierarchie}\\
\begin{tabular}{c@{\qquad}l}
  $CH(0)$& unlösbar\\
  $CH(1)$& lösbar\\
  $CH(2)$& effizient lösbar
\end{tabular}

\section{Grammatiken und Sprachen vom Typ-3}

Als Ziel steht die weitere Vereinfachung der Regeln, um das Wortproblem
mit linearem Aufwand zu lösen.

\begin{defini}
  Eine Grammatik $G=(N,T,S,P)$ ist eine
  \highl[Grammatik!Typ-3]{Typ-3-} oder
  \highl[Grammatik!rechtslinear|see{Grammatik!Typ-3}]{rechtslineare} oder
  \highl[Grammatik!regulär|see{Grammatik!Typ-3}]{reguläre} Grammatik
  \gdwdef alle Regeln sind von der Form
  \begin{align*}
    A&\rightarrow w\ \text{oder}&&w\in T^{\ast}, A\in N\\
    A&\rightarrow wB&& B\in N
  \end{align*}
\end{defini}

\begin{defini}
  Eine Grammatik $G=(N,T,S,P)$ heißt
  \highl[Grammatik!linkslinear]{linkslinear} \gdwdef alle
  Regeln sind von der Form
  \begin{align*}
    A&\rightarrow w\ \text{oder}&&w\in T^{\ast}, A\in N\\
    A&\rightarrow Bw&& B\in N
  \end{align*}
\end{defini}

\begin{satz}
  Zu jeder \highl[Grammatik!rechtslinear]{rechtslinearen Grammatik} $G$
  gibt es eine äquivalente \highl[Grammatik!linkslinear]{linkslineare
  Grammatik} $G'$ und umgekehrt!
\end{satz}

\begin{defini}
  Eine Sprache $L\subseteq\Sigma^{\ast}$ ist eine \highl[Sprache!Typ-3]
  {Typ-3-Sprache} oder \highl[Sprache!regulär|see{Sprache!Typ-3}]
  {reguläre Sprache}, falls es eine reguläre Grammatik $G$ mit $L(G)=L$
  gibt.

  $CH(3) =REG$\index{$CH(3)$|see{Klasse!Typ-3-Sprache}}\ldots bezeichnet die
  \highl[Klasse!Sprachen!Typ-3]{Klasse der Typ-3-Sprachen} (regulären
  Sprachen)
\end{defini}

Es gilt:\index{Chomski-Hierarchie}
\begin{gather*}
  REG \subseteq CF \subseteq CS \subseteq RE
\end{gather*}

\section{Zusammenfassung}

\begin{tabularx}{\linewidth}{l|X|X}
  Grammatik & allgemeine Form & Chomski-Normalform\\
  \hline
  Typ-0& $(p\rightarrow q)\in (N\cup T)^{+}\times (N\cup T)^{\ast}$
     \newline $p$ enthält min. ein $X\in N, p\ne\lambda$ &
     $X\rightarrow a$\newline $X\rightarrow YZ$\newline $XY\rightarrow
     Z$\\
  \hline
  Typ-1&
     $S\rightarrow\lambda$ und $S$ in keiner rechten Seite\newline
     $\abs{p}\leq\abs{q}$\newline
     oder\newline
     $S\rightarrow\lambda$ und $S$ in keiner rechten Seite\newline
     $uAv \rightarrow uwv, w\in(N\cup T)^{+}$\newline
     kontextsensitiv &
     $X\rightarrow a$\newline $X\rightarrow YZ$\newline $XY\rightarrow
     UV$\\
  \hline
  Typ-2& $A\rightarrow w, w\in(N\cup T)^{\ast}$ & $X\rightarrow
     a$\newline $X\rightarrow YZ$\\
  \hline
  Typ-3& $A\rightarrow w$\newline $A\rightarrow wB, w\in T^{\ast}$
     \newline rechtslinear &
     $X\rightarrow a$\newline $X\rightarrow aY$\\
  & $A\rightarrow w$\newline $A\rightarrow Bw, w\in T^{\ast}$
     \newline linkslinear &
     $X\rightarrow a$\newline $X\rightarrow Ya$
\end{tabularx}

\noindent $A, B\in N,\quad U,V,X,Y,Z\in (N\cup T)$

\chapter{Die Hierarchie der Sprachklassen}

Wir wissen bereits:
\begin{center}
  \begin{tabular}{*{7}{c}}
    Typ-3 && Typ-2 && Typ-1 && Typ-0\\
    regulär && kontextfrei && kontextsensitiv && aufzählbar\\
    $REG$ & $\subseteq$ & $CF$ & $\subseteq$ & $CS$ & $\subseteq$ & $RE$
  \end{tabular}
\end{center}

\begin{satz}[Hierarchiesatz für Klassen der Chomski-Hierarchie]
  \begin{gather*}
    REG \subsetneq CF \subsetneq CS \subsetneq RE
  \end{gather*}

  \begin{proof}
    \begin{enumerate}
     \item $RE\setminus CS\ne\emptyset$ wegen \autoref{satz:3} und
      \autoref{satz:4}
    \end{enumerate}
  \end{proof}
\end{satz}

\section{Das Wortproblem für Sprachen vom Typ-%
  \texorpdfstring{$i$ ($i=0,1,2,3$)}{i (i=0,1,2,3)} }

\underline{Wiederholung:} Als Wortproblem bezeichnet man die Frage, ob
für eine Eingabe $w$ und eine Sprache $L\subseteq \Sigma^{\ast}$ vom
Typ-$i$ ($i=0,\ldots,3$) gilt
\begin{gather*}
  w\stackrel{?}{\in} L
\end{gather*}

\begin{satz}\label{satz:3}
  Das Wortproblem für Sprachen vom Typ-0 ist nicht lösbar. Das heißt, es
  gibt Sprachen vom Typ-0, die nicht entscheidbar sind.

  \begin{proof}
    Im Kapitel über Aufzählbarkeit und Entscheidbarkeit \todo{Link
    ergänzen; Den Beweis gibt es nicht}
  \end{proof}
\end{satz}

\begin{satz}\label{satz:4}
  Das Wortproblem für Sprachen vom Typ-1 ist lösbar. Das heißt, jede
  Sprache vom Typ-1 ist entscheibbar.

  Es gilt: Das Wortproblem für Sprachen vom Typ-1 ist
  \highl{$PSPACE$-vollständig}, d.\,h. dieses Problem ist praktisch
  \emph{hochgradig ineffizient}.

  \begin{proof}
    Es sei $G=(N,T,S,P)$ eine (Normalform-)Grammatik vom Typ-1 und es sei
    $w\in\Sigma^{\ast} (=T^{\ast})$.

    \begin{enumerate}[1{.\,Fall:}]
     \item $w=\lambda$, (triviale Fall) Frage: Gilt $\lambda\in L(G)$? Oder anders
      formuliert: Ist $(S\rightarrow\lambda)\in P$?
     \item $w\ne\lambda$, es sei $\abs{w}=n$, dann gilt $n\geq 1$
    \end{enumerate}

    \underline{Idee:} berechnen \emph{alle} Wörter $x\in (N\cup T)^{\ast}$ mit
    $\abs{x}\leq n$. Dies funktioniert, weil die Regeln nicht
    verkürzend sind; wir definieren dazu Wortmengen $Z_{n}(m)$.

    Dabei ist $Z_{n}(m)$ die Menge alljener Wörter über $(N\cup T)$, die
    höchstens die Länge $n$ haben und in höchstens $m$ Schritten aus $S$
    ableitbar sind.
    \begin{gather*}
      Z_{n}(m) = \{ x\in(N\cup T)^{\ast}\colon \abs{x}\leq n \wedge S
         \rightarrow ^{k} x, k\leq m\}
    \end{gather*}
    Induktive Definition von $Z_{n}(m)$:
    \begin{align*}
      Z_{n}(0) &:= \{S\}\\
      Z_{n}(m+1) &:= Z_{n}(m) \cup \{ x\in(N\cup T)^{\ast}\colon \abs{x}\leq
         n \wedge \exists y\in Z_{n}(m)\ \text{mit}\ y\rightarrow x\}
    \end{align*}

    Dann gilt:
    \begin{gather*}
      \{ w\in L(G)\colon \abs{w}\leq n\} \subseteq \bigcup_{m\geq0} Z_{n}(m)\\
         \intertext{und es gilt:}
      Z_{n}(0) \subseteq Z_{n}(1) \subseteq \ldots \subseteq Z_{n}(m)
         \subseteq Z_{n}(m+1) \subseteq \ldots
    \end{gather*}
    Andererseits ist durch die Längenbeschränkung $\abs{x}\leq n$ ($x\in
    Z_{n}(m)$) die Anzahl der möglichen Wörter in $Z_{n}(m)$ beschränkt
    und damit endlich.
    \begin{gather}\label{eq:1}
      \abs[\Big]{\bigcup_{m\geq0} Z_{n}(m)} \leq \sum_{i=1}^{n}
         (\abs{N}+\abs{T})^{i}
    \end{gather}
    Deshalb existiert ein $k\geq 1$ mit $Z_{n}(k) = Z_{n}(k+1)$

    Dies liefert den folgenden Algorithmus:\\
    \underline{begin} \{ Eingabe: $w$ \}
    \begin{enumerate}
     \item $n:= \abs{w}$
     \item $m:= 0$
     \item $Z_{n}(0) = \{0\}$
     \item \underline{repeat}
     \item \quad berechne $Z_{n}(n+1)$
     \item \quad $m := m+1$
     \item \underline{until} $w\in Z_{n}(m)$ oder $Z_{n}(m+1)=Z_{n}(m)$
     \item \underline{if} $w\in Z_{n}(m)$
     \item \underline{then} \underline{return} "`Ja, $w\in L(G)$"'
     \item \underline{else} \underline{return} "`Nein, $w\ne L(G)$"'
    \end{enumerate}
  \end{proof}
\end{satz}

\begin{bemerk}
  zu \autoref{eq:1}: Im allgemeinen sind für die Eingaben $w$ der Länge
  $n$ exponentiell viele Zwischenschritte $x\in\bigcup_{m\geq 0}
  Z_{n}(m)$ zu berechnen $\Rightarrow$ $O(k^{n})$.
\end{bemerk}

\section{Das Pumping-Lemma für kontextfreie Sprachen}

\begin{satz}[Das Pumping-Lemma für $CF$]\label{satz:pumpcf}
  Es sei $L\in CF$. Dann existiert ein $n\in \N^{+}$, so dass für alle
  Wörter $z\in L$ mit $\abs{z}\geq n$ eine Zerlegung $z=uvwxy$ mit
  folgenden Eigenschaften existiert:
  \begin{enumerate}
   \item $\abs{vx}\geq 1$ ($v\ne\lambda$ oder $x\ne\lambda$)
    \label{enu:pumpcf1}
   \item $\abs{vwx} \leq n$ \label{enu:pumpcf2}
   \item $\forall k\geq 1\colon uv^{k}wx^{k}y\in L$ \label{enu:pumpcf3}
  \end{enumerate}

  \begin{proof}
    Es sei $G$ mit $L(G)=L$ eine (Chomski-)Normalform-Grammatik vom
    Typ-2. Es sei die Anzahl der Nichtterminale $\abs{N}=n_{1}$ und es
    sei $n=2^{n_{1}}$.

    \begin{figure}
      \centering
      \input{pumpcf-ablbaum.pdf_t}
      \caption{Allgemeiner Ableitungsbaum einer kontextfreien Grammatik.}
      \label{fig:4}
    \end{figure}

    Wir beschreiben die Ableitung von $z$ in der Grammatik $G$ durch
    einen Ableitungsbaum. Ein solcher \highl{Ableitungsbaum} ist ein
    Binärbaum mit einer Wurzel, die mit dem Startsymbol $S$ markiert ist
    und mit $\abs{z}$ vielen Blättern, die mit den Buchstaben aus $z$
    markiert sind. siehe \autoref{fig:4} Alle inneren Knoten sind mit Nichtterminalen markiert:
    Es gibt zwei Sorten von inneren Knoten:
    \begin{itemize}
     \item mit \emph{einem} Sohn: die stehen für Regeln der Form
      $X\rightarrow a$ und haben alle die Höhe 1
     \item mit \emph{zwei} Söhnen: die stehen für Regeln der Form
      $X\rightarrow YZ$
    \end{itemize}

    Der gesamte Graph ist der Ableitungsbaum $T$ für $z$. Die Höhe von
    $T$ sei $h+1$. Dann gilt: $h\geq \log_{2}\abs{z}\geq \log_{2}n
    =n_{1}$. Also ist $h\geq n_{1}=\abs{N}$.

    Es gibt insgesamt $n_{1}$ verschiedene Nichtterminale. Für $h>n_{1}$
    gibt es darum auf einem Pfad von der Wurzel $S$ bis zu einem Blatt
    $z_{i}$ mit dem Knoten $v_{0}=S,v_{1},v_{2},\ldots,v_{n},
    v_{n+1}=z_{i}$ zwei Knoten $v_{i}$ und $v_{j}$ ($i<j$), die mit dem
    Nichtterminal $A$ markiert sind, und für alle anderen $v_{k}$ ($k\geq
    i+1$) sind die Markierungen verschieden. Die Höhe des Knotens $v_{i}$
    wird somit durch $n_{1}$ beschränkt.

    % Dies sind insgesamt $h+1\geq n_{1}+1$ Marken. Da es nur $n_{1}$
    % verschiedene Markierungen gibt, müssen zwei übereinstimmende auf
    % diesem Pfad \emph{von unten nach oben} sein. Seien $v_{i}$ und
    % $v_{j}$ die ersten Stellen mit $i<j$, aber $A_{i}=A_{j}$. Für diese
    % Indizes gilt:
    % \begin{enumerate}
    %  \item für alle $k=i+1,\ldots,h$ sind $A_{k}$ paarweise verschieden
    %  \item die Höhe des Knotens $v_{i}$ ist durch $n_{1}$ beschränkt
    %   \label{enu:1}
    % \end{enumerate}
    Wir setzen $A = A_{i} =A_{j}$!

    Die durch $A_{i}$ und $A_{j}$ bestimmten Teilbäume bewirken eine
    Zerlegung des Wortes $z$ in $z=uvwxy$.

    \underline{Eigenschaften dieser Zerlegung:}
    \begin{enumerate}
     \item Die Knoten $v_{i}$ stehen für die Anwendung der Regel
      $A_{i}\rightarrow BC$. \obda sei $v_{j}$ ein Nachfolger des
      Knotens, der mit $C$ markiert ist.

      Dann ist das Wort, das aus $B$ abgeleitet wird, ein Anfangswort von
      $v$.

      Deshalb ist $v\ne \lambda$ (andersnfalls $x\ne\lambda$) und
      damit gilt $\abs{vx}\geq 1$.

     \item Da die Höhe des Knotens $v_{i}$ durch $n_{1}$ beschränkt ist,
      hat der durch $A_{i}$ bestimmte Teilbaum höchstens $2^{n_{1}}=n$
      Blätter!

      Das hierdurch erzeugte Wort ist $vwx$ und es gilt $\abs{vwx}\leq n$.

     \item
      \begin{itemize}
       \item Wird der Teilbaum bei $A_{j}$ durch den Teilbaum $A_{i}$
        erzeugt (m.\,a.\,W. bei $v_{j}$ wird nochmal der Teilbaum $A_{i}$
        verwendet), ergibt sich ein Ableitungsbaum $T_{2}^{2}$ für das Wort
        $z_{2}=uv^{2}wx^{2}y$
       \item dieser Vorgang lässt sich beliebig oft wiederholen
       \item wird der Teilbaum bei $A_{i}$ durch den Teilbaum bei $A_{j}$
        ersetzt, ergibt sich dein Ableitungsbaum $T_{2}^{0}$ für das Wort
        $z_{0}=uwy$
      \end{itemize}
    \end{enumerate}

    \underline{Insgesamt:} mit $z=uvwxy$ gehören alle Wörter
    $uv^{k}wx^{k}y$ ($k\in\N$) zu $L$!
  \end{proof}
\end{satz}

\begin{bsp}
  Wir wissen bereits (aus der Übung), dass $L=\{a^{n}b^{n}c^{n}\colon
  n\in\N\}$ eine kontextsensitive Sprache ist. Nehmen wir nun an, $L$ sei
  auch eine kontextfreie Sprache. Dann gilt das Pamping-Lemma
  (\autoref{satz:pumpcf}) und es gibt eine natürliche Zahl $n$, so dass
  für alle $z\in L$ mit $\abs{z}\geq n$ ein Zerlegung $z=uvwxy$ mit den
  % skript-check aus
  \hyperref[enu:pumpcf1]{Eigenschaften \ref*{enu:pumpcf1}}, \ref{enu:pumpcf2} und
  \ref{enu:pumpcf3} existiert.
  % skript-check an

  Wir betrachten folgendes Wort: $z=a^{n}b^{n}c^{n}$ für dieses spezielle $n$.
  Dann ist $\abs{z}=3n\geq n$.

  Nun untersuchen wir die entsprechende Zerlegung $z=uvwxy$. Nach
  \hyperref[enu:pumpcf2]{Eigenschaft \ref*{enu:pumpcf2}} gilt $\abs{vwx}\leq n$. Damit kann das
  Teilwort $vwx$ aber nicht gleichzeitig $a$'s \emph{und} $b$'s
  \emph{und} $c$'s enthalten.

  Entsprechendes gilt für das Teilwort $vx$. Es gibt also mindestens
  einen Buchstaben, der nicht in $vx$ vorkommt.

  Aus der \hyperref[enu:pumpcf1]{Eigenschaft \ref*{enu:pumpcf1}} folgt,
  dass $\abs{vx}\geq 1$ ist, d.\,h. $vx$ enthält mindestens einen Buchstaben.

  Wegen \hyperref[enu:pumpcf3]{Eigenschaft \ref*{enu:pumpcf3}} gehört $uwy$ zu $L$. Aber
  dieses Wort hat weniger $a$'s als $b$'s und damit nicht die Form
  $a^{n}b^{n}c^{n}$, womit es nicht Teil der Sprache $L$ seien kann.

  Aus diesem Widerspruch folgt, dass die Annahme $L\in CF$ falsch ist.
\end{bsp}

\section{Das Pumping-Lemma für reguläre Sprachen}

\begin{satz}[Das Pumping-Lemma für $REG$]\label{satz:pumpreg}
  Für jede Sprache $L\in REG$ gibt es eine natürliche Zahl $n$, so dass
  für alle Wörter $z\in L$ mit $\abs{z}\geq n$ eine Zerlegung $z=uvw$
  existiert, die folgende Eigenschaften erfüllt:
  \begin{enumerate}
   \item $\abs{v}\geq 1$ \label{enu:pumpreg1}
   \item $\abs{uv} \leq n$ \label{enu:pumpreg2}
   \item für alle $k\in\N_{0}$ ist $uv^{k}w\in L$ \label{enu:pumpreg3}
  \end{enumerate}

  \begin{proof}
    \obda $\lambda\notin L$. Idee des Beweises: Es sei $G$ eine
    linkslineare Grammatik in Normalform vom Typ-3. Alle Regeln sind von
    der Form $A\rightarrow Ba$ oder $ A\rightarrow a$.

    Wir setzen $n_{1}=\abs{N}$. Dabei ist $G=(N,T,S,P)$ und $n=n_{1}+1$.

    \begin{figure}
      \centering
      \input{pumpreg-ablbaum.pdf_t}
      \caption{Ableitungsbäume für linkslineare Grammatiken sehen wie
        eine Raupe mit der Haarlänge 1 aus \todo{Die Zeichnung könnte
      noch flacher sein}}
      \label{fig:1}
    \end{figure}
    Wie sehen in einer solchen Grammatik die Ableitungsbäume aus?
    \autoref{fig:1}
  \end{proof}
\end{satz}

\begin{bsp}
  Wir wissen, dass $L=\{a^{n}b^{n}\colon n\in\N\}$ eine kontextfreie Sprache
  ist. Treffen wir nun die Annahme, $L$ sei regulär.

  Dann würde das Pumping-Lemma für reguläre Sprachen
  \autoref{satz:pumpreg} gelten und wir könnten ein (spezielles) $n$ (für
  diese Sprache) finden, so dass für alle Wörter $z\in L$ mit
  $\abs{z}\geq n$ eine Zerlegung $z=uvw$ mit den
  \hyperref[enu:pumpreg1]{Eigenschaften \ref*{enu:pumpreg1}},
  % skript-check aus
  \ref{enu:pumpreg2} und \ref{enu:pumpreg3} existiert.
  % skript-check an

  Wir betrachten jetzt das Wort $z=a^{n}b^{n}$ für dieses spezielle $n$.
  Dann folgt aus \hyperref[enu:pumpreg2]{Eigenschaft \ref*{enu:pumpreg2}}, dass $\abs{uv}\leq
  n$ und damit $\abs{v}\leq n$ ist. \hyperref[enu:pumpreg1]{Eigenschaft \ref*{enu:pumpreg1}}
  liefert: $\abs{v}\geq 1$. Diese beiden Sachen zusammen ergeben: $1\leq
  \abs{v} \leq n$.

  Also kommen in $v$ $a$'s vor und keine $b$'s. Also hat $uw$ weniger
  $a$'s als $b$'s und damit nicht die Form $a^{n}b^{n}$, obwohl nach
  \hyperref[enu:pumpreg3]{Eigenschaft \ref*{enu:pumpreg3}} $uw\in L$ ist -- Widerspruch.
\end{bsp}

\begin{bsp}
  \begin{gather}\label{eq:3}
    L_{1} = \{a^{m^{2}}\colon m\in \N\}\qquad w\in L_{1} \gdw
       w\in\{a\}^{\ast} \wedge \abs{w}\ \text{ist Quadratzahl}
  \end{gather}
  Prüfen wir, ob diese Sprache regulär ist und nehmen dazu an, sie sei es.

  Entsprechend gilt dann das Pumping-Lemma für reguläre Sprachen
  \autoref{satz:pumpreg} und wir finden eine natürliche Zahl $n$, so dass
  für alle Wörter $z\in L_{1}$ mit $\abs{z}\geq n$ eine Zerlegung $z=uvw$
  mit den \hyperref[enu:pumpreg1]{Eigenschaften \ref*{enu:pumpreg1}},
  % skript-check aus
  \ref{enu:pumpreg2} und \ref{enu:pumpreg3} existiert.
  % skript-check an

  Wir betrachten das Wort $z^{n^{2}}$ mit der zugehörigen Zerlegung
  $z=uvw$.

  % skript-check aus
  \hyperref[enu:pumpreg1]{Eigenschaft \ref*{enu:pumpreg1}} und \ref{enu:pumpreg2} liefern
  % skript-check an
  $1 \leq \abs{v} \leq \abs{uv}\leq n$.

  Wegen \hyperref[enu:pumpreg3]{Eigenschaft \ref*{enu:pumpreg3}} ist auch $uv^{2}w\in L_{1}$
  und es gilt:
  \begin{gather*}
    n^{2} = \abs{uvw} < \abs{uv^{2}w} = \abs{uvw} + \abs{v} \leq n^{2}+n
       < n^{2}+2n+1 = (n+1)^{2}
  \end{gather*}
  Die Länge des Wortes $uv^{2}w$ ist aber demnach keine Quadratzahl
  ($n^{2}< \abs{uv^{2}w} < (n+1)^{2}$), weshalb es nicht zur Sprache
  $L_{1}$ gehört -- Widerspruch. Die Annahme $L_{1}$ sei eine reguläre
  Sprache war also falsch.
\end{bsp}

\begin{bsp}
  \begin{gather}\label{eq:4}
    L_{2} = \{a^{p}\colon p\ \text{ist Primzahl}\}\qquad w\in L_{2} \gdw
       w\in\{a\}^{\ast} \wedge \abs{w}\ \text{ist Primzahl}
  \end{gather}

  Prüfen wir, ob diese Sprache regulär ist und nehmen dazu an, sie sei es.

  Entsprechend gilt dann das Pumping-Lemma für reguläre Sprachen
  \autoref{satz:pumpreg} und wir finden eine natürliche Zahl $n$, so dass
  für alle Wörter $z\in L_{2}$ mit $\abs{z}\geq n$ eine Zerlegung $z=uvw$
  mit den \hyperref[enu:pumpreg1]{Eigenschaften \ref*{enu:pumpreg1}},
  % skript-check aus
  \ref{enu:pumpreg2} und \ref{enu:pumpreg3} existiert.
  % skript-check an

  Wir betrachten das Wort $z=a^{p}$ ($n+2\leq p$ ist prim) und die
  zugehörige Zerlegung $z=uvw$.

  \hyperref[enu:pumpreg1]{Eigenschaft \ref*{enu:pumpreg1}} liefert wieder, dass $v$
  mindestens einen Buchstaben hat, und \hyperref[enu:pumpreg3]{Eigenschaft \ref*{enu:pumpreg3}}
  liefert $z_{i} = uv^{i}w \in L_{2}$ ($\forall i\in \N$)
  \begin{gather*}
    \abs{z_{i}} = \abs{uw}+i\abs{v}
  \end{gather*}

  Dabei muss $\abs{uw}\geq 2$ sein, denn
  \begin{align*}
    \abs{uw} &= \abs{z} - \abs{v} \geq n+2 - \abs{v}\\
    &\geq n+2 -n =2&&\text{wegen
       \hyperref[enu:pumpreg1]{Eigenschaft \ref*{enu:pumpreg2}} $\abs{v}\leq n$}
  \end{align*}

  Setzen wir $i=\abs{uw}$. Dann gilt für dieses $i$:
  \begin{gather}\label{eq:2}
    \abs{z_{i}} = \abs{uw} + \abs{uw} \abs{v} = \abs{uw}\cdot(1+\abs{v})
  \end{gather}
  $z_{i}$ ist aber nicht in $L_{2}$, da die Länge $\abs{z_{i}}$ keine
  Primzahl ist (Faktorisierung in $\abs{uw}\cdot(1+\abs{v})$).
\end{bsp}

\section{Kontextfreie Sprachen über einelementigen Alphabeten}

Ist die Sprache $L_{1}$ aus \autoref{eq:3} oder die Sprache $L_{2}$ aus
\autoref{eq:4} kontextfrei?

Überprüfen wir $L_{1}$ und behaupten dazu $L_{1}$ sei kontextfrei.

Dann gilt das Pumping-Lemma für kontextfreie Sprachen
\autoref{satz:pumpcf} und wir finden eine natürliche Zahl $n_{1}$, so
dass für alle Wörter $z\in L_{1}$ mit $\abs{z}\geq n$ eine Zerlegung
$z=uvwxy$ mit den \hyperref[enu:pumpreg1]{Eigenschaften
% skript-check aus
\ref*{enu:pumpcf1}}, \ref{enu:pumpcf2} und \ref{enu:pumpcf3} existiert.
% skript-check an

Da nur ein Buchstabe vorhanden ist, ist die Position der Teilwörter
unwesentlich und kann als $z=u'v'w'$ geschrieben werden. Für
einbuchstabige Sprachen fallen die Aussagen der beiden Pumping-Lemma
\autoref{satz:pumpcf} und \autoref{satz:pumpreg} also zusammen.

$L_{1}$ und $L_{2}$ sind also nicht kontextfrei und es gilt sogar der
folgende Satz:
\begin{satz}
  Jede kontextfreie Sprache $L\subset\{a\}^{\ast}$ über einem
  einbuchstabigen Alphabet ist regulär.
\end{satz}

\chapter{Die Hierarchie der Automaten}

Ausgangspunkt ist der folgende Satz:
\begin{satz}
  Eine Sprache $L\subseteq \Sigma^{\ast}$ ist vom
  \highl[Sprache!Typ-0]{Typ-0} \gdw es eine
  \highl[Turing-Maschine!gewöhnliche]{gewöhnliche}
  \highl[Turing-Maschine!deterministische]{deterministische
  Turing-Maschine} $M$ mit $L(M)=L$ gibt.
\end{satz}

Dies erlaubt die folgende Sprechweise:
\highl[Turing-Maschine!gewöhnliche]{Gewöhnliche Turing-Maschinen} sind
Turing-Maschinen vom Typ-0.\help{Widerspruch zu Definition 6.1}

Was sind dann Turing-Maschine vom Typ-$i$ ($i=1,2,3$)?

\section{Das Phänomen "`Nichtdeterminismus"'} \index{Nichtdeterminismus}

Wir hatten im Beweis von \autoref{satz:5} für eine Typ-0-Grammatik in
Normalform $G=(N,T,S,P)$ den markierten Ableitungsbaum mit $Succ(u) = \{
v\colon u\rightarrow v\ \text{gemäß Regel}\ (p\rightarrow q)\in P\}$
definiert. Typisch dabei ist, dass aus einer Situation \emph{mehrere}
Nachfolgersituationen entstehen. Anders war es bisher mit
Turing-Maschinen, bei denen aus einer Situation \emph{genau eine}
Nachfolgersituation entsteht.

Dies wirft einige Fragen auf:
\begin{enumerate}
 \item Können Turing-Maschinen mit dieser Fähigkeit des
  nichtdeterminierens ausgestattet werden. \label{enu:2}
 \item Was heißt es für eine solche Turing-Maschine, dass sie die Eingabe
  akzeptiert? \label{enu:3}
 \item Haben nichtdeterministische Turing-Maschinen eine größere
  Berechnungskraft als gewöhnliche deterministische Turing-Maschinen?
  \label{enu:4}
\end{enumerate}

Zur \hyperref[enu:2]{Frage \ref*{enu:2}} ist folgendes zu sagen: Bisher war die
Überführungsfunktion $\delta$ für eine Turing-Maschine
$M=(Q,\Sigma,\Gamma,\delta, q_{0},F)$ als Funktion definiert.
Die Berechnung von $M$ bei einer Eingabe $w$ ist eine eindeutig bestimmte
Folge von Konfigurationen
\begin{gather*}
  Start-Konf_{M}(w) = K_{0} \vdash K_{1} \vdash K_{2} \vdash \ldots \vdash
     \begin{cases}
       K_{acc}\\
       \ldots
     \end{cases}
\end{gather*}

Jede Berechnung ist ein (endlicher oder unendlicher) Pfad. Das ist
\highl{Determinismus}! (Dies ist gerade der Unterschied zu Ableitungen in
Grammatiken!)

Ein Möglicher Ausweg wäre, wir erlauben für jede Konfiguration mehrere
Nachfolger mit dem Effekt, dass die Berechnung für eine Eingabe $w$ die
Form eines \todo{Skizze} \highl{Berechnungsbaumes} bekommt
(\highl{Nichtdeterminismus}) (Der Berechnungsbaum der Turing-Maschine
entspricht dem markierten Ableitungsbaum der Grammatik.)

Formal gesprochen heißt das, die Überführungsfunktion
\begin{gather*}
  \delta\colon Q\times \Gamma \rightarrow Q\times\Gamma\times\{L,R,0\}
\end{gather*}
wird durch eine \highl{Überführungsrelation}
\begin{gather*}
  \delta \subseteq \big(Q\times \Gamma\big) \times
     \big(Q\times\Gamma\times\{L,R,0\}\big)
\end{gather*}
ersetzt. Diese Relation lässt sich ihrerseits als Funktion schreiben:
\begin{gather*}
  \delta\colon Q\times \Gamma \rightarrow \mathfrak{P}(Q\times\Gamma\times\{L,R,0\})
\end{gather*}

Eine \highl[Turing-Maschine!nichtdeterministische]{nichtdeterministische
Turing-Maschine} ist eine Turing-Maschine mit einer solchen
Überführungsfunktion.

\begin{figure}
  \centering
  \todo{Skizze}
  \caption{caption}
  \label{fig:2}
\end{figure}

Zur \hyperref[enu:3]{Frage \ref*{enu:3}} folgendes: Wir können den Berechnungsbaum wie
ein Labyrinth betrachten (\autoref{fig:2}). Es gibt zwei Strategien,
dieses Labyrinth abzulaufen:
\begin{enumerate}
 \item \highl{Obelix-Strategie}: an jeder Verzweigung klont sich Obelix,
  wobei einer der Klone den Schatz findet
 \item \highl{Asterix-Strategie}: ein Asterix durchläuft systematisch
  alle Gänge
\end{enumerate}

Gemäß der Obelix-Stategie akzeptiert eine nichtdeterministische
Turing-Maschine eine Eingabe $w$, wenn sie auf einem Pfad erfolgreich war:
\begin{gather*}
  L(M) = \{w\in \Sigma^{\ast}\colon Start-Konf_{M}(w) \vdash^{\ast} K_{acc}\}
\end{gather*}

Zur \hyperref[enu:4]{Frage \ref*{enu:4}} folgendes: Gemäß der Asterix-Strategie lässt
sich jede nichtdeterministische Turing-Maschine (Algorithmus,
Arbeitsweise) durch eine deterministische Turing-Maschine (Algorithmus,
Arbeitsweise) simulieren! Daher sind beide Systeme gleichmächtig in Bezug
auf Berechenbarkeit.

Jedoch besteht ein wesentlicher Unterschied im Zeitaufwand. Für ein
Labyrinth der Tiefe $t$ benötigt die Obelix-Strategie lineare Laufzeit
$O(t)$, die Asterix-Strategie hingegen exponentiellen Zeitaufwand
$O(2^{t})$.

\begin{table}
  \begin{minipage}{.9\linewidth}
    \begin{tabularx}{\linewidth}{Xcc>{\centering}p{4mm}c}
      Turing-Maschine & Sprachklasse & \multicolumn{3}{c}{Automaten}\\
      &&\multicolumn{3}{c}{nichtdeterm.\hfill determ.}\\
      \hline
      Typ-0: gewöhnliche, nichtdeterministische Turing-Maschine & $RE$ & $RE$&
         ?\footnote{$P$-$NP$-Problem: Sind nichtdeterministische Turing-Maschinen
         schneller als ($NP \supsetneq P$) oder gleichschnell wie ($NP = P$)
         deterministische Turing-Maschinen}\newline \makebox[0pt]{Turing-Maschinen}
         & $RE$\\
      Typ-1: nichtdeterministische Turing-Maschine mit endlichem Band & $CS$ &
         $LBA$ & ?\footnote{LBA-Problem: $LBA\supsetneq DLBA$ oder $LBA =
         DLAB$}\newline \makebox[0pt]{linear beschränkte Autom.} & $DLBA$\\
      Type-2: nichtdeterministische Turing-Maschine mit einem
         Einwegeingabeband\footnote{\highl{Einwegeingabeband}: jedes Zeichen
         kann nur einmal gelesen werden} und einem zweiten Turing-Band, auf
         dem der Kopf stehts am rechten Ende der Eingabe steht & $CF$ & $PDA$ &
         $\supsetneq$\newline \makebox[0pt]{Kellerautomaten} & $DPDA$\\
      Typ-3: nichtdeterministische Turing-Maschine, bei dem die Eingabe auf
         einem Einwegeingabeband steht & $REG$ & $NFA$ & =\newline
         \makebox[0pt]{endliche Automaten} & $DFA$
    \end{tabularx}
  \end{minipage}
  \caption{Beziehungen zwischen Turing-Maschinen, Sprachen und Automaten}
  \label{tab:1}
\end{table}

\section{Turing-Maschinen vom Typ-0}

\begin{defini}[nichtdeterministische Turing-Maschinen]
  Als eine \highl[Turing-Maschine!nichtdeterministische]
  {nichtdeterministische Turing-Maschine}
  $M=(Q,\Sigma,\Gamma,\delta,q_{0},F)$ bezeichnet man eine
  Turing-Maschine mit der Überführungsfunktion
  \begin{gather*}
    \delta\colon Q\times \Gamma \rightarrow \mathfrak{P}(Q\times\Gamma\times\{L,R,0\})
  \end{gather*}

  Die von einer nichtdeterministischen Turing-Maschine akzeptierte Sprache
  beinhaltet alle Wörter, für die es einen akzeptierenden Berechnungspfad
  gibt.
  \begin{gather*}
    L(M) = \{w\in\Sigma^{\ast}\colon Start-Konf_{M}(w) \vdash^{\ast} Konf_{acc}\}
  \end{gather*}
\end{defini}

\begin{auflistung}
  % Wegen dem \protect siehe weiter oben bei \protect\Prr
  $\mathcal{DTM}$\index{DTM@$\protect\mathcal{DTM}$}& Klasse der Sprachen, die
     durch eine deterministische Turing-Maschine akzeptiert werden\\
  $\mathcal{NTM}$\index{NTM@$\protect\mathcal{NTM}$}& Klasse der Sprachen, die
     durch eine nichtdeterministische Turing-Maschine akzeptiert werden\\
  $CH(0)$& Klasse der Sprachen, die durch eine Grammatik vom Typ-0
     erzeugt werden
\end{auflistung}

Wir wissen bereits aus \autoref{sec:3}, dass $\mathcal{DTM} = CH(0)$. Es
gilt also $\mathcal{DTM}\subseteq CH(0)$ -- für jede deterministische
Turing-Maschine existiert eine Grammatik $G$ vom Typ-0, so dass $G$ die
Maschine $M$ durch "`Rückwärtsberechnung"' simmuliert --
\autoref{satz:6}.

Dieser Beweis lässt sich wortwörtlich auf nichtdeterministische
Turing-Maschine übertragen. Das heißt, $\mathcal{NTM}\subseteq CH(0)$.
Andererseits gilt $\mathcal{DTM}\subseteq \mathcal{NTM}$ und damit
$CH(0)\subseteq \mathcal{DTM}\subseteq \mathcal{NTM}\subseteq CH(0)$.

Wie lässt sich die Grammatik $G$ unmittelbar durch eine
nichtdeterministische Turing-Maschine $M$ simulieren? Eingabe für die
nichtdeterministische Turing-Maschine $M$ sei ein Wort
$w\in\Sigma^{\ast}$. $w\in L(G) \gdw S\rightarrow ^{\ast}_{G}
w$ Die nichtdeterministische Turing-Maschine $M$ "`rät"' rückwärts eine
mögliche Ableitung für $w$. (Der Berechnungsbaum von $M$ entspricht damit
möglichen Ableitungsfolgen!)

\textbf{\large Einschub: $P$-$NP$}
bisher: $\mathcal{DTM}=\mathcal{NTM}$ (Grundsätzlich die selbe
Berechnungskraft, falls keine Einschränkung)

dagegen:\\
\begin{auflistung}
  $P$& Klasse aller Sprachen, die durch eine deterministische
     Turing-Maschine mit \emph{polynomieller} Rechenzeit akzeptiert
     werden\\
  $NP$& Klasse aller Sprachen, die durch eine nichtdeterministische
     Turing-Maschine mit \emph{polynomieller} Rechenzeit akzeptiert
     werden
\end{auflistung}

Die \highl[Rechenzeit!deterministische]{Rechenzeit \textnormal{einer}
deterministischen} Turing-Maschine ist die Länge der Berechnung als Folge
von Konfigurationen oder mit anderen Worten: ist die Länge des
Berechnungspfades.

Die \highl[Rechenzeit!nichtdeterministische]{Rechenzeit \textnormal{einer}
nichtdeterministischen} Turing-Maschine ist die Tiefe des
Berechnungsbaumes.

Diese Rechenzeit wird gemesssen bzgl. der Länge der Eingabe. Polynomielle
\highl[Rechenzeit!polynomielle]{Rechenzeit} heißt also, es gibt ein
Polynom $p$, so dass für alle Eingaben $w\in\Sigma^{\ast}$ gilt:
\begin{gather*}
  Zeit_{M}(w) \leq p(\abs{w})
\end{gather*}

Die Arbeit einer \highl[Turing-Maschine!nichtdeterministische]
{nichtdeterministischen Turing-Maschine} lässt sich in "`Rate-"' und
"`Testphasen"' aufteilen.

\begin{bsp}[Erfüllbarkeitsproblem]\index{SAT@$SAT$}
  Es sei $F$ eine Formel mit den Atomen $A_{1},\ldots,A_{n}$. $F$ gehört
  zu $SAT$ \gdw es eine Belegung
  $\beta\colon\{A_{1},\ldots,A_{n}\} \mapsto \{0,1\}$ mit $I_{\beta}(F)=1$ gibt.
  \begin{gather*}
    SAT = \{ F\colon F\ \text{ist Formel in konjunktiver Normalform und $F$
       ist erfüllbar}\} \in NP
  \end{gather*}
\end{bsp}

Eine nichtdeterministische Turing-Maschine $M_{N}$ rät eine Belegung
$\beta$ und berechnet $I_{\beta}$. Ist $I_{\beta}(F)=1$ akzeptiert sie, wenn
nicht rät sie die nächste Belegung. Existiert keine Belegung $\beta$ mit
$I_{\beta}(F)=1$, stoppt die Turing-Maschine \emph{nie}.

Die Frage, ob $SAT\in P$ ist bis jetzt ungeklärt. Es ist aber bereits
gezeigt worden, dass $SAT\in DEXP$ \index{DEXP@$DEXP$} (in exponenzieller
Zeit mit deterministischen Turing-Maschinen entscheidbar).

Wäre $SAT\in P$, so wäre $P=NP$. Damit ist $SAT$ ein
\highl[NP-schwer@$NP$-schwer]{$NP$-schweres Problem}. $SAT$ ist
\highl[NP-vollständig@$NP$-vollständig]{$NP$-vollständig}.

\begin{bsp}[Hamiltonkreis-Problem]\listlinebreak
  \begin{gather*}
    HC = \{ G\colon G=(E,V) \ \text{einfacher ungerichter Graph und $G$
       besitzt Hamiltonkreis}\}
  \end{gather*}

  Wir interpretieren $G=(E,V)$ als ein Straßennetz, in dem die Knoten
  $v\in V$ Städte und die Kanten $e\in E$ Straßen zwischen den Städten
  sind. Als \highl{Hamiltonkreis} bezeichnet man eine Rundreise durch
  $G$, bei der jede Stadt \emph{genau} einmal besucht wird und man in der
  Stadt, in der man begonnen hat, endet. Wenn es eine solche Rundreise
  gibt, besitzt $G$ einen Hamiltonkreis.
\end{bsp}

Es gilt: $HC\in NP$. Eine nichtdeterministische Turing-Maschine $M_{N}$
rät eine Folge von Kanten ($n!$ Möglichkeiten) und prüft, ob diese
geratene Folge einen Hamiltonkreis bildet.

Die Frage, ob $HC\in P$, ist ebenfalls ungeklärt, aber man konnte -- wie
schon für $SAT$ -- zeigen, dass $HC\in DEXP$. Gleichfalls gilt: Könnte
man zeigen, dass $HC\in P$, so wäre $NP=P$. Damit ist $HC$ auch ein
\highl[NP-vollständig@$NP$-vollständig]{$NP$-vollständiges}
(\highl[NP-schwer@$NP$-schwer]{$NP$-schweres}) Problem.

% Aufgabe: Simulation einer nichtdeterministische Turing-Maschine durch
%   eine deterministische Turing-Maschine

\section{Turing-Maschinen vom Typ-1}

Formal gesehen, ist eine Turing-Maschine vom Typ-1, eine Turing-Maschine
mit dem Sonderzeichen $\triangleright$ am linken Ende und $\triangleleft$ am
rechten Ende, die nicht überschrieben und nicht verrückt werden dürfen.
Für die Überführungsfunktion heißt das
\begin{align*}
  \delta(q, \triangleright) &= (q', \triangleright, L)\\
  \delta(q, \triangleleft) &= (q', \triangleleft, L)
\end{align*}
mit dem Effekt, dass sich der gesamte Bereich zwischen $\triangleright$ und
$\triangleleft$ vollzieht.

Eine solche Turing-Maschine kann für eine Eingabe $w$ (mit $\triangleright
w\triangleleft$) rückwärts die Ableitung einer nichtverkürzenden Grammatik
(vom Typ-1 -- \autoref{sec:Gr+S-T1}) nachvollziehen.

\section{Turing-Maschinen vom Typ-2}

Motivation: Wir betrachen Linksableitungen von kontextfreien Grammatiken
(\autoref{sec:Gr+S-T3}) in Normalform (\autoref{def:7}).
\begin{bsp}\listlinebreak
  \begin{align*}
    G &= (N,T,S,P)\\
    N &= \{S, A, B\}\\
    T &= \{a,b,c\}\\
    P &= \{ S\rightarrow SS, S\rightarrow aAa, S\rightarrow bBb,\\
    &\qquad A\rightarrow aAa, A\rightarrow c\\
    &\qquad B\rightarrow bBb, B\rightarrow c\}
  \end{align*}

  Eine mögliche Linksableitung wäre:
  \begin{multline*}
    S \rightarrow SS \rightarrow bBbS \rightarrow bcbS \rightarrow bcbSS
       \rightarrow bcbaAaS\\ \rightarrow bcbaaAaaS \rightarrow bcbaacaaS
       \rightarrow bcbaacaaaAa \rightarrow bcbaacaaaca \in T^{\ast}
  \end{multline*}
\end{bsp}

Für jedes $w\in L(G)$ existiert stets eine Linksableitung. Es sei
$S\rightarrow ^{\ast} uAv \rightarrow ^{\ast} w$, d.\,h. $uAv$ ist ein
Zwischenergebnis einer Linksableitung und hat die Form $u\in T^{\ast},
A\in N, v\in (N\cup T)^{\ast}$

\subsection{Beschreibung von Linksableitungen durch
  Kellerautomaten}\index{Kellerautomaten}

\highl{Einwegeingabeband}: die Eingaben $w$ steht zwischen zwei Endmarken
$\triangleright$ und $\triangleleft$ und kann (nur) von links nach rechts gelesen
werden. Das \highl{Kellerband} ist ein Turing-Arbeitsband mit einer
linken Endmarke $\ast$ (\highl{Kellersymbol}) und der Einschränkung, dass der
Kopf stehts am rechten Ende des Bandinhalts steht.

Ein Zwischenergebnis $uAv$ einer Linksableitung steht für:\\
\begin{auflistung}
  $u$ & steht für den Teil der Eingabe $w$, der bereits gelesen wurde\\
  $v$ & ist der Inhalt des Kellerbandes\\
  $A$ & wird in der Zustandsmenge gespeichert
\end{auflistung}

Die Überführungsfunktion der entsprechenden Turing-Maschine:
\begin{gather*}
  \delta\colon Q\times \underbrace{(\Sigma\cup\{\triangleright,
     \triangleleft\})}_{=\Sigma'} \times
     \underbrace{(\Gamma\cup\{\ast\})}_{=\Gamma'} \rightarrow Q\times
     \Gamma'\times\{R,0\}
\end{gather*}

Für einen Kellerautomaten sieht die Überführungsfunktion etwas anders aus:
\begin{gather*}
  \delta\colon Q\times(\Sigma'\cup\{\lambda\})\times\Gamma' \rightarrow
     Q\times\Gamma'
\end{gather*}

zwei Regeltypen der Grammatik:
\begin{enumerate}
 \item $A\rightarrow a$: Buchstabe wird verglichen mit dem nächsten
  Buchstaben der Eingabe. Falls Übereinstimmung $\rightarrow$
  weiterrechnen, falls nicht $\rightarrow$ Abbrechen.

  "`Leseschritt"'
 \item $A\rightarrow BC$: kein Test von Buchstaben der Eingabe, sondern
  schreiben $C$ auf das Kellerband und nehmen $B$ als neuen Zustand an.
\end{enumerate}

\begin{defini}[Formale Definition des Kellerautomaten]
  Ein nichtdeterministischer \highl{Kellerautomat} $K$ ist ein Tupel
  $K=(Q, \Sigma,\Gamma,\delta,q_{0},F)$.\\
  \begin{auflistung}
    $Q$& endliche Menge der Zustände\\
    $\Sigma$& endliche Menge, Eingabealphabet, $\triangleright, \triangleleft\notin
       \Sigma$\\
    $\Gamma$& endliche Menge, Kelleralphabet, $\ast\notin\Gamma$\\
    $q_{0}\in Q$ & Startzustand\\
    $F\in Q$ & Finalzustände
  \end{auflistung}

  die Überführungsfunktion
  \begin{gather*}
    \delta\colon Q\times (\Sigma\cup \{\triangleright,\triangleleft\}\cup\{\lambda\})
       \times \underbrace{(\Gamma\cup\{\ast\})}_{=\Gamma'} \rightarrow
       \mathfrak{P}(Q\times \Gamma')
  \end{gather*}
\end{defini}

\subsection{Akzeptanzverhalten eines Kellerautomaten}

Ein Konfiguration $(q,w',\gamma)$ ist eine Momentanbeschreibung des
Automaten, die gegeben ist durch den aktuellen Zustand $q$, den noch
nicht gelesenen Teil $w'$ der Eingabe und den kellerinhalt $\gamma$.

Es sei $w'=aw''$ und $\gamma=\gamma' A$ (Topsymbol des Kellers)
\begin{enumerate}
 \item (Lese-Schritt), $(q',\beta)\in \delta(q,a,A)$,
  Nachfolgekonfiguration: $(q', w'', \gamma'\beta)$
  \begin{enumerate}
   \item $\gamma\in\Gamma^{+}$ -- Schreib- oder Push-Operation
   \item $\gamma=\lambda$ -- Lösch- oder Pop-Opteration
  \end{enumerate}
 \item ($\lambda$-Schritt), $(q', \beta)\in\delta(q,\lambda,A)$,
  Nachfolgekonfiguration: $(q', w'', \gamma'\beta)$
  \begin{enumerate}
   \item $\beta\in\Gamma^{\ast}$ -- Push-Operation (von links nach rechts
    bzw. von unten nach oben)
   \item $\beta=\lambda$ -- Pop-Operation (von rechts nach links bzw.
    oben nach unten)
  \end{enumerate}

  Dies ist gerade das \highl{Kellerprinzip} oder auch
  \highl{Push-Down-Prinzip} genannt.
\end{enumerate}

Es gibt zwei Möglichkeiten, wie ein Kellerautomat eine Eingabe $w$
akzeptieren kann:
\begin{itemize}
 \item entweder mit Finalzuständen
  \begin{gather*}
    L(K) = \{w\in\Sigma^{\ast}\colon (q_{0}, w\triangleleft, \ast) \vdash^{\ast} (q,
       \triangleleft, \ast\gamma) \wedge q\in F\}
  \end{gather*}

 \item oder mit einem leeren Keller
  \begin{gather*}
    L_{\lambda}(K) = \{w\in\Sigma^{\ast}\colon (q_{0}, w\triangleleft, \ast)
       \vdash^{\ast} (q,\triangleleft,\ast) \wedge q\in F\}
  \end{gather*}
\end{itemize}

\begin{satz}
  Zu jedem Kellerautomaten $K$, der mit Finalzuständen akzeptiert, gibt
  es einen äquivalenten Kellerautomat $K'$, der mit einem leeren Keller
  akzeptiert, so dass $L(K) = L_{\lambda}(K')$
\end{satz}

\begin{bsp}
  \begin{gather*}
    L =\{ww^{R}\colon w\in\{0,1\}^{\ast}\}
  \end{gather*}

  \underline{Idee:} Wir lesen die Eingabe und schreiben $w$ auf das
  Kellerband. Aufgrund des Kellerprinzips ist $w$ von rechts nach links,
  also in umgekehrter Reihenfolge zu lesen und wird mit der Eingabe
  $w^{R}$ vergleichen.

  Dabei haben wir ständig die Wahl zwischen "`weiter $w$ einlesen"' und
  "`beginnen $w^{R}$ zu testen"'. Dies ist gerade der Nichtdeterminismus
  des Kellerautomaten.

  \begin{align*}
    \Sigma &=\{0,1\}\\
    \Gamma &= \{0,1\}\\
    Q&= \{q_{0}, q_{1}, q_{+}, q_{-}\}\\
    F &= \{q_{+}\}\\
    \intertext{Seien $a,b\in\{0,1\}$, wobei $a\ne b$}
    \delta(q_{0}, a, \ast) &= \{(q_{0}, \ast a)\}\\
    \delta(q_{0}, \triangleleft, \ast) &= \{(q_{+}, \ast)\}\\
    \delta(q_{0}, a, b) &= \{(q_{0}, ba)\}\\
    \delta(q_{0}, a, a) &= \{(q_{0}, aa), (q_{1}, \lambda)\}\\
    \delta(q_{1}, a,a) &= \{(q_{1},\lambda)\}\\
    \delta(q_{1},\triangleleft, \ast) &= \{(q_{+}, \ast)\}\\
    \delta(q_{1}, a,b) &= \{(q_{-}, b)\}
  \end{align*}
\end{bsp}

\begin{satz}
  Eine Sprache $L\subseteq\Sigma^{\ast}$ ist von Typ-2 \gdw
  $L$ wird von einem nichtdeterministischen Kellerautomat akzeptiert.
\end{satz}

\section{Turing-Maschinen vom Typ-3}

\begin{defini}
  Ein nichtdeterministischer Automat $M$ ist ein Tupel
  $M=(Q,\Sigma,\Gamma,\delta,Q_{0},F)$ wobei\\
  \begin{auflistung}
    $Q$& endliche Menge von Zuständen\\
    $Q_{0}\subseteq Q$ & endliche Menge von Anfangszuständen\\
    $F\subseteq Q$ & endliche Menge von Finalzuständen
  \end{auflistung}
  und der Überführungsfunktion
  \begin{gather*}
    \delta\colon Q\times \Sigma \rightarrow \mathfrak{P}(Q)
  \end{gather*}

  Diese Überführungsfunktion $\delta$ wird fortgesetzt zu einer
  \highl[Überführungsfunktion!erweiterte]{erweiterten
    Überführungsfunktion} $\delta'$
  \begin{gather*}
    \delta'\colon \mathfrak{P}(Q)\times\Sigma^{\ast} \rightarrow
       \mathfrak{P}(Q)\\
    \delta'(Q', wa) = \bigcup_{q\in Q'} \delta\big(\delta(q,w), a\big)
  \end{gather*}

  $L\subseteq\Sigma^{\ast}$ wird von $M$ akzeptiert \gdw
  $L=\{w\in\Sigma^{\ast}\colon \delta'(Q_{0},w)\cap F\ne\emptyset\}$
\end{defini}

\chapter{Ausblick in die Theorie der Entscheidbarkeit}

\section{Entscheidbarkeit und Aufzählbarkeit}
Widerholung: \todo{Links finden}
\begin{itemize}
 \item $L\subseteq \Sigma^{\ast}$ heißt entscheidbar \gdw
  $\chi_{L}$ ist berechenbar
 \item $L\subseteq \Sigma^{\ast}$ heißt semientscheidbar
  \gdw $\chi_{L}^{P}$ ist berechenbar

  \begin{gather*}
    \chi_{L}(w)=\begin{cases}1&\colon w\in L\\0&\colon w\notin L\end{cases} \qquad
       \chi_{L}^{P}(w) = \begin{cases}1&\colon w\in L\\\ndef&\colon\sonst\end{cases}
  \end{gather*}
 \item $L\subseteq\Sigma^{\ast}$ heißt aufzählbar \gdw es
  eine total definierte und berechenbare Funktion $f$ mit
  $f(\Sigma^{\ast})=L$ gibt oder $L=\emptyset$.
\end{itemize}

These von Church (\autoref{satz:church}): Jede im intuitiven Sinne mit
Hilfe eines Algorithmus' berechenbare Funktion ist berechenbar.

\section{Charakterisierung der aufzählbaren Mengen}

\begin{defini}
  Es sei $M$ eine Turing-Maschine, die die Funktion $Res_{M}\colon
  \Sigma^{\ast}\rightarrow\Delta^{\ast}$ berechnet.

  Die Menge $D_{M}=\{u \in \Sigma^{\ast}\colon \text{die Maschine $M$ stoppt
  bei Eingabe $u$}\}$ heißt
  \highl{Haltebereich} der Turing-Maschine $M$. ($D_{M}$ ist gerade der
  Definitionsbereich der Funktion $Res_{M}$)

  Die Menge $W_{M}=\{v\in\Delta^{\ast}\colon \exists u\in\Sigma^{\ast}\colon
  v=Res_{M}(u)\}$ heißt \highl{Ergebnisbereich} der Turing-Maschine $M$.
  ($W_{M}$ ist gerade der Wertebereich der Funktion $Res_{M}$)
\end{defini}

\begin{satz}
  Für eine Menge $L\subseteq \Sigma^{\ast}$ sind folgende Aussagen
  äquivalent:
  \begin{enumerate}
   \item $L$ ist aufzählbar
   \item $L$ ist Ergebnisbereich einer Turing-Maschine
   \item $L$ ist Haltebereich einer Turing-Maschine
   \item $\chi_{L}^{P}$ ist berechenbar
   \item $L$ wird von einer Typ-0-Grammatik erzeugt
  \end{enumerate}

  \begin{proof}
    \begin{mdescription}
     \item[1. $\Rightarrow$ 2.]\listlinebreak
      \begin{enumerate}
       \item Wenn $L=\emptyset$ ist, dann ist $L$ der Ergebnisbereich
        einer Turing-Maschine, die nirgends stoppt.
       \item Wenn $L\ne\emptyset$ ist, Dann ist $L=f(\Sigma^{\ast})$
        und jede Turing-Maschine, die $f$ berechnet, hat $L$ als
        Ergebnisbereich
      \end{enumerate}
     \item[2. $\Rightarrow$ 3.] $L$ sei der Ergebnisbereich einer
      Turing-Maschine. $D_{M}^{\ast}=\{v_{1},v_{2},v_{3},\ldots\}$ sei
      eine Aufzählung von $D_{M}$ in quasilexikographischer Reihenfolge.
      Wir konstruieren eine Turing-Maschine $M'$, die für eine Eingabe
      $w\in\Sigma^{\ast}$ genau dann stoppt, wenn $M$ das Ergebnis $w$
      produziert.

      $M'$ arbeitet wie folgt: für Eingabe $w$ wird (nacheinander) erzeugt:
      \begin{gather*}
        w\#\#Konf_{i}^{M}(v_{0})\#Konf_{i-1}^{M}(v_{1})\#\ldots
           \#Konf_{i-j}^{M}(v_{j})\#\ldots \#Konf_{0}^{M}(v_{i})
      \end{gather*}
      Prüfe, ob ein Resultat von $M$ vorliegt:
      \begin{description}
       \item[Ja:] vergleiche die Eingabe $w$ mit dem Resultat
        $Res_{M}(v_{j})=u$
        \begin{description}
         \item[Ja:] dann (lösches alles überflüssige und) stoppe
         \item[Nein:] dann künfig ignorieren und weiterrechen
        \end{description}
       \item[Nein:] Bestimme für jedes $Konf_{i-j}^{M}(v_{i})$ die
        Nachfolgekonfiguration $Konf_{i-j+1}^{M}(v_{i})$ sowie
        $Konf_{0}^{M}(v_{i+1})$
      \end{description}

      Es gilt: $w\in W_{M}$ \gdw $w\in D_{M}$
     \item[3. $\Rightarrow$ 4.] Es sei $M$ eine Turing-Maschine mit
      $D_{M}=L$. $M'$ arbeitet wie $M$, wobei auf einer zusätzlichen Spur alle
      Felder markiert werden, die der Arbeitskopf gelesen hat. Falls $M$
      bei einer Eingabe $w$ stoppt, löscht $M'$ alle markierten
      Bandinhalte und schreibt "`1"'. Falls $M$ bei der Eingabe $w$ nicht
      stoppt, dann stoppt auch $M'$ nicht.

      Damit berechnet $M'$ gerade $\chi_{L}^{P}$.
     \item[4. $\Rightarrow$ 5.]\listlinebreak
      \begin{enumerate}
       \item $L=\emptyset$ klar
       \item $L\ne\emptyset$: Es sei $w_{fix}$ ein Wort aus $L$. Wir
        schreiben folgenden Algorithmus "`\highl{dovetailing}"'
        (\textit{engl. Schwalbenschwanz})

        Eingabe: $w\in\Sigma^{\ast}$
        \begin{enumerate}
         \item Bestimme die Nummer $n$ von $w$ in der
          quasilexikographischen Aufzählung (d.\,h. bestimme $D_{M}(n)=w$)
         \item Verstehen $n$ als Cantornummer und bestimmen $n=c
          \big(l(n),r(n)\big)$
         \item setzen $u=v_{l(n)}$ und $t=r(n)$
         \item $M$ sei eine Turing-Maschine, die $\chi_{L}^{P}$
          berechnet. Simuliere die Arbeit von $M$ auf der Eingabe $u$ mit
          insgesamt $t$ Takten! Falls $M$ das Resultat "`1"' liefert
          ($u\in L$), liefert der Algorithmus die Ausgabe $u$. Sollte $M$
          nicht das Resultat "`1"' liefern, gibt der Algorithmus die
          Ausgabe $w_{fix}$ aus.

          Das bedeutet also:
          \begin{itemize}
           \item für jede Eingabe stoppt der Algorithmus
           \item alle Ausgaben gehören zu $L$
           \item jedes Wort aus $L$ kommt als Ausgabe vor
            \begin{align*}
              w\in L &\Rightarrow \chi_{L}^{P}(w)=1\\
              &\Rightarrow Res_{M}(w) = 1\\
              &\Rightarrow \exists t_{0}\in\N\colon M\ \text{liefert}\ 
                 Res_{M}(w)=1 \text{ in } t_{0} \text{ Takten}
            \end{align*}

            $n_{0}$ sei die Nummer von $w$ ($w=v_{n_{0}}$). Weiter sei
            $n=c(n_{0}, t_{0})$. Bei Eingabe $v_{n}$ liefert der
            Algorithmus gerade $w$.
          \end{itemize}
        \end{enumerate}
      \end{enumerate}
     \item[5. $\Rightarrow$ 1.] \autoref{satz:5}
    \end{mdescription}
  \end{proof}
\end{satz}

\section{Codierung von Turing-Maschinen}

Wir kennen aus \autoref{satz:7} bereits ein "`Wörterbuch"' der
partiell-rekursiven Funktionen und wollen jetzt ein "`Wörterbuch"' der
Turing-berechenbaren Funktionen. Die Idee ist, wir konstruieren die
folgende Turing-Maschine $M=(Q,\Sigma,\Gamma,\delta,q_{0},F)$.
\begin{align*}
  Q &= \{0,1,\ldots,n\}\\
  \Sigma \subseteq \Gamma &= \{ a_{0} =\Box, a_{1}, a_{2},\ldots,a_{k-1}
     \}\\
  F &= \{1\}\\
  q_{0} &= 1
\end{align*}
$\delta$ besteht aus $k\cdot n$ Zeilen zu je fünf Werten $(i, a_{j})
\mapsto (i, a_{k}, bew)$. Wir betrachten
\begin{gather*}
  A = \{a_{0},\ldots,a_{k-1}\} \cup \{0,1,\ldots,n\} \cup\{ \text{;} ,
     \text{,}\}
\end{gather*}

Die Turing-Maschine kann umkehrbar eindeutig durch folgendes Wort
$w_{TM}\in A^{\ast}$ dargestellt werden:
\begin{align*}
  w_{TM} &:= n, a_{0}, \ldots, a_{k-1}, a_{i_{1}}, \ldots, a_{i_{r}},\\
  &\qquad
     \begin{matrix}
       0, &a_{0}, &\delta(0,a_{0}), &0, &a_{1}, &\delta(0,a_{1}),
          &\ldots, &0, &a_{k-1}, &\delta(0,a_{k-1}),\\
       1, &\ldots \\
       2, &\ldots \\
       %3, &\ldots \\
       \vdots\\
       n, &a_{0}, &\delta(n,a_{0}), &\hdotsfor{4}, &n, &a_{k-1}, &\delta(n,a_{k-1})
     \end{matrix}
\end{align*}

\begin{defini}
  $w_{TM}$ heißt \highl{Standardcodierung} der Turing-Maschine
  $TM$.
\end{defini}

Für ein beliebiges $w\in A^{\ast}$ ist es entscheidbar, ob eine
Turing-Maschine $TM$ mit $w=w_{TM}$ existiert. Das Alphabet $A$ hängt
offensichtlich von $TM$ ab (da $\Gamma\subseteq A$). Es sei
$A=\{b_{1},\ldots,b_{j}\}$. Verwenden deshalb $B=\{0,1\}$ und definieren
die folgende Abbildung $\beta \colon A^{\ast}\rightarrow B^{\ast}$ durch
\begin{align*}
  \beta(\lambda) &= \lambda\\
  \beta(b_{i}) &= 10^{i}&&(1\leq i \leq j)\\
  \beta(uv) &= \beta(u)\cdot\beta(v) &&(u,v\in A)
\end{align*}
$\beta$ ist ein Homomorphismus von $A^{\ast}$ nach $B^{\ast}$ und
eindeutig bestimmt!

\begin{defini}
  $bw_{TM} =\beta(w_{TM})$ heißt \highl[Standardcodierung!binäre]{binäre
  Standardcodierung} von $TM$. ($bw_{TM}\in\{0,1\}^{\ast}$ und für jedes
  $w\in\{0,1\}^{\ast}$ ist entscheidbar, ob es eine binäre
  Standardcodierung ist.)
\end{defini}

Die binäre Standardcodierung liefert eine \emph{effektive Nummerierung}
aller Turing-Maschinen:\\
Eingabe: n\\
Erzeuge: das $n$-te Wort über $\{0,1\}^{\ast}$, das binäre
Standardcodierung einer Turing-Maschine ist. Dies sei $bw_{n}$.

Nach der These von Church (\autoref{satz:church}) gibt es eine
Turing-Maschine, die als Ergebnisbereich gerade $\{bw_{0}, bw_{1},
bw_{2}, \ldots\}$ hat.

\begin{defini}
  $T_{n}$ sei diejenige Turing-Maschine $TM$ mit $bw_{TM} =bw_{n}$. $n$
  heißt \highl{Gödelnummer} der Turing-Maschine.

  Eine \highl{Gödelisierung} ist also eine \emph{effektive Nummerierung}
  der Turing-Maschinen!
\end{defini}

Wir haben damit auch zwei Gödelisierungen der aufzählbaren Mengen:\\
\begin{auflistung}
  $D_{n}=D_{T_{n}}$ & ist Haltebereich von $T_{n}$\\
  $W_{n}=W_{T_{n}}$ & ist Ergebnisbereich von $T_{n}$
\end{auflistung}

Wir betrachten Turing-Maschinen mit $\{0,1\}\subseteq \Sigma$.
% Es sei $B=\{0,1\}$
\begin{defini}
  $H:=\{bw_{TM}11n\colon \text{ die Turing-Maschine $TM$ stoppt bei Eingabe
  $w$}\}$ ($H\subseteq\{0,1\}^{\ast}$) Die Wortmenge $H$ heißt
  \highl{Halteproblem} für Turing-Maschinen.
\end{defini}

\begin{satz}[Anhaltesatz]
  \begin{enumerate}
   \item $H$ ist aufzählbar
   \item $H$ ist nicht entscheidbar
   \item $\bar{H}=\{0,1\}^{\ast}\setminus H$ ist nicht aufzählbar
  \end{enumerate}
\end{satz}

\begin{defini}
  Eine Turing-Maschine, die $H$ aufzählt, heißt
  \highl[Turing-Maschine!universelle]{universelle Turing-Maschine}.
\end{defini}

\begin{bemerk}
  $H\in CH(0)\setminus CH(1)$
\end{bemerk}

\clearpage
\appendix

\pdfbookmark[0]{Index}{index}
\printindex
\end{document}
