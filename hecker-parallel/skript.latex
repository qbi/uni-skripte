% ToDo:
%  * fehlende Grafiken ergänzen
%  * Überlegen, ob man für KOSTEN auch einen Befehl macht. Kommt es oft
%    genug im Dokument vor?
%  * Den Stil in den Algorithmen vereinheitlichen. Auf Felder sollte immer mit
%    A[i] zugegriffen werden und nicht mit $a_{i}$

% Einige zusätzliche Informationen für rubber
%  rubber erkennt nicht, dass die Datei weg kann, daher sagen wir es ihm
% rubber: clean $base.thm
%  rubber soll nach Änderungen an der Datei nochmal bauen
% rubber: watch $base.thm
% rubber: makeidx.tool      xindy
% rubber: makeidx.language  german-din
% rubber: makeidx.modules   indexstyle.xdy

\RequirePackage[l2tabu,orthodox]{nag}  % nag überprüft den Text auf verältete Befehle
                          % oder solche, die man nicht in LaTeX verwenden
                          % soll -- l2tabu-Checker in LaTeX

\documentclass[draft,german,twoside]{scrreprt}

\usepackage{ifthen}

\usepackage[algochapter,linesnumbered]{algorithm2e}
\usepackage[final]{graphicx}
\usepackage{color}
\usepackage{fancyvrb}

\usepackage[ngerman]{babel}
\usepackage[latin1]{inputenc}

\usepackage{mathptmx}		% Times
\usepackage[scaled=.9]{helvet}
\usepackage{courier}
\usepackage[T1]{fontenc}

\usepackage{amssymb}
\usepackage[intlimits,leqno]{amsmath}
\usepackage[all,warning]{onlyamsmath}  % warnt bei Verwendung von nicht
                                       % amsmath-Umgebungen z.\,B. $$...$$
\usepackage{fixmath}

\usepackage{paralist}
\usepackage{xspace}
\usepackage[draft=false,colorlinks,bookmarksnumbered,linkcolor=blue,breaklinks]{hyperref}

\usepackage[amsmath,thmmarks,hyperref]{ntheorem}

\usepackage{svn}         % Zum Auswerten und ordentlichen Darstellen der
                         % SVN-Schlüsselwörter (s. vor \begin{document})
                         % dafür muss in SVN noch das Flag svn:keywords
                         % auf "LastChangedRevision LastChangedDate"
                         % gesetzt werden

\usepackage{makeidx}
\usepackage{fixltx2e}
\usepackage[final]{microtype} % Verbesserung der Typographie
\usepackage{nicefrac}

\theoremstyle{break}
\theorembodyfont{\normalfont}
\newtheorem{satz}{Satz}
\newtheorem{bemerk}{Bemerkung}
\newtheorem{lemma}{Lemma}
\newtheorem{bsp}{Beispiel}
\newtheorem{folger}{Folgerung}
\newtheorem{defini}{Definition}
\newtheorem{verein}{Vereinbarung}

\theoremstyle{nonumberbreak}
\theoremheaderfont{\scshape}
\theoremsymbol{\ensuremath{_\blacksquare}}
\newtheorem{proof}{Beweis:}

% Hier die Definition, wie \autoref die Umgebungen nennen soll, die mit
% \newtheorem definiert wurden
\newcommand*{\satzautorefname}{Satz}
\newcommand*{\bemerkautorefname}{Bemerkung}
\newcommand*{\lemmaautorefname}{Lemma}
\newcommand*{\definiautorefname}{Definition}
\newcommand*{\bspautorefname}{Beispiel}
\newcommand*{\folgerautorefname}{Folgerung}
\newcommand*{\vereinautorefname}{Vereinbarung}
\newcommand*{\algocflineautorefname}{Algorithmus}
\newcommand*{\AlgoLineautorefname}{Zeile}
% Zwischen Unter- und Unterunterabschnitten sollte nicht unterschieden
% werden.
\renewcommand*{\subsectionautorefname}{Abschnitt}
\renewcommand*{\subsubsectionautorefname}{Abschnitt}

\pagestyle{headings}

% Zur Korrektur von \thref
% <news:col095$me8$2@n.ruf.uni-freiburg.de>
\makeatletter
% setzt / als Trenner zwischen Abschnitt und Satznummer
\def\@thmcountersep{/}
\makeatother

\SetKwFor{Forpar}{for}{pardo}{endfor}

\newcommand*{\help}[1]{\textcolor{green}{help: #1}}
\newcommand*{\todo}[1]{\textcolor{blue}{todo: #1}}

% Um wichtige Begriffe im Text überall gleich vorzuheben (gleiches
% Markup), sollte dieser Befehl verwendet werden. Das Argument wird
% automatisch als Indexeintrag verwendet. Dieser kann aber auch als
% optionales Argument selbst bestimmt werden.
\newcommand*{\highl}[2][]{\textbf{\boldmath{#2}}%
  \ifthenelse{\equal{#1}{}}{\index{#2}}{\index{#1}}%
}

% Damit die Paare immer vollstädig sind:
\newcommand*{\abs}[2][]{#1\lvert#2#1\rvert}
\newcommand*{\lrangle}[2][]{#1\langle#2#1\rangle}
\newcommand*{\ceil}[2][]{#1\lceil#2#1\rceil}
\newcommand*{\floor}[2][]{#1\lfloor#2#1\rfloor}

% Prof. Hecker schwankt in der Vorlesung ständig zwischen Zeit und Time
% bzw. Work und Arbeit. Diese zwei Befehle sollen helfen, die Begriffe
% einheitlich im Skript zu verwenden und ggf. alle Stellen leicht
% änderbar machen
\newcommand*{\Time}{\text{TIME}\xspace}
\newcommand*{\Work}{\text{WORK}\xspace}
\newcommand*{\Space}{\text{SPACE}\xspace}
\newcommand*{\Z}{\mathbb{Z}}
\newcommand*{\N}{\mathbb{N}}
\newcommand*{\R}{\mathbb{R}}
\newcommand*{\NP}{\mathrm{NP}}    % Klasse der nichtpolynomiellen Probleme
\newcommand*{\NC}{\mathrm{NC}}    % Klasse der polylogarithmischen PRAM-Probleme
\newcommand*{\PP}{\mathrm{P}}     % Klasse der polynomiellen RAM-Probleme

\DeclareMathOperator{\card}{card}     % Kardinalität

\renewcommand*{\tilde}[1]{\widetilde{#1}}  % die normale Schlange ist recht klein

% Definition für Xindy für die Trennung der einzelnen Abschnitte im
% Index. siehe auch die Datei indexstyle.xdy
\newcommand*{\indexsection}{\minisec}

\makeindex

\SVN $LastChangedRevision$
\SVN $LastChangedDate$

\begin{document}

\title{Parallele Algorithmen}
\author{Prof.\,Dr.\,Hans-Dietrich Hecker}
\date{SS 2005 / 2007}
\maketitle

\clearpage
\chapter*{Vorwort}
{\itshape
  Dieses Skript ist im Rahmen des
  \href{http://www.minet.uni-jena.de/~joergs/skripte/}{Projekts
  "`Vorlesungsskripte der Fakultät für Mathematik und Informatik"'}
  entstanden und wird im Rahmen dieses Projekts weiter betreut. Das
  Skript ist nach bestem Wissen und Gewissen entstanden. Denoch
  garantiert weder der auf der Titelseite genannte Dozent, noch die
  Mitglieder des Projekts für dessen Fehlerfreiheit. Für etwaige Fehler
  und dessen Folgen wird von keiner der genannten Personen eine Haftung
  übernommen. Es steht jeder Person frei, dieses Skript zu lesen, zu
  verändern oder auf anderen Medien verfügbar zu machen, solange die
  Adresse der Internetseiten des Projekts
  \texttt{\href{http://www.minet.uni-jena.de/~joergs/skripte/}%
               {http://www.minet.uni-jena.de/}
    \href{http://www.minet.uni-jena.de/~joergs/skripte/}%
         {\textasciitilde{}joergs/skripte/}}
  genannt wird.

  Diese Ausgabe trägt die Versionsnummer~\SVNLastChangedRevision{} und ist
  vom \SVNDate{}. Eine neue Ausgabe könnte auf der Webseite des Projekts verfügbar
  sein.

  Jeder ist aufgerufen Verbesserungen, Erweiterungen und
  Fehlerkorrekturen für das Skript einzureichen bzw. zu melden oder selbst
  einzupflegen -- einfach eine E-Mail an die
  \href{mailto:skripte@listserv.uni-jena.de}{Mailingliste
  \texttt{<skripte@listserv.uni-jena.de>}} senden. Weitere Informationen
  sind unter der oben genannten Internetadresse des Projekts verfügbar.

  Hiermit möchten wir allen Personen, die an diesem Skript mitgewirkt
  haben, vielmals danken:
  \begin{itemize}
   \item \href{mailto:joerg@alea.gnuu.de}{Jörg Sommer
    \texttt{<joerg@alea.gnuu.de>}} (2004, 2005, 2007)
   \item Fred Thiele (2005)
   \item Christian Raschka (2005)
   \item Michael Preiss (2007)
  \end{itemize}
}

\clearpage
\pdfbookmark[0]{Inhaltsverzeichnis}{inhaltsverzeichnis}
\tableofcontents

\clearpage
\pdfbookmark[0]{Auflistung der Sätze}{theoremlist}
\chapter*{Auflistung der Theoreme}

\pdfbookmark[1]{Sätze}{satzlist}
\section*{Sätze}
\theoremlisttype{optname}
\listtheorems{satz}

\pdfbookmark[1]{Definitionen und Festlegungen}{definilist}
\section*{Definitionen und Festlegungen}
% \theoremlisttype{all}
\listtheorems{defini,festl}

\pdfbookmark[0]{Literaturverzeichnis}{literaturverzeichnis}
\begin{thebibliography}{99}
 \bibitem{JaJa} Joseph Ja'Ja: Introduction to parallel algorithms
 \bibitem{AKL} AKL: Introduction to parallel algorithms
 \bibitem{Gibbon} Gibbon and Rytter: parallel algorithms
 \bibitem{Chemnitz} Andreas Goerdt: "`Skript zur Vorlesung Parallele
  Algorithmen"', Technische Universität Chemnitz, 1994,
  \texttt{
    \href{http://www.tu-chemnitz.de/informatik/TI/paralg_ws20022003/skript.ps.gz}%
         {http://www.tu-chemnitz.de/informatik/TI/}\\
    \href{http://www.tu-chemnitz.de/informatik/TI/paralg_ws20022003/skript.ps.gz}%
         {paralg\_ws20022003/skript.ps.gz}},
  Vorsicht: Es sind einige Fehler im Skript!
 \bibitem{zusfas} Markus Krebs, Andreas Horstmann: "`Zusammenfassung der
  Vorlesung \glq{}Parallele Algorithmen\grq{} von Prof.\,Dr.\,Amitava Datta"',
  2002,
  \texttt{\small
    \href{http://www.informatixx.de/privat/files/informatik/pdf/Parallele_Algorithmen_Komplett.pdf}%
         {http://www.informatixx.de/privat/}\\
    \href{http://www.informatixx.de/privat/files/informatik/pdf/Parallele_Algorithmen_Komplett.pdf}%
         {files/informatik/pdf/Parallele\_Algorithmen\_Komplett.pdf}},
  Vorsicht: Es sind einige Fehler im Skript!
\end{thebibliography}

\chapter{Einleitung}

Die Paradigmen (Strategien) für den Entwurf serieller Algorithmen werden durch die
Kriterien Speicher- (\Space) und Zeitkomplexität (\Time), sowie ihrer
einfachen Formulierbarkeit (Beschreibungskomplexität) bestimmt. Ein serieller
Algorithmus soll bezüglich dieser Kriterien "`gut"' sein.

Für die Bewertung serieller Algorithmen ist ein allgemein anerkanntes Modell
die random access machine (\highl{RAM}). Die RAM verfügt über eine
Recheneinheit und einen beliebig großen Speicher, auf dessen Inhalt wahlfrei
zugegriffen werden kann. Alle Basisoperationen können in $O(1)$~\Time
berechnet werden.

Für parallele Algorithmen hingegen gibt es verschiedene Modelle, die
wesentlich abhängiger vom konkreten Rechner sind. Einige (spezielle) Kriterien
für Modelle sind:
\begin{itemize}
 \item Geringe Anzahl leistungsfähiger Prozessoren
 \item Hohe Anzahl "`einfacher"' Prozessoren
 \item Verteilte Systeme (nicht Gegenstand der Vorlesung, siehe Rechnerarchitektur)
\end{itemize}

Bei der Betrachtung von parallelen Algorithmen treten aber auch neue Fragen
auf, die sich für den seriellen Fall nicht ergeben:
\begin{itemize}
 \item Computational Concurrency: Wie stark lässt sich eine Problem
  parallelisieren? Bringt der Einsatz weiterer Prozessoren eine weitere
  Beschleunigung?
 \item Processor Allocation: Welcher Prozessor soll wann welche Operation
  ausführen?
 \item Scheduling: Welche Operationen können parallel ausgeführt werden? Welche
  Operationen hängen von Ergebnissen anderer Operationen ab?
 \item Communication: Wie kommen die Ergebnisse von einem Prozessor zu den
  anderen Prozessoren?
 \item Synchronization: Arbeiten alle Prozessoren unabhängig voneinander oder
  arbeiten sie alle im gleichen Rythmus? Wie synchronisieren sie die
  Prozessoren?
\end{itemize}

\section{Modelle für parallele Algorithmen}

\subsection{DAG -- Modell eines gerichteten, kreisfreien Graphen}

Mit Hilfe eines gerichteten, kreisfreien Graphen~$DAG=(E,V)$ (directed acyclic
graph; \highl{DAG}) beschreibt man eine Berechnung, indem man jedem inneren
Knoten~$v\in V$ einen Berechnungsschritt zuweist und über die Kanten~$e\in E$
die Abhängigkeiten der Operanten der Berechnungsschritte untereinander
modelliert. Eine Kante~$e$ von $v_{1}$ nach $v_{2}$ besagt, dass die Ausgabe
von $v_{1}$ als Eingabe von $v_{2}$ verwendet wird. Einen Knoten mit Indegree
null bezeichnet man als Eingabeknoten der Berechnung, einen Knoten mit
Outdegree null als einen Ausgabeknoten. Alle anderen Knoten bezeichnet man als
innere Knoten.

\begin{figure}
  \centering
  \input{figures/dag_parallel.pdf_t}
  \caption{Zwei mögliche DAGs zur Berechnung der Summe von $n$~Zahlen}
  \label{fig:dag}
\end{figure}

In \autoref{fig:dag} sind zwei verschidene Graphen für die parallele
Berechnung der Summe von $n$~Zahlen dargestellt, wobei eine der beiden
Darstellungen keine Parallelität aufweist.

\begin{defini}
  Gegeben seien $p$~Prozessoren und ein gerichter, kreisfreier
  Graph~$DAG=(E,V)$, der eine Berechnung beschreibt. Jedem inneren
  Knoten~$v\in V$ ordnet man ein Paar $(j_v,t_v)$ zu, wobei $t_v$ einen
  Zeitpunkt bestimmt, an dem der Prozessor~$j_{v}$ ($1 \le j_v \le p$) diesen
  Knoten berechnet. Zudem gelten folgende Bedingungen:
  \begin{enumerate}
   \item ein Prozessor kann zu einem Zeitpunkt nur an einem Knoten aktiv sein;
    wenn $t_u=t_v$ für $u,v\in V$ und $u\ne v$, so gilt: $j_u\ne j_v$
   \item der Prozessor kann für einen Knoten $v$ erst dann aktiv werden, wenn
    die Prozessoren der Vorgängerknoten fertig sind; wenn $(u,v)\in V^{2}$
    eine gerichtete Kante (von $u$ nach $v$) ist, so ist $t_v \ge t_u +1$.
  \end{enumerate}

  Eine solche Zuordnung $S\colon V\rightarrow (\{1,\dotsc,p\}\times\N)$
  bezeichnet man als \highl{Ablaufplan} oder
  \highl{Schedule}.

  Als die Zeit~$T$ eines Ablaufplans~$S$ bezeichnet man $T(S) = \max\{ t\colon
  \exists v\in V\colon S(v)=(j_{v},t_{v})\}$.
\end{defini}

Man erkennt an dem DAG leicht, welche Berechnungen voneinander abhängen und
welche unabhängig voneinander sind, also parallel zueinander ausgeführt werden
können. Jedoch wird nicht auf die Speicherung der Daten und die Kommunikation
der Prozessoren untereinander eingegangen, weswegen das Modell des
gerichteten, kreisfreien Graphen für unsere Bedürfnisse zu allgemein ist.

\subsection{Netzwerkmodell}

Das \highl{Netzwerkmodell} beschreibt durch einem ungerichteten Graphen eine
Menge von Prozessoren ($=$ Knoten) und deren Vernetzung ($=$ Kanten)
untereinander. Die Prozessoren verfügen über einen \textit{lokalen} Speicher
und tauschen ihre Daten mit den Operationen \highl{receive} und \highl{send}
aus.

\begin{figure}
  \centering
  \input{figures/netmodell_input.pdf_t}
  \caption{Sortierung der Zahlen 2, 1, 5, 0 und 3 in einem linearen Feld von
    Prozessoren, ein sogenanntes Sortiernetzwerk}
  \label{fig:lin-feld}
\end{figure}

Mögliche Arten der Vernetzung, sogenannte Topologien, sind:
\begin{itemize}
 \item ein linearen Feld mit $p$~Prozessoren, in dem jeder innere Knoten genau
  zwei Nachbarn hat. Dabei können noch der erste und der letzte Knoten
  miteinander verbunden werden, so dass ein Ring entsteht.
  \autoref{fig:lin-feld}

 \item ein zweidimensionales Gitter, in dem jeder innere Knoten genau vier
  Nachbarn hat.

  \begin{figure}
    \centering
    \input{figures/network_modell.pdf_t}
    \caption{Ein zweidimensionales Gitter und ein Hypercube für $d=4$ und
      $d=2$ mit der Kennzeichnung der Nachbarschaften}
    \todo{Das Bild trennen in zwei Grafiken. Das Gitter hat nicht direkt etwas
      mit dem Hypercube zu tun.}
    \label{fig:hypercube}
  \end{figure}

 \item oder ein $d$-dimensionaler Würfel (Hypercube) mit $2^{d}$~Prozessoren,
  in dem die Nachbarschaftsverhältnisse über binäre Zahlen beschrieben werden:
  Zwei Prozessoren sind benachbart, wenn sich die Binärdarstellungen ihre
  Prozessornummern nur in genau einer Stelle unterscheiden.
\end{itemize}

Für unsere Bedürfnisse ist das Netzwerkmodell zu speziell, da für jede
Problemstelle die jeweilige Topologie betrachtet werden muss.

\subsection{Synchrones Shared-Memory-Modell}

\begin{figure}
  \centering
  \input{figures/parall_modell.pdf_t}
  \caption{Modell der parallel random access machine}
  \label{fig:pram}
\end{figure}

Eine direkte Erweiterung der random access machine ist die parallel random
access machine (\highl{PRAM}), bei der mehrere RAMs über einen unbegrenzt
großen, gemeinsamen Speicher (\highl{globaler Speicher} oder \highl{shared
memory}) verfügen, den sie unabhängig voneinander in einer Zeiteinheit lesen und verändern können.
Untereinander sind die Prozessoren nicht verbunden, so dass jegliche
Kommunikation über den globalen Speicher erfolgen muss. Die Prozessoren
arbeiten mit einem gemeinsamen Zeitsignal (\highl{synchron}), d.\,h. jede
Anweisung wird von allen Prozessoren zum gleichen Zeitpunkt ausgeführt.
\autoref{fig:pram}

\todo{einarbeiten: PRAM berücksichtigt Zuordnung der Aufgaben an die
  Prozessoren und Kommunikation der Prozessoren untereinander.}

Der Zugriff auf den globalen Speicher erfolgt mit den Operationen
\highl{globalRead}$(A,x)$ zum Lesen der globalen Speicherzelle~$A$ in die
lokale Speicherzelle~$x$ und \highl{globalWrite}$(x,A)$ zum Schreiben der
lokalen Speicherzelle~$x$ in die globale Speicherzelle~$A$. Zur Vereinfachung
der Schreibweise verwenden wir große Buchstaben für globale Speicherzellen und
kleine Buchstaben für lokale Speicherzellen, so dass man für einen globalRead
$x:=A$ und für einen globalWrite $A:=x$ schreiben kann.

Beim simultanen Zugriff auf den globalen Speicher kann es zu Konflikten
kommen, wenn mehrere Prozessoren auf die gleiche Speicherzelle zugreifen.
Man unterscheidet die verschiedenen PRAMs anhand der Art, welche Zugriffe sie
zulassen:
\begin{itemize}
 \item \highl{EREW} (exclusive read and exclusive write): eine
  Speicherzelle kann zu einem Zeitpunkt nur von einem Prozessor gelesen oder
  beschrieben werden.

 \item \highl{CREW} (concurrent read and exclusive write): eine
  Speicherzelle kann zu einem Zeilpunkt von beliebig vielen Prozessoren
  gelesen, aber nur von einem Prozessor beschrieben werden.

 \item \highl[CRCW!common]{common CRCW} (concurrent read and concurrent
  write): eine Speicherzelle kann zu einem Zeitpunkt von beliebig vielen
  Prozessoren gelesen und beschrieben werden. Beim Schreibzugriff müssen alle
  Prozessoren den gleichen Wert schreiben.

 \item \highl[CRCW!arbitrary]{arbitrary CRCW}: eine Speicherzelle kann zu
  einem Zeitpunkt von beliebig vielen Prozessoren gelesen und beschrieben
  werden. Wenn die Prozessoren unterschiedliche Werte schreiben, kann der
  tatsächlich geschriebene Wert einer der Werte oder die
  Summe/""Minumim/""Maximum der Werte sein.

 \item \highl[CRCW!priority]{priority CRCW}: eine Speicherzelle kann zu einem
  Zeitpunkt von beliebig vielen Prozessoren gelesen und beschrieben werden.
  Welcher Wert in die Speicherzelle tatsächlich geschrieben wird, hängt von
  einer vorgegebenen Priorisierung der Prozessoren ab; z.\,B. könnte der Wert
  des Prozessors mit der kleinsten Prozessornummer geschrieben werden.
\end{itemize}

\begin{bsp}[Matrixmultiplikation]
  Um die Multiplikation einer $n\times n$-Matrix~$A$ mit einem
  $n$-dimensionalen Spaltenvektor~$x$ parallel auf $p$~Prozessoren
  auszuführen, muss man die Berechnung in $p$ unabhängige Probleme zerlegen.
  Dazu eignet sich die Zerlegung des Ergebnisvektors~$y$, da die Einträge
  unabhängig von den anderen Einträgen in $y$ bestimmt werden können. Jeder
  Prozessor übernimmt $r=\frac{n}{p}$~Zeilen (o.\,B.\,d.\,A. ist $n$ ein
  Vielfaches von $p$) von $y$
  \begin{gather*}
    \begin{pmatrix}
      \begin{array}{|c|}
        \hline
        \hspace{1.6mm} y_1 \hspace{1.6mm} \\
        \vdots \\
        y_{r}\\
        \hline
      \end{array}\\[8mm]
      \begin{array}{|c|}
        \hline
        y_{r+1}\\
        \vdots\\
        y_n\\
        \hline
      \end{array}
    \end{pmatrix}
       = \begin{pmatrix}
           \begin{array}{|ccc|}
             \hline
             \hspace{2.75mm} a_{11}\hspace{2.75mm} & \hdots &
               \hspace{2.75mm} a_{1n} \hspace{2.75mm} \\
             \vdots & \ddots & \vdots \\
             a_{r1} & \hdots & a_{rn} \\
             \hline
           \end{array}\\[8mm]
           \begin{array}{|ccc|}
             \hline
             a_{(r+1)1} & \hdots & a_{(r+1)n} \\
             \vdots & \ddots & \vdots \\
             a_{n1} & \hdots & a_{nn}\\
             \hline
           \end{array}
         \end{pmatrix} \cdot
       \begin{pmatrix}
         x_1 \\
         \vdots \\
         x_{r}\\[3mm]
         x_{r+1}\\
         \vdots\\
         x_n
       \end{pmatrix}
  \end{gather*}

  \begin{algorithm}
    \dontprintsemicolon
    \caption{Das Programm für den $i$.\,Prozessor zur Berechnung von $A\cdot x$}
    \label{alg:matrix-mult}
    \KwIn{$A_{(n,n)}, \vec{x}$, Prozessorzahl $i$, $p$ Anzahl der
      Prozessoren ($r:=\frac{n}{p}$)}
    \KwOut{Die Komponenten $[(i-1)\,r+1,\ldots,i\,r]$ von $y=A\cdot x$}

    globalread(x, z) \tcc*{Alle Proz. lesen $x$ zur gleichen
    Zeit}
    globalread(A[(i - 1) $\cdot$ r + 1 : ir , 1 : n], B)\;
    Berechne w := B $\cdot$ z \tcc*{Arbeit der Prozessoren}
    globalwrite(w, y[(i - 1) $\cdot$ r + 1 : i $\cdot$ r])\;
  \end{algorithm}
\end{bsp}

\begin{bemerk}
  \begin{itemize}
   \item In der ersten Zeile lesen allen Prozessoren zur selben Zeit aus dem
    selben Speicherbereich. Die PRAM muss also concurrent read (CR)
    unterstützen.

   \item In den vierten Zeile schreiben alle Prozessoren in unterschiedliche
    Speicherbereiche. Die PRAM muss also nur exclusive write (EW) unterstützen.

   \item Da kein Prozessor die Ergebnisse eines anderen benötigt, also kein
    Datenaustausch untereinander statt findet, ist keine Synchronisation nötig.

   \item Alternativ könnte man die Spalten von $A$ zu Blöcken
    zusammenzufassen, diese mit den entsprechenden Zeilen von $x$
    multiplizieren und danach die Summe bilden. Allerdings ist dann eine
    Synchronisation notwendig!
  \end{itemize}
\end{bemerk}

\begin{algorithm}[tpb]
  \caption{Vereinfachte Darstellung von \autoref{alg:matrix-mult}}
  \label{alg:matrix-mult-vereinf}
  \KwIn{$A_{(n,n)}, \vec{x}$, Prozessorzahl $i$, $p$ Anzahl der
      Prozessoren ($r:=\frac{n}{p}$)}
  \KwOut{Die Komponenten $[(i-1)\,r+1,\ldots,i\,r]$ von $y=A\cdot x$}
  z := X\;
  b := A[(i-1) r + 1 : ir , 1 : n]\;
  w := b + z\;
  Y[(i - 1) $\cdot$ r + 1 : i $\cdot$ r] := w\;
\end{algorithm}

Entsprechend der obigen Vereinbarung zur Vereinfachung der Schreibweise lässt
sich der \autoref{alg:matrix-mult} auch als \autoref{alg:matrix-mult-vereinf}
schreiben. Da die Ein- und Ausgabe nur jeweils $O(1)$~Schritte dauert, kann
sie ignoriert werden, um die Schreibweise noch weiter zu verkürzen:
\begin{gather*}
  Y[(i - 1) \cdot r + 1 : i \cdot r] := A[(i-1) r + 1 : ir , 1 : n] \cdot X
\end{gather*}

Man kann die Beschreibung der Algorithmen in zwei unterschiedlichen
Abstraktionsschichten betrachten: Die obere Stufe (upper level) beschreibt nur
die generelle Vorgehensweise, wärend auf der unteren Stufe (lower level) die
Prozessorallokation berücksichtigt wird.

\begin{bsp}
  Als Beispiel soll die Summation von $n$~Zahlen betrachtet werden. Die
  Beschreibung auf dem hohen Abstraktionsniveau (\autoref{alg:sum-hoch})
  arbeitet mit der \highl{for-pardo}-Schleife, die angibt, dass der Schleifenrumpf
  für jedem Wert der Laufvariablen parallel auf so viel wie nötig Prozessoren
  ausgeführt werden soll. Jede Anweisung stellt eine \highl{Zeiteinheit}
  --~oder auch \highl{Takt} oder \highl{Time-unit} genannt~-- dar.

  \begin{algorithm}
    \caption{Summation von Zahlen -- auf hohem Abstraktionsniveau}
    \label{alg:sum-hoch}
    \KwIn{Ein Feld~$A$ mit $n=2^{k}$~Zahlen}
    \KwOut{Summer~$S$ der Zahlen im Feld}
    \Forpar{i := 1 \KwTo n}{$B[i] := A[i]$}
    \For{h := 1 \KwTo log(n)}{
      \Forpar{i := 1 \KwTo $\frac{n}{2^h}$}{$B[i] := B[2i-1] + B[2i]$}
    }
    $S := B[1]$\;
  \end{algorithm}

  Auf der unteren Stufe geht es um das konkrete Programm, das auf den
  Prozessoren ausgeführt wird. \autoref{alg:sum-niedrig} Dabei wird auf die
  Aufteilung der einzelnen Schritte auf die Prozessoren --~\highl{Allokation}
  genannt~-- eingegangen. Es muss z.\,B. auf den Fall geachtet werden, dass
  weniger Prozessoren als Eingabedaten vorhanden sind, einige Prozessoren also
  mehrere Datensätze bearbeiten müssen.

  \begin{algorithm}
    \dontprintsemicolon
    \caption{Summation von Zahlen -- auf niedrigem Abstraktionsniveau}
    \label{alg:sum-niedrig}
    \KwIn{Ein Feld~$A$ mit $n$~Zahlen}
    \KwOut{Die Summe~$S$ der Zahlen in $A$}

    \emph{Es sei $r$ die Prozessornummer und $l = \frac{n}{p}$ ($=2^{k}$) die
      Anzahl der Einträge aus $A$, für die der Prozessor verantwortlich ist,
      wobei $p$ die Anzahl der Prozessoren ist}\;
    \For{$j := 1$ \KwTo $l$}{$B[l\cdot(r-1)+j] := A[l\cdot(r-1)+j]$\;}
    \For{$h := 1$ \KwTo $log(n)$}{
      \uIf{$2^{h} \leq l$}{
        \For{$j :=  2^{-h}\cdot l\cdot (r-1)+1$ \KwTo $2^{-h}\cdot l\cdot r$}%
            {$B[j] := B[2\cdot j-1] + B[2\cdot j]$\;}
      }
      \ElseIf{$r\cdot2^{h} \leq n$}{$B[r] := B[2\cdot r - 1] + B[2\cdot r]$\;}
    }
    \If{$r=1$}{$S := B[1]$\;}
  \end{algorithm}

  \begin{figure}
    \centering
    \resizebox{\linewidth}{!}{\input{figures/add_tree.pdf_t}}
    \todo{Die Grafik muss im Original mal verkleinert werden, damit die Schritt
    bzw. die Boxgröße mit angepasst wird.}
    \caption{\todo{ausfüllen}}
    \label{fig:sum-baum}
  \end{figure}

  \begin{figure}
    \centering
    \input{figures/sum_bsp.pdf_t}
    \caption{\todo{ausfüllen}}
    \label{fig:sum-niedrig-baum}
  \end{figure}
  Wie der Ablauf und die Zuordnung der Prozessoren bei $n=8$~Werten für
  \autoref{alg:sum-hoch} ist, ist in \autoref{fig:sum-baum} dargestellt.
  Stehen für \autoref{alg:sum-niedrig} nur $p=4$~Prozessoren zur Verfügung,
  ist die Zuordnung die in \autoref{fig:sum-niedrig-baum}.
\end{bsp}

Die Allokation ist technisch aufwendig, ohne dass neue Ideen gefragt sind.
Deshalb werden wir uns darauf konzentrieren, die Operationen zu beschreiben,
die gleichzeitig möglich sind (obere Stufe) und die Allokation über das
Theorem von Brent (\autoref{satz:brent}) zu behandeln.

\chapter{Die Güte von parallelen Algorithmen und das Theorem von Brent}
\label{sec:algo-bewertung}

Für die Bewertung serieller Algorithmen ist entscheident, wie viele
Rechenoperationen (\Time) und wie viel Speicherplatz (\Space) sie zur
Berechnung benötigen. Bei parallelen Algorithmen muss zusätzlich noch sie
Anzahl der verwendeten Prozessoren bzw. der sich daraus ergebende Aufwand
betrachtet werden.

\begin{defini}
  Für ein Problem~$\mathcal{P}$ bezeichnet $T^{*}(n)$ die beste
  komplexitätstheoretische Abschätzung für die Rechenzeit einen seriellen
  Algorithus, der das Problem~$\mathcal{P}$ löst.
\end{defini}

Da bei parallelen Algorithmen mehrere Rechenschritte in einer Zeiteinheit
ausgeführt werden --~bis zu $p$ Schritten bei $p$ Prozessoren in einer Zeiteinheit~--
trifft man eine Unterscheidung bezüglich dieser beiden Größen:
\begin{defini}
  Die \highl{Rechenzeit}~$T_{p}(n)$ (\highl{\Time}) eines parallelen
  Algorithmus' mit $p$~Prozessoren ist die Mindestanzahl an Zeiteinheiten, die
  der Algorithmus zur Lösung des Problems benötigt.

  Der \highl{Arbeitsaufwand}~$W(n)$ (\highl{\Work}) eines parallelen
  Algorithmus' ist die Anzahl der insgesamt ausgeführten Einzeloperationen
  (aller Prozessoren zusammen).
\end{defini}

Wenn man $W_{i}(n)$ als die Anzahl der Operationen, die in einem Schritt
durchgeführt werden, bzw. als die Anzahl der Prozessoren, die in einem Schritt
aktiv sind, betrachtet, so ist der Arbeitsaufwand des gesamten Algorithmus'
die Summe davon:
\begin{gather*}
  W(n) = \sum_{i=1} W_{i}(n)
\end{gather*}

\begin{defini}[Speed-Up]
  Für ein Problem~$\mathcal{P}$ definiert man als ein Maß für die Verbesserung
  (\highl{Speed-up}) eines parallelen Algorithus' gegenüber dem besten
  seriellen Algorithmus
  \begin{gather*}
    S_{p}(n):=\frac{T^{\ast}(n)}{T_{p}(n)}
  \end{gather*}
\end{defini}

\begin{satz}
  \label{satz:2}
  Der \highl{Speed-up} eines parallelen Algorithmus' kann nie größer sein als
  die Anzahl der Prozessoren oder anders gesagt, die $p$-fache Zeit eines
  parallelen Algorithmus' kann nie kleiner sein als die Zeit des seriellen
  Algorithmus'.
  \begin{align*}
    S_{p}(n)&\le p & T^*(n) &\le p T_p(n)
  \end{align*}

  \begin{proof}
    Simuliert man die Berechnungen der $p$~Prozessoren schrittweise
    nacheinander auf einer Einprozessormaschine, ergibt dies einen neuen
    seriellen Algorithmus mit $p\cdot T_{p}(n)$ Schritten. Dies kann aber
    nicht weniger als $T^*(n)$ sein, da $T^{*}(n)$ bereits das serielle
    Optimum ist.
  \end{proof}
\end{satz}

\begin{bemerk}
  Wenn der Speed-up $S_{p}(n)$ das Maximum~$p$ erreicht, braucht ein
  paralleler Algorithmus den $p$.\,Teil der Rechenzeit des seriellen
  Algorithmus'. Insbesondere kann man mit einem parallelen Algorithmus und
  polynomial vielen Prozessoren kein $\NP$-schweres Problem in Polynomialzeit
  lösen!
  \begin{gather*}
    S_{p}(n) = \frac{T^{\ast}(n)}{T_{p}(n)}=p
       \quad\Rightarrow\quad T_{p}(n) = \frac{T^{\ast}(n)}{p}
  \end{gather*}
\end{bemerk}

\begin{defini}[Effizienz]
  Die \highl{Effizienz} eines parallelen Algorithmus' beschreibt das
  Verhältnis von Speed-up zur Anzahl der eingesetzten Prozessoren.
  \begin{gather*}
    E_{p}(n):= \frac{S_{p}(n)}{p} = \frac{T^{*}(n)}{p\cdot T_{p}(n)} \leq 1
  \end{gather*}
\end{defini}

\begin{defini}
  Als die \highl{Kosten}~$C_{p}(n)$ eines parallelen Algorithmus' bezeichnet man
  das Produkt aus Anzahl der eingesetzten Prozessoren und der benötigten
  Rechenzeit.
  \begin{gather*}
    C_{p}(n) := p\cdot T_{p}(n)
  \end{gather*}
\end{defini}

\begin{satz}
  Die Kosten~$C_{p}(n)$ eines parallelen Algorithmus' können nicht unter der
  seriellen Komplexität liegen.
  \begin{gather*}
    T^{*}(n) \leq C_{p}(n)
  \end{gather*}

  \begin{proof}
    Nach \autoref{satz:2} ist
    \begin{gather*}
      S_{p}(n) = \frac{T^{*}(n)}{T_{p}(n)} \leq p
    \end{gather*}
    also ist $T^{*}(n) \leq p\cdot T_{p}(n) = C_{p}(n)$.
  \end{proof}
\end{satz}

\begin{satz}
  Die Kosten~$C_{p}(n)$ eines parallelen Algorithmus' sind mindestens in der
  Größenordnung von \Work bzw. der Arbeitsaufwand überseigt nie die Kosten:
  $W(n) \leq C_p(n)$.

  \begin{proof}
    Es seien $W_{i}(n)$ die Anzahl der Schritte, die der Algorithmus in
    Schritt~$i$ macht, d.\,h. $W(n) = \sum_{i=1}^{T_{p}(n)} W_{i}$. In einem
    Schritt können nicht mehr Operationen ausgeführt werden als Prozessoren da
    sind: $W_{i}(n)\leq p$
    \begin{gather*}
      W(n) = \sum_{i=1}^{T_{p}(n)} W_{i}(n) \leq \sum_{i=1}^{T_{p}(n)} p =
         p\cdot T_{p} = C_p(n)
    \end{gather*}
  \end{proof}
\end{satz}

\begin{satz}
  Beim Einsatz von $p=O(\frac{W(n)}{T_{p}(n)})$~Prozessoren liegen \Work und
  Kosten in der gleich Größenordnung:
  \begin{gather*}
    C_p(n) = p\cdot T_{p}(n) = O(\frac{W(n)}{T_{p}(n)}\cdot T_{p}(n))
       =O\bigl(W(n)\bigr)
  \end{gather*}
\end{satz}

Ein erster Ansatz für ein Gütekriterium eines Algorithmus wäre:
\begin{defini}
  Ein paralleler Algorithmus heißt \textit{kostenoptimal}, wenn seine Kosten der
  seriellen Komplexität entsprechen: $C_p(n) = T^{*}(n)$.
\end{defini}

Bewerten wir mit dieser Maßgabe die Summation von $n$~Zahlen, so zeigt sich:
\begin{itemize}
 \item Der serielle Algorithmus mit einem Prozessor ist \textit{optimal}:
  $C_1(n) = 1\cdot T^{*}(n) = O(n)$.

 \item Der \autoref{alg:sum-hoch} mit $n$~Prozessoren ist \textit{nicht optimal},
  denn wie man in \autoref{fig:sum-baum} sieht, ist die Laufzeit in $O(\log
  n)$ und damit sind die Kosten $C_p(n)= n\cdot\log n \ne O(n)$.

 \item Berechnet man in einem Vorschritt mit $\frac{n}{\log n}$~Prozessoren
  jeweils sequentiell die Summe von $(\log n)$~Zahlen (Laufzeit: $O(\log n)$)
  und berechnet dann mit \autoref{alg:sum-hoch} die Summe der verbleibenden
  $\frac{n}{\log n}$~Zahlen (Laufzeit: $O(\log\frac{n}{\log n})$ mit
  $\frac{n}{\log n}$~Prozessoren), ist der Algorithmus \textit{optimal}, da die
  Kosten $C_{\frac{n}{\log n}}(n) = O(\frac{n}{\log n}) \cdot \bigl(O(\log n) + O(\log
  \frac{n}{\log n})\bigr) = O(n)$ betragen. Dieses Vorgehen bezeichnet man als
  Accelarated Cascading, was im \autoref{sec:acc-casc} noch einmal genauer
  besprochen wird.
\end{itemize}

Die Definition ist also unzureichend. Eine bessere Definition ergibt sich mit
dem Arbeitsaufwand~$W(n)$ eines Algorithmus'.
\begin{defini}
  Ein paralleler Algorithmus heißt \highl{optimal} (\Work-optimal), wenn der
  Arbeitsaufwand der besten seriellen Laufzeit entspricht: $W(n) = T^{*}(n)$.
  Ein paralleler Algorithmus heißt \highl{WT-optimal} (\Work-\Time-optimal
  oder \highl{streng optimal}), wenn er optimal ist und wenn es keinen
  schnelleren optimalen Algorithmus gibt.
\end{defini}

\begin{bemerk}
  Diese Definition wird auch relativ zu einem speziellen Modell des
  Maschinentyps gebraucht, z.\,B. WT-optimal für die common CRCW.
\end{bemerk}

\begin{satz}[Satz von Brent]
  \label{satz:brent}
  Ein paralleler Algorithmus, der mit $p$~Prozessoren eine \Time von
  $T_{p}(n)$ und einen \Work von $W(n)$ hat, kann auf $p'<p$~Prozessoren in
  $T_{p'}(n) = T_{p}(n)+\floor[\Big]{\frac{W(n)}{p'}}$ ausgeführt werden.

  \begin{proof}
    In der $i$.\,Zeiteinheit werden mit $p$~Prozessoren $W_{i}(n)$~Operationen
    ausgeführt. Mit $p'$~Prozessoren benötigt man zur Berechnung dieser
    $W_{i}(n)$~Operationen höchstens
    $t_{p'}^{i}(n)\leq\ceil[\Big]{\frac{W_{i}(n)}{p'}}$~Zeiteinheiten. Um die
    gesamte Arbeit ($W(n) = \sum_{i=1}^{T_{p}(n)} W_{i}(n)$) zu verrichten,
    muss man alle Schritte der $p$-Prozessor-PRAM nachvollziehen.
    \begin{align*}
      T_{p'}(n) &= \sum_{i=1}^{T_{p}(n)} t_{p'}^{i}(n)
         \leq \sum_{i=1}^{T_{p}(n)} \ceil[\bigg]{\frac{W_{i}(n)}{p'}}
         \leq \sum_{i=1}^{T_{p}(n)} \floor[\bigg]{\frac{W_{i}(n)}{p'}} + 1\\
      &\leq \floor[\bigg]{\frac{1}{p'}\sum_{i=1}^{T_{p}(n)} W_{i}(n)}
           + T_{p}(n)
         = \floor[\bigg]{\frac{W(n)}{p'}} + T_{p}(n)
    \end{align*}
  \end{proof}
\end{satz}

Dieser Satz liefert die Grundlage für die allgemeine Betrachtung der
Algorithmen mit einer nicht konkreten Anzahl an Prozessoren, denn jeder
parallele Algorithmus kann im Normalfall auf jede Anzahl an Prozessoren
angepasst werden.

\begin{satz}[Satz von Eckstein]
  Eine EREW-PRAM mit $p$~Prozessoren kann eine priority CRCW-PRAM so
  simulieren, dass die Laufzeit nur um den Faktor $O(\log p)$ wächst.

  \begin{proof}
    Um das konkurierende Lesen der CRCW zu realisieren, kann ein vorbestimmter
    Prozessor die Zelle lesen und die Information dann baumartig verteilen
    --~jeder Prozessor gibt die Information an zwei andere Prozessor weiter.
    so können alle Prozessoren in $\log p$~\Time benachrichtigt werden.

    Für das konkurierende Schreiben wird der Baum von den Blättern aus
    abgearbeitet. Jeder Prozessor verständigt sich mit einem Nachbarn über den
    Wert, der geschrieben werden soll. Nach $\log p$~Schritten ist ein zu
    schreibender Wert ermittelt.
  \end{proof}
\end{satz}

\begin{bemerk}
  Es gilt die folgende Ordnung der verschiedenen PRAM-Typen, wobei $X\preceq Y$
  bedeutet: Algorithmen, die für $X$ erstellt wurden, können auf $X$ in der
  gleichen Zeit ausgeführt werden.
  \begin{center}
    EREW $\preceq$ CREW $\preceq$ common CRCW $\preceq$ arbitrary CRCW
    $\preceq$ priority CRCW
  \end{center}
\end{bemerk}

\chapter{Die sieben Paradigmen zum Entwurf paralleler Algorithmen}

\section{Binärbaumparadigma}

\todo{Allgemeine Idee des Binärbaumparadigmas beschreiben}

Gegeben sei eine Folge~$(x_{i})_{i\in\N}$ von $n$~Zahlen. Als
\highl{Präfixsumme}~$S$ des $k$.\,Gliedes bezeichnet man die Summe aller
Glieder bis zum $k$.\,Glied. Die Präfixsumme des $n$.\,Gliedes ist die Summe
aller Folgenglieder.
\begin{gather*}
  s_{k} = x_{1} + x_{2} + \dotsb+ x_{k-1} + x_{k}
     = \sum_{j=1}^{k} x_{j}
\end{gather*}

Wir betrachten im Folgenden sowohl den rekursiven als auch den nichtrekursiven
Ansatz zur Berechnung der Präfixsummen. 

\subsection{Rekursiver Ansatz}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% eingefügt aus Vorlesung vom 23.4.07 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{algorithm}
  \KwIn{Array X der Länge $n=2^k$}
  \KwOut{Feld S der Länge n mit Partialsummen $s_{i}$}
  \uIf{n=1}{$s_{1}:=x_{1}$ und exit}
  \Forpar{i:= 1 \KwTo $\frac{n}{2}$}{$y_{i}:=x_{2i-1}+x_{2i}$}
  Berechne rekursiv prefixsums ($y_{1},\dotsc,y_{\frac{n}{2}}$) und speichere %
  sie in $z_{1}$, ..., $z_{\frac{n}{2}}$
  \Forpar{i:=1 \KwTo n}{}
  \caption{Präfixsumme}
  \label{alg:praefix_rek}
\end{algorithm}



\subsection{Nichtrekursiver Ansatz}

\begin{algorithm}
  \KwIn{Feld $A$ der Länge $n=2^r$}
  \KwOut{Feld $S$ der Länge $n$ mit $s_{k}=\sum_{j=1}^{k} a_{j}$ -- Präfixsummen}

  \Forpar{j := 1 \KwTo  n}{$b_{0,j} := a_{j}$}
  \For{h := 1 \KwTo log(n)}{
    \Forpar{j := 1 \KwTo $n\cdot 2^{-h}$}%
           {$b_{h, j} := b_{h-1, 2\cdot j-1}+b_{h-q, 2\cdot j}$}
  }
  \For{h := log(n) \KwTo 1}{
    \Forpar{j := 1 \KwTo $n \cdot 2^{-h}$}{
      \uIf{j gerade}{$c_{h,j} := c_{h+1, \nicefrac{j}{2}}$}
      \uElseIf{j=1}{$c_{h,1} := b_{h,1}$}
      \Else{$c_{h,j} := c_{h+1, \nicefrac{j-1}{2}} + b_{h,j}$}
    }
  }
  \Forpar{j := 1 \KwTo n}{
    \uIf{j gerade}{$s_{j} := c_{1, \nicefrac{j}{2}}$}
    \uElseIf{j=1}{$s_{1} := b_{0,1}$}
    \Else{$s_{j} := c_{1, \nicefrac{j-1}{2}} + b_{0,j}$}
  }
  \caption{Präfixsumme}
  \label{alg:praefix}
\end{algorithm}

\begin{figure}
  \centering
  \input{figures/praefix.pdf_t}
  \caption{Die zwei Schritte des Präfixsummenalgorithmus': links die
    Berechnung der Teilsummen und rechts die Berechnung der Präfixsummen}
  \label{fig:praefix}
\end{figure}

Der nichtrekursive Algorithmus zur Berechnung aller Präfixsummen einer Folge
(\autoref{alg:praefix}) läuft in zwei Schritten ab (\autoref{fig:praefix}):
\begin{enumerate}
 \item Zuerst wird von den Blattknoten aus ein Baum erzeugt, so dass in desses
  inneren Knoten jeweils die Summe ihrer Söhne steht, wobei die Blattknoten
  die Glieder der Folge sind. Im Wurzelknoten steht dann die Summe aller
  Folgenglieder.

  Es sei $h$ die Blattebene im Baum, wobei die Blätter die Höhe~0 haben und
  die Wurzel die Höhe~$\log n$ hat, und $j$ die Position (beginnend bei eins)
  des Knotens in der Blattebene von links gesehen ist.
  \begin{gather*}
    B_{h,j} = B_{h-1, 2j-1} + B_{h-q, 2j}
  \end{gather*}

 \item Danach wird vom Wurzelknoten aus für alle Teilbäume die Präfixsumme
  des am weitesten rechts stehenden Blattknotens bestimmt (und im Wurzelknoten
  des Teilbaums gespeichert). Dabei sind drei Fälle zu unterscheiden:
  \begin{itemize}
   \item Der Teilbaum ist rechter Sohn, d.\,h. $j$ ist gerade: Dann ist der
    äußere rechte Blattknoten des Teilbaums derselbe Knoten, der auch im
    Vaterbaum rechts außen steht. Also wird der Eintrag des Vaters übernommen.
    \begin{gather*}
      C_{h,j} = C_{h+1, \frac{j}{2}}
    \end{gather*}

   \item Der Teilbaum ist linker Sohn und steht ganz links, d.\,h. $j=1$: Dann
    ist die Präfixsumme des äußeren rechten Knotens die Summe aller
    Blattknoten.
    \begin{gather*}
      C_{h,j} = B_{h,j}
    \end{gather*}

   \item Der Teilbaum ist linker Sohn und steht nicht ganz links, d.\,h. $j>1$
    und ungerade: Dann ist die Präfixsumme des äußeren rechten Blattknotens
    gleich der Summe aller Blattknoten des Teilbaums plus der Präfixsumme des
    Blattknotens, der links vom am weitesten links stehenden Blattknoten in
    diesem Teilbaum steht. Diese Präfixsumme steht bereits im linken
    Onkelknoten.
    \begin{gather*}
      C_{h,j} = B_{h, j} + C_{h+1, \frac{j-1}{2}}
    \end{gather*}
  \end{itemize}
\end{enumerate}

Der Algorithmus lässt sich für beliebige zweistellige, assoziative
Operationen~$\star$ verwenden und kann für beliebige $n$-stellige, assoziative
Operationen erweitert werden.
\begin{gather*}
  s_{k} = x_{1} \star x_{2} \star\dotsb\star x_{k-1} \star x_{k}
\end{gather*}

Beide Schritte benötigen jeweils $O(\log n)$~\Time und $O(n)$~\Work. Der
Algorithmus braucht also insgesamt $O(\log n)$~\Time und $O(n)$~\Work und ist
daher optimal. Da ein serieller Algorithmus für die Berechnung der
$n$.\,Präfixsumme mindestens einmal alle Folgenglieder betrachten muss,
benötigt er $O(n)$~\Time. Der parallele Präfixsummenalgorithmus ist also auch
streng optimal.
\todo{Prüfen! Diese Aussage stimmt IMO nicht, da wir später noch einen
  schnelleren Algorithmus bekommen.}

Wenn die Zahlen in Form einer verketteten Liste gegeben sind, kann dieser
Algorithmus nicht verwendet werden, da die Zuordnung des $n$.\,Element auf den
$n$.\,Prozessor, wie sie für den Aufbau des Baums notwendig ist, nicht in
$O(1)$ durchgeführt werden kann. Dazu später mehr unter dem Thema
Parallel Prefix im \autoref{sec:par-pref}.

\section{Pointer Jumping}

Um die Idee des \highl[Pointer jumping]{Pointer jumpings} (oder \highl{path
doubling}) zu verdeutlichen, soll in einem Wald (Disjoint Set Forest) zu jedem
Knoten der Wurzelknoten des Baums, in dem der Knoten hängt, bestimmt werden.

\begin{figure}
  \centering
  \todo{Bild aus Beispiel 2.9 übernehmen}
  % \input{figures/wald.pdf_t}
  \caption{Ein Wald mit drei wurzelgerichteten Bäumen}
  \label{fig:wald}
\end{figure}

Ein \highl{Wald} ist eine Menge von paarweise disjunkten Bäumen, die durch
ihre Wurzel gekennzeichnet sind. Im Speziellen geht es um wurzelgerichtete
Bäume, d.\,h. jeder Knoten des Baums, außer der Wurzel~$r$, hat genau einen
Vorgängerknoten und der Baum ist in der Form gegeben, dass jeder Knoten auf
seien Vorgängerknoten verweist. Der Vorgängerknoten des Wurzelknotens ist er
selbst. \autoref{fig:wald}

\begin{algorithm}
  \caption{Pointer jumping}
  \label{alg:ptr-jmp}
  \dontprintsemicolon
  \KwIn{$n$-dimensionales Feld~$F$, wobei $F[i]=j$, wenn $j$ der Vater
    von $i$ ist}
  \KwOut{$n$-dim.\,Feld~$S$, wobei $S[i]=j$, wenn $j$ die Wurzel des
    Baums ist, in dem $i$ steht}

  \Forpar{i := 1 \KwTo n}%
         {$S[i] := F[i]$\;
          \While{$S[i]\ne S[S[i]]$}%
                {$S[i] := S[S[i]]$}
         }
\end{algorithm}

Der Wald ist als ein $n$-dimensionales Feld~$F$ gegeben, in dem der
$i$.\,Eintrag~$F[i]$ den Vorgängerknoten des $i$.\,Knotens beinhaltet. Jedem
Knoten wird ein Prozessor zugewiesen, der den Wurzelknoten dadurch findet,
dass er in jedem Schritt den Vorgängerknoten seines Vorgängerknotens
ermittelt. \autoref{alg:ptr-jmp}

\begin{figure}
  \centering
  \input{figures/ptr_jumping.pdf_t}
  \caption{Veranschaulichung des Pointer jumpings}
  \label{fig:ptr-jump}
\end{figure}

Nach dem \textit{ersten} Schritt zeigen alle Knoten auf den Vorgänger
(2.\,Generation) ihres direkten Vorgängers. Im zweiten Schritt greifen die
Prozessoren auf diese Ergebnisse zu, so dass sie nicht den Vorgänger der
3.\,Generation bestimmen, wenn sie den Vorgänger des Vorgängers der
2.\,Generation bestimmen, sondern den der 4.\,Generation. Nach dem
\textit{zweiten} Schritt verweisen also alle Knoten auf den Vorgänger der
4.\,Generation. \autoref{fig:ptr-jump} Im \textit{dritten} Schritt ist dann
der Vorgänger des Vorgängers (der 4.\,Generation) der Vorgänger der
8.\,Generation. So springt der Zeiger durch den Baum und bewegt sich nicht von
Knoten zu Knoten.

$h$ sei die maximale Höhe eines Baums im Wald. Auf einer CREW-PRAM liefert der
Algorithmus in $O(\log h)$~\Time und $O(n\cdot\log h)$~\Work die Wurzel zu
jeden Knoten. Da sich das Problem im Seriellen in $\theta(n)$ lösen lässt, ist
der Algorithmus nicht optimal.

\subsection{Parallel Prefix}
\label{sec:par-pref}

Entartet man den Wald zu einem Baum, der auch keine Verzweigungen hat, kann
man damit die \highl[Präfixsumme]{Präfixsummen} für Zahlen, die in einer
verketteten Liste gegeben sind, berechnen. Dieses Problem bezeichnet man als
\highl{parallel Prefix}. Die Zahlen sind in einer weiteren Liste~$W$ gegeben,
die allen Knoten im Wald~$F$ ein Gewicht zuordnet: $W[i]$ ist das Gewicht am
Knoten~$i$. Der Wald selbst beschreibt die Ordnung der Zahlen, wobei der
Wurzelknoten die erste Zahl und der Blattknoten die letzte Zahl ist.

\begin{algorithm}
  \caption{Pointer Jumping mit Knotengewichten}
  \label{alg:par-pref}
  \dontprintsemicolon
  \todo{Algorithmus auf Feldschreibweise ($[]$ statt Index) umstellen}\;
  \KwIn{zwei $n$-dim.\,Felder~$F,W$, wobei $w_i$ das Gewicht am Knoten~$i$
    ist und $f_{i}=j$, wenn $j$ der Vater von $i$ ist}
  \KwOut{$n$-dim.\,Feld~$P$, wobei $p_{i}$ die Summe der Gewichte auf dem
    Pfad von Knoten~$i$ zur Wurzel ist}

  \Forpar{i := 1 \KwTo n}%
         {$s_{i} := f_{i}$ \tcc*{$S$ ist die Liste der Vorgängerknoten}
          $p_{i} := w_{i}$\;
          \While{$s_{i}\ne s_{s_{i}}$}%
                {$p_{i} := p_{i} + p_{s_{i}}$\;
                  $s_{i} := s_{s_{i}}$}
         }
\end{algorithm}

Jeder Prozessor übernimmt wieder einen Knoten und springt auf die oben
beschriebene Weise durch den Baum (die Liste). Dabei berechnet er jeweils die
Summe der Gewichte von ihm bis zu seinem Vorgängerknoten, auf den er gerade
springt/verweist.

Mit parallel Prefix kann man also in $O(\log n)$~\Time und $O(n\log n)$~\Work
sie Präfixsummen einer verketteten Liste berechnen.
Da die Präfixsummenberechnung im seriellen mit $O(n)$~\Time funktioniert, ist
der Algorithmus nicht optimal.

In einem nicht entarteten Wald kann mit diesem Algorithmus für jeden Knoten
die Entfernung zu seinem Wurzelknoten bestimmen, wenn man für die Knoten das
Gewicht~$w_{i}=1$ und für den Wurzelknoten~$r$ das Gewicht~$w_{r}=0$ wählt.

% \begin{center}
%   \input{figures/ptr_jumping_weight.pdf_t}
% \end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Ende Vorlesung vom 19.04.05
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Teile und Herrsche}
\label{sec:teile-herrsch}

Die Strategie \highl{Teile und Herrsche} (engl. \highl{Divide and Conquer})
ist bereits von den seriellen Algorithmen bekannt. Ein Problem wird in
Teilprobleme zerlegt, die untereinander möglichst gleich groß, aber kleiner
als das ursprüngliche Problem sind. Diese Probleme werden unabhängig
voneinander gelöst und aus deren Lösung die Lösung des Gesamtproblems
konstruiert.

Die Zerlegung in Teilprobleme sollte dabei "`einfach"' sein, das Zusammenfügen
der Gesamtlösung kann "`kompliziert"' sein. --~Der umgekehrte Fall heißt
Partitioning (\autoref{sec:partitioning}).~-- Durch die Teilung in
\textit{unabhängige} Teilprobleme bietet sich eine Verteilung auf mehrere
Prozessoren direkt an.

Zur Erläuterung des Paradigmas soll das Problem der Bestimmung der konvexen
Hülle einer Punktmenge im $\R^{2}$ aus der algorithmischen Geometrie dienen:
Die \highl{konvexe Hülle} einer Punktmenge~$S\subset\R^{2}$ ist das kleinste
Polygon, dass alle Punkte der Menge und die Strecke zwischen
ihnen\footnote{Man nennt eine Menge~$M$ \highl{konvex}, wenn für alle
Punkte~$x_{1}$ und $x_{2}$ aus $M$ auch die Strecke zwischen $x_{1}$ und
$x_{2}$ zu $M$ gehört: $\forall x_{1},x_{2}\in M, \forall\lambda\in[0,1]\colon
(\lambda x_{1}+ (1-\lambda)x_{2})\in M$} umfasst.

Das Problem lässt sich im seriellen in $O(n\log n)$~\Time lösen, wobei
$\Omega(n\log n)$ die untere Schranke für die Laufzeit ist, da man aus der
konvexen Hülle, die Sortierung der Punkte herleiten kann und dafür ist
$\Omega(n\log n)$ bekanntlich die untere Schranke.

O.\,B.\,d.\,A. seien die $x$- und die $y$-Koordinaten der Punkte von $S$
paarweise verschieden. Die Punktmenge~$S$ sei aufsteigend nach der
$x$-Koordinate geordnet. Der Punkt mit der kleinsten und der mit der größten
$x$-Koordinate gehören zu konvexen Hülle und teilen sie in eine obere und eine
untere konvexe Hülle. Wir betrachten nur die Konstruktion der oberen konvexen
Hülle~$UCH$ (engl. upper convex hull), die der unteren konvexen Hülle~$LCH$
verläuft analog.

\begin{algorithm}
  \caption{Bestimmen der oberen konvexen Hülle einer Punktmenge~$S$ -- $UCH(S)$}
  \label{alg:conv-hull}
  \KwIn{Punktmenge $S\subset \mathbb{R}^2$, nach $x$ sortiert}
  \KwOut{Obere konvexe Hülle von $S$}

  \uIf{$n \leq 4$}{bestimme $UCH(S)$ durch einfaches Durchsuchen aller Tupel}
  \Else{teile $S$ in $S_1 = \{p_1, \ldots , p_{\frac{n}{2}}\}$ und
    $S_2 = \{p_{\frac{n}{2} + 1}, \ldots , p_n\}$\;
    bestimme $UCH(S_{1})$ und $UCH(S_{2})$ rekursiv und parallel\;
    bestimme die obere Tangente von $UCH(S_{1})$ und $UCH(S_{2})$ und
      konstruiere $UCH(S)$ durch Verbinden der beiden höchsten Punkte
  }
\end{algorithm}

Der Algorithmus (\autoref{alg:conv-hull}) verläuft in zwei Phasen:
\begin{itemize}
 \item in der Top-Down-Phase zerlegt man die Menge~$S$ solange in zwei
  gleichgroße Teilmengen $S_{1} = \{p_{1}, \dotsc, p_{\frac{n}{2}}\}$ und
  $S_{2}=\{p_{\frac{n}{2}+1}, p_{n}\}$ bis die Konstruktion der oberen konvexen
  Hülle trivial ist. Das Bestimmen von $UCH(S_{2})$ wird dabei an einen
  anderen Prozessor abgegeben.

  \help{Könnte man nicht auch die Menge in $\frac{n}{4}$ Teilmengen zerlegen
    und davon mit $\frac{n}{4}$ Prozessoren in $O(1)$~\Time und $O(1)$~\Work
    die konvexen Hüllen bestimmen?}

 \item in der Bottom-Up-Phase wird für je zwei oberen konvexen Hüllen die
  gemeinsame obere konvexe Hülle bestimmt, indem man die gemeinsame obere
  Tangente an beide Hüllen findet und sie so verbindet.
\end{itemize}

Der Rekursionsbaum hat also die Tiefe $O(\log n)$. Damit der Algorithmus
streng optimal ist, d.\,h. $O(\log n)$~\Time und $O(n\log n)$~\Work, darf
jeder Rekursionsschritt nur $O(1)$~\Time und $O(n)$~\Work benötigen. Die
Bestimmung der Tangente muss also in $O(1)$~\Time erfolgen.

% Den folgenden Algorithmus entspricht nicht dem, der in der Vorlesung kam. Den
% aus der Vorlesung habe ich nicht verstanden und dieser hier ist auch noch
% schneller. Der in der Vorlesung war in $O((\log n)^{2})$
% Quelle:
% http://www.informatixx.de/privat/files/informatik/pdf/Parallele_Algorithmen_Komplett.pdf

\begin{figure}
  \centering
  \input{figures/konvexe-huelle0.pdf_t}
  \caption{Bestimmung der Tangente vom Punkt~$u$ aus an $V$}
  \label{fig:konv-h0}
\end{figure}

Zur Vereinfachung der Schreibung sei $U:=UCH(S_{1})$ und $V:=UCH(S_{2})$. Der
Punkt~$\tilde{v}_{u}\in V$ sei der Berührungspunkt der Hülle, so dass die
Gerade durch $u$ und $\tilde{v}_{u}$ eine Tangente an $V$ ist. Da $V$ konvex
ist, liegen alle Punkte unterhalb oder auf der Geraden~$\overline{u\tilde{v}_{u}}$.

Um für einen Punkt~$u\in U$ die relative Lage des Punkts~$\tilde{v}_{u}\in V$
zu $v_{i}\in V$ zu bestimmen, verbindet man die beiden Punkte durch eine
Gerade~$\overline{uv_{i}}$ und bestimmt, ob der Vorgänger~$v_{i-1}\in V$ und
der Nachfolger~$v_{i+1}\in V$ von $v$ nicht auf der gleichen Seite der
Gerade~$\overline{uv_{i}}$ liegen. Ist dies der Fall, so liegt der
Punkt~$\tilde{v}_{u}$ oberhalb von $v_{l}$, da die Eigenschaft der Tangente
eben besagt, dass kein Punkt über ihr liegt. Sind also die Punkte $v_{i-1},
v_{i}, v_{i+1}$ mit wachsender $y$-Koordinate, so ist $j>i$ für
$v_{j}=\tilde{v}_{u}$. Andernfalls ist $j\leq i$ für $v_{j}=\tilde{v}_{u}$.
Siehe \autoref{fig:konv-h0}.
Diese Entscheidung lässt sich in $O(1)$~\Time treffen.

\begin{figure}
  \centering
  \input{figures/konvexe-huelle1.pdf_t}
  \caption{Einschränken des Intervalls, in dem der Punkt für die Tangente
    liegt}
  \label{fig:konv-h1}
\end{figure}

\begin{figure}
  \centering
  \input{figures/konvexe-huelle2.pdf_t}
  \caption{Bestimmen des Punkts für die Tangente im einschränkten Intervall}
  \label{fig:konv-h2}
\end{figure}

Zerlegt man $V$ in $d_{V} = \sqrt{\card V}$~gleichgroße
Segmente~$V^{1},\dotsc, V^{d_{V}}$, so kann man für den Punkt~$u$ in
$O(1)$~\Time mit $d_{V}$~Prozessoren ein Segment bestimmen, in dem der
Punkt~$\tilde{v}_{u}$ liegt. Jeder Prozessor~$P_{k}$ bestimmt für die beiden
Endpunkte von $V^{k}$, ob $\tilde{v}_{u}$ zwischen ihnen liegt --~also rechts
vom linken und links vom rechten Punkt aus. Siehe \autoref{fig:konv-h1}. Das
geht in $O(1)$~\Time. Da das
Intervall $d_{V}$~Punkte enthält, kann man mit den $d_{V}$~Prozessoren in
$O(1)$~\Time darin den Punkt~$\tilde{v}_{u}$ finden, für den beide Nachbarn
unterhalb der Geraden~$\overline{u\tilde{v}_{u}}$ liegen. Siehe
\autoref{fig:konv-h2}. Aufwand wiederum
$O(1)$~\Time.

\begin{figure}
  \centering
  \input{figures/konvexe-huelle3.pdf_t}
  \caption{Parallele Bestimmung der Tangente für ausgewählte Punkte von $U$}
  \label{fig:konv-h3}
\end{figure}

Zerlegt man ebenfalls $U$ in $d_{U}=\sqrt{\card U}$~gleichgroße
Segmente~$U^{1},\dotsc, U^{d_{U}}$ und führt mit $d_{U}$~Prozessoren die
Bestimmung der Tangenten von den Endpunkten der $U^{j}$ aus, so bekommt man in
$O(1)$~\Time über die gleiche Beziehung wie oben für $\tilde{v}_{u}$ ein
Segment~$\hat{U}$, in dem der Berührungspunkt~$\hat{u}\in U$ der gemeinsamen
Tangente an $U$ liegt. Siehe \autoref{fig:konv-h3}. Dafür werden insgesamt
$d_{U}\cdot d_{V} =\sqrt{U}
\cdot\sqrt{V}\leq\sqrt{\frac{n}{2}}\cdot\sqrt{\frac{n}{2}} =
O(n)$~Prozessoren eingesetzt.

\begin{figure}
  \centering
  \input{figures/konvexe-huelle4.pdf_t}
  \caption{Bestimmung der oberen Tangente durch betrachten aller Tangenten aus
    dem verbleibenden Intervall}
  \label{fig:konv-h4}
\end{figure}

Da in dem Segment $\hat{U}$, das $\hat{u}$ enthält, $d_{U}$ Punkte liegen, kann
man mit $d_{V}$~Prozessoren für jeden Punkt~$u_{i}\in U^{k}$ in $O(1)$~\Time
den Berührungspunkt~$\tilde{v}_{u_{i}}$ an $V$ bestimmen. Die gemeinsame
Tangente zeichnet sich dadaruch aus, dass die Nachbarpunkte~$u_{i-1}$ und
$u_{i+1}$ unterhalb der Geraden~$\overline{u_{i}\tilde{v}_{u_{i}}}$ liegen.
Siehe \autoref{fig:konv-h4}.

\section{Partitioning}
\label{sec:partitioning}

\highl{Partitioning} oder auch \highl{Zerlegunsstrategie} genannt, ähnelt
dem Teile-und-Herrsche-Ansatz (\autoref{sec:teile-herrsch}). Ein Problem wird
in unabhängige Teilprobleme zerlegt, diese werden einzeln gelöst und aus deren
Teillösugen die Gesamtlösung konstruiert. Der Unterschied zum
Teile-und-Herrsche-Ansatz ist, dass beim Partitioning die Zerlegung in
Teilprobleme kompliziert, aber der Aufbau der Gesamtlösung einfach ist.

Die Idee des Partitionings soll an der Vereinigung von zwei sortierten
Folgen~$A$ und $B$ mit $m$ bzw. $n$~Elementen zu einer sortierten Folge~$C$
mit $m+n$~Elementen erläutert werden. Dieses Problem wird als \highl{Merge}
oder \highl{Mischen} bezeichnet.

\begin{defini}
  Eine Folge~$A=(a_{1},\dotsc, a_{m})$ heißt genau dann \highl{sortiert}, wenn
  alle Folgenglieder größer oder gleich ihren Vorgängern sind: $\forall
  i\in\{1,\dotsc,m\} \forall j\in\{1,\dotsc,i\}\colon a_{j}\leq a_{i}$.
\end{defini}

\begin{defini}
  Als den \highl{Rang} eines Elements~$x$ bezüglich einer
  Menge~$A=\{a_{1},\dotsc, a_{m}\}$ bezeichnet man die Anzahl der Elemente aus
  $A$, die kleiner oder gleich $x$ sind.
  \begin{gather*}
    Rang(x:A) := \card\{ a\colon a\in A \wedge x\leq a\}
  \end{gather*}

  Als den \highl{Rang} einer Folge~$B=(b_{1},\dotsc, b_{n})$ bezüglich einer
  Menge~$A=\{a_{1},\dotsc, a_{m}\}$ bezeichnet man die Folge der Ränge der
  Elemente von $B$
  \begin{gather*}
    Rang(B:A) := \bigl(Rang(b_{1}:A), Rang(b_{2}:A),\dotsc,Rang(b_{n-1}:A),
       Rang(b_{n}:A)\bigr)
  \end{gather*}
\end{defini}

\begin{bsp}
  \begin{align*}
    Rang(4 : \{7,25,23,5\}) &=0 & Rang(12: \{5,7,23,25\}) &=2\\
    Rang(4: \emptyset) &= 0
       & Rang(12: \{1,3,2\}) &= 3\\
    Rang((4,12) : \{5,7,23,25\}) &= (0,2) &
       Rang((12,4):\{7,23,3,25,1,2,5\}\bigr) &= (5,3)
  \end{align*}
\end{bsp}

\begin{bemerk}
  Im Folgenden seien zur Vereinfachung die Elemente aus $A$ und $B$ paarweise
  verschieden.
\end{bemerk}

\begin{satz}
  Seien $A$ und $B$ zwei Folgen mit $m$ bzw. $n$~Elementen. Die
  Folge~$C=(c_{1},\dotsc, c_{m+n})$ mit den Gleidern $c_{i}$ ist die
  gemischte, sortierte Folge von $A$ und $B$, wobei $c_{i} = x\in A\cup B$
  genau dann, wenn $i=Rang(x:A\cup B)$ ist.
  \begin{proof}
    trivial
  \end{proof}
\end{satz}

Um also zwei Folgen~$A$ und $B$ zu einer sortierten Folge~$C$ zu
vereinen, muss man für alle $x\in A\cup B$ den Rang von $x$ in $A\cup B$
bestimmen. Dabei gilt die folgenden Beziehung:
\begin{gather*}
  Rang(x: A\cup B) = Rang(x:A) + Rang(x:B)
\end{gather*}

Sind $A$ und $B$ bereits sortiert, so ist der Rang von $a\in A$ bezüglich $A$
bzw. der Rang von $b\in B$ bezüglich $B$ die Postition in der Folge. Bestimmt
man dann noch $Rang(A:B)$ und $Rang(B:A)$, so ist die sortierte, gemischte
Folge von $A$ und $B$ leicht zu bestimmen.

\begin{bemerk}
  Im Folgenden seien $A$ und $B$ immer sortiert.
\end{bemerk}

Um den Rang eines Elements~$x$ bezüglich einer sortierten Folge~$B$ mit $n$~Elementen
zu bestimmen, kann man auf die sequentielle, binäre Suche zurückgreifen, womit
sich $Rang(x:B)$ in $O(\log n)$~\Time bestimmen lässt.

Da beide Aufgaben ($Rang(A:B)$ und $Rang(B:A)$) symetrisch sind, genügt es den
Vorgang $Rang(A:B)$ zu analysieren: Da die Folge~$B$ sortiert ist, kann man
für ein Element~$x\in A$ mit binärer Suche in $O(\log n)$~\Time mit einem
Prozessor $Rang(x:B)$ bestimmen. Da alle Operationen parallel auf einer
CREW-PRAM ausgeführt werden können, erhält man so für die gesamte Folge
$O(\log n)$~\Time und $O(m\log n)$~\Work.

Analog erhält man für $Rang(B:A)$ $O(\log m)$~\Time und $O(n\log m)$~\Work.
Für den gesamten Algorithmus ergibt sich somit $O(\log(m+n))$~\Time und
$O((m+n)\log(m+n))$~\Work. Da das Mischen im Seriellen in Linearzeit
$T^{*}(n)=\Theta(n)$~\Time geht, ist der Algorithmus nicht optimal.

Um einen optimalen Algorithmus zu erhalten, kann man das Problem mit der
\highl{Partitioning}-Strategie angehen:
\begin{enumerate}
 \item Zerlegung (Partitioning) von $A$ in $\frac{m}{\log m}$~Abschnitte
  der Länge~$\log m$.
 \item Für die Elemente an den Abschnittsgrenzen ihre Position innerhalb der
  Folge~$B$ bestimmen.
 \item Damit ergeben sich Paare von Abschnitten von $A$ und $B$ die unabhängig
  voneinander mit einem sequentiellen Algorithmus, der in Linearzeit arbeitet,
  gemicht werden können. Das Mischen der Abschnitte geschieht parallel.
 \item Aneinanderhängen der gemischten Abschnitte zur Folge~$C$.
\end{enumerate}

\begin{figure}
  \centering
  \input{figures/merge-bin.pdf_t}
  \caption{Zerlegung von zwei Folgen in kleine Abschnitte (Streifen) zum
    direkten Mischen}
  \label{fig:merge-bin}
\end{figure}

Beim Mischen der Paare~$(A_{i}, B_{i})$ muss darauf geachtet werden, dass
beide Abschnitte höchstens $\log m$ bzw. $\log n$~Elemente enthalten, damit der
Mischvorgang nicht länger als $(\log m+\log n)$~\Time braucht. Unter
ungünstigsten Umständen sind alle Elemente aus $A$ größer als alle Elemente
aus $B$, so dass der Prozessor für das Paar $(A_{0}, B_{0})$ alle Elemente von
$B$ behandelt, weil $B_{0}=B$ ist.

Für die Abschnitte~$A_{i}$ ist die Größenbeschränkung bereits gegeben. Sollte
ein Abschnitt~$B_{i}$ mehr als $\log n$~Elemente enthalten, so teilt man ihn
in Abschnitte der Länge $\log n$ und bestimmt für diese die zugehörigen
(Unter"")"~Abschnitte innerhalb von $A_{i}$. Dadurch werden es zwar mehr
Paare, aber es ist sichergestellt, dass sie in $O(\log m+\log n)$~\Time
gemischt werden können, und es werden nie mehr als $m+n+1$~Paare. Siehe
\autoref{fig:merge-bin}.

Für das Eingliedern der neuen Abschnitte von $B_{i}$ ist es ausreichend den
Abschnitt~$A_{i}$ zu betrachten, da alle Elemente aus $B_{i}$ größer sind als
das erste Element im Abschnitt und dieses so gewählt wurde, dass es kleiner
oder gleich dem ersten Element von $A_{i}$ ist. Ebenso sind alle Elemente
kleiner als das letzte, welches so gewählt wurde, dass es kleiner oder gleich
dem letzten Element in $A_{i}$ ist. Anschaulich gesprochen: Die Pfeile können
sich nicht überschneiden.

\begin{algorithm}
  \dontprintsemicolon
  \caption{Zerlegen zweier sortierten Folgen in Paare von Teilfolgen zum
    Mischen}
  \label{alg:mischen}
  \KwIn{Zwei sortierte Folgen $A$ und $B$ mit $m$ bzw. $n$ Gliedern.}
  \KwOut{Menge von Paaren von Teilfolgen $(A_{i},B_{i})$ für die gemischte
    Gesamtfolge}

  $k := \frac{m}{\log m}$\;
  $j[0] := 0$\;
  $j[k] := n$\;
  \Forpar{$i:= 1$ \KwTo $k-1$}{
    $j[i] := Rang(A[i\cdot \log m] : B)$\tcc*{mit binärer Suche}
  }
  \Forpar{$i:= 0$ \KwTo $k-1$}{
    $A_i := \bigl[A[(i\cdot \log m)+1],\dotsc,A[(i+1)\cdot \log m]\bigr]$\;
    $B_i := \bigl[B[j[i]+1],\dotsc,B[j[i+1]]\bigr]$\;
  }
\end{algorithm}

\begin{satz}
  Das Mischen von zwei sortierten Folgen $A$ und $B$ mit $m$ bzw.
  $n$~Elementen benötigt $O(\log m+\log n)$~\Time und $O(m+n)$~\Work.

  \begin{proof}
    Die Zerlegung von $A$ in Teilabschnitte $O(1)$~\Time und
    $O(1)$~\Work.

    Die binäre Suche benötigt $\log n$~Schritte für die Bestimmung von
    $Rang(A[i\cdot\log m]:B)$. Da dies für $\frac{m}{\log m}$~Elemente
    gleichzeitig geschieht, ist der Aufwand für den zweiten
    Schritt $O(\frac{m}{\log m}\cdot\log n)=O(m+n)$~\Work. Die Rechenzeit ist
    $O(\log n)$~\Time.

    Da $\lim_{z\rightarrow\infty}\frac{z}{\log z} = \infty$ ist, gilt für
    $m<m+n$
    \begin{gather*}
      \frac{m}{\log m} < \frac{m+n}{\log(m+n)} \quad\Rightarrow\quad
         \frac{m}{\log m} \log n < \frac{m}{\log m} \log(m+n) < m+n
    \end{gather*}

    Das Mischen der Teilfolgen mit einem sequentiellen Algorithmus geht in
    $O(\log m+\log n)$~\Time und benötigt $O(m+n)$~\Work.
  \end{proof}
\end{satz}

Der parallele Algorithmus ist aber nicht streng optimal, da es einen
Algorithmus gibt, der in $O(\log\log n)$~\Time mit $O(n)$~\Work funktioniert.
Dazu später noch einmal mehr im \autoref{sec:mischen}.

\section{Pipeline-Verfahren}

Unter dem \highl{Pipeline-Verfahren} versteht man folgendes Vorgehen: Zwei
Aufgaben~$\mathcal{A}$ und $\mathcal{B}$ werden in eine Folge von
paralleilierbaren Teilaufgaben $\mathcal{A}=(a_{1},\dotsc, a_{n})$ und
$\mathcal{B}=(b_{1},\dotsc, b_{n})$ aufgeteilt, so dass nach der Beendigung
einer Teilaufgabe~$a_{i}$ die folgende Teilaufgabe~$a_{i+1}$ begonnen und
parallel dazu die neue Teilaufgabe~$b_{i}$ abgearbeitet werden kann. Dieses
Vorgehen ist nur dann lohnenswert, wenn mehrere Aufgaben erfüllt werden
müssen.

\begin{bsp}
  Das Pipeline-Verfahren existiert auch in der Wirklichkeit und kann z.\,B.
  beim täglichen Gang in die Mensa beobachtet werden. Die Aufgabe
  "`Essensausgabe"' für viele Gäste ist in die Teilprobleme "`Hauptspeiße auf
  den Teller legen"', "`Sättigungsbeilage auf den Teller legen"' und
  "`Gemüsebeilage auf den Teller legen"' geteilt. Dafür sind drei Angestellte
  (Prozessoren) zuständig.

  Der erste Angestellte nimmt einen Teller und legt die Hauptspeiße darauf.
  Danach gibt er den Teller dem zweiten Angestellten und nimmt sich wieder
  einen neuen Teller, auf den er die Hauptspeiße legt. Der nächste Angestellte
  legt die Sättigungsbeilage auf den Teller, gibt ihn an den dritten
  Angestellten und nimmt den nächsten Teller in Empfang und befüllt ihn. Der
  dritte Angestellte legt noch das Gemüse auf den Teller und reicht ihn dem
  Gast und nimmt den neuen Teller an.

  Nach einer kurzen Anlaufphase von drei Takten, wird in jedem Takt ein Teller
  ausgegeben.
\end{bsp}

2-3-Bäume (ähnlich Top-Down-2-3-4-Bäumen, ausbalancierter Suchbaum mit Knoten aus zwei oder drei Elementen)\\

Gegeben: $A=(a_1,a_2,\ldots,a_n)\quad : \quad a_{1}<a_{2}<\ldots<a_{n}$ Blattsuchbaum\\
Innere Knoten: Pfad-Infos $(L[v],M[v],R[v])$ - jeweils größter Knoten im linken (bzw. mittleren oder rechten) Teilbaum\\

Wir wollen nun in diesen Baum $B={b_1,\ldots,b_k}\quad : \quad b_{1}<b_{2}<\ldots<b_{k}\quad k<<n$ einfügen:

% Nutzen dieser Idee zum Algorithmusentwurf
%
% Beispiel: INSERT von ($b_{1}<b_{2}<\ldots<b_{k})$ in
% ($a_{1}<a_{2}<\ldots<a_{n}$) $k=O(n)$, sogar $k<<n$
%
% \begin{description}
%  \item[Variante B] task: INSERT($b_{1}, b_{2},\ldots,b_{k})$
%  \item[Variante A] task: INSERT einen Teil davon
% \end{description}
%
% Verwaltung der Werte in (2,3)-Suchbaum (-Blattsuchbaum)
%
% Knoten $v$: L[v], M[v], R[v]
% INSERT : SEARCH+ Einf"ugen
% START: INSERT $b$: gesucht $i$: $a_{i}<b<a_{i+1}$
%
% % Bild: Einf"ugen in 2-3-Baum

\begin{defini}
  $B_i \subseteq B$ - Werte zwischen $a_i$ und $a_{i+1}$\\
  $|B_i| := k_i \quad (\to$ Summe der $k_i$ sind ergibt im wesentlichen $k-2$, nach dem ersten Schritt)
\end{defini}

Vorschritt: Füge $b_{1},b_{k}$ ($O(\log n)$ \Time) (Damit alle Elemente
zwischen zwei Elementen im Baum eingefügt werden und nicht vor dem
linken oder nach dem rechten)\\

% Dann: Umbenennung: $a_{1}<\ldots<a_{n}$ neu = $a_{1},\ldots,a_{n}$ alt
% erg"anzt um $b_{1},b_{k}$
% Jetzt Def.: $B_{i}:= $ Teilkette der $b_{2},\ldots,b_{k-1}$ zwischen
% $a_{i}$ und $a_{i+1}$
\begin{enumerate}[1.\,{Fall}]
 \item $|B_{i}|\leq 1 \quad\forall i=1,\ldots,n-1$

  WORSTCASE
  \todo{ Bild: Worstcase bei Fall1 einfügen}

  $\Rightarrow$ bei pardo insert ($b_{2},\ldots,b_{k-1})$ im Fall 1
  entstehen pro Knoten über der Blattebene max. 6 Söhne
 \item ($\neg$ 1. Fall)
  $|B_{i}|=k_{i}$ ($\sum k_{i} = k-2$)
  möglich für ein $i$: |$B_{i}$|=$k_{i}$=$\Omega(k)$

  $b_{i_{1}},\ldots,b_{i_{k}} \rightarrow$ mittleres Element mit Index $z
  := \lceil\frac{1+k_{i}}{2}\rceil$ also $b_{i_{z}}$ das für alle $i$

  insert alle $b_{i_{z}}$ = 1. Fall

  Damit reduzieren wir die Maximallänge der Folge der einzufügenden
  Elemente zwischen zwei Elementen auf die Hälfte. Das wird fortgesetzt,
  bis Fall 1 erreicht.
\end{enumerate}

Höhe des Baumes: $O(\log n)$
Im 1. Fall: parallel (pardo) : $O(\log n)$ \Time, $O(k \log n)$ \Work
2. Fall: ($\log k$)-mal durchzuführen, jedesmal Fall 1 $\Rightarrow$
$O(\log k \log n)$ \Time, $O(k \log n)$ \Work

Aufgabe: INSERT z.\,B. $b_{i_{1}},\ldots,b_{i_{k_{i}}}$

1. Teilaufgabe INSERT: INSERT jeweils das erste gelbe Element
2. Teilaufgabe: INSERT jeweils die beiden nächsten gelben Elemente
$\Rightarrow O(\log n + \log k)=O(\log n)$ \Time
\begin{bemerk}
  Das erste Element braucht $\log n$ Schritte um an seiner Stelle zu sein.
  Das letzte Element wird nach $\log k$ Schritten losgeschickt und kommt
  nach weiteren $\log n$ Schritten an, also $\log k+\log n$
\end{bemerk}

\section{Accelarated Cascading}
\label{sec:acc-casc}

Im \autoref{sec:algo-bewertung} kam bereits die Strategie des
\highl{Accelarated Cascading} schon einmal zum Einsatz. Die Idee ist, einen
langsamen, optimalen und einen schnellen, nicht optimalen Algorithmus so zu
kombinieren, dass ein schneller(er) und optimaler Algorithmus entsteht.
\begin{enumerate}
 \item Verkleinere das Problem mit einem optimalen, aber langsamen Algorithmus,
  bis durch die Anwendung des nicht optimalen, aber schnellen Algorithmus'
  sich der \Work nicht erhöht.
 \item Wende auf das verkleinerte Problem aus dem ersten Schritt den nicht
  optimalen, aber schnellen Algorithmus an.
\end{enumerate}

Ein Spezialfall des Accelarated Cascading ist das \highl{Sequential Subset},
bei dem die zwei Algorithmen nicht nacheinander ausgeführt werden, sondern
ineinander verschachtelt sind, so dass einer der beiden den globalen Ablauf
bestimmt und der andere für die lokale Arbeit eingesetzt wird.

Durch den Einsatz von Sequential Subset und Accelarated Cascading kann man
einen Algorithmus bekommen, der in $O(\log\log n)$~\Time mit $O(n)$~\Work das
Maximum bestimmt. Dies gilt aber nur für eine CRCW-PRAM. Auf einer CREW-PRAM
gilt prinzipell $\Omega(\log n)$~\Time unabhängig von \Work.

\begin{satz}
  Auf einer CREW-PRAM ist $\Omega(\log n)$ die untere Schranke für das
  bestimmen des Maximums von $n$~Elementen.

  \begin{proof}
    Das Problem ist äquivalent zur Berechnung einer $n$-stelligen boolschen
    Funktion~$f\colon\{0,1\}^{n}\rightarrow\{0,1\}$.

    Für eine Eingabe~$I=(x_{1},\dotsc, x_{n})\in\{0,1\}^{n}$ ist $I(i) =
    (x_{1},\dotsc, \neg x_{i},\dotsc, x_{n})\in\{0,1\}^{n}$. Eine Eingabe
    heißt genau dann kritisch, wenn für alle $i$ ($1\leq i\leq n$) gilt: $f(I)
    \ne f(I(i))$. (Bezogen auf das Maximumproblem wäre die Folge
    $(0,\dotsc,0)$ eine kritische Eingabe.)

    Irgendwo kommt ein Haupttheorem her, das besagt: Besitzt eine Funktion
    $f\colon\{0,1\}^{n}\rightarrow \{0,1\}$ eine kritische Eingabe, dann sind
    auf der CREW-PRAM $\Omega(\log n)$~Schritte zur Berechnung von $f$ nötig.
    \help{Warum? Wieso? Weshalb? Können wir das beweisen oder dauert das zu
      lange?}
  \end{proof}
\end{satz}

% 7.5.

Die Bestimmung des Maximums einer Folge von $n$~Elementen geht mit dem
Binärbaumparadigma in $O(\log n)$~\Time mit $O(n)$~\Work. Das ist optimal, da
das serielle Optimum $T^{*}(n)=\Theta(n)$ ist, aber es geht schneller.
\autoref{alg:max-konst} bestimmt das Maximum in konstanter Zeit mit
$O(n^{2})$~\Work und kann auf einer common CRCW-PRAM implementiert werden, da
in \autoref{line:max} alle Prozessoren das gleiche schreiben. Dieser
Algorithmus ist aber nicht optimal.

\begin{algorithm}
  \dontprintsemicolon
  \caption{schnelle, nicht optimale Bestimmung des Maximums von $n$~Elementen}
  \label{alg:max-konst}
  \KwIn{Ein Feld~$A$ mit $n$ verschiedenen Elementen}
  \KwOut{Boolsches Feld~$M$ der Länge an, für das gilt $M[i]=1 \Leftrightarrow
    A[i]=\max A$}
  \Forpar{$i:= 1$ \KwTo $n$}{
    $M[i] := 1$\;
    \Forpar{$j:= 1$ \KwTo $n$}{
      \If{$A[i] < A[j])$}{$M[i] := 0$\nllabel{line:max}}
    }
  }
\end{algorithm}

Das Problem an \autoref{alg:max-konst} ist, dass er zu viele Prozessoren
verwendent, wärend beim Binärbaum von Stufe zu Stufe weniger Prozessoren
verwendet werden. Kombiniert man beide Algorithmen in dem Sinne, dass man die
Berechnung stufenweise ablaufen lässt und immer größere Gruppen von
Prozessoren mit dem nicht optimalen Algorithmus zusammenfasst, so bekommt man
die gewünschte Beschleunigung mit konstantem Aufwand.

Die Gruppengröße soll doppeltexponentiell wachsen, d.\,h. in der ersten Stufe
sind es Zweiergruppen, in der zweiten Vierergruppen, in der dritten Sechzehnergruppen
usw. Es entsteht ein sogenannter Baum mit doppellogarithmischer Tiefe.
\begin{gather*}
  \begin{array}{l*{6}{c}}
    \text{Stufe}& \#\,\text{Eingabe}& \text{Gr.größe}&
    \#\,\text{Gr.}& \text{Proz. pro Gr.}& \text{Proz. insg.}&
    \#\,\text{Ausgabe}\\
    1.& n = \frac{n}{2^{0}}& 2=2^{1}& \frac{n}{2}& 2^{2}& 2n& \frac{n}{2}\\
    2.& \frac{n}{2} = \frac{n}{2^{1}}& 4=2^{2}& \frac{n}{8}& 4^{2}&
      \frac{16n}{8} = 2n& \frac{n}{8}\\
    3.& \frac{n}{8}=\frac{n}{2^{3}}& 16=2^{4}& \frac{n}{128}& 16^{2}&
      \frac{256n}{128}=2n& \frac{n}{128}\\
    4.& \frac{n}{128}=\frac{n}{2^{7}}& 256=2^{8}& \frac{n}{2^{15}}& 2^{16}&
      \frac{2^{16}n}{2^{15}}=2n& \frac{n}{2^{15}}\\
    \vdots\\
    i.& n\cdot2^{1-2^{i-1}}& 2^{2^{i-1}}& n\cdot2^{1-2^{i}} ~(\star)&
      (2^{2^{i-1}})^{2} = 2^{2^{i}}& 2n~(\star\star)& n\cdot
      2^{1-2^{i}}
  \end{array}
\end{gather*}

Für die Rechnung~$(\star)$:
\begin{gather*}
  n\cdot2^{1-2^{i-1}}\cdot 2^{-2^{i-1}} = n\cdot2^{1-2^{i}}
\end{gather*}

Für die Rechnung~$(\star\star)$:
\begin{gather*}
  n\cdot2^{1-2^{i-1}}\cdot2^{2^{i-1}} = n\cdot 2
\end{gather*}

Das Maximum ist bestimmt, wenn die Ausgabe einer Stufe nur noch ein Element
umfasst:
\begin{align*}
  n\cdot 2^{1-2^{i}} &= 1 &\Leftrightarrow&
     & 2^{2^{i}-1} &= n\\
  & & \Leftrightarrow& & 2^{i}-1 &=\log n\\
  & & \Leftrightarrow& & i&= \log(1+\log n)
\end{align*}

Der Algorithmus braucht also $O(\log\log n)$~\Time und $O(n\cdot\log\log
n)$~\Work und ist damit nicht optimal. Aber durch den Einsatz von Accelarated
Cascading kann ein optimaler Algorithmus entworfen werden:
\begin{enumerate}
 \item Mit dem optimalen (Binärbaum-)Algorithmus reduziert man die Elemente
  auf $\frac{n}{\log\log n}$ Stück und
 \item arbeitet dann mit dem nicht optimalen, doppeltexponentiellen Algorithmus
  weiter.
\end{enumerate}

Der erste Schritt braucht $O(\log\log\log n)$~\Time und verwendet $O(n)$~\Work
(da der Algorithmus optimal; grobe Abschätzung).
\begin{align*}
  n\cdot2^{-i} &= \frac{n}{\log\log n} &\Leftrightarrow&
     & 2^{i} &= \log\log n& \Leftrightarrow& &i=\log\log\log n
\end{align*}

Im zweiten Schritt gehen $\frac{n}{\log\log n}$~Elemente ein. Das Ergebnis
wird also in $O(\log\log\frac{n}{\log\log n})=O(\log\log n)$~\Time mit
$O(\frac{n}{\log\log n}\cdot\log\log\frac{n}{\log\log n})=O(n)$~\Work
bestimmt. Damit ist der Algorithmus optimal und alle sind glücklich.

\section{Aufbrechen von Symmetrien}

% Bild: greichteter Kreis

Einfärben der Knoten, so dass eine Kante nicht zwei Knoten gleicher
Farbe verbindet. Geht seriell in O(n) \Time

Basisalgortihmus.
INPUT: Array der n Knoten (Kreis), zulässige Farbung $c_{n}$
OUTPUT: c' neue Färbung, zulässig
begin
\begin{Verbatim}
for 1 $\leq$ i $\leq$ n pardo
setze k gleich der kleinsten singifikanten Position, wo sich c(i)
und c(s(i)) als Binärzahlen sich unterscheiden
c'(i) := 2k+c(i)
\end{Verbatim}
end

% 11.5.

Basisoperationen:
$i=i_{t-1}i_{t-2}\ldots i_{1}i_{0}$ $k$-t-kleinstes signifikantes Bit :=
$i_{k}$

% Bild: Kreis.gd

-- vierstellige: 0001
Vereinbarung: möglichst kurz

\begin{tabular}{{cccccccccccccccc}}
  0&1&2&3&4&5&6&7&8&9&10&11&12&13&14&15\\
  *&3& &7& & & &14&& &  &  &  &  &2 &\\
\end{tabular}

\begin{tabular}{cccc}
  v&Basisfärbung & k& c'\\
  1& 0001 & 1 & 2\\
  3& 0011 & 2 & 4\\
  7& 0111 & 0 & 1\\
  14& 1110& 2&5\\
  2&0010 & 0& 0\\
  15& 1111& 0&1\\
  4&0100&0&0\\
  5& 0101 & 0 & 1\\
  6& 0110 & 0&0
\end{tabular}

\begin{gather}
  c'(1) = 2k+c(1)=2+0=2\\
  c'(2) = 2 \cdot 0+0=0
\end{gather}

\begin{lemma}
  c zulässig $\rightarrow$ c' ist auch zulässig, T(n)=O(1), W(n)=O(n)

  \begin{proof}
    (indirekt) Ann.: c'(i)=c'(j) für einen Kante $(i,j)\in E$, d.\,h.
    j=S(i) $\Rightarrow c'(i) =2k+c(i)_{k} =c'(j)=2l+c(j)_{l}$ Wegen
    Faktor 2 und da $c(i)_{k}, c(j)_{l}\in\{0,1\} \Rightarrow k=l
    \Rightarrow c(i)_{k}=c(j)_{l}$ Widerspruch zur Wahl von $k$
    $\Rightarrow c'(i) \ne c'(j)$

    Die Aussagen zu \Time und \Work gelten offensichtlich.
  \end{proof}
\end{lemma}

Sei $t>3$. Dafür reichen für c' $\lceil\log t\rceil+1$ Binärplätze

$\Rightarrow c$ $q$ Farben hatte $\Rightarrow$ $2^{t-1}<q\leq2^{t}$, so
braucht c' $2^{\lceil\log t\rceil+1}=O(t)=O(\log g)$ Farben

$t>3 \Rightarrow \lceil\log t\rceil +1 < t$

Iterative Anwendung des Basisalgo. bis $t=3 (\lceil\log t\rceil+1=2+1=3)$

Farben: \{0,1,2,3,4,5\}=6
Eliminiere: 3;4;5 $\rightarrow$ 3 O(1)-Schritte parallel mit O(n) \Work

\begin{satz}
  Wir können einen Kreis mit n Knoten mit 3 Farben färben in
  $O(\log^{\ast} n)$ \Time mit $O(n \log^{\ast} n)$ \Work

  \begin{proof}
    Basisalgo. iterativ bis auf $t=3$ anwenden.
  \end{proof}
\end{satz}

\begin{bemerk}
  Dieser Algorithmus ist ohne Mühe auf der EREW implementierbar.
\end{bemerk}

\begin{bemerk}
  Algo nicht Optimal.
\end{bemerk}

Ziel: optimaler Algrotihmus in $O(\log n)$ Zeit.

\begin{satz}(o.Bew.)
  Man kann ganze Zahlen aus $[0,\log n]$ in $O(\log n)$ \Time mit $O(n)$
  \Work sorierten.
\end{satz}

Optimale Färbung:
INPUT: Di-Kreis mit n Knoten, S
OUTPUT: 3-Färbung
begin
\begin{Verbatim}
for i \le i \le n pardo C(i) := i
Wende den Basisalgo genau einmal an
Sortiere die Ecken nach Farbe
for i=3 to \lseil\log n\rseil do für alle Ecken der Farbe i
pardo Färbe v mit kleinster farbe aus \{0,1,2\}, die vom Vorgänger
und Nachfolger verschieden ist.
\end{Verbatim}
end.

\begin{satz}
  3-Färben geht in $O(\log n)$ \Time optimal.
\end{satz}

\chapter{Listen und Bäume}
\section{List-Ranking}
verkettete Liste $L$ , Nachfolgerarray $S$ $i\rightarrow S(i)$, $S(i)=0$
Ende der Liste bei Knoten $i$

List-Ranking-Problem: $\forall i$ bestimme den Abstand von $i$ zum Ende der
Liste. (Erinnerung: Pointerjumping: $O(\log n)$ \Time, \Work: $O(n\log n)$)

Idee: sequential subset
$\cdot\rightarrow\cdot\rightarrow\cdot\rightarrow\ldots\rightarrow\cdot$

Aufteilen des Arrays S in Abschnitte der Länge $\log n$.

Leider funktioniert die Idee nicht, da die Elemente in den Abschnitten
sich auf Elemente außerhalb des Abschnitts beziehen, was das spätere
mischen verkompliziert macht.

\section{optimales Listranking}
\begin{description}
 \item[Ergebnis:] Listranking geht in $O(\log n)$ \Time mit $O(n)$ \Work
 \item[Wir beweisen:] $O(\log n\log\log n)$ geht optimal
\end{description}

\subsection{Pointer Jumping}

$O(\log n)$ \Time, $O(n\log n)$ \Work

Unterteilung des Arrays in Blöcke der Größe $\log n$ funktioniert
nicht, da die Zeiger in den Blöcken auch außerhalb des Blocks zeigen
können -- Block nicht abgeschlossen.

Strategie trotzdem
\begin{enumerate}
 \item Reduziere die Startliste von $n$ auf $\frac{n}{\log n}$ Knoten.
 \item Pointer Jumping auf red. Liste anwenden
 \item Stelle die Ausgangsliste wieder her.
\end{enumerate}

Aufgabe für Listranking: INPUT Liste, OUTPUT für jeden Knoten den
Abstand zum Ende.

Algo. Pointer Jumping
\begin{tabular}{cccccccccc}
  $i$&1&2&3&4&5&6&7&8&9\\
  $S(i)$&2&6 &1&5&7&8&3&9&0
\end{tabular}
% Bild der Liste: Einfacher Strang


\begin{algorithm}
\KwIn{Nachfolgerarray S}
\KwOut{$\forall i: R(i)\ldots$ Abstand zum Ende}
\dontprintsemicolon
\caption{Algorithmus: List-Ranking}
  \Forpar {i := 1 \KwTo n}{
     if $S(i) \ne 0$ then $R(i) := 1$ \;
     else $R(i) := 0$ ;
  }
  \Forpar {$i:=1 \KwTo n$}{
    $Q(i) := S(i)$ \;
    \While{$Q(i) \ne 0 and Q(Q(i)) \ne 0$}{
      $R(i) := R(i) + R(Q(i))$ ;
      $Q(i) := Q(Q(i))$ ;
    }
  }
\end{algorithm}


\begin{defini}
  Eine Teilmenge $I$ aller Knoten heiße unabhängig, wenn für alle $i$:
  $[i\in I\rightarrow S(i)\notin I]$
\end{defini}

begin
\begin{algorithm}
\KwIn{Nachfolgerarray S, Vorgängerarray P, Teilliste I, $\forall i: R(i)$}
\KwOut{Gesamtliste ohne I (independent set)}
\caption{Algorithmus: Entferne I}
\dontprintsemicolon
  Bestimme Seriennummern $N(i) \forall i \in I$: %
  $1 \leq N(i) \leq |I| =: n'$ geht in $O(\log n)$ \Time optimal %
  mit Hilfe des Präfixsummen-Algo über den Array \;
  \Forpar {$i \in I$}{
    $U(N(i)) := (i, S(i), R(i))$ -- Info, die sonst verlohren geht! \;
    $R(P(i) (Vorgänger) ) := R(P(i)) + R(i)$ \;
    $S(P(i)) := S(i)$ \;
    $P(S(i)) := P(i)$ \;
  }
\end{algorithm}
end.

\begin{bsp}
  $I = \{1,5,6\}$, $i=6$: $U(N(6)) = U(3) = (6,8,2)$
  R(2)=4, S(2)=8, P(8)=2
  Da U(3)=(6,8,2) $\rightarrow$ 8 war Nachfolger von 6 $\rightarrow$ $R(6) = R(8)+2 = 3$
  Ausserdem kann jetzt 6 wieder eingefügt werden
\end{bsp}

\begin{description}
 \item[Ziel:] große unabhängige Menge; k-Färbung der Knoten
\end{description}

Die Knoten seien k-gefärbt: Farben \{0,\ldots,k-1\}
Knoten heißt lokales Minimum $\Leftrightarrow$ Farbe(i) =
$\min\{\text{Farbe}(i), \text{Farbe(Vorgänger}(i)), \text{Farbe(Nachfolger}(i))\}$

\begin{lemma}
  Bei gegebener k-Färbung in einer Liste $L^{n}$ ist die Mende der
  lokalen Minima unabh. Menge von size $\Omega(\frac{n}{k})$ (Finde sie
  in O(1) \Time, O(n) \Work)

  \begin{proof}
    u,v lok. Minima, benachbert in dieser Eigenschaft
    max. Anzahl von Knoten zwischen zwei Minima u und v
    = 2k-2-1=2k-3 $\Rightarrow$ $\Omega(\frac{n}{k})$

    Bsp.: k=3: 2k-3=3

  \end{proof}
\end{lemma}

$\frac15$ Elemente kommen raus (es bleiben $\frac45$ Rest)  Wir
reduzieren von n Elementen auf höchstens $\frac45n$ Elemente

\subsection{Optimales Listranking}

Um es ein wenig vorweg zu nehmen: der folgende Algorithmus benötigt
zwar wie Pointer Jumping ebenfalls $O(\log n)$ \Time, jedoch nur
$O(n)$ \Work.

\begin{algorithm}
\KwIn{$S^{n}$}
\KwOut{$\forall$ Knoten Abstand zur Wurzel}
\caption{Algorithmus: Allgemeines einfaches optimales Listranking}
\dontprintsemicolon
  $n_{0} := n$ \;
  $k := 0$ \;
  \While{$n_{k}>\frac{n}{\log n}$}{
    $k := k+1$ \;
    Färbe Liste mit 3 Farben, Bestimme I (lok. Minima) \;
    Entferne die Knoten aus I (wie gehabt) \;
    $n_{k}$ sei die Zahl der Restknoten, die wir in %
    aufeinanderfolgende Speicherplätze komprimieren \;
  }
  Pointer Jumping auf weißen Rest - optimal in $O(\log n)$ \Time \;
  Nutze die Informationen in den Arrays U, um die Gesamtausgabe zu erhalten ;
\end{algorithm}

Analyse
$n_{k}\leq\big(\frac{4}{5}\big)^{k}\cdot n\leq\frac{n}{\log n} \Rightarrow
\big(\frac45\big)^{k}\leq\frac1{\log n} ((\frac45)^{\log\log
n}=O(\log n)) k=O(\log\log n)$ reicht

while-schleife $O(\log\log n)$ mal.
$\Rightarrow$ \Time: $O(\log n\log\log n)$, \Work: $O(n)$

\Work des Algorithmus.: $n_{k}$ Elemente bleiben nach Iteration $k$,
damit
\begin{gather}
  \Work=O(\sum_{k}n_{k})= O(\sum_{k}\left(\frac45\right)^{k}\cdot n) = O(n)
\end{gather}

\help{Kann das jemand entschlüsseln?}
\begin{tabular}{l*8c}
  I & 6 & \color{red}{4} & 1 & \color{red}{3} & 7 & \color{red}{2} & 8
     & \color{red}{5}\\
  3-Färbung & (1) & (0) & (2) & (0) & (2) & (1) & (2) & (0)\\
  R: [1] & [1] & [1] & [1] & [1] & [1] & [1] & [0]\\
  && U(1,N(4)) = (4,1,1)\\
  \hline
  \multicolumn{9}{l}{Nach dem Löschen der Elemente}\\
  & 6 && \color{red}{1} & & 7 && \color{red}{8}\\
  R: & [2] && [2] && [2] && [1]\\
  3-Farben & (2) && (1) && (2) && (0)\\
  &&& U(2,N(1))=(1,7,2) &&& U(2,N(8)) = (8,0,1)\\
  \hline
  & 6 &&&& 7\\
  & [4] &&&& [3]\\
  $\frac8{\log 8}=\frac83> 2 \rightarrow$ Abbruch\\
  \hline
  einfügen der Knoten in umgekehrter Reichenfolge ihres Entnehmens und
     dabei ergibt sich die Entfernung aus dem im U gespeicherten + der
     Entferung des Nachfolgers vom Ende\\
  $R_{\text{Ende}}$& [7]
\end{tabular}

\begin{bemerk}
  Analog dazu ist:
  Wende Parallel-Prefix auf die umkehrte Liste (Nachfolger = Vorgänger)
  an, um die Entfernung zum Ende zu berechnen.
\end{bemerk}

\begin{bemerk}
  Listranking geht auch in $O(\log n)$, Zeit optimal (Lit.: Ja Ja)
\end{bemerk}

\section{Eulertour-Technik}

\begin{defini}
  Sei $G=(V,E)$ ein gerichteter Graph. $G$ ist genau dann ein
  \highl[Kreis!gerichteter]{gerichteter Kreis}, wenn für jeden Knoten~$v\in V$
  es genau zwei Kanten $(u,v)\in E$ und $(v,w)\in E$ gibt, wobei $u\ne v$ und
  $w\ne v$. Der Knoten~$u$ heißt \highl{Vorgänger} von $v$ und der Knoten~$w$
  heißt \highl{Nachfolger}.
\end{defini}

$\Rightarrow$ Kreise sind immer zusammenhängende Graphen.

\begin{defini}
  Ein (ungerichteter) Graph~$G=(V,E)$ heißt genau dann \highl{Eulergraph}, wenn es
  einen gerichteten Kreis~$\tilde{G}$ gibt, der jede Kante von $G$ genau
  einmal durchläuft. $\tilde{G}$ heißt \highl{Eulerkreis}.
  \help{Ist dann $\tilde{G}$ isomorph zu $G$?}
\end{defini}

Ein ungerichteter Baum~$T=(V,E)$ kann leicht in einen gerichteten
Baum~$T'=(V,E')$ überführt werden, indem man jede Kante~$e=(u,v)\in E$ durch
zwei gerichtete Kanten~$\{<u,v>,<v,u>\}\subset E'$ ersetzt.

\begin{satz}
  Ein zusammenhängender gerichteter Graph~$G=(V,E)$ ist genau dann ein
  Eulergraph, wenn für alle Knoten~$v\in V: Indegree(v)=Outdegree(v)$ gilt.
\end{satz}

ungerichteter Graph gegeben als Menge von Adjazenzlisten, $<v,L[v]>\in
V\times\mathfrak{P}(V)$, wobei $L[v]$ die Nachbarn von $v$ sind.

\todo{Grafik vom Eulergraph einfügen}

z.\,B. $L[1]=<2,3,4>$

Eulerkreis wird als Menge von Kanten dargestellt.

Beispiel für Eulerkreis:
\begin{gather*}
  <1,2>\rightarrow<2,5>\rightarrow<5,2>\rightarrow<2,6>\rightarrow<6,2>
     \rightarrow<2,7>\ldots<3,1>\rightarrow<1,4>\rightarrow<4,1>
\end{gather*}

Ziel: parallele Berechnung des Eulerkreises mit $S(<u,v>)=<v,w>$ (Nachfolger
einer Kante)

Die Nachbarn~$L[v]$ von $v\in V$ seien durchnummeriert:
$L[v]=<u_{0},\ldots,u_{d-1}>$. Ein Knoten~$v$ hat genau dann den Grad~$d$,
wenn er $d$~Nachbarn hat: $\abs{L[v]}=d$.

\begin{satz}
  Die Funktion $S\colon E'\rightarrow E'$ beschreibt einen Eulerkreis in
  $T'=(V,E')$
  \begin{gather}
    S(<u_{i},v>) := <v,u_{(i+1)\bmod d}>
  \end{gather}
\end{satz}

\begin{bsp}
  Setzen das Gewicht einer Kante vom Vater zum Sohn $
  w(<p(v),v>) := +1$ und vom Sohn zum Vater $
  w(<v,p(v)>) := -1$

  Damit lässt sich das Level eines jeden Knoten bei Wahl eines Knotens
  als Root in $O(\log n)$ \Time mit $O(n)$ \Work berechnen. (Vor.: Rooting
  geht in diesen Grenzen und Eulertour geht so)
\end{bsp}

\begin{bsp}
  ROOTING: Eulertour-Technik, alle Kanten erhalten Gewicht 1 + Parallel
  Prefix

  Der Vorgänger eines Knoten hat ein kleineres Gewicht
\end{bsp}

\begin{bsp}
  POST-Order, PRE-Order w(<v,p(v)>)=1, w(<p(v),v>)=0

  Ergebnis: O(1) \Time mit O(n) \Work kann eine Eulertour berechnet werden
\end{bsp}

äquvalent: Angabe der Nachfolgerfunktion s:
$s(e)= e' (e,e'\in E') T=(V,E), T'=(V,E')$

Vor.:
% Bild: Stern; Mittelpunktknoten mit Sternf"ormig davonlaufenden S"ohnen;
% gegen den Urzeigersinn nummerieren $u_{i}$

adj(v) = <$u_{0}$, \ldots, $u_{d-1}$> Liste aller Pfade, die von v zu
$u_{i}$ führen.

adj als Ringliste implementieren.

Ringlisten für Standardgraph:
\begin{tabular}{*8l}
  1 &\\
  2 & (1,) (5,) (6,) (7,Zeiger auf (2,) in Liste 7)\\
  7 & (2,) (8,) (9,)\\
  8 & (7,)
\end{tabular}

Beipiel: wähle $u_{i}=7$, v=2; bestimme den Index j: L[v] =
<$u_{1},\ldots,u_{j},\ldots>$

Damit lässt sich der Nachfolger in O(1) berechnen.

\section{Baumkontraktion}

Was ist eine Harke (engl. Rake)? Entfernen des Vaters und eines Sohnes,
der andere Sohn wird mit dem Großvater verbunden.

\begin{description}
  \item[Ziel:] Schnelle parallele Auswertung arithm. Ausdrücke (+,$\cdot$)
\end{description}
% Bild: arithm. Baum

Ausgehend von einem Binärbaum sollen nur noch 3 Knoten übrig bleiben, d.h. der
Restbaum wird entfernt und die Auswertung des Baumes kann auf den 3 Restknoten
(Vater, linker und rechter Sohn) erfolgen, was in einem Schritt geht. Es ergibt
sich also das Problem, dass die Informationen der entfernten Knoten im Restbaum
gespeichert werden müssen, damit die arithmetische Auswertung kein falsches
Ergebnis liefert. 

Von unten nach oben führt in zweitem Fall zu O(n), was keine
Verbesserung gegenüber dem Seriellen darstellt.

\begin{algorithm}
\KwIn{Binärbaum T, jeder innere Knoten hat genau 2 Söhne und 
   für alle Knoten v: parent(v) und brother(v)}
\KwOut{Reduktion auf Wurzel und linkestes und rechtestes Blatt}
\dontprintsemicolon
\caption{Algorithmus: Baumkontraktion}
  markiere alle Blätter von A (Array der Blätter) (ohne linkestes %
   und rechtestes) wachsend von links nach rechts; über parallel %
   Prefix mit gewicht w(v) = 0 wenn v innerer Knoten, w(v)=1 wenn %
   v Blatt \;
  \For{$\ceil{\log (n+1)}$}{
    RAKE auf $A_{odd} = \{v_{i}: i odd\}$, die linke Söhne sind \;
    RAKE auf Rest von $A_{odd}$ \;
    $A := A_{even}$ ;
  }
\label{alg:tree_contr}
\end{algorithm}

% Hier fehlt was! -> Beispielgrafik

\begin{satz}
  Die Kontraktion funktioniert auf einer EREW-PRAM in 
  $O(\log n)$ \Time und $O(n)$ \Work.

  \begin{proof}
    \begin{itemize}
      \item Es gibt m Blätter $\rightarrow$ nach einer Iteration $\floor{\frac{m}{2}}$ Blätter $\rightarrow$
            nach $\ceil{\log (n+1)}$ Iterationen fertig.

      \item Zeile 1 mit Eulertour in $O(\log n)$ \Time
      \item Zeilen 3 und 4 mit Eulertour in $O(1)$ \Time und $O(n)$ \Work
      \item Zeile 5 in $O(1)$ \Time

      \item Anzahl der Operationen: $O(|A|)$, $A_{even} \leq \frac{|A|}{2}$, $O(\sum_{i} \frac{n}{2^{i}})=O(n)$
    \end{itemize}
  \end{proof}
\end{satz}

\help{RAKE-Beispiel aus Vorlesung (21.5.07) einfügen}

\begin{satz}
  Bei gegebenem Binärbaum, der Konstanten in den Blättern hält und '+' und '*' in den inneren Knoten,
  kann die Auswertung in $O(\log n)$ \Time und $O(n)$ \Work erfolgen.
  Denn: Ummarkierung bei RAKE in $O(1)$ \Time; Baumkontraktion erfüllt diese Schranken
\end{satz}

\begin{bemerk}
  Gegeben sei ein Wurzelbaum T, der in den Knoten Zahlen enthält. Dann kann das Maximum / Minimum (oder
  jede andere angewendete binäre Operation) in $O(\log n)$ \Time optimal gewonnen werden.
  \begin{proof}
    Umformung in Binärbaum und Baumkontraktion mit Markierung
  \end{proof}
\end{bemerk}

% Grafik: "`B"' Kreise mit Zahlen: 8 3 4 5 2 11 15 17 n=$2^{l}$

% -- eingefügt aus Vorlesung am 21.5.07

\section{Das LCA-Problem}

LCA steht für "lowest common ancestor" (jüngster gemeinsame Vorfahre) und bezieht
sich auf den tiefsten Knoten in einem Binärbaum, der Vater der Teilbäume ist, 
in denen die Knoten u und v vorkommen.
Das Problem ist ein Preprocessing-Problem, welches den Baum so vorbereitet, dass 
die Anfrage LCA(u, v) möglichst schnell beantworten werden kann (man besteht auf $O(1)$ \Time).

INPUT: Wurzelbaum T
OUTPUT: Baum, für den einzelne LCA-Anfragen schnell beantwortet werden können

Man unterscheidet 2 Fälle, für die LCA-Anfragen trivial sind:
\begin{enumerate}
 \item T ist ein einfacher Pfad
 \item T ist ein vollständiger Binärbaum
\end{enumerate}

\begin{description}
 \item[Achtung:] Der Algorithmus im Ja'Ja ist falsch! In der Praxis ist dieser Umstand lange 
   nicht aufgefallen, da der Algorithmus wohl nur für den Spezialfall angewendet wird, für den er 
   zufälligerweise richtig ist. Bisher gab es wohl keine Neuauflage des Ja'Ja und es ist nicht 
   bekannt, ob der Fehler an den Autor bzw. den Verleger weitergereicht worden ist. Der Ansatz 
   ist aber wohl brauchbar.
 \item[Algorithmus von Ja'Ja:] Der Algorithmus hat als INPUT zwei Knoten u und v, die entsprechend
   ihrer INORDER-Nummer innerhalb des Baums bezeichnet sind. Laut Ja'Ja wird der $LCA(u,v)$ so
   ermittelt, dass die Knotennummern (binär) von links nach rechts durchlaufen werden und an der
   ersten sich unterscheidenden Stelle wird eine '1' gesetzt, der Rest ist '0'.
 \item[Gegenbeispiel:] Man nehme zwei Knoten, deren Nummerierung $code(u)=1100$ und
   $code(v)=1101$ ist. Da die Nummerierung wie erwähnt in INORDER erfolgt, ist $1100$ der Vater
   von $1101$, jedoch würde der Ja'Ja-Algorithmus die letzte Stelle als die erste sich unterscheidende
   Stelle erkennen, diese 1 setzen und den Wert $'1101'$ ausgeben; das ist falsch. Die Lösung des
   Problems erfolgt mittels des Algorithmus von Spillner.
\end{description}

% Algorithmus von Spillner 

\begin{algorithm}
\KwIn{$u,v$}
\KwOut{$LCA(u,v)$}
\caption{Algorithmus von Spillner}
\dontprintsemicolon
  Berechne $k_{u}$, $k_{v}$: letzte '1' von links \;
  \While {Durchlaufe die Ziffern von u, v von links nach rechts} {
    Falls $k_{u}$ oder $k_{v}$ noch nicht erreicht, aber Ja'Ja hat Ergebnis, dann OUTPUT Ja'Ja \;
    Falls vor $k_{u}$ erreicht, dann OUTPUT bis $k_{u}$, Rest '0'en \;
    analog $k_{v}$ \;
  }
\end{algorithm}

Vereinbarung: Sei v ein Knoten und l(v) das linkeste Vorkommen im Level- bzw. Eulerarray. Analog
r(v) als rechtestes Vorkommen.

\begin{lemma}
  Sei T=(V,E) ein Wurzelbaum \
  Eulerarray A, Levelarray B, r(v) und l(v) seien definiert \
  seien u und v zwei verschiedene Knoten \
  Dann gilt:

  \begin{enumerate}
    \item u ist Vorfahre von v $\Leftrightarrow$ l(u) < l(v) < r(u)
    \item u,v sind nicht direkt verwandt $\Leftrightarrow$ r(u) < l(v) oder r(v) < l(u)
    \item falls r(u)<l(v), so ist LCA (u,v) der Knoten im Eulerarray mit minimalen Level
          im Intervall [r(u), l(v)] im Levelarray
  \end{enumerate}
\end{lemma}

\begin{proof}
   (1) $\rightarrow$ Eulertour entspricht Tiefensuche, Beginn ist Wurzel. \
     Es folgt: u wird vor v besucht; ausserdem wird der ganze Teilbaum 
     mit Wurzel v komplett durchsucht, bevor u ein letztes Mal besucht wird. \
     $\leftarrow$ Annahme: u sein kein Vorfahre von v. Da l(u) < l(v), wird der 
     Teilbaum mit Wurzel u komplett durchsucht, bevor v durchsucht wird $\rightarrow$ 
     auch r(u) < l(u) $\rightarrow$ Widerspruch zu Voraussetzung! \
   (2,3) Ähnlich.
\end{proof}

\begin{folger}
  Ist Levelarray B bekannt und können wir das Range-Minima-Problem lösen, haben wir die LCA-Bestimmung
  gelöst!
\end{folger}

\section{Das Range-Minima-Problem}
 
Wir beginnen mit der Bestimmung der Eulertour von T (setzen voraus, dass der 
Baum in einer wohl-verarbeitbaren Form vorliegt) und erhalten sowohl das 
Eulerarray A als auch das Levelarray B.

Zusätzlich kennen wir für jeden Knoten v l(v) und r(v) (linkestes und rechtestes 
Vorkommen von v im Eulerarray).

Zur Bestimmung des Range-Minimas reicht es nicht, die Minima der Blätter der
Teilbäume in den Knoten zu speichern!

\begin{defini}
  Die Präfixminima eines Arrays $(c_{1}, \ldots, c_{m})$ sind die Werte
  $(e_{1}, \ldots, e_{m})$ mit $e_{i} = min\{ c_{1}, \ldots, c_{i} \}$
\end{defini}

Idee: Speichere in jedem Knoten die Suffix- und Präfixminima

- Sei $v=LCA(b_{i},b_{j})$

- Allgemein: Teilbaum mit Knoten v enthält Blätter 
\{$b_{r},\ldots,b_{i},\ldots,b_{j},\ldots,b_{s}\}$

- Teilung der Folge in linken und rechten Teil:
\{$b_{r},\ldots,b_{i},\ldots,b_{p}\},\{b_{p+1},\ldots,b_{j},\ldots,b_{s}\}$

Suchen: Minimum(Minumum(\{$b_{i},\ldots,b_{p}\})$,
Minimum(\{$b_{p+1},\ldots,b_{j}\}))$

Vorteil dieses Mal: Die Minuma liegen am Rand. Min($b_{i},\ldots,b_{p})$
ist ein Suffix-Minimum, Min($b_{p+1},\ldots,b_{j})$ ist ein Prefix-Minimum

\begin{algorithm}
\dontprintsemicolon
  \caption{Rang-Min}
  \KwIn{$B^{n}, n=2^{l}$}
  \KwOut{vollständiger Binärbaum mit den Arrays P,S}
\Forpar {j:=1 \KwTo n} {
   P(0,j) := B(j)\;
   S(0,j) := B(j)\;
}
\For {h:=1 \KwTo log(n)} {
  \Forpar {j:=1 \KwTo n/$2^{h}$} {
  \tcc{h ist das Level von den Blättern an (h=0)}
  Merge(P(h-1,2j-1) mit P(h-1,2j) zu P(h,j)\;
  Merge S analog
  }
}
\end{algorithm}

Entscheidend: wie funktioniert das mischen $\ldots$

Analyse: \Time: $O(\log n)$
\Work: $O(n\log n)$ ($O(n)$ pro Stufe)

\begin{satz}\label{satz:1}
  Das Preprocessing für Rang-Minima-Problem ist $O(\log n)$ \Time mit
  $O(n\log n)$ \Work.
\end{satz}

\begin{bemerk}
  Im Seriellen gilt: optimal in O(n) Zeit sind LCA und Range-Minima
  lösbar. (im Sinne der Einzelanfrage in $O(1)$ \Time)
\end{bemerk}

\begin{folger}
  \autoref{satz:1} ist nicht optimal.
\end{folger}

Im Parallelen gilt: LCA geht in $O(\log n)$ \Time optimal
Range-Minima geht in $O(\log\log n)$ \Time optimal

Aufgabe: Range-Minima \emph{optimal} in $O(\log n)$ \Time

Standardtechnik:
\begin{enumerate}
 \item Zerlege B in Blöcke gleicher Länge $\log n$
 \item Preprocessing mit seriellem Algorithmus parallel für alle Blöcke
 \item berechne für jeden Block das Minimum $x_{i}
  (i=1,\ldots,\frac{n}{\log n})$ und die Prefix- und
  Suffix-Minima innerhalb der Blöcke
 \item wende den Algorithmus Range-Minima auf Array
  B'=($x_{1},\ldots,x_{\frac{n}{\log n}})$
\end{enumerate}

Analyse:
\begin{enumerate}
 \item $O(\log n)$ \Time, $O(n)$ \Work
 \item $O(\log n)$ \Time, $O(n)$ \Work
 \item $O(\log n)$ \Time, $O(n)$ \Work
 \item $O(\log n)$ \Time, $O(\frac{n}{\log n} \log n)=O(n)$ \Work
\end{enumerate}

Algo:

MIN($b_{i},\ldots,b_{j}) = MIN(Suffixmin_{B_{s-1}}(b_{i}),
min(x_{s},\ldots,x_{t}), Präfixmin_{B_{t+1}}(b_{j})$

Ergebnis: Satz * geht auch mit O(n) \Work.

\begin{folger}
  Die analogen Schranken gelten für LCA.
\end{folger}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Suchen, Mischen, Sortieren} % Kapitel 4
\section{Suchen in einer sortierten Menge nach Kruskal}

\begin{figure}
  \centering
  \input{figures/kruskal-suche.pdf_t}
  \caption{parallele Suche nach Kruskal in $n=124$~Elementen mit
    $p=4$~Prozessoren}
  \label{fig:krsukal-suche}
\end{figure}

\begin{lemma}
  \label{lem:1}
  Mit $k$~Schritten lässt sich ein Element in einem sortierten Feld mit
  $n$~Elementen finden, wenn $n=(p+1)^{k}-1$ ist und $p$~Prozessoren
  eingesetzt werden. \autoref{fig:krsukal-suche}

  \begin{proof}
    Der Beweis erfolgt induktiv.
    \begin{description}
     \item[$k=1$:] Dann ist $n=(p+1)^{1}-1=p$. Ein Feld von $n$~Elementen mit
      $p=n$~Prozessoren zu durchsuchen geht in einem Schritt.

     \item[$k-1\rightarrow k$:] Verteilt man die $p$~Prozessoren gleichmäßig
      auf die $n$~Elemente, so dass sich $p+1$~Abschnitte der
      Länge~$\frac{n+1}{p+1}$\footnote{Ergebnis der Kombinatorik} ergeben, und
      ordnet dem $j$.\,Prozessor ($j=1,\dotsc,p$) den $j$.\,Abschnitt zu, kann
      jeder Prozessor das letzte Element~$j\frac{n+1}{p+1}$ in seinem
      Abschnitt untersuchen.
      \begin{enumerate}[1.\,{Fall:}]
       \item Das Element ist das gesuchte $\rightarrow$ fertig.
       \item Wenn das Element nicht gefunden wird, hat man aber einen
	Abschnitt bestimmt, in dem sich das Element befinden muss. Da in dem
        Abschnitt bereits ein Element untersucht wurde, verbleiben noch
        $\frac{n+1}{p+1}-1$~Elemente.
        \begin{gather*}
          \frac{n+1}{p+1}-1 = \frac{(p+1)^{k}-1 +1 -p-1}{p+1}
             = (p+1)^{k-1} -1
        \end{gather*}

        In diesem Abschnitt lässt sich nach Induktionsvorraussetzung in
        $k-1$~Schritten das Element finden. Also lässt sich das Feld in
        $1+(k-1)=k$~Schritten durchsuchen.
      \end{enumerate}
    \end{description}
  \end{proof}
\end{lemma}

\begin{satz}[Satz von Kruskal (1984)]
  \label{satz:kruskal}
  Um eine Folge von $n$~Elementen mit $p$~Prozessoren zu durchsuchen, sind
  $T_{p}(n)$~Schritte notwendig und hinreichend.
  \begin{gather*}
    T_{p}(n) = \Theta\bigg(\frac{\log(n+1)}{\log(p+1)}\bigg)
  \end{gather*}

  \begin{proof}
    \begin{description}
     \item[hinreichend:] Nach \autoref{lem:1} kann man bei einer geschickten
      Platzierung der Prozessoren ein Feld von $(p+1)^{k}-1$ Elementen mit
      $k$~Schritten durchsuchen. Für die Zeit~$T_{p}(n)$ (Anzahl der
      Schritte~$k$) gilt also $T_{p}(n) =
      O\bigl(\frac{\log(n+1)}{\log(p+1)}\bigr)$.
      \begin{align*}
        n &\leq (p+1)^{k}-1 &
        % \Leftrightarrow& n+1 &&\leq (p+1)^{k}\\
        &\Leftrightarrow& \log(n+1) &\leq k\log(p+1)\\
        &&&\Leftrightarrow& \frac{\log(n+1)}{\log(p+1)} &\leq k\\
        &&&\Leftrightarrow& k &=\ceil[\bigg]{\frac{\log(n+1)}{\log(p+1)}}
      \end{align*}

     \item[notwendig:] Wenn man die Prozessoren beliebig positioniert, bleibt
      nach dem ersten Suchschritt mindestens ein Abschnitt mit mehr als
      $\frac{n+1}{p+1}-1$ nicht untersuchten Elementen übrig. Positioniert man
      in diesem die Elemente wieder beliebig, so bleicht mindestens ein
      Abschnitt, der größer ist als
      \begin{gather*}
        \frac{\overbrace{\frac{n+1}{p+1}-1}^{\text{Elem. aus 1.\,Schritt}}+1}%
             {\underbrace{p+1}_{\text{Anz. der Abschnitte}}} - 1
           = \frac{n+1}{(p+1)^{2}}-1
      \end{gather*}

      Induktiv kann man also zeigen, dass nach $k$~Schritten mehr als
      $\frac{n+1}{(p+1)^{k}}-1$~Elemente nicht untersucht wurden. Damit keine
      nicht untersuchten Elemente mehr verbleiben, das Feld also komplett
      durchsucht ist, sind mindestens $\frac{\log(n+1)}{\log(p+1)}$~Schritte
      notwendig. Die Laufzeit ist also
      $T_{p}(n) = \Omega\bigl(\frac{\log(n+1)}{\log(p+1)}\bigr)$
      \begin{align*}
        \frac{n+1}{(p+1)^{k}} - 1 &\leq 0
           &&\Leftrightarrow& n+1 &\leq (p+1)^{k}
        &&\Leftrightarrow& \frac{\log(n+1)}{\log(p+1)} &\leq k
      \end{align*}
    \end{description}
  \end{proof}
\end{satz}

\begin{algorithm}
  \dontprintsemicolon
  \caption{Parallele Suche in einer sortierten Folge nach \highl{Kruskal}}
  \KwIn{Ein aufsteigend sortiertes Feld $A$ von $n$~Zahlen und ein gesuchtes
    Element~$x$}
  \KwOut{Index~$i$, so dass $A[i]\leq x<A[i+1]$}
  $beg := 1$\;
  $end := n$\;
  \For{$k := 1$ \KwTo log(n)}{
    \Forpar{$j := 1$ \KwTo p}{
      $len := ende - beg +1$
      $pos := beg + j\cdot\frac{len+1}{p+1}$\;
      \uIf{$A[pos] < x$}{
        \If{$j=p$}{$beg := pos + 1$\;}
      }
      \uElseIf{$x < A[pos]$}{
        \uIf{$j=1$}{$end := pos -1$\;}
        \Else{$A[beg + (j-1) \frac{len+1}{p+1}] < x$}{
          $beg := (j-1) \frac{len+1}{p+1} + 1$\;
          $end := pos - 1$\;
        }
      }
      \Else(\tcc*[f]{$A[pos] =x$}){\KwRet{$j$}\;}
    }
  }
\end{algorithm}

\section{Mischen}
\label{sec:mischen}

\todo{In diesem Abschnitt fehlen sehr viele Bilder, die das Vorgehen
  wesentlich anschaulicher machen würden. Einarbeiten.}

Das Thema Mischen war bereits Gegenstand des Abschnitts über Partitioning
(\autoref{sec:partitioning}). Dabei wurden für die Operation $Rang(x:A)$ die
serielle, binäre Suche eingesetzt. Mit der neuen Idee von Kruskal für die
parallele Suche lässt sie das Mischen optimal in $O(\log\log n)$~\Time (statt
$O(\log n)$~\Time mit binärer Suche) lösen.

\begin{satz}
  Für die Bestimmung des Rangs~$Rang(X:Y)$ einer Folge~$X$ mit $m$~Gliedern
  bezüglich einer größeren, sortierten Folge~$Y$ mit $n$~Gliedern ($n> m =
  \Theta(n^{s})$ für $0<s<1$) benötigt man $O(1)$~\Time und $O(n)$~\Work.

  \begin{proof}
    Für ein Element aus $X$ kann der Kruskel-Algorithmus mit
    $p=\floor[\big]{\frac{n}{m}}$~Prozessoren durchgeführt.
    Dies geht in $O(1)$~\Time.
    \begin{gather*}
      \frac{\log(n+1)}{\log(p+1)}
         = \frac{\log(n+1)}{\log(\floor{\frac{n}{m}}+1)}
         = \frac{\log(n+1)}{\log(\floor{n\cdot n^{-s}}+1)}
         \leq \frac{\log(n+1)}{\log(n^{1-s})}
         = \frac{1}{1-s} \cdot \frac{\log(n+1)}{\log n}
    \end{gather*}

    Verwendet man $n = m\cdot\frac{n}{m}$~Prozessoren, kann man für die
    $m$~Elemente von $X$ in $m\cdot O(1)=O(1)$~\Time mit $W(n) = m\cdot
    O\bigl(\frac{n}{m}\bigr) = O(n)$~\Work den Rang bezüglich $Y$ bestimmen.
  \end{proof}
\end{satz}

\begin{algorithm}
  \dontprintsemicolon
  \caption{Rangbestimmung einer Folge bezüglich einer wesentlich größere Folge}
  \label{alg:rang}
  \KwIn{$A^{n}$ und $B^{m}$, wobei $\sqrt{m}$ ganzzahlig}
  \KwOut{$Rang(B:A)$}
  \If(\tcc*[f]{$B$ zu kurz}){$m<4$}{trivial mit Kruskal, da $p=n$\nllabel{line:step1}\;
    \KwRet{}\;
  }
  $J[\sqrt{m}+1] := 0$\;
  \Forpar{$i := 1$ \KwTo $\sqrt{m}$}{
    $J[i] := Rang(B[i\cdot\sqrt{m}]:A)$ mit $\sqrt{n}$ Prozessoren
      \nllabel{line:step2}\;
    $B_{i} := B[i\cdot\sqrt{m} +1,\dotsc,(i+1)\cdot\sqrt{m}-1]$\;
    $A_{i} := A[J[i]+1,\dotsc,J[i+1]]$\;
    \uIf{$J[i] = J[i+1]$}{$Rang(B_{i}:A_{i})=(0,0,\ldots)$\;}
    \Else{
      berechne mit diesem Algorithmus $R=Rang(B_{i}:A_{i})$ rekursiv
        \nllabel{line:step3}\;
      \KwRet{$\forall k\colon i\cdot\sqrt{m} < k < (i+1)\cdot\sqrt{m}$ ist
        $Rang(B[k]:A) := J[i] + R[k-i\cdot\sqrt{m}+1]$}\;
    }
  }
\end{algorithm}

\begin{satz}
  \label{satz:3}
  Für zwei sortierte Folgen~$A$ mit $n$~Gliedern und $B$ mit $m$~Gliedern,
  wobei $m\leq n$ ist, geht $Rang(B:A)$ in $O(\log\log m)$~\Time mit
  $O((n+m)\log\log m)$~\Work.

  \begin{proof}
    Die (worst case) Laufzeit für den gesamten Algorithmus sei $T(n,m)$.

    Der erste Schritt (\autoref{line:step1} in \autoref{alg:rang}) geht in
    $O(1)$~\Time mit $O(n)$~\Work, also ist $T(n, 3) = O(1)$.

    Der zweite Schritt (\autoref{line:step2} in \autoref{alg:rang}) zur Bestimmung von
    $Rang(B[i\cdot\sqrt{m}]:A)$ verwendet $\sqrt{n}$~Prozessoren und benötigt
    nach \autoref{satz:kruskal} $O\bigl(\frac{\log(n+1)}{\log(p+1)}\bigr) =
    O(1)$~\Time und $O(\sqrt{m}\cdot\sqrt{n}) = O(n+m)$~\Work.
    \begin{gather*}
      \frac{\log(p\cdot p+1)}{\log(p+1)}
         \leq \frac{\log(p\cdot(p+1))}{\log(p+1)}
         \leq \frac{\log(p+1) + \log(p+1)}{\log(p+1)}\\
      \sqrt{m}\cdot\sqrt{n} \leq \bigl(\sqrt{\max\{n,m\}}\bigr)^{2}
         \leq \max\{n,m\} + \min\{n,m\} = n+m
    \end{gather*}

    Der zweite Schritt zerlegt $A$ in Teile~$A_{i}$ ($i=1,\dotsc,\sqrt{m}$)
    der Länge $n_{i} := \abs{A_{i}}$. In diese Teile können unabhängig
    voneinander jeweils die entsprechenden Teile von $B$ einsortiert werden,
    da die Elemente aus einem $B_{i}$ nicht in einem $A_{k}$ ($k\ne i$) liegen
    können --~die Pfeile überschneiden sich nicht.

    Die Zeit für den dritten Schritt $Rang(B_{i}:A_{i})$ (\autoref{line:step3}
    in \autoref{alg:rang}) ist $T(n_{i},\sqrt{m})$~\Time, da diese alle
    parallel ausgeführt werden, ist
    \begin{gather*}
      T(n,m) \leq  O(1) + \max_{i} T(n_{i}, \sqrt{m}) = O(\log\log m)
    \end{gather*}
    da man nach $k$~rekursiven Rufen die Menge auf $m^{2^{-k}}$~Elemente
    reduziert hat. Zum Schluss hat man eine konstante Anzahl an Elementen
    ($c\leq3$), die in $T_{p}(n,3) = O(1)$ eingegliedert werden. Also gilt:
    \begin{gather*}
      m^{(\frac{1}{2})^{k}} = m^{2^{-k}} \leq c
         \Leftrightarrow \log\log m - \log\log c \leq k
    \end{gather*}

    Der Aufwand ergibt sich aus der Arbeit im zweiten Schritt und der Anzahl
    der rekursiven Aufrufe: $O\bigl((n+m)\log\log m\bigr)$~\Work.
  \end{proof}
\end{satz}

\begin{folger}
  Zwei sortierte Folgen~$A$ und $B$ mit je $n$~Elementen können in $O(\log\log
  n)$~\Time mit $O(n\log\log n)$ \Work gemischt werden.
\end{folger}

Leider ist das Ergebnis noch nicht WT-optimal, da das Mischen im seriellen
Fall in $T^{*}(n,m)=O(n+m)$~\Time geht. Zur Vereinfachung sei im Folgenden
immer $n=m$.

\todo{Der Rest dieses Abschitts ist wahrscheinlich falsch.}

Mit Accellerated Cascading können wir auch hier zu einem optimalen Algorithmus
kommen.

\begin{enumerate}
 \item Zerlege $A$ und $B$ in $\frac{n}{\log\log n}$~Abschnitte der Länge
  $\log\log n$: Die Abschnitte seien $A_{i}$ und $B_{i}$.
 \item Erzeuge aus den Elementen an den Abschnittsgrenzen zwei neue
  Folgen~$A'$ und $B'$.
 \item Bestimme $Rang(A':B')$ und $Rang(B':A')$ -- damit hat man bestimmt, in
  welchen Abschnitt der anderen Folge die jeweiligen Grenzelemente müssen. Zum
  Beispiel ergibt sich, dass $B'[j]$ zwischen $A'[k]$ und $A'[k+1]$ kommt.
  $A'[k]$ und $A'[k+1]$ ist der Abschnitt $A_{k}$
 \item Man kennt also zu jedem Grenzelement von $A$ einen Abschnitt $B_{j}$
  der Länge $\log\log n$, in den man das Element liegen muss. Innerhalb dessen
  kann man die genaue Position seriell mit binärer Suche bestimmen. Ebenso
  kann man in die umgekehrte Richtung für die Grenzelemente von $B$ ihre
  genaue Position bestimmen.
 \item Damit hat man $A$ und $B$ in $2\cdot\frac{n}{\log\log n}$~Abschnitte
  der Größe $\leq\log\log n$ zerlegt und kennt jeweils den korrespondierenden
  Abschnitt in der anderen Folge. Diese Abschnitte kann man jetzt paarweise
  und unabhängig ineinander ordnen.
\end{enumerate}

\begin{figure}
  \centering
  \input{figures/merge.pdf_t}
  \caption{\todo{ausfüllen}}
  \label{fig:merge}
  \todo{noch die Bilder für die anderen Schritte zeichnen}
\end{figure}
Bilder zum Vorgehen: \autoref{fig:merge}

Zeit- und Aufwandsanalyse:\\
\begin{tabular}{l|c|c|l}
  Schritt& \Time& \Work& Bemerk.\\
  \hline
  1.+2.& $O(1)$& $O(1)$&\\[2mm]
  3.& $O\bigl(\log\log\frac{n}{\log\log n}\bigr) = O(\log\log n)$&
     $O\bigl(\frac{n}{\log\log n} \cdot\log\log\frac{n}{\log\log n}\bigr) =
     O(n)$& \autoref{satz:3}\\[2mm]
  4.& $O(\log\log\log n)=O(\log\log n)$&
     $\frac{n}{\log\log n}\cdot O(\log\log\log n)=O(n)$& \\[2mm]
  5.& $O(1)$& $\frac{n}{\log\log n}\cdot O(\log\log n)=O(n)$& \autoref{satz:3}
\end{tabular}

\begin{enumerate}
 \item Zerlege die Folgen~$A,B$ in $\sqrt{n}$~Abschnitte der Länge~$\sqrt{n}$.
 \item Erstelle aus den Abschnittsgrenzen zwei neue Folgen $A'$ und $B'$.
 \item Für jedes Element aus $A'$ mit $\sqrt{n}$~Prozessoren bestimme
  $Rang(A':B')$. Ebenso für $Rang(B':A')$.
 \item Bestimme $Rang(A':B)$
\end{enumerate}

\begin{bemerk}
  Die Klasse $\PP$ der in polynomeller Zeit lösbaren Algorithmen zerfällt für
  parallele Ansätze in drei Klassen:
  \begin{itemize}
   \item $O(1)$, z.\,B. Eulertour-Technik
   \item $O(\log n)$, vielzahl der Probleme
   \item $O(\log\log n)$, z.\,B. Merge
  \end{itemize}
\end{bemerk}

\section{Sortieren}

Baumparadigma
Ansatz
% Baum mit sortierten Listen als Bl"atter

- Umwandlung in Binärbaum

oBdA
\begin{enumerate}
 \item Binärbaum
 \item Innere Knoten haben genau 2 Söhne
 \item In Blättern stehen Einerlisten
\end{enumerate}

Richard Cole:
% Grafik: Cole-Baum

\begin{verein}
  % kleiner baum mit vuw
  v: Vaterknoten
  u: linke Sohn
  w: rechter Sohn
\end{verein}

Trivial gilt: Sortieren geht mit der Idee des Baumparadigmas
("`merge-sort"') in $O(\log n\log\log n)$ \Time (optimal).
\begin{proof}
  Merge in $O(\log\log n)$ \Time optimal
\end{proof}

\subsection{Merge with the help of a cover}
c-Decke $c\in\Z$

\begin{defini}
  sortierte Folge X heiße c-Decke einer sortierten Folge Y, wenn Y
  höchstens c Elemente zwischen zwei aufeinanderfolgenden Elementen der
  Folge $X_{\infty} := (-\infty, X, \infty)$ enthält
\end{defini}

\begin{satz}
  Seien $A^{n}, B^{m}$ sortiert, sei X c-Decke von $A^{n}$ und $B^{m}$.

  Wenn der Rang(X:A) und Rang(X:B) bekannt sind, so kann Merge(A, B) in
  O(1) \Time und $O(|X|)$ \Work erhalten werden.

  \begin{proof}
    X = ($x_{1},\ldots,x_{s}$), Rang(X:A)=($r_{1},\ldots,r_{s}$),
    Rang(X:B)=($t_{1},\ldots,t_{s})$

    Da c-Decke: $|B_{i}|,|A_{i}|\leq c$
  \end{proof}
\end{satz}

Sei $T$ unser Baum, $v$ ein Knoten von $T$, $Level(v)$, Höhe $h(T)$, Altitude
$alt(v) := h(T)-Level(v)$

Algorithmus arbeitet in Schritten $s$.

\begin{defini}
  $L[v]:$ Lister der sortierten Elemente der Söhne

  $L_{s}[v]:$ Liste im Knoten $v$ nach Schritt $s$, Ziel: $L_{s}[v] =
  L[v]$ für $s\geq 3\cdot alt(v)$

  v \emph{voll} im Schritt $s$, wenn $L_{s}[v]=L[v]$
\end{defini}

\begin{defini}
  $v$ heißt \emph{aktiv} im Schritt $s$ :$\Leftrightarrow$ $alt(v) \leq
  s \leq 3\cdot alt(v)$
\end{defini}

\begin{folger}
  Wir bekommen für root:
  \begin{gather}
    alt(root) = h(T) \leq s \leq 3\cdot alt(root) = 3\cdot h(T)
  \end{gather}

  Root ist damit voll nach $3\cdot h(T)$ Schritten.
\end{folger}

\subsection{Optimales Sortieren - Pipeline Merge Sort}

Hier widmen wir uns der Herleitung eines optimalen Sortieralgorithmus, der mit
$O(log n)$ TIME auskommt. Allerdings betrachten wir hier ein allgemeineres Problem, 
dessen Lösung uns den optimalen Algorithmus liefert.

Formulierung des allgemeineren Problems: sei T ein Binärbaum, für den jedes Blatt $u$
eine Liste $A(u)$ enthält, die aus einer geordneten Menge stammt. Problem sei, für
jeden inneren Knoten $v$ die sortierte Liste $L(v)$ der in im Teilbaum mit Wurzel $v$
gespeicherten Elemente (die Liste $A(u)$ eines Blattes $u$ kann auch leer sein).

Wir beginnen mit einer Menge von Transformationen: jedes Blatt $u$ wird durch einen
balancierten Binärbaum mit $\abs{A(u)}$ Blättern ersetzt, so dass jedes Element von
$A(u)$ in den Blättern des Binärbaums abgelegt ist. Die Höhe des Baumes T ist demnach
nun um $O(log (max_{u} \abs{A(u)}))$ gewachsen, nur beinhaltet nun jedes Blatt von
T wenigstens ein Element.

Die zweite Transformation erzwingt, dass für jeden inneren Knoten zwei Kinder
existieren. Ist dies nicht der Fall, so wird ein Blatt, welches kein Element
beinhaltet, angefügt.

\begin{defini}
  Sei $L$ sortierte Liste. Das c-Raster $Raster_{c}(L)$ (c-sample) ist die sortierte
  Teilliste aus jedem $c$-ten Element.

  Sei $L=(l_{1}, l_{2}, \ldots)$ eine sortierte Liste, so ist $Raster_{c}(L) = 
  (l_{c}, l_{2c}, \ldots)$.
\end{defini}

\begin{bsp}
  \begin{gather}
    L = (1,3,5,6,7,8,11,13,14,15,16)\\
    Raster_{4}(L) = (6,13)\\
    Raster_{2}(L) = (3,6,8,13,15)\\
    Raster_{1}(L) = L
  \end{gather}
\end{bsp}

Die früher vorgestellte Strategie für paralleles Merge-Sort basiert auf einer
Vorwärtstraversierung des Binärbaums, so dass für alle Knoten $v$ in einer speziellen
Höhe $h$ die Liste $L(v)$ komplett bestimmt ist, bevor die Berechnung der Knoten
bei Höhe $h+1$ beginnt.

\begin{description}
 \item[Die Pipeline-Strategie]
  besteht aus der Bestimmung der $L(v)$ über eine Anzahl von
  Schritten, so dass bei Schritt $s$ $L_{s}(v)$ eine Approximation von $L(v)$ ist, die
  im Schritt $s+1$ verbessert wird. Gleichzeitig wird ein Raster von $L_{s}(v)$ im
  Richtung Wurzel propagiert, um dort für Annäherungen der Listen auf eben anderen 
  Leveln genutzt zu werden.
\end{description}

Kommen wir nun dazu, wie man die $L_{s}(v)$ präzise bestimmt $\ldots$ \\
Sei $L_{0}(v)=\emptyset$, wenn $v$ ein innerer Knoten ist bzw. $L_{0}(v)$ enthält
das Element, was im Blatt $v$ gespeichert ist.

\begin{defini}
  Sei $alt(v) = height(T) - level(v)$, wobei $level(v)$ als Abstand von $v$ zur Wurzel
  definiert ist.
\end{defini}

Die Liste, die in den internen Knoten $v$ gespeichert wird, wird in den Schritten $s$
aktualisiert, wenn die Bedingung $alt(v) \leq s \leq 3alt(v)$ erfüllt ist. Ist dies der
Fall, dann sprechen wir davon, dass $v$ in diesem Schritt $s$ aktiv ist. Der Algorithmus
aktualisiert die Liste $L_{s}(v)$, so dass $v$ gefüllt wird, d.h. $L_{s}(v) = L(v)$ - wenn
also $s \geq 3alt(v)$. Somit ist klar, dass nach $3height(T)$ Schritten der Wurzelknoten
voll ist und die inneren Knoten die sortierten Listen enthalten.

Bevor wir zum Algorithmus kommen, führen wir eine weitere Notation ein.

\begin{defini}
  Für einen beliebigen Knoten $x$:
  \begin{gather}
    Sample(L_{s}[x]):=
       \begin{cases}
         Raster_{4}(L_{s}[x])& s\leq3\cdot alt(x)\\
         Raster_{2}(L_{s}[x])& s=3\cdot alt(x)+1\\
         Raster_{1}(L_{s}[x])& s=3\cdot alt(x)+2\\
       \end{cases}
  \end{gather}
\end{defini}

Also ist $Sample(L_{s}[x])$ die Teilliste bestehend aus jedem vierten Element von $L_{s}[x]$,
bis es voll ist. Anschließend ist $Sample(L_{s}[x])$ die Teilliste aus jedem zweiten Element
im Schritt $3alt(x)+1$ und schließlich die vollständige Liste im Schritt $3alt(x)+2$.

\begin{algorithm}
  \dontprintsemicolon
  \caption{Algorithmus von Richard Cole}
  \label{alg:rcole}
  \KwIn{$\forall v:L_{s}[v]$ $v$ voll, wenn s$\geq$ 3 alt(v)}
  \KwOut{$\forall$ v: $L_{s+1}[v]$, v voll, wenn s+1$\geq$ 3alt(v)}
  \Forpar{$\forall$ aktiven Knoten $v$}{
    $L'_{s+1}[w] = Sample(L_{s}[w])$\;
    $L'_{s+1}[u] = Sample(L_{s}[u])$\;
    $Merge(L_{s+1}'[u], L'_{s+1}[w])$ zu $L_{s+1}[v]$
  }
\end{algorithm}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Hier fehlen zwei Vorlesungen : Beweise zu R. Cole %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{description}
 \item[Hinweis:]
  es fehlen an dieser Stelle zwei Vorlesungen. Diese beinhalteten 180 Minuten
  Beweise und Lemmas zum Richard-Cole-Algo und sind nicht Prüfungsrelevant. Es
  reicht ein Verständnis dessen, was passiert. Natürlich absolut inoffiziell.
  Es sei hiermit auf Ja'Ja (Seiten 164 ff) verwiesen.
\end{description}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Selektion}


%%%%%%%%%%%%%%%%%%%%%%%%%%
% nachträglich eingefügt %
%%%%%%%%%%%%%%%%%%%%%%%%%%

\highl{Input}: $A=(a_{1}, \ldots, a_{n})$, $k := 1 \leq k \leq n$ \\
\highl{Output}: Element $a_{i}$ mit $Rang(a_{i}:A)=k$ \\



\begin{description}
  \item[Lösung:] SORT A $\Rightarrow$ $O(log n)$ TIME mit $O(n log n)$ WORK nicht optimal,
    da man seriell mit $O(n)$ WORK auskommt.
  \item[Ziel:] CREW (EREW, optional): $O(log n log log n)$ TIME, $O(n)$ WORK;
    nutzen R.Cole und Accelerated Cascading
\end{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%

Median der Mediane-Technik; R.\,Cole; Prefixsummenalgo.; Litheratur liefert u.\,a. 2
Ansätze: Akl (s. Info 3), R.Cole

Akl: 0<x<1: O($n^{x}$) \Time optimal

Fälle k=1,n. $O(\log\log n)$ CRCW, optimal \Work $O(n)$
Median: nicht erreichbar.
Bem. dazu: $par_{n}(\alpha_{1},\ldots,\alpha_{n}) := \alpha_{1}\oplus
\alpha_{2}\oplus\ldots\oplus \alpha_{n}$ ($\alpha_{i}$ boolsche Werte)

Die Berechnung von $par_{n}$ erfordert auf der PRIORITY-CRCW-PRAM
$\omega(\frac{\log n}{\log\log n})$ \Time. (Beweis schwer!) Die gleiche
Schranke gilt für den Median.


\begin{algorithm}
  \dontprintsemicolon
  \caption{Algorithmus: Parallele Selektion}
  \label{alg:parsel}
  \KwIn{$A=(a_{1},\ldots,a_{n}), k: 1 \leq k \leq n$}
  \KwOut{$ldots$}
  $n_{0} := n$\;
  $s := 0$\;
  \While{$n > \frac{n}{log n}$} {
    $s := s+1$\;
    zerlege $A$ in Blöcke $B_{i}$ mit je log n Elementen; Berechne den %
    Median $m_{i}$ für Block $B_{i}$ parallel \;
    Berechne den Median der Mediane: $m$\;
    Bestimme die Anzahlen $s_{1}$, $s_{2}$, $s_{3}$ der Elemente von $A$, %
    die kleiner, gleich oder größer als $m$ sind (mit Präfixsumme in $O(log n)$ %
    TIME optimal)\;
    \If{$s_{1} < k \leq s_{1}+s_{2}$}{
       OUTPUT m
    }
    \If{$k \leq s_{1}$}{
       kontrahiere die Elemente von A, die <m sind, in aufeinander folgende %
       Positionen \;
       $s:=s_{1}$
    }
    \If{$k > s_{1}+s_{2}$}{
       kontrahiere \ldots\;
       $n_{s}=s_{3}$\;
       $k := k - (s_{1}+s_{2})$
    }
  }
  SORT die restlichen $n_{s} \leq \frac{n}{log n}$ Elemente, gib das k-te %
  Element aus
\end{algorithm}

$n_{s}$\ldots Zahl der Elemente nach Schritt $s$


\highl{Leistungsparameter:} \\
\begin{description}
  \item[Zeile 5:] $\abs{B_{i}} = log n$ - seriell: bestimme $m_{i}$ $\rightarrow$ pardo \\
     gesamt $O(log n)$ TIME mit $O(n_{s})$ WORK
  \item[Zeile 6:] mit R. Cole wird sortiert $\rightarrow$ Mittelwert problemlos abzählbar \\
    $O(log n)$ TIME, $O(\frac{n}{log n} * log (\frac{n}{log n})) = O(\frac{n}{log n} * log n) = O(n)$ WORK
  \item[Zeile 7:] mit Präfixsumme: Markiere die Elemente von $a_{i}$ parallel
    mit \{1,2,3\}, je nachdem, ob $a_{i}" kleiner, gleich oder größer als $m$
    ist $\Rightarrow$  $O(1)$ TIME, $O(n)$ WORK \\
    mit Präfixsumme $O(log n) / O(n)$
  \item[Zeile 8:] $O(log n) / O(n)$
\end{description}

\begin{lemma}
  $n_{s+1} \leq \frac{3 n_{s}}{4}$ \\
  Beweis mittels Median-der-Mediane-Argument
\end{lemma}

\begin{folger}
  fertig mit Schritt 3 nach $O(log log n)$ Iterationen \\
  WORK: $\sum_{s=1}^{\infty} O(n_{s}) = O(n)$\\
  TIME: $O(log n log log n)$
\end{folger}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Parallelisierbarkeit}

Laut dem Satz von Brent (\autoref{satz:brent}) kann jeder parallele
Algorithmus in $O\bigl(\frac{W(n)}{p}+T(n)\bigr)$~\Time realisiert werden.
Jedoch ist es in vielen Fällen nicht sinnvoll, mehr als
$\alpha(n)$~Prozessoren zu verwenden, da dies keine Verbesserung bringt. Um
z.\,B. ein Element in 100~Zahlen zu suchen, ist der Einsatz von mehr als
100~Prozessoren nicht sinnvoll.

Man kann die Laufzeitverbesserung auf zwei Wegen angehen. Wenn mehr
Prozessoren eine bessere Zeit liefern, so ist natürlich die Erhöhung der
Prozessoranzahl das Mittel der Wahl. Der andere Weg ist einen anderen
Algorithmus zu finden, der das Problem schneller löst.

\begin{defini}
  Die Menge~\highl{$\NC$}\footnote{$\NC$: Nick's class, nach seinem Erfinder
  Nick Pipenger benannt} ist die Klasse der Sprachen, die sich in
  polylogarithmischer\footnote{\highl{polylogarithmisch}: $O\bigl( (\log
  n)^{k}\bigr)$ für ein festes $k$} Zeit mit
  polynomiell\footnote{\highl{polynomiell}: $O(n^{k})$ für ein festen $k$}
  vielen Prozessoren auf einer PRAM entscheiden\footnote{Eine
  Sprach~$L\subset\Sigma^{*}$ heißt genau dann \highl{entscheidbar}, wenn sich
  ihre \highl{charakteristische Funktion}~$\chi_{L}$\footnotemark{} berechnen lässt} lassen.
  \footnotetext{$\chi_{L}(w)=1$, wenn $w\in L$, sonst $\chi_{L}(w)=0$}
  \begin{multline*}
    \NC = \{ L\subset \Sigma^{*} \colon \forall w\in\Sigma^{n} \text{~ist
       $\chi_{L}(w)$ in $O\bigl( (\log n)^{k}\bigr)$~\Time}\\
      \text{mit $O(n^{k})$~Prozessoren (für festes $k$) auf einer PRAM
        berechenbar}\}
  \end{multline*}

  Eine Sprache~$L$ heißt genau dann \highl{hochgradig parallelisierbar} oder
  \highl{$\NC$-berechenbar}, wenn $L\in\NC$.
\end{defini}

\begin{defini}
  Seien $L_{1}$ und $L_{2}$ zwei Sprachen. $L_{1}$ heißt
  \highl{$\NC$-reduzierbar} auf $L_{2}$ (Schreibweise: $L_{1}\preceq_{\NC}L_{2}$),
  wenn es eine hochgradig parallelisierbare Funktion~$f\colon
  \Sigma^{*}\rightarrow \Sigma^{*}$ gibt, so dass für alle $w\in\Sigma^{*}$
  gilt: $w\in L_{1}$ dann und nur dann, wenn $f(w)\in L_{2}$
\end{defini}

\begin{defini}
  Eine Sprache~$L$ heißt genau dann \highl{$\PP$-vollständig}, wenn $L$ in
  polynomieller Zeit auf einer deterministischen Turingmaschine berechenbar
  ist ($L\in\PP$) und alle Sprachen~$L'\in\PP$ $\NC$-reduzierbar auf $L$ sind:
  $L'\preceq_{\NC}L$.
\end{defini}

\begin{satz}
  Alle Probleme, die sich in polylogarithmischer Zeit mit polynomiell vielen
  Prozessoren auf einer PRAM berechnen lassen, können in polynomieller Zeit
  auf einer deterministischen Turingmaschine berechnet werden:
  $\NC\subset\PP$.

  \begin{proof}
    über serielle Modellierung der Rechnung
    \todo{machen}
  \end{proof}
\end{satz}

\section{\texorpdfstring{$\PP$}{P}-vollständige Probleme}

\subsection{Maximaler Fluss in einem Netzwerk}

Ein \highl{Netzwerk}~$N=(V,E,s,t,c)$ ein gerichteter Graph, dessen
Kanten~$e\in E$ eine Kapazität~$c(e)\in\N_{0}$ zugeordnet ist. Der
Knoten~$s\in V$ wird als Startknoten und der Knoten~$t\in V$ als Zielknoten
bezeichnet.

Der \highl{Fluss}~$f\colon E\rightarrow\N$ über eine Kante~$e$ ist durch ihre
Kapazität beschränkt: $0\leq f(e)\leq c(e)$. Als \highl{Zufluss}~$f^{+}(v)$
eines Knotens~$v\in V$ bezeichnet man die Summe über den Fluss aller
eingehenden Kanten und als \highl{Abfluss}~$f^{-}(v)$ die Summe über den Fluss
aller ausgehenden Kanten. Für alle Knoten außer dem Start- und dem Zielknoten
soll der Zufluss gleich dem Abfluss sein.
\begin{align*}
  f^{+}(v) &:= \sum_{e\in E\colon e=(*,v)} f(e) &
     f^{-}(v) &:= \sum_{e\in E\colon e=(v,*)} f(e)
\end{align*}

Als den Wert~$\mathrm{val}(f_{N})$ eines Flusses~$f$ durch ein Netzwerk
bezeichnet man die Summe $\mathrm{val}(f) = f^{+}(s)-f^{-}(s) = f^{-}(t) -
f^{+}(t)$.

\begin{defini}
  Das Problem "`\highl{maximaler Fluss}"' ist die Frage nach dem
  größtmöglichen Fluss~$\tilde{f}$ durch ein Netzwerk, so dass für alle
  anderen möglichen Flüsse~$f$ gilt: $\mathrm{val}(\tilde{f})\geq
  \mathrm{val}(f)$.
\end{defini}

\todo{Es gab eine Grafik dazu. Einarbeiten.}
\help{Warum ist das jetzt in $\PP\setminus\NC$? Eventuelle könnte man es als
  lin.\,Op. schreiben, d.\,h. $maxFlusss\preceq_\NC linOp$}

\subsection{Lineare Optimierungsprobleme}

\begin{defini}
  Als ein \highl{lineares Optimierungsproblem} bezeichnet man die Aufgabe, zu
  einer gegebenen Matrix~$A\in\R^{n\times m}$ und zwei Vektoren $b\in\R^{m},
  c\in\R^{n}$ einen Vektor $x\in\R^{n}$ zu finden, so dass $c^{T}x$ maximal
  ist, wobei $0\leq x$ und $Ax\leq b$ gilt.
  \begin{gather*}
    \max\{ c^{T}x \colon Ax\leq b, 0 \leq x\}
  \end{gather*}
\end{defini}

\help{Warum ist das jetzt in $\PP\setminus\NC$?}

\subsection{Das circuit value problem}

\begin{defini}
  Als einen \highl{Schaltkreis}~$c=\lrangle{g_{1},\ldots,g_{n}}$ (engl.
  \highl{circuit}) bezeichnet man eine Menge von
  \highl[Gatter]{Gattern}~$g_{1},\dotsc, g_{n}$, die entweder ein
  Eingabegatter mit den möglichen Werten $\{0,1\}$ sind oder eine boolsche
  Verknüpfung von einem oder zwei anderen Gattern realisieren, d.\,h. für
  $1\leq j,k<i\leq n$ ist $g_{i} = \neg g_{j}$ oder $g_{i} = g_{j}\vee g_{k}$
  oder $g_{i}=g_{j}\wedge g_{k}$.
\end{defini}

\begin{defini}
  Als \highl{circuit value problem} (\highl{$CVP$}) bezeichnet man das
  Entscheidungsproblem, ob für einen gegebenen
  Schaltkreis~$c=\lrangle{g_{1},\dotsc,g_{n}}$ der Wert des letzten
  Gatters~$g_{n}=1$ ist.
  \begin{gather*}
    CPV(c) = \begin{cases}
               0& g_{n}=0\\
               1& g_{n}=1
             \end{cases}
  \end{gather*}
\end{defini}

Um zu zeigen, dass das circuit value problem $\PP$-vollständig ist, muss man
für jede beliebige Sprachen~$L\in\PP$ zeigen, dass sie sich auf $CVP$
reduzieren lässt ($L\preceq_{NC}CVP$) und dass $CVP\in\PP$ liegt. Analog zum
Beweis des Satz' von Cook über die $\NP$-Vollständigkeit des
Erfüllbarkeitsproblems der Aussagenlogik~$SAT$ zeigen wir die
$\NC$-Reduzierbarkeit und, dass $CVP\in\PP$ liegt, ist leicht einzusehen, da
man den Ausgabewert des letzten Gatters einfach bestimmen kann, indem man alle
Gatterausgaben bestimmt, also lässt sich $g_{n}=1$ in $O(n)$ entscheiden.

Da $L\in\PP$ liegt, gibt es eine Turingmaschine~$M$, die nach polynomiell
vielen Schritten eine Eingabe~$w$ genau dann akzeptiert, wenn $w\in L$, indem
sie eine $1\in\Gamma$ in die erste Zelle schreibt. Die
\highl{Turingmaschine}~$M$ ist ein Sextupel $(Q,\Sigma,\Gamma,\delta,
q_{1},q_{s})$ mit dem Arbeitsalphabet~$\Gamma$, dem
Eingabealphabet~$\Sigma\subset\Gamma$, der Zustandsmenge~$Q$, wobei $q_{1}\in
Q$ der Startzustand ist, und der Zustandsüberführungsfunktion~$\delta\colon
Q\times\Gamma\rightarrow Q\times\Gamma\times\{L,R\}$.

Damit $L\preceq_{NC}CVP$ gilt, muss man einen $\NC$-berechenbaren Algorithmus
angeben, der für eine Turingmaschine~$M$ einen Schaltkreis~$c$ konstruiert,
der genau dann durchschaltet ($g_{n}=1$), wenn $M$ die Eingabe akzeptiert.

% jedes Wort~$w\in\Sigma^{*}$ einen
% Schaltkreis~$c=\lrangle{g_{1},\dotsc, g_{n}}$ konstruiert, so dass
% $CVP(c)=\chi_{L}(w)$ bzw. $g_{n}=1$ genau dann, wenn die Turingmaschine~$M$
% die Eingabe~$w$ akzeptiert.

% Der Algorithmus erzeugt für jeden Arbeitstakt~$t\in\{0,\dotsc,T(n)\}$ der
% Turingmaschine polynomiell viele Gatter. Die Ausgabe des gesamten Schaltkreis'
% kann also in polynomieller Zeit bestimmt werden.

Einige Hilfsfunktionen für die Konstruktion der Gatter:
\begin{align*}
  % Head -- Kopfposition
  H(i,t) &=
     \begin{cases}
       1& \text{der Lese-Schreib-Kopf steht zum Zeitpunkt~$t$ auf Zelle~$i$}\\
       0& \text{sonst}
     \end{cases}\\
  % Character -- Zeichen
  C(i,j,t) &=
     \begin{cases}
       1& \text{das Zeichen~$a_{j}\in\Gamma$ steht zum Zeitpunkt~$t$ in
       Zelle~$i$}\\
       0& \text{sonst}
     \end{cases}\\
  % State -- Zustand
  S(k,t) &=
     \begin{cases}
       1& \text{$M$ befindet sich zum Zeitpunkt~$t$ im Zustand~$q_{k}$}\\
       0& \text{sonst}
     \end{cases}
\end{align*}

Modellierung der Startkonfiguration ($t=0$) ist
\begin{align*}
  H(i,0) &= \begin{cases}1&i=1\\0&i>1\end{cases}\\
  C(i,j,0) &= \begin{cases}
                1&\text{Zelle~$i$ enthält Zeichen~$a_{j}$}\\
                0&\text{sonst}
              \end{cases}\\
  S(k,0) &= \begin{cases}1&k=1\\0&k>1\end{cases}
\end{align*}
Das letzte Gatter sei $g_{n} = C(1,1,T(n))$, d.\,h. $g_{n}$ ist genau dann
eins, wenn die Turingmaschine nach $T(n)$~Schritten eine Eins in die erste
Zelle geschrieben hat.

\todo{Das ganze muss nochmal überarbeitet werden. Herr Hecker hat dazu auch
  eine Kopie des Beweises aus dem Ja'Ja ausgeteilt. Es sollte noch erklärt
  werden, dass die Gatter für $H$ in $O(1)$~\Time mit $O(T^{2}(n))$~\Work, die
  Gatter für $C$ in $O(1)$~\Time mit $O(T^{2}(n))$~\Work und die Gatter für
  $S$ in $O(\log n)$~\Time mit $O(T^{2}(n))$~\Work erzeugt werden können. Die
  Erzeugung des Schaltkreises geht also in polylogarithmischer Zeit mit
  polynomiell vielen Prozessen $\rightarrow$ der Algorithmus ist
  $\NC$-berechenbar.
  \url{http://www.informatixx.de/privat/files/informatik/pdf/Parallele_Algorithmen_Komplett.pdf}
  Seite~58}

In $T(n)$~Schritten kann die Turingmaschine auf höchstens $T(n)$~Zellen des
Arbeitsbands zugreifen: $i\in\{1,\dotsc,T(n)\}$. Für die Zeit~$t$ gilt:
$t\in\{0,\dotsc,T(n)\}$.

Mittels $\delta$ beschreiben wir $t\rightarrow t+1$

\subsection{DFS (geordnete Tiefensuche)}

\todo{Der Abschnitt muss auch nochmal überarbeitet werden.}

INPUT: beginnend bei $a$ %garfik dfs
OUTPUT:
\begin{tabular}{l|l}
  Ecken& DFS-Liste\\
  \hline
  a& 1\\
  b & 2\\
  c & 5\\
  d& 3\\
  e& 4\\
  f&6\\
  g&7
\end{tabular}

Formulieren wir ein Problem "`Kommt $e$ vor $d$ in DFS-Liste"' so haben
wir damit ein Entscheidungsproblem -- ein Sprachproblem.

relevante Entscheidungsproblem: -- wenn das Ursprungsproblem lösbar ist,
dann auch das relevante Entscheidungsproblem. Wenn das relevante
Entscheidungsproblem unlösbar ist, so erstrecht das Ursprungsproblem.

% 9.7.

Mit dem letzten Satz haben wir gezeigt, dass CVP schwer entscheibar ist.
Diese Aussagen wollen wir jetzt nutzen, um zu zeigen, dass auch DFS
schwer ist.

Um zu zeigen, dass $DFS$ $\PP$-vollständig ist, verwendet man den folgenden
\autoref{satz:hauptsatz} und zeigt, dass $CVP\preceq_{NC}DFS$ und
$DFS\in\PP$. Da $CVP\in\PP$ folgt aus \autoref{satz:hauptsatz}, dass
$DFS\notin\NC$ ist.

\begin{satz}[Hauptsatz über die Reduktion]
  \label{satz:hauptsatz}
  Seien $L_{1}, L_{2}\in \Sigma^{\ast}$ zwei Sprachen und $L_{1}$ sei
  $\NC$-reduzierbar auf $L_{2}$. Dann ist $L_{1}\in\NC$, wenn $L_{2}\in\NC$
  ist: $L_{1}\preceq_{NC} L_{2}\wedge L_{2}\in\NC \Rightarrow L_{1}\in\NC$.

  \begin{proof}
    Da $L_{1}$ $\NC$-reduzierbar auf $L_{2}$ ist, existiert eine
    Funktion~$f\in\NC$, die jede Eingabe~$w\in\Sigma^{*}$ für $\chi_{L_{1}}$
    in eine Eingabe für $\chi_{L_{2}}$ transformiert, wobei $w\in L_{1}
    \Leftrightarrow f(w)\in L_{2}$. Da $L_{2}$ $\NC$-berechenbar ist, lässt
    sich die charakteristische Funktion~$\chi_{L_{2}}$ in polylogarithmischer
    Zeit mit polynomiell vielen Prozessoren auf einer PRAM berechnen.

    Die charakteristische Funktion von $L_{1}$ lässt sich also mit Hilfe der
    Funktion~$f$ und der charakteristischen Funktion~$\chi_{L_{2}}$ in
    polylogarithmischer Zeit mit polynomiell vielen Prozessoren auf einer PRAM
    berechnen. $L_{1}$ ist also $\in\NP$.
    \begin{gather*}
      \chi_{L_{1}}(u) = \chi_{L_{2}}\bigl( f(u) \bigr)
    \end{gather*}
  \end{proof}
\end{satz}

Wir zeigen, dass CVP leichter ist als DFS. Jedoch ist DFS kein
Entscheidungspoblem, was eine direkte Abbildung der INPUT-Mengen
aufeinander nicht möglich macht. Daher konstruieren wir ein
Entscheidungsproblem, das leichter ist als DFS, an dem wir aber zeigen
können, dass es schwerer ist als CVP. Damit wäre dann auch gezeigt,
dass DFS schwerer ist, als CVP und damit auch schwer entscheidbar ist.

Dafür brauchen wir noch folgenden Satz:
\begin{satz}[Satz über Transitivität]
  Die Relation $\preceq_{\NC}$ ist transitiv, d.\,h. wenn
  $L_{1}\preceq_{NC}L_{2}$ und $L_{2}\preceq_{NC}L_{3}$, so ist auch
  $L_{1}\preceq_{NC}L_{3}$.

  \begin{proof}
    \todo{machen} Sollte einfach sein. $L_{1}\preceq_{NC}L_{2}$ $\Rightarrow$
    $\exists f\in\NC$, $L_{2}\preceq_{NC}L_{3}$ $\Rightarrow$ $\exists
    g\in\NC$, dann ist $f\circ g\in\NC$.
  \end{proof}
\end{satz}

DFS:
INPUT: gerichteter Graph, Kantenmarkierung (genormt), Startknoten,
Traversierung im Graph soll möglich sein
OUTPUT: DFS-Liste

zu konstruieren mit NC-Zuordnung.

Jedem INPUT von CVP: $I_{CVP} \rightarrow f(I_{CVP})=I_{DFS}(v,w):$
Wert($I_{CVP})=1 \Leftrightarrow$ das relevante Entscheidungsproblem von
$I_{DVS}$ wahr ist (=1 ist) (d.\,h. $u$ wird vor $v$ besucht.

$I_{CVP}: <g_{1},g_{2},\ldots,g_{n}>$
entweder $g_{i}=1 \vee g_{i}=\neg(g_{i}\wedge g_{k}), k,j<i$
$\rightarrow$ Graph, s,u,v
\begin{enumerate}[1.\,{Fall}]
 \item $g_{i}=1$ $\Rightarrow$ Abb.1 $g_{i}$ sei INPUT für
  $g_{j_{1}},\ldots,g_{j_{k}}$, bilde <i,$j_{1}$>,\ldots,<i,$j_{k}$>

  Ind.beweise: Wenn wert=1 $\Leftrightarrow$ so wird s(i) vor t(i) besucht
 \item $g_{i} = \neg (g_{j}\vee g_{k}) \Rightarrow $ Abb.2

  Ind.beweis: Sei Wert($g_{i}$)=1 $\Rightarrow$ ($g_{j}=0=g_{k})$
  Ind.vor. $\Rightarrow$ t(j) vor s(j) besucht (t(k) vor s(k)) genauer:
  Abb.4-Verlauf: speziell: <j,i>, <k,i> sind nicht besucht $\Rightarrow$
  für $g_{i}$ wird Abb.5 verfolgt $\Rightarrow$ s(i) vor t(i)

  sei Wert($g_{i}$)=0 $\Rightarrow$ ($g_{j}$=1 oder $g_{k}$=1)

  \begin{enumerate}
   \item $g_{j}=1 \rightarrow G_{j}$ (Graph, der $g_{i}$ zugeordnet ist)
    wird nach Abb.5 durchlaufen $\Rightarrow$ "`Zackenweg"'

    $\Rightarrow$ in Abb.3 ist <j,i> bereits besucht $\Rightarrow$ für i
    $\Rightarrow$ Weg wie Abb.4
   \item $g_{j}=0, g_{k}=1$ $\Rightarrow$ im wesentlichen Weg wie in
    Abb.4 (Ausnahme: erst <j,i> dann zurück)
  \end{enumerate}
  $\Rightarrow$ t(i) vor s(i)
\end{enumerate}

\begin{defini}
  u:=s(n), v=t(n) $\Rightarrow$ u vor v besucht $\Leftrightarrow$
  wert($g_{n}$)=1
\end{defini}

\clearpage
\appendix
\pdfbookmark[0]{Index}{index}
\printindex

\end{document}
