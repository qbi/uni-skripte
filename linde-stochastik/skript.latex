%
% scrreprt trifft am Besten die Bedürfnisse eines Skripts, das ganze wird
% zweiseitig (twoside), d.h. es wird zwischen linker und rechter Seite
% unterschieden, und wir verwenden zwischen den Absätzen einen Abstand
% von einer halben Zeile (halfparskip) und dafür keinen Absatzeinzug,
% wobei die letzte Zeile eines Absatzes zu min. 1/4 leer ist.

\documentclass[halfparskip*,draft,12pt,twoside]{scrreprt}

\usepackage{index}

\usepackage[T1]{fontenc}
\usepackage{times}
\usepackage{helvet}

\usepackage[latin1]{inputenc}
\usepackage{ngerman}
\usepackage[final]{graphicx}
\usepackage{delarray}
\usepackage{epsfig}
\usepackage{boxedminipage}
\usepackage{pictexwd,color}
%\usepackage{m-pictex}        % Dieses Paket behebt einige Probleme mit
                             % Registern von von pictex; s. DE-TeX-FAQ 6.4.5
\usepackage{amssymb}
\usepackage[intlimits]{amsmath}
\usepackage{theorem}
%\usepackage{treetex}

\usepackage[draft=false,colorlinks,bookmarksnumbered,linkcolor=blue]{hyperref}
\usepackage{svn}

\makeindex
\theoremstyle{break}
\newtheorem{Ax}{Axiom}[chapter]
\newtheorem{Bsp}{Beispiel}
\newtheorem{Def}[Ax]{Definition}
\newtheorem{Satz}{Satz}[chapter]
\newtheorem{Lemma}[Satz]{Lemma}
\newtheorem{Theorem}[Satz]{Theorem}

\newcommand{\B}{\mathcal{B}}
\newcommand{\EX}{\mathbb{E}X}
\newcommand{\X}{X }
\newcommand{\Y}{Y }
\newcommand{\N}{\mathcal{N}}
\newcommand{\p}{\mathbb{P}}
\newcommand{\PR}{\mathfrak{R}} %Potenzmenge statt: mathcal{P}} %ist das sinnvoll?
\newcommand{\A}{\mathcal{A}}
\newcommand{\E}{\mathcal{E}}
\newcommand{\Ll}{\mathcal{Ll}}
\newcommand{\ar}{\curvearrowright}
\newcommand{\lb}{\left\{}               %kleine Klammer {
\newcommand{\blb}{\bigl\{} %grosse Klammer {
\newcommand{\bblb}{\biggl\{} %ganz grosse Klammer {
\newcommand{\rb}{\right\}}  %kleine Klammer }
\newcommand{\brb}{\bigr\}} %grosse Klammer }
\newcommand{\bbrb}{\biggr\}} %ganz grosse Klammer }

\newcommand{\vektor}[1][\omega]{\ensuremath{\lb#1_1,\ldots,#1_n\rb}}
\newcommand{\vol}{V\!ol}

\SVN $LastChangedRevision$
\SVN $LastChangedDate$
\newcolumntype{L}{>{$}l<{$}}

% Damit auch die Zeichen im Mathemode in Überschriften fett sind
% <news:lzfyyvx3pt.fsf@tfkp12.physik.uni-erlangen.de>
\addtokomafont{sectioning}{\boldmath}

\begin{document}
\author{Prof. Dr. Linde}
\date{WS 2002/2003}
\title{Vorlesung Mathematik für Informatiker 3\\
    Wahrscheinlichkeitstheorie\\[0.5cm]
    %\Large Arbeitstitel:\\Hochgradig nicht trivial
	}
\maketitle

\pagestyle{headings}

\chapter*{Vorwort}
{\itshape

  Dieses Skript ist im Rahmen des
  \href{http://www.minet.uni-jena.de/~joergs/skripte/}{Projekts
  "`Vorlesungsskripte der Fakultät für Mathematik und Informatik"'}
  entstanden und wird im Rahmen dieses Projekts weiter betreut. Das
  Skript ist nach bestem Wissen und Gewissen entstanden. Denoch
  garantiert weder der auf der Titelseite genannte Dozent, noch die
  Mitglieder des Projekts für dessen Fehlerfreiheit. Für etwaige Fehler
  und dessen Folgen wird von keiner der genannten Personen eine Haftung
  übernommen. Es steht jeder Person frei, dieses Skript zu lesen, zu
  verändern oder auf anderen Medien verfügbar zu machen, solange ein
  Verweis die Internetadresse \url{http://www.minet.uni-jena.de/~joergs/skripte/}
  des Projekts enthalten ist.

  \sloppy Diese Ausgabe trägt die Versionsnummer~\SVNLastChangedRevision\ und ist
  vom \SVNDate. Eine (mögliche) aktuellere Ausgabe ist unter
  \url{http://www.minet.uni-jena.de/~joergs/skripte/pdf/} ist eine
  (mögliche) aktuellere Ausgabe verfügbar.
  
  Jeder ist dazu aufgerufen, Verbesserungen, Erweiterungen und
  Feh\-ler\-kor\-rek\-tu\-ren für das \linebreak[4] Skript ein\-zu\-reichen
  bzw. zu melden oder selbst
  einzupflegen -- einfach eine eMail an die
  \href{mailto:skripte@listserv.uni-jena.de}{Mailingliste
  \texttt{<skripte@listserv.uni-jena.de>}} senden. Weitere Informationen
  sind unter der oben genannten Internetadresse des Projekts verfügbar.

  Hiermit möchten wir allen Personen, die an diesem Skript mitgewirkt
  haben, vielmals danken:
  \begin{itemize}
   \item \href{mailto:chrisra@informatik.uni-jena.de}
    {Christian Raschka \texttt{<chrisra@informatik.uni-jena.de>}} (2003)
   \item \href{mailto:cat5@minet.uni-jena.de}
    {Matti Bickel \texttt{<cat5@minet.uni-jena.de>}} (2005)
  \end{itemize}
}

\pdfbookmark[0]{Inhaltsverzeichnis}{inhaltsverzeichnis}
\tableofcontents
\clearpage

\chapter{Das Modell der Wahrscheinlichkeitstheorie}
\index{Wahrscheinlichkeitstheorie}
\label{sec:WTheorie}

\section{Der Wahrscheinlichkeitsraum}
\index{Wahrscheinlichkeitsraum}
\label{sec:WRaum}
        
WT = Mathematisches Modell zur Beschreibung von Versuchen mit zufälligem Ergebnis, 
von Zufallsexperimenten und von zufälligen Erscheinungen.
        
\begin{itemize}
        \item{kein philosophischer Ansatz}
        \item{Modell vs. Realität? (nie 100\%)}
        \item{Versuch mit zufälligem Ergebnis $\widehat{=}$ bei identischer
           Versuchsanordnung sind verschiedene Ergebnisse möglich
           (nicht vorhersehbar)}
        \item{\index{Zufallsexperiment}Zufallsexperiment $\widehat{=}$ gezieltes Experiment und Aussagen über den wahren
                                Sachverhalt zu bekommen.\\
                                Beobachtung = Stichprobe (Statistisches Experiment)}
        \item{zum Beipiel Meinungsforschung, Gütekontrolle o.ä.}
        \item{zufällige Erscheinung $\widehat{=}$ Dinge der realen Welt, die anscheinend völlig
                                gesetzlos auftreten, zum Beispiel Anzahl Anrufe in einem Callcenter an einem Tag, 
                                Ausfallszeit eines Bauteils, Anzahl der Verkehrsunfällen in einer Stadt pro Tag, 
                                Brände usw.}
        \item{\underline{Zwei Typische Beispiele}
                \begin{enumerate}
                        \item{Würfeln:
                                \begin{itemize}
                                        \item{Einmaliges Würfeln:\\
                                                Ergebnis, zufällige Zahl aus $\left\{1,\dots,6\right\}$}
                                        \item{n-maliges Würfeln:\\
                                                Ergebnis, zufälliger Vektor, Länge n, $\omega=(\omega_1,\dots,\omega_n)
                                                                \quad \omega_j \in \left\{1,\dots,6\right\}$}
                                \end{itemize}
                        \item{Lebensdauer eines Bauteils, Lebewesens\\
                                                Zum Zeitpunkt 0 nehmen wir Bauteil in Betrieb\\
                                                Zum zufälligen Zeitpunkt $t>0$ Ausfall des Bauteils\\
                                                Zufall: $t>0$;
                                                Beobachten zufällige
                                                reelle zahl 
                                                $t \in \left[ 0,\infty \right)$.}}
                \end{enumerate}}                
\end{itemize}

\begin{Ax}
        Vorgänge, bei denen zufällige Erscheinungen auftreten, werden durch einen
        Wahrscheinlickeitsraum
        \index{Wahrscheinlichkeitsraum}\index{Grundraum $\Omega$}
        \index{Ereignis-$\sigma$-Algebra}\index{Wahrscheinlichkeitsmaß}
        \LARGE
  \begin{gather*}
    \left(\underbrace{\Omega}_{Grundraum},\underbrace{\A}_{
        Ereignis-\sigma-Algebra},\underbrace{\mathbb{P}}_{Wahrscheinlichkeitsma"s} \right)
  \end{gather*}
        \normalsize beschrieben.
\end{Ax}

\subsection{Grundraum $\Omega$}
\label{sec:Omega}

        Der Raum der Elementarereignisse $\Omega$ enhält (mindestens) alle möglichen
        Versuchsausgänge. Aus mathematischen Gründen wählt man manchmal $\Omega$ größer.

\begin{Bsp}
        \begin{enumerate}
                \item{Einmaliges Würfeln:\\
                                        $\Omega=\left\{1,\dots,6\right\}$ \quad 
                                        möglich wäre $\Omega=\left\{1,2,3,\dots\right\}$ oder
                                        $\Omega=\mathbb{R}$, \\
                                        \quad \underline{nicht möglich $\Omega=\left\{1,\dots,5\right\}$}}
                \item{n-maliges Würfeln:\\
                                        $\Omega=\left\{1,\dots,6\right\}^n=\left\{\omega=(\omega_1,\dots,\omega_n):
                                        \omega_j \in \left\{1,\dots,6\right\}\right\}$}
        \end{enumerate}
\end{Bsp}

\begin{Bsp}
        Urne mit weißen und schwarzen Kugeln\\
        Man ziehe zwei Kugeln\\
        $\Omega=\left\{(s,s),(s,w),(w,s),(w,w)\right\}$\\
        Interesse Anzahl weiße Kugeln: $\Omega=\left\{0,1,2\right\}$
\end{Bsp}

\begin{Bsp}
        Würfeln bis erste Sechs\\
        Registriere die Anzahl der Würfeldauer\\
        $\Omega=\left\{0,1,2,3,\dots\right\}=\mathbb{N}_0$
\end{Bsp}

\begin{Bsp}
        Lebensdauer eines Bauteils\\
        $\Omega = \left[0,\infty\right)$
\end{Bsp}

\begin{Def}
        \index{Ereignis}
        Eine Teilmenge $A\subseteq\Omega$ heißt Ereignis.\\
        $\omega \in \Omega$ wurde beobachtet:
        \begin{itemize}
                \item{$\omega \in A$, d.h. A ist \underline{eingetreten}}
                \item{$\omega\notin A$, d.h. A ist \underline{nicht eingetreten}}
                                                                                                                                                        \end{itemize}
\end{Def}

\begin{Bsp}
        Sei $\Omega=\left\{1,\dots,6\right\}\quad A=\left\{2,4,6\right\}$\\
        Würfel zeigt "`Drei"' $\curvearrowright$ A ist \underline{nicht} eingetreten!
\end{Bsp}

Die einpunktigen Teilmengen von $\Omega$ heißen \underline{Elementarereignisse!}\\
\index{Ereignis!Elementar-}
Sei $\Omega=\left\{1,\dots,6\right\}$\\
Ereignisse: $\emptyset,\underbrace{\left\{1\right\},\dots,\left\{6\right\},}_{Elementarereignisse}
                                                 \left\{1,2\right\},\left\{1,3\right\},\dots,\Omega$
                                                 
\begin{Bsp}
        Lebensdauer eines Bauteils \quad $A = \left[0,\infty\right)$ \\
        A ist eingetreten $\Leftrightarrow$ Bauteil arbeitet mindestens 100 Zeiteinheiten
        $\Leftrightarrow$ Zum Zeitpunkt 100 ist es noch nicht defekt! Ein Elementarereignis
        $\left\{\omega_0\right\}$ tritt ein $\Leftrightarrow \omega_0$ beobachtet wird.
\end{Bsp}                                                

\underline{Eigenschaften}
\index{Ereignis!Eigenschaften}
\begin{enumerate}
        \item{$\Omega$ tritt stets ein $\curvearrowright$ 
        \underline{sicheres} Ereignis}\index{Ereignis!sicheres}
        \item{$\emptyset$ tritt niemals ein $\curvearrowright$ \underline{unmögliches} Ereignis}\index{Ereignis!unmögliches}
        \item{$A,B \subseteq \Omega;A\cup B$ tritt ein $\Leftrightarrow$ A \underline{oder} B
                                tritt ein}
        \item{$A\cap B$ tritt ein $\Leftrightarrow$ A \underline{und} B treten ein}
        \item{$A^C$ (Komplement)$=\Omega \backslash A$ tritt ein $\Leftrightarrow
                                A$ tritt \underline{nicht} ein}
\end{enumerate}
\underline{Zusammenfassung:}\\
Der Grundraum $\Omega$ besteht aus allen möglichen Versuchsausgängen. Die
Teilmengen treten ein, gdw. ein Element der Teilmenge beobachtet wird.

\subsection{Wahrscheinlichkeitsmaß und Ereignis-$\sigma$-Algebra}

                                                 
Der Zufall unterliegt gewissen Gesetzmäßigkeiten. Ereignisse treten
nicht völlig willkürlich ein, sondern mit gewisser Wahrscheinlichkeit.\\
\underline{Ziel:}\\
Jedem Ereignis $A\subseteq \Omega$ die Wahrscheinlichkeit $\mathbb{P}(A)$ zuordnen.\\
$0\ge \mathbb{P}(A) \ge 1$\\
$\mathbb{P}(A)=0$, d.h. Wahrscheinlichkeit des Eintretens $A$ ist Null.\\
$\mathbb{P}(A)=1$, d.h. $A$ tritt sicher ein

\setcounter{Bsp}{0}
\begin{Bsp}
        $\Omega=\left\{1,\dots,6\right\}$, Würfel sei fair\\
        $A=\left\{1\right\}\Rightarrow \mathbb{P}(A)=\frac{1}{6}$ \quad
        $A=\left\{2,5\right\}\Rightarrow \mathbb{P}(A)=\frac{2}{3}$ \quad
        $\mathbb{P}(\Omega)=1$\\
        Was bedeutet $\mathbb{P}(\left\{2,5\right\})=\frac{1}{3}$ ?
\end{Bsp}

\begin{Bsp}
        Krankheit X: Überlebenschance ist $\frac{1}{2}$ ! Was bedeutet das?
\end{Bsp}

$\mathbb{P}(A)\widehat{=}$ mathematische Abstraktion für den Grenzwert der relativen Häufigkeiten $r_n$\\
\index{Häufigkeit!relative}
n-unabhängige Versuche:
\begin{gather*}
  r_n:=\frac{\sharp\text{ Versuche, bei denen } A \text{ eingetreten ist}}{n}
\end{gather*}
$r_n\rightarrow\mathbb{P}(A)$\\
\underline{Bestimmung von $\mathbb{P}(A)$:}\\
\begin{enumerate}
        \item{Theoretische Überlegung: (z.B. Symmetrie)}
        \item{Statistische Untersuchung}
        \item{Subjektive Annahme aufgrund von Erfahrungen}      
\end{enumerate}

\underline{Ziel:}\\
Abbildung $\mathbb{P} : \mathfrak{R}( \Omega ) \rightarrow \left[ 0,1
\right]$, die jedem Ereignis $A\subseteq\Omega$ die Wahrscheinlichkeit seines Eintretens zuordnet.\\
Welche Eigenschaft sollte $\mathbb{P}$ besitzen?
\begin{enumerate}
        \item{$\mathbb{P}(\emptyset)=0$,\quad $\mathbb{P}(\Omega)=1$}
        \item{$A\cap B=\emptyset \rightarrow \mathbb{P}(A \cup B)\stackrel{\text{!}}{=}
                                \mathbb{P}(A) + \mathbb{P}(B)$ (endliche Additivität)\\
                                $\Rightarrow A_1,\dots,A_n : A_i \cap A_j=\emptyset;i\neq j
                                \Rightarrow \mathbb{P}(\bigcup^n_{j=1}{A_j})=\sum^n_{j=1}{\mathbb{P}(A_J)}$\\
                                endliche Additivität reicht nicht aus.}
\end{enumerate}

\begin{Bsp}
        Würfeln bis erste Sechs\\
        $A_n := \left\{ \text{Erste Sechs erscheint in } (n+1) \text{-ten Versuch}
                                        \right\}; n=0,1,\dots$\\
        \underline{Frage:} Wahrscheinlichkeit von 
        $B := \left\{\text{erste Sechs nach ungerader Wurfzahl}\right\}$ \\
  \begin{gather*}
    \mathbb{P}(B)=\mathbb{P}(\bigcup^\infty_{n=0}{A_{2n}})\stackrel{\text{!}}{=}
                \sum^\infty_{n=0}{\mathbb{P}(A_{2n})}
  \end{gather*}
\end{Bsp}

\begin{Def}
        $\mathbb{P}:\mathfrak{R}(\Omega)\rightarrow \left[0,1\right]$ heißt $\sigma$-additiv, wenn
                für $A_1,A_2,\dots$ mit $A_i \cap A_j \emptyset;i\neq j$, stets
  \begin{gather*}
    {\mathbb{P}(\bigcup^\infty_{j=1}{A_j})=\sum^\infty_{\mathbb{P}(A_j)}}
  \end{gather*}
  folgt.
\end{Def}

\underline{Problem:}
$\Omega$ "`groß"' z.B. $\Omega=\mathbb{R}$, dann existiert keine solche Abbildung
\underline{Lösung:}
Teilsystem $\A\subseteq \mathfrak{R}(\Omega)$ und man
definiert $\mathbb{P}(A)$ nunmehr nur für Mengen $A \in \A$,
d.h. nicht alle Ereignisse besitzen eine Wahrscheinlichkeit ihres Eintretens.\\
$\A$ sollte die "`wichtigen"' Teilmengen enthalten, z.B. alle Intervalle, Punkte usw.\\
\begin{Def}
        $\A$ heißt $\sigma$-Algebra, wenn
        \begin{enumerate}
                \item{$\emptyset,\Omega \in \A$}
                \item{$A \in \A \curvearrowright A^C \in \A$}
                \item{$A_1,A_2,\dots \in \A \curvearrowright \bigcup^\infty_{j=1} A_j
                                        \in\A$}
        \end{enumerate}
\end{Def}

\underline{Eigenschaften:}\\
\begin{enumerate}
        \item{$A_1,A_2,\dots \in\A
                                \quad \curvearrowright \quad 
                                \bigcap^\infty_{j=1}{A_j}
                                \in\A$\\
                                \underline{Beweis:} $A_1,A_2,\dots \quad \curvearrowright \quad
                                A^C_1,A^C_2,\dots \in \A \quad \curvearrowright \quad
                                \bigcup^\infty_{j=1}{A^C_j} \in \A
                                \quad \curvearrowright \\\
                                (\bigcup^\infty_{j=1}{A^C_j})^C \in \A
                                \quad \curvearrowright \quad
                                \bigcup^\infty_{j=1}{A_j} \in \A$; \boxed{}
        \item{$A,B \in \A \quad \curvearrowright \quad
                                A \cup B \in \A$\\
                                \underline{Beweis:} $A_1:=A,A_2:=B,A_3:=\emptyset,A_4:=\emptyset,\dots
                                \quad \curvearrowright \quad
                                \bigcup^\infty_{j=1}{A_j} \in \A
                                \quad \\ \curvearrowright \quad
                                A_1 \cup A_2 = A \cup B$; \qquad\boxed{}}}
\end{enumerate}

\begin{Def}[\underline{Wahrscheinlichkeitsraum($\Omega,\A,\mathbb{P}$)}]
    \index{Wahrscheinlichkeitsraum!Definition}
  \large
        $ \text{Grundraum } \Omega \neq \emptyset$\\
        $\A \subseteq \mathfrak{R}(\Omega) - \sigma\text{-Algebra}$\\
        $\mathbb{P}: \A \rightarrow \left[0,1\right] \text{ mit } 
                \mathbb{P}(\emptyset)=0,\mathbb{P}(\Omega)=1\text{, und }
                 \mathbb{P} \text{ ist } \sigma\text{-additiv!}$
        \normalsize
\end{Def}

\begin{Bsp}
        Modell des Würfelns:\\
  \begin{gather*}
    (\left\{1,\dots,6\right\},\mathfrak{R},\mathbb{P})\\
    \mathbb{P}(A)=\frac{\sharp(A)}{6}
  \end{gather*}
\end{Bsp}
Versuch mir zufälligem Ausgang; \\
Aufgabe : Man finde das passende Modell!
\section{Einfache Eigenschaften von Wahrscheinlichkeitsmaßen}
\index{Wahrscheinlichkeitsmaß!diskret!Eigenschaften}
{ \LARGE
  \begin{gather*}
    (\Omega,\A,\p)
  \end{gather*}
}

\begin{Satz}
\label{satz:11}
        \begin{enumerate}
                \item{Sind $A_1,\dots,A_n \in \A$ disjunkt, so folgt $\p(\bigcup^n_j{A_j})=\sum^n_j{\p(A_j)}$ 
                                        \underline{endliche Additivität}}
                \item{$A \subseteq B \ar \p(A) \leq \p(B)$ \underline{Monotonie}}
                \item{$A \subseteq B \ar \p(B \backslash A)=\p(B)-\p(A)$}
                \item{$\p(A^C)=1-\p(A)$}
                \item{$A_1\subseteq A_2 \subseteq \ldots \ar \p(\bigcup^\infty_{j=1}A_j)=\lim_{n \rightarrow \infty}{\p(A_n)}$
                                                (Stetigkeit von unten)}
                \item{$A_1\supseteq A_2 \supseteq \ldots \ar
                    \p(\bigcap^\infty_{j=1}{A_j})= \lim_{n\rightarrow \infty}{\p(A_n)}$
                                                (Stetigkeit von oben)}
        \end{enumerate}
        \underline{Beweis:}\\
        \begin{enumerate}
                \item{$B_1 := A_1; B_2 := A_2;\ldots;B_n:=A_n;\qquad B_{n+1}:=\emptyset;B_{n+2}:\emptyset;\ldots;\\
                                        B_i\cap B_j=\emptyset;i\neq j;\\
                                        \ar \underline{\sigma-Add.:}\qquad$
                                        \begin{eqnarray*}
                                                \underbrace{\p(\bigcup^\infty_{j=1}{B_j})}_=
                                                &=& \underbrace{\sum^\infty_{j=1}{\p(B_j)}}_=\\
                                                \p(\bigcup^n_{j=1}{A_j})
                                                &=&
                                                \sum^n_{j=1}{\p(A_j)}+
                                                \underbrace{\p(\emptyset)+\ldots}_{=0}
                                        \end{eqnarray*}}
                \item{$\p(B)=\p(A)+\p(B\backslash A)\geq \p(A)$}
                \item{$B=\underbrace{A\cup (B\backslash A)}_{\text{disjunkt}} \ar^{(1)} \qquad
                                        \p(B)=\p(A)+\p(B\backslash A) $\\
                \emph{siehe Abbildung \ref{fig:satz11abb01}}}
          \label{item:satz113}
                \item{$\Omega=A\cup A^C \qquad \p(\Omega)=1=\p(A)+\p(A^C) $}
                \item{$A_0 := \emptyset; B_n:=A_n\backslash A_{n-1} \qquad \text{(Ringe), für}\quad n=1,2,\ldots \\
                                        \ar B_n \text{ sind disjunkt
                                          \& }
                                        \bigcup^\infty_{n=1}{B_n} := A = \bigcup^\infty_{j=1}{A_j}\\
                                        \p(A)=\sum^\infty_{n=1}{\p(B_n)}=\sum^\infty_{n=1}{\p(A_n\backslash A_{n-1})}
                                        \ar^{(3)} \sum^\infty_{n=1}{\left[\p(A_n)-\p(A_{n-1})\right]} \\ 
                                        =\lim_{n\rightarrow\infty}\sum^n_{j=1}{\left[\p(A_j)-\p(A_{j-1})\right]}
                                        =\lim_{n\rightarrow\infty}\left[\p(A_n)-\underbrace{\p(A_0)}_=\right]
                                        =\lim_{n\rightarrow\infty}\p(A_n) $\\
                                        \emph{siehe Abbildung \ref{fig:satz11abb02}}}
                \label{item:satz115}
                \item{$A_1 \supseteq A_2 \supseteq \ldots \qquad A:= \bigcap^\infty{n=1}{A_n}
                                        \ar A_1^C \subseteq A_2^C \subseteq \ldots \\
                                        \bigcup^\infty_{n=1}{A_n^C}
                                        \overbrace{=}^{\text{de Morgan}}(\bigcap^\infty_{n=1}{A_n})^C=A^C        \\
                                        \ar^{(5)} \underbrace{\lim_{n\rightarrow\infty}{\p(A_n^C)}}_{=}= \p(A^C)\\
                                         1 - \lim_{n\rightarrow\infty}{\p(A_n)}=1-\p(A) \qquad$}\boxed{}
        \end{enumerate}
  \begin{figure}
                \noindent
                \begin{minipage}[b]{.46\linewidth}
                        \centering\input{figures/satz11abb01.pictex}%\epsfig{figure=satz11abb01.eps}
                        \caption{zu Satz \ref{satz:11} (\ref{item:satz113})}
                        \label{fig:satz11abb01}
                \end{minipage}\hfill
                \begin{minipage}[b]{.46\linewidth}
                        \centering\input{figures/satz11abb02.pictex}%\epsfig{figure=satz11abb02.eps}
                  \caption{zu Satz \ref{satz:11} (\ref{item:satz115})}
                        \label{fig:satz11abb02}
                \end{minipage}
        \end{figure}
\end{Satz}

\section{Diskrete Wahrscheinlichkeitsmaße}
\label{sec:diskret}
\index{Wahrscheinlichkeitsmaß!diskret}

Experiment: endlich viele der höchstens abzählbar unendlich vielen Werte können auftreten:\\
$\ar \Omega=\left\{\omega_1,\ldots,\omega_n\right\} \quad \text{oder}
\quad \Omega= \left\{\omega_1,\omega_2,\ldots\right\}$\\
\setcounter{Bsp}{0}
\begin{Bsp}
\label{bsp:nmal}
        Würfel n-mal $\ar
        \Omega=\left\{1,\ldots,6\right\}^n=\left\{(x_1,\ldots,x_n):x_j\in
        \left\{1,\ldots,6\right\}\right\}$
\end{Bsp}

\begin{Bsp}
\label{bsp:erste6}
        Würfel bis erste "`Sechs"', Registriere Anzahl Würfe\\
        $\ar \Omega=\left\{0,1,2,\ldots\right\}\cup\left\{\infty\right\}$\\
        Man kann in beiden Fällen stets $\A=\mathfrak{R}(\Omega)$ wählen!
\end{Bsp}

zu Beispiel \ref{bsp:nmal}:\\
\begin{gather*}
  \Omega=\lb\omega_1,\ldots,\omega_n\rb \qquad p_j =
     \p(\lb\omega_j\rb),\quad 1 \leq j \leq N.\\
  p_j \geq 0; 1 =
     \p(\Omega)=\p(\bigcup^n_{j=1}{\omega_j})=
     \sum^n_{j=1}{\p(\lb\omega_j\rb)}=\sum^n_{j=1}{p_j}\\
  A\subseteq \Omega \qquad \p(A)=\p(\bigcup_{w_j\in
     A}{\omega_j})=\sum_{\lb j:\omega_j \in A\rb}{p_j}
\end{gather*}
$\p$ ist Wahrscheinlickeitsmaß $\Rightarrow^{\text{eindeutig}} (p_j)^N_{j=1}$ mit $p_j \geq 0;
 \sum_j^N{p_j}=1$\\
Seien nunmehr $p_j \geq$ mit $\sum^N_j{p_j}=1$ gegeben. Definieren nun:
\begin{Def}
  \begin{gather*}
    \p:\quad \mathfrak{R}(\Omega) \rightarrow \left[0,1\right]
  \end{gather*}
  \text{durch}
  \begin{gather*}
    \p(A) := \sum_{w_j \in A}{p_j} \qquad \rightarrow \p \quad \text{Wahrscheinlichkeitsmaß}
  \end{gather*}
\end{Def}

$\Omega=\lb\omega_1,\ldots,\omega_n\rb \qquad \lb\p: \p\quad\text{Wahrscheinlichkeitsmaß auf }\Omega\rb$\\
$\Leftrightarrow$\\
$\lb(p_j)^N_{j=1}:p_j\geq0;\quad\sum^N_{j=1}{p_j}=1\rb$\\
"`$\Rightarrow$"'$\quad p_j:=\p(\lb\omega_j\rb)\qquad \qquad \qquad$
"'$\Leftarrow$"'$\quad \p(A):=\sum_{\omega_j\in A}{p_j}$

\begin{Bsp}
        $\Omega=\lb1,\ldots,6\rb$\\
        Wahrscheinlichkeitsmaße auf $\Omega$ entsprechen eineindeutig Zahlen $p_1,\ldots,p_6 \geq0;\\ p_1+\ldots+p_6=1$\\
        Würfel(fair): $\qquad p_1=\ldots=p_6=\frac{1}{6}$\\
        Würfel(unfair): $\quad p_1=p_2=p_5=0;p_3=p_4=\frac{1}{4};p_6=\frac{1}{2}$\\
        Frage: $\qquad\qquad\quad \p(\lb1,2,3\rb)=\frac{1}{4} \qquad \p(\lb4,6\rb)=\frac{3}{4}$
\end{Bsp}

zu Beispiel \ref{bsp:erste6}:\\
$\Omega=\lb\omega_1,\omega_2,\ldots\rb \qquad p_j=\p(\lb\omega_j\rb), j=1,2,\ldots \qquad
p_j \geq 0;\quad \sum^\infty_{j=1}{p_j}=1$\\
$\p \Rightarrow (p_j)^\infty_{j=1};p_j\geq0;\sum^\infty_{j=1}{p_j}=1$\\
Seien nun $(p_j)^\infty_{j=1}$ mit diesen Eigenschaften gegeben:\\
\begin{gather*}
  \p(A):=\sum_{\omega_j\in A}{p_j}
\end{gather*}
$\ar \p$ ist ein Wahrscheinlichkeitsmaß auf $\mathfrak{R}(\Omega)$\\

\begin{Bsp}
        $\Omega=\lb1,2,\ldots\rb \qquad p_j:=\frac{1}{2^j};\ar
        p_j\geq0;\ar \sum^\infty_{j=1}{p_j}= \frac{1}{1-\frac{1}{2}}-1=1$\\
        $\p(A):=\sum{j\in A}{\frac{1}{2^j}}$; Erzeugendes Wahrscheinlichkeitsmaß\\
        $A=\lb2,4,6,\ldots\rb \qquad \p(A)=\sum^\infty_{j=1}{\frac{1}{2^{2j}}}=\frac{1}{1-\frac{1}{4}}-1=\frac{1}{3}$\\
        $\p(\lb2,3,4,\ldots\rb)=\sum^\infty_{j=2}{\frac{1}{2^j}}\qquad \text{besser:}\quad
        1-\p(\lb1\rb)=1-\frac{1}{2}=\frac{1}{2}$\\
\end{Bsp}

\underline{Allgemeiner:} $\Omega$ beliebig; $D \subseteq \Omega$ mit $D=\lb\omega_1,\ldots,\omega_n\rb$
oder  $D=\lb\omega_1,\omega_2,\ldots\rb$, so daß $\p(D)=1$. Dann heißt $D$ \underline{diskret}.
\begin{gather*}
  \p(A)=\p(A\cap D)=\sum_{\omega_j \in A}{\p(\omega_j)}
\end{gather*}

\begin{Bsp}
        $\Omega=\mathbb{R} \qquad D=\lb1,2,3,\ldots\rb \qquad \text{Sei } \p(D)=1 \ar \p \text{diskret.}$
\end{Bsp}

\section{Wichtigste diskrete Wahrscheinlichkeitsmaße}
\label{sec:dMasse}

\makeatletter
\renewcommand{\theenumi}{\alph{enumi}}
\renewcommand{\labelenumi}{\theenumi)}
\renewcommand{\p@enumi}{}
\makeatother
\index{Einpunktverteilung}
\index{Zweipunktverteilung}
\index{Gleichverteilung!diskret}
\index{klass. Verteilung|see{Gleichverteilung}}
\begin{enumerate}
        \item{\underline{Einpunktverteilung:}\\
        \[
                \Omega \text{ beliebig; } \omega_0 \in \Omega \text{ fest. }\quad\p(A)= 
                        \left\{\begin{split}
                                1 : & \omega_0 \in A\\
                                0 : & \omega_0 \notin A
                        \end{split}\right.\\
        \]
                $\ar \p$ ist Einpunktverteilung in $\omega_0$ ("`Dirac"'-Maß)\\
                $D:=\lb\omega_0\rb \ar \p(D)=1 \text{ diskretes Wahrscheinlichkeitsmaß} \p(\lb\omega_0\rb)=1;$
                das heißt mit Wahrscheinlichkeit von 1 tritt $\omega_0$ ein: Deterministisches Experiment}
        \item{\underline{Zweipunktverteilung:}\\
                $\Omega=\lb0,1\rb \qquad \p(\lb1\rb)=p,\quad 0\geq p \geq 1 \qquad \p(\lb0\rb)=1-p$}
        \item \underline{Klassische Verteilung bzw. Gleichverteilung}\\
          \begin{gather*}
            \Omega=\vektor
          \end{gather*}
                                Alle Elemtarereignisse sind gleichwahrscheinlich. $\ar p_1=p_2=\ldots=p_n=\frac{1}{N} \\
                                \p(A)=\sum_{\omega_j\in
                                  A}{p_j}=\frac{1}{N}\sum_{\omega_j\in
                                  A}{1}=\frac{1}{N}card(A)= \frac{\sharp(A)}{N}$\\
                                $\p$ nennt man Gleichverteilung auf $\Omega$\\
        \large
        \underline{Merkregel:}
\begin{center}\begin{boxedminipage}[t]{13cm}
                \begin{gather*}
                  \p(A)=\frac{\text{Anzahl der günstigen Fälle für A}}{\text{Anzahl aller möglichen Fälle}}=
                     \frac{\sharp(A)}{\sharp(\Omega)}
                \end{gather*}
\end{boxedminipage}\end{center}
\normalsize
\setcounter{Bsp}{0}
\begin{Bsp}
        Werfe n-mal faire Münze (0,1) $\Omega=\lb0,1\rb^N$ Alle Folgen von 0 und 1 sind gleichwahrscheinlich\\
        $\p(\lb\omega\rb)=\frac{1}{2^N}\quad A:=\lb\text{1. Wurf 0 }\rb \quad   \ar \quad 
        \sharp(A)=2^{N-1}\quad \ar \quad \p(A)=\frac{2^{N-}}{2^N}=\frac{1}{2}$\\
        $B:=\lb\text{Genau k-mal "`Eins"' } \rb \quad \sharp(B)=\binom{n}{k}
        \quad \ar \quad \p(B)=\frac{1}{2^N}\binom{n}{k}$
\end{Bsp}

\begin{Bsp}
        6 aus 49 $\ar \quad \Omega=\blb\vektor[x];x_j\in \lb1,\ldots,49\rb;x_i\neq x_j;i\neq j\brb$\\
        $\sharp(\Omega)=49\cdot48\cdot46\cdot45\cdot44 \qquad$ Tippe 6 Zahlen $t_1,\ldots,t_6$\\
        $A:=\lb\text{6 Richtige}\rb \qquad \sharp(A)=6! \quad \ar \quad
         \p(A)=\frac{6!}{49\cdot\ldots\cdot44}=\frac{1}{\binom{49}{6}}\approx7,151\cdot10^{-8}$
\end{Bsp}

\underline{Beispiele aus der Physik}\\
N Kästen, n Teilchen, $n\leq N$\\
Verteile Teilchen auf die Kästen so, dass alle Verteilungen gleichwahrscheinlich sind.


\makeatletter
\renewcommand{\theenumii}{\Roman{enumii}}
\renewcommand{\labelenumii}{Fall \theenumii:}
\renewcommand{\p@enumii}{Fall }
\makeatother

\begin{enumerate}
        \index{Boltzmann-Statistik@{\emph{Boltzmann}-Statistik}}
        \item \emph{(Boltzmann-Statistik)} \\ Teilchen tragen Namen (unterscheidbar)
                \label{item:fall1}
        \index{Bose-Einstein-Statistik@{\emph{Bose-Einstein}-Statistik}}
        \item \emph{(Bose-Einstein-Statistik)}\\  Teilchen sind anonym
                \label{item:fall2}
        \index{Fermi-Dirac-Statistik@{\emph{Fermi-Dirac}-Statistik}}
        \item \emph{(Fermi-Dirac-Statistik)} \\ Teilchen sind anonym und maximal 1 Teilchen pro Kasten
                \label{item:fall3}
\end{enumerate}

$A:=\lb\text{In n vorgegebenen Kästen $K_1,\ldots,K_n$ befindet sich genau ein Teilchen}\rb$\\ \vspace{0.5cm}
$B:=\lb\text{In keinem Kasten ist mehr als ein Teilchen}\rb$\\
Zu \ref{item:fall1}: \underline{Boltzmann-Statistik} (Teilchen tragen Namen)\\
$\Omega=\blb(a_1,\ldots,a_n);a_j\in \lb1,\ldots,N\rb\brb$\\
$(a_1,\ldots,a_n)$ ist eingetreten $\Leftrightarrow$ Teilchen k im Kasten $a_k ($für $k=1,\ldots,N)$\\
          \begin{gather*}
            \sharp(\Omega)=N^n
          \end{gather*}
Günstig für A: Ist $(K_1,\ldots,K_n)$ und alle Permutationen davon\\
          \begin{gather*}
            \sharp(A)=n! \qquad \Rightarrow \qquad \p(A)=\frac{n!}{N^n}
          \end{gather*}
Man kann $\binom{N}{m}$ Kästen $K_1,\ldots,K_n$ vorher auswählen\\
          \begin{gather*}
            \ar \quad \p(B)=\binom{N}{n}\p(A)=\binom{N}{n}\binom{n!}{N^n}=\frac{N!}{(N-n)!N^n}
          \end{gather*}
Zu \ref{item:fall2}: \underline{Bose-Einstein-Statistik} (Teilchen anonym)\\

%Abbildung

N Kästen $\Leftrightarrow n-1 \quad$ Trennwände (2 äußere Trennwände fest)\\
Alle Anordnungen von $N-1$ Trennwände und n Teilchen\\
          \begin{gather*}
            \Omega=\lb(\omega_1,\ldots,\omega_{N+n-1})\rb \qquad n
               \text{ der } \omega_j \text{ sind Teilchen, N-1 Trennwände}
          \end{gather*}
%Abbildung
$\ar \sharp(\Omega)=(N+n-1)! \qquad \sharp(A)=n!(N-1)! \qquad
\p(A)=\frac{n!(N-1)!}{(N+n-1)!}$\\
$\ar \p(B)=\binom{N}{n}\p(A)=\frac{N!(N-1)!}{(N-m)!(N+n-1)!}$

Zu \ref{item:fall3}: \underline{Fermi-Dirac-Statistik} (Teilchen anonym, max. ein Teil pro Kasten)\\
          \begin{gather*}
            \Omega=\blb(k_1,\ldots,k_n):1\leq k_j \leq N;\quad k_i \neq k_j;\quad i\neq j \brb
          \end{gather*}
$(k_1,\ldots,k_j)$ tritt ein gdw. in den Kästen $k_1,\ldots,k_j$ befindet sich genau ein Teilchen\\
          \begin{gather*}
            \sharp(\Omega)=N\cdot(N-1)\cdot(N-2)\cdot\ldots\cdot(N-n+1)
          \end{gather*}
Günstig für A: $(k_1,\ldots,k_n)$ und alle Permutationen davon $\quad \ar \quad \sharp(A)=n!$\\
          \begin{gather*}
            \ar \quad \p(A)=\frac{n!}{N\cdot\ldots\cdot(N-n+1)}=\frac{1}{\binom{N}{n}};\quad
               \p(B)=\binom{N}{n}\frac{1}{\binom{N}{n}}=1
          \end{gather*}
        \item {\underline{Binominialverteilung:}\\
                \index{Binominialverteilung}
                Modell: In jedem Versuch ist das Resultat entweder Null oder Eins\\
                Die Wahrscheinlichkeit einer "`1"' ist: $p\in \left[0,1\right]$ und "`0"' mit $1-p$\\
                Es gibt $n$ unabhängige Versuche. Wir suchen die Wahrscheinlichkeit $\p(k-mal 1)$\\
          \begin{gather*}
            \p(k-mal 1)\overbrace{=}^{\text{später}}
               \binom{n}{k}p^k(1-p)^{n-k}\\
            \Omega=\lb0,\ldots,n\rb \qquad 0\leq p \leq 1;\\
            \boxed{B_{n,p}(\lb k\rb):=\binom{n}{k}p^k(1-p)^{n-k};\quad k=0,\ldots,n}
          \end{gather*}
          zu zeigen: $B_{n,p}(\lb k\rb)\geq0$ (klar), bleibt zu zeigen:
          \begin{gather*}
            \sum^n_{k=0}{B_{n,p}(\lb k\rb)}=1\\
          \end{gather*}
          Mit dem binomischen Satz gilt:
          \[\sum^n_{k=0}{\binom{n}{k}p^k(1-p)^{n-k}}=(p+(1-p))^n=1^n=1\]\\
          $\ar B_{n,p}$ ist Wahrscheinlichkeitsmaß auf $\Omega$:
          Binominialverteilung mit Parametern n,p.\\
                $n=1 \quad \ar \Omega(\lb0,1\rb)\quad B_{1,p}=1-p\qquad B_{1,p}(\lb1\rb)=p:$ Zweipunktverteilung\\
                $n\geq4 \qquad A=\lb0,1,2\rb\quad B_{n,p}(A)=(1-p)^n+np(1-p)^{1\cdot n}+\binom{n}{2}p^2(1-p)^{n-2}$\\
        }
        \item {\underline{Hypergeometrische Verteilung}\\
                \index{Hypergeometrische Verteilung}
                Lieferung von N-Geräten. Davon sind $M\leq N$ defekt. Entnehme aus der Lieferung zufällig $n\leq N$ Geräte
                und prüfe sie. Gesucht ist die Wahrscheinlichkeit\\
                $\p(\text{Genau m der geprüften Geräte sind defekt})$.
                Insgesamt $\binom{N}{n}$ Möglichkeiten, Geräte zu
                entnehmen. Damit davon genau m defekt sind, m Geräte aus den
                M defekten entnehmen, n-m Geräte aus den N-M nicht defekten.
          \begin{gather*}
            \binom{M}{m}\binom{N-M}{n-m}\text{ Möglichkeiten}
          \end{gather*}
                Ansatz: 
          \begin{gather*}
            \p(\lb m \rb):=\frac{\binom{M}{m}\binom{N-M}{n-m}}{\binom{N}{n}};\quad m=0,\ldots,n
          \end{gather*}
                $\Rightarrow$ Hypergeometrische Verteilung mit Parametern N,M,n.\\
                z.\,z.
          \begin{gather*}
            \sum^n_{m=0}{\binom{M}{m}\binom{N-M}{n-m}}=\binom{N}{N}\quad \text{Übungsaufgabe!}
          \end{gather*}
                $\ar \p$ ist Wahrscheinlichkeitsmaß auf $\Omega(\lb0,\ldots,n\rb)\quad \binom{M}{m}=0 \quad \text{für }m\leq M$\\
        }
        \item {\underline{POISSON-Verteilung:}\\
                \index{Poisson-Verteilung@{\emph{Poisson}-Verteilung}}
                Starten mit $B_{n,p}$ (n Versuche, Erfolgswahrscheinlichkeit p)
          \begin{gather*}
            \text{"`}n\rightarrow\infty,\quad p\rightarrow0\text{"'}
          \end{gather*}
                Gegeben: $\lambda>0 \qquad p_n:=\frac{\lambda}{n} \underset{n\rightarrow\infty}{\rightarrow}0$
                \begin{Satz}
                        \begin{boxedminipage}[t]{9.5cm}
                                \underline{Poissonscher-Grenzwertsatz}\\
                                \index{Poissonscher-Grenzwertsatz@
                                {\emph{Poisson}scher-Grenzwertsatz}}
                          \begin{gather*}
                            \lambda>0,\quad k \in \mathbb{N}_0\\
                                \underset{n\rightarrow\infty}{lim}{B_{n,\frac{\lambda}{n}}
                                  (\lb k\rb)=\frac{\lambda^k}{k!}e^{-\lambda}}
                          \end{gather*}
                        \end{boxedminipage}
                \end{Satz}
                \underline{Beweis: }\\
                \begin{equation*}
                \begin{split}
                        B_{n,\frac{\lambda}{n}}(\lb k\rb) &=
                                                \binom{n}{k}\left( \frac{\lambda}{n}\right) ^k(1-\frac{\lambda}{n})^{n-k}\\
                                                &=
                                                \frac{n!}{(n-k)!k!}\frac{\lambda^k}{n^k}(1-
                                                \frac{\lambda}{n})^n(1-\frac{\lambda}{n})^{-k}\\
                                                &=
                                                \frac{\lambda^k}{k!}\frac{n(n-1)\cdot\ldots\cdot(n-k+1)}
                                                {\underbrace{n\cdot n\cdot\ldots\cdot n}_{k-mal}}
                                                                (1-\frac{\lambda}{n})^n(1-\frac{\lambda}{n})^{-k}\\
                                                &\underset{n\rightarrow\infty}{\rightarrow}
                                                                \frac{\lambda^k}{k!}\cdot\qquad 1 \cdot
                                                                \qquad e^{-\lambda}\cdot\qquad1\\
                                                &=\frac{\lambda^k}{k!}e^{-\lambda}\qquad \boxed{}
                \end{split}
                \end{equation*}
                
                \begin{Def}
                        Die Abbildung $P_\lambda$ mit
                  \begin{gather*}
                    P_\lambda(\lb
                       k\rb):=\frac{\lambda^k}{k!}e^{-\lambda}; \qquad k=0,1,\ldots
                  \end{gather*}
                        heißt Poisson-Verteilung mit Parameter $\lambda>0$\\
                \end{Def}
                \underline{Probe: } $\Omega=\mathbb{N}_0$\\
                zu zeigen: $\sum^\infty_{k=0}{P_\lambda(\lb k \rb)}\overset{\text{?}}{=}1$
  \begin{gather*}
    e^{-\lambda}\sum^\infty_{k=0}{\frac{\lambda^k}{k!}}=e^{-\lambda}\cdot
       e^\lambda=1\\
    B_{n,\frac{\lambda}{n}}(\lb k \rb)
       \underset{n\rightarrow\infty}{\rightarrow}P_\lambda(\lb k \rb)
  \end{gather*}
                Poisson-Verteilung trifft auf, wenn viele Versuche und
                geringe Erfolgswahrscheinlichkeiten herrschen
                \begin{itemize}
                  \item{Telefonzentrale, viele Teilnehmer,
                      Wahrscheinlichkeit, dass einzelner Kunde anruft
                      ist sehr gering\\
                      $\Rightarrow$ ges. Zahl der Anrufe pro Tag ist
                      \emph{Poisson}-Verteilung}
                  \item{Anzahl der Hausbrände pro Jahr}
                \end{itemize}
                \emph{Bemerkung:} $B_{n,p}(\lb k \rb)$ schlecht
                berechenbar für n groß, $P_\lambda$ mit $\lambda:=np$
                ist Approximation für $B_{n,p}$
                \setcounter{Bsp}{0}
                \begin{Bsp}
                  500 Studenten, gesucht ist $\p($Genau k Studenten
                  haben am 24.12. Geburtstag)\\
                  Exakt:
                  \[
                    B_{500,\frac{1}{365}}(\lb k
                    \rb)=\binom{500}{k}\frac{1}{365}^k\binom{364}{365}^{500-k}
                  \]
                  Appr. Lösung:\quad $\lambda = \frac{500}{365}$
                  \[
                    \p_\lambda(\lb k
                    \rb)=\frac{\binom{500}{365}^k}{k!}e^{-\frac{500}{365}}
                  \]
                \end{Bsp}
                \begin{Bsp}
                  $10.000$ Würfe auf ein Ziel mit
                  Trefferwahrscheinlichkeit $\frac{1}{1000},\quad
                  \lambda=10$
                  \[\p_\lambda(\lb k \rb)=\frac{10^k}{k!}e^{-10}\]
                  \[\p_\lambda(\lb 0 \rb)=e^{-10}\approx 0,0000453\hdots\]
                \end{Bsp}
        }
\end{enumerate} 
\section{Stetige Verteilungen}
Bauteil, Lebenszeit ist zufällig, wir registrieren den Zeitpunkt
$t>0$, an dem der Defekt eintritt. $t>0$ ist zuf. reelle Zahl\\
Ziel: diesen Vorgang zu beschreiben\\
Hier: $\Omega=[0,\infty)$\\
Keinen Sinn zu fragen, nach der Wahrscheinlichkeit, dass der
Ausfall zum Zeitpunkt\\ $t_0>0 \quad(t_0=2.000000000\hdots)$
eintritt. $\to$ wäre 0\\
Interesse: $\p($Ausfall im Zeitintervall [a,b])\\
Suchen: $\p([a,b])=$ ?
\makeatletter
\renewcommand{\theenumi}{\arabic{enumi}}
\renewcommand{\labelenumi}{\theenumi)}
\renewcommand{\p@enumi}{}
\makeatother
\begin{Def}
  Eine \emph{Riemann}-integrierbare Funktion $p:\quad \mathbb{R}\to
  \mathbb{R}$ heisst Wahrscheinlichkeitsdichte, wenn gilt:
    \index{Wahrscheinlichkeitsdichte}
  \begin{enumerate}
    \item{$p(x)\geq 0,\quad x \in \mathbb{R}$}
    \item{$\int\limits_{-\infty}^\infty p(x)\; dx$ = 1}
  \end{enumerate}
\end{Def}
\begin{figure}
  \centering\input{figures/def15.pictex}
    \caption{Definition der Wahrscheinlichkeitsdichte}
    \label{fig:def15}      
\end{figure}
\begin{Def}
  Die Wahrscheinlichkeit eines Intervalls $[a,b]$ ist
  \[ \p([a,b]):=\int\limits_a^bp(x)\; dx\]
  p Dichte des Wahrscheinlichkeitsmaß $\p$\index{Dichte|see {Wahrscheinlichkeitsdichte}}
  \begin{itemize}
    \item{$\p([a,b])\geq 0$}
    \item{$\p(\mathbb{R})=\int\limits_{-\infty}^\infty p(x) \; dx = 1$}
  \end{itemize}
\end{Def}
\emph{Problem:} $\Omega=\mathbb{R}$, $\sigma$-Algebra ? $\p([a,b])$
definiert. Was ist $\p(A)=$ ? für $A\in \A$\\
\setcounter{Bsp}{0}
\begin{Bsp}
  \[ p(x) := \left\{ \begin{array}{r@{\quad:\quad}l}
               0 & x \leq 0 \\ \lambda e^{-\lambda x} & x > 0
             \end{array} \right. \qquad \lambda > 0\]
  \[ p(x)\geq 0,\qquad \left. \int\limits_0^\infty\lambda e^{-\lambda x}\; dx
  = -e^{-\lambda x}\right|_0^\infty=1\]
  \[ \p([a,b])= \int\limits_a^b\lambda e^{-\lambda x}\; dx=e^{-\lambda
    a}-e^{-\lambda b} \]
\end{Bsp}
Diskrete Wahrscheinlichkeistmaße sind ungeeignet zur Beschreibung von
Vorgängen, bei denen das Ergebnis eine reelle Zahl ist. Stetige
Wahrscheinlichkeitsmaße:\\[0.5em]
\index{Wahrscheinlichkeitsmaß!stetig}
$\Omega = \mathbb{R}$ \qquad Suchen $\sigma$-Algebra $\A \subseteq
\mathcal{R}(\mathbb{R})$, so dass
\begin{gather*}
  \p:\quad \A \to [0,1]
\end{gather*}
Im Moment ist $\p$ nur auf $\lb[a,b]:\quad a\leq b \rb$ definiert.\\
\emph{Aussage:} $\Omega$ beliebig, $\E \subseteq
\mathfrak{R}(\Omega)$\\
Dann existiert eine kleinste $\E$-umfassende
$\sigma$-Algebra $\A$.\\
\emph{Beweis:} 
\[ \A_0 := \bigcap \lb \underbrace{\A:\quad \A\supseteq
  \E,\quad \A \text{ ist }\sigma\text{-Algebra}}_{\neq
  \emptyset \text{ ,da }\mathfrak{R}(\Omega) \supseteq
  \E}\rb\]
man zeigt: $\A_0$ ist $\sigma$-Algebra; $\A_0\supseteq \E$\\
$\Ll(\mathbb{R})$ kleinste $\mathcal{E}$-umfassende
  $\sigma$-Algebra.\\
Ein stetiges Wahrscheinlichkeitsmaß $\p$ lässt sich eindeutig von $\E$ auf
  $\mathcal{L}(\mathbb{R})$ fortsetzen. $\to
  (\mathbb{R},\Ll(\mathbb{R}),\p)$ mit $\p$ erzeugt von der
  Dichte p
\subsection*{Eigenschaften stetiger Wahrscheinlichkeitsmaße}
\index{Wahrscheinlichkeitsmaß!stetig!Eigenschaften}
\begin{enumerate}
  \item{Da $p(x) \geq 0 \to \int\limits_a^bp(x)\; dx \geq 0 \to
      \p([a,b])\geq 0$}
  \item{$\p(\mathbb{R})=\int\limits_{-\infty}^\infty p(x)\; dx=1$}
  \item{$\p(\lb a\rb)=\int\limits_a^ap(x)\; dx=0$}
  \item{$\p\left(\left(a,b\right)\right)=\p([a,b])-\p(\lb a\rb) -
      \p(\lb b\rb)=\p([a,b])$}
  \item{Sei $p(x)>0$\quad auf $[a,b] \to \int\limits_a^bp(x)\; dx >
      0$}
  \item{Sei $p(x)=0$ für $x \not\in[a,b] \to \p([a,b])=1$}
\end{enumerate}
\subsection*{Wichtige Stetige Verteilungsgesetze}
\begin{description}
    \index{Gleichverteilung!stetig|(}
  \item[1.) Gleichverteilung auf $I=(a,b)$]{Experiment: Zufälliges
      Ziehen einer Zahl aus $[a,b]$. Wahrscheinlichkeit dass ein
      Intervall eintritt hängt nur von der Länge, nicht aber von der
      Lage des Intervalls ab.
      \[ p(x)= \lb \begin{array}{r@{\quad:\quad}l}
                          \frac{1}{\left|I\right|} & x \in I \\
                          0                        & \mbox{sonst}
                   \end{array} \right. \quad ; \quad\left|I\right|=b-a
                          \]
      \begin{itemize}
        \item{$p(x)=0$}
        \item
        \begin{gather*}
          \int_{-\infty}^\infty p(x)\,dx=\int_a^bp(x)\,dx=
             \frac{1}{\left|I\right|}\int_a^bdx=\frac{b-a}{b-a}=1
        \end{gather*}
      \end{itemize}
      $[\alpha,\beta]\subseteq [a,b]$
    \begin{gather*}
      \p([\alpha,\beta])=\int_\alpha^\beta
      p(x)\,dx=\frac{1}{ba}\int_\alpha^\beta
      dx=\frac{\beta-\alpha}{b-a}=1
    \end{gather*}
      $\to\quad$ Wahrscheinlichkeit ist proportional zur Länge von
      $[a,b]$\\
      \begin{figure}[h]
	  \centering\input{figures/gv01.pictex}%}
	  \caption{Beispiel zur Gleichverteilung}
         \label{fig:gv01}
      \end{figure}
      \setcounter{Bsp}{0}
      \begin{Bsp}
        Straßenbahn fährt alle 15 Minuten. man gehe zufällig zur
        Strassenbahnhaltestelle. Wie groß ist die Wahrscheinlichkeit,
        mehr als 5 Minuten zu warten?\\
      \begin{figure}[h]
	  \centering\input{figures/gv02.pictex}%}
	  \caption{2. Beispiel zur Gleichverteilung}
         \label{fig:gv02}
      \end{figure}%
	Wahrscheinlichkeit ist $\frac{10}{15}=\frac{2}{3}$
      \end{Bsp}
      }
      \item[2.) n-dimenstionale Gleichverteilung]{ Sei $p:\quad
          \mathbb{R}^n \to \mathbb{R}$, Wahrscheinlichkeitsdichte,
          dann gilt:
          \begin{itemize}
            \item{$p(x)\geq 0;\quad x \in \mathbb{R}^n$}
            \item{$1=\int_{\mathbb{R}^n}p(x)\,dx=\int_{-\infty}^\infty\cdots\
                   Int_{-\infty}^\infty p(x_1,\ldots,x_n)\,dx_1,\ldots,x_n$}
          \end{itemize}
          $A\subset \mathbb{R}^n\quad$ Quader oder Kugel oder
          ähnliches
        \begin{gather*}
          \p(A):=\int_Ap(x)\,dx\quad\mbox{Wahrscheinlichkeitsmaß}
        \end{gather*}
          \setcounter{Bsp}{0}
          \begin{Bsp}
            $p(x_1,x_2):=\lb \begin{array}{c@{\quad :\quad}l}
                               x_1 + x_2 & 0 \leq x_1,x_2 \leq 1 \\
                               0         & \mbox{sonst}
                             \end{array}\right.$\\
            $p:\quad \mathbb{R}^2 \to \mathbb{R}$\\
            \begin{enumerate}
              \item{$\p(x_1,x_2)\geq 0$}
              \item{\begin{eqnarray*}
                     \int_{-\infty}^\infty\!\int_{-\infty}^\infty
                     p(x_1,x_2)\,dx_1\,dx_2
                     &=& \int_0^1\!\int_0^1 (x_1+x_2)\,dx_1\,dx_2\\
                     &=& \int_0^1\left[\frac{1}{2}x_1^2+x_1x_2\right]_0^1\,dx_2\\
                     &=& \int_0^1\left(\frac{1}{2}+x_2\right)\,dx_2\\
                     &=& \frac{1}{2}+\frac{1}{2}=1 \to p\quad \mbox{ist Wahrscheinlichkeitsmaß!}
                   \end{eqnarray*}}
	     \end{enumerate}
            \begin{gather*}
              A:=\lb(x_1+x_2):\quad x_1 \leq x_2\rb
            \end{gather*}
                   \begin{figure}[htbp]
                     \begin{center}
                        \input{figures/gv03.pictex}
                        \caption{Fläche A}
                        \label{fig:gv03}
                     \end{center}
                   \end{figure}
                   \begin{eqnarray*}
                     \p(A)&=&\int_{A \atop 0\leq x_1,x_2\leq
                     1}(x_1+x_2)\,dx_1\,dx_2 \\
                     &=&
                     \int_0^{x_1}\!\int_0^{x_2}(x_1+x_2)\,dx_1\,dx_2\\
                     &=& \int_0^13\frac{x_2^2}{2}\,dx_2=\frac{1}{2}
                   \end{eqnarray*}
             \end{Bsp}
                   Sei nun $B \subseteq \mathbb{R}^n\quad$ Quader,
                   Kugel oder ähnliches\\
                   $\vol_n(B) \quad$ n-dimensionale Volumen von B\\
                   ($n=1 \to $ Länge; $n=2 \to$ Fläche; $n=3 \to$
                   Volumen $\ldots$\\
                   $p:\quad \mathbb{R}^n\to\mathbb{R}$
                   \[ p(x):= \left\{\begin{array}{c@{\quad : \quad}l}
                               \frac{1}{\vol_n(B)} & x \in B\\
                               0                   & \mbox{sonst}
                             \end{array}\right. \]
                   \begin{figure}[h]
                     \begin{center}
                        \input{figures/gv04.pictex}
                        \caption{2-dimensionale Gleichverteilung}
                        \label{fig:gv04}
                     \end{center}
                   \end{figure}
                   p Wahrscheinlichkeitsdichte?\\
                   \begin{enumerate}
                     \item{$p(x)\geq 0$}
                     \item{$\int_{\mathbb{R}^n}p(x)\,dx=\int_B\frac{1}{\vol_n(B)}\,dx=\frac{\vol_n(B)}{\vol_n(B)}=1$}  
                   \end{enumerate}
                   $A\subseteq B$
                   \[
                   \p(A)=\int_Ap(x)\,dx=\frac{1}{\vol_n(B)}\int_Adx=\mbox{\fbox{$\frac{\vol_n(A)}{\vol_n(B)}$}}\]
                   \[ \to \mbox{\emph{n-dimensionale Gleichverteilung
                       auf B von }} (A\subseteq B)\]
\setcounter{Bsp}{0}
\begin{Bsp}
  Zwei Freunde treffen zufällig zwischen 12-13 Uhr auf dem Marktplatz
  ein. Jeder wartet nach Eintreffen noch 20 Minuten, dann geht er. Wie
  groß ist die Wahrscheinlichkeit, dass sich beide treffen?
  $t_1$ sei Zeitpunkt Freund$_1;\quad t_2$ Zeitpunkt Freund$_2$
  treffen ein.\\
  $(t_1,t_2)$ gleichverteilt auf $[12,13] \times [12,13]$\\
  Treffen $\Leftrightarrow \quad t_2 \leq t_1 + \frac{1}{3}$ oder $t_1
  \leq t_2 + \frac{1}{3} \quad \Leftrightarrow \quad
  \left|t_1-t_2\right| \leq \frac{1}{3}$\\
  $\p(A)=1-\frac{2}{9}-\frac{2}{9}=\frac{5}{9}$
                   \begin{figure}[h]
                     \begin{center}
                        \input{figures/gv05.pictex}
                        \caption{Fläche für das Treffen}
                        \label{fig:gv05}
                     \end{center}
                   \end{figure}
\end{Bsp}
\begin{Bsp}
  Kugel mit Radius $R>0\quad$ Gleichverteilung auf dieser Kugel
  \[ \p(A)=\frac{\vol_3(A)}{\frac{4}{3}\pi\mathbb{R}^3} \]
  $0<r<R$
  \[ A=\lb(x,y,z):\quad x^2+y^2+z^2\leq r^2\rb \]
  \[ \Rightarrow \quad \p(A)=\frac{r^3}{R^3} \]
\end{Bsp}
\begin{Bsp}
  \emph{Nadeltest von Buffon (\symbol{126}1740)}\\
  lineares Papier und Nadel der Länge $a<1$\\
%Abbildung einfügen
%\begin{figure}
%  \centering\input{figures/nadel01.pictex}
%    \caption{Definition der Wahrscheinlichkeitsdichte}
%    \label{fig:def15}      
%\end{figure}
  Gesucht ist die Wahrscheinlichkeit, dass die Nadel eine Gerade
  (Linie) schneidet.\\[0.2cm]
  \begin{tabular}{crr}
%Abbildung einfügen 
    & \begin{tabular}{l}
        x Mittelpunkt \\
        $\theta$ Winkel
      \end{tabular}
    & \begin{tabular}{c}
        $0\leq x \leq 1$ \\
        $-\frac{\pi}{2} \leq \theta \leq +\frac{\pi}{2}$\\
        $\theta \in [-\frac{\pi}{2},\frac{\pi}{2}]$
      \end{tabular}
  \end{tabular}\\[0.2cm]
  Zufälliges Werfen der Nadel bedeutet:\\
  Wähle Punkt $(x,\theta) \in [0,1]\times
  [-\frac{\pi}{2},\frac{\pi}{2}]$ entsprechend der
  Gleichverteilung. \\
  Nadel schneidet untere Gerade
  \begin{gather*}
    \Leftrightarrow \quad x \leq \frac{a}{2}\cos\theta
  \end{gather*}
  Nadel schneidet untere Gerade
  \begin{gather*}
    \Leftrightarrow \quad 1-x \leq \frac{a}{2}\cos\theta
  \end{gather*}
%Abbildung einfügen
  \[
  \p(A)=\frac{\vol_2(A)}{\pi}=\frac{1}{\pi}2\int_{-\frac{\pi}{2}}^\frac{\pi}{2}\frac{a}{2}\cos\theta\,d\theta
  =
  \left.\frac{a}{\pi}\sin\theta\right|_{-\frac{\pi}{2}}^\frac{\pi}{2}=\frac{2a}{\pi}\]
  zum Beispiel für $a=\frac{\pi}{4} \to \p(A)=\frac{1}{2}$
  \[r_n := \frac{\mbox{Anzahl der Schritte bei n
  Versuchen}}{n}\quad\mbox{(Relative Häufigkeit)}\]
  \[ r_n \to_{n \to \infty} \quad \to \quad \pi \approx \frac{2a}{r_n}
  \]
  \begin{table}[h]
  \centering
  \begin{tabular}{|l|c|c|c|c|}\hline
                            & a   & n      & Anzahl der Schritte & $\pi$\\ \hline
    \emph{Wolf} (1850)      & 0.8 & 5000   & 2532                & 3.160\\ \hline    
    \emph{Smith} (1855)     & 0.6 & 3204   & 1218                & 3.157\\ \hline
    \multicolumn{1}{|c|}{\vdots} & \vdots & \vdots & \vdots & \vdots  \\ \hline
    \emph{Lazzerini} (1913) & $\frac{5}{6}$ & 3408   & 1808      & 3.142\\ \hline
    \emph{Reinhard} (1925)  & 0.5419        & 2520   & 859       & 3.179\\ \hline
  \end{tabular}
	\caption{Versuche zur Bestimmung der Kreiszahl Pi}	
  \end{table}
\end{Bsp}}
    \index{Gleichverteilung!stetig|)}
    \item[3.) Normalverteilung (\emph{Gau"s-Verteilung})]{ .
        \index{Gauß-Verteilung@{\emph{Gauß}-Verteilung}|see{Normalverteilung}}
        \index{Normalverteilung}
        \begin{Satz}
            \[ \int\limits_{-\infty}^\infty e^{-\frac{x^2}{2}} \; dx=\sqrt{2 \pi} \]
        \end{Satz}
        \underline{Beweis:}
        \begin{align*}
            a :&= \int\limits_{-\infty}^\infty e^{-\frac{x^2}{2}} \;dx  \\
            a^2 &= \left( \int\limits_{-\infty}^\infty e^{-\frac{x^2}{2}} \;dx \right)
            \left( \int\limits_{-\infty}^\infty e^{-\frac{y^2}{2}} \;dy \right) \\
            &= \int\limits_{-\infty}^\infty \int\limits_{-\infty}^\infty
            e^{-\frac{1}{2}(x^2+y^2)} \;dx\;dy \\
            x &= r \cos \theta &0<r<\infty \\
            y &= r \sin \theta &0 \leq \theta < 2 \pi \\
            dx\;dy &= r\;dr\;d\theta\\
            \to a^2 &= \int\limits_0^\infty \int\limits_0^{2 \pi}
            e^{-\frac{r^2}{2}} r\;dr\;d\theta 
            = 2\pi \int\limits_0^\infty r e^{-\frac{r^2}{2}}\;dr \\
            &= 2\pi \left[ -e^{-\frac{r^2}{2}} \right]_0^\infty = 2\pi \\
            \to a &= \sqrt{2\pi}\qquad\boxed{}\\
        \end{align*}
        \begin{center}\begin{boxedminipage}[t]{9.5cm}\Large
            \[ a,x \in \mathbb{R};\quad \sigma > 0 \]
            \[  \p_{a,\sigma^2}(x):=\frac{1}{\sqrt{2\pi}\sigma}
                e^{\frac{-\frac{1}{2}(x-a)^2}{\sigma^2}}\]
        \end{boxedminipage}\end{center}
        \begin{figure}
            \centering\input{figures/nv01.pictex}
            \caption{Normalverteilung}
            \label{fig:nv01}      
        \end{figure}
        \underline{Behauptung:}\\
        $\p_{a,\sigma^2}$ ist eine Wahrscheinlichkeitsdichte!\\
        $\p_{a,\sigma^2}(x)\geq 0$ klar, da $e^x >0; \forall x \in \mathbb{R}$\\
        $\int\limits_{-\infty}^\infty \frac {1}{\sqrt{2\pi} \sigma}
        e^{\frac{-\frac{1}{2}(x-a)^2}{\sigma^2}} $\\
        Substitution: $y := \frac{x-a}{\sigma} \quad dx = \sigma\;dy$\\
        \[ \frac{1}{\sqrt{2\pi}\sigma} \int_{-\infty}^\infty e^{-\frac{y^2}{2}}
        \;\sigma\;dy=\frac{1}{\sqrt{2\pi}} \underbrace{\int_{-\infty}^\infty
        e^{-\frac{y^2}{2}}\;dy}_{=\sqrt{2\pi}}=1 \]
        \begin{Def}
            $\mathcal{N}(a,\sigma^2)$ hei"st das von $\p_{a,\sigma^2}$ erzeugte
            Wahrscheinlichkeitsmaß, d.h. 
            \[ \mathcal{N}(a,\sigma^2)([\alpha,\beta])=\frac{1}{\sqrt{2\pi} \sigma}
            \int\limits_\alpha^\beta
            e^{\frac{-\frac{1}{2}(x-a)^2}{\sigma^2}}\;dx \]
            $\mathcal{N}(a,\sigma^2)$ Normalverteilung mit Erwartungswert
            $a\in \mathbb{R}$ und Varianz $\sigma^2>0$\\
            $\mathcal{N}(0,1)$ hei"st Standardnormalverteilung und hat die Dichte
            $\frac{e^{-\frac{x^2}{2}}}{\sqrt{2\pi}}$ (Wichtigstes Wahrscheinlichkeitsmaß!)
        \end{Def}
    }
    \item[4.) Exponentialverteilung]{.\index{Exponentialverteilung}\\
        $\lambda>0;\quad p(x) := \left\{ \begin{array}{l@{\quad:\quad}l}
            \lambda e^{-\lambda x} & x > 0 \\
            0 & x \leq 0               \end{array}\right.$\\[0.2cm]
        \underline{Behauptung:}\\
        $p$ ist eine Wahrscheinlichkeitsdichte:
        \begin{enumerate}
            \item{$p(x) \geq 0$ (klar)}
            \item{$\int\limits_{-\infty}^\infty p(x)\;dx = 
            \int\limits_0^\infty \lambda e^{-\lambda x}\;dx=
            \lambda\left[ \frac{e^{-\lambda x}}{-\lambda}\right]_0^\infty=1$}
        \end{enumerate}
        Das erzeugte Wahrscheinlichkeitsmaß $E_\lambda$ hei"st Exponentialverteilung
        mit Parameter $\lambda>0$\\
        \[ E_\lambda([\alpha,\beta])=\int\limits_\alpha^\beta \lambda
        e^{-\lambda x}\;dx=\left[ -e^{-\lambda x}\right]_\alpha^\beta
        =e^{-\lambda\alpha}-e^{-\lambda\beta}\quad (\alpha \geq 0) \]
        $E-lambda$ wird verwendet zur Beschreibung von Lebensdauerverteilungen
        (ohne Altern).
        \setcounter{Bsp}{0}
        \begin{Bsp}
            Lebensdauer eines Bauteils sei Exponentialverteilt mit Parameter
            $\lambda = \frac{1}{2}$. Wie gro"s ist die Wahrscheinlichkeit, dass
            das Bauteil zum Zeitpunkt $t>o$ noch funktioniert?
            \[ A := \left\{\text{arbeitet zum Zeitpunkt } t\right\}=
            \left\{\text{Ausfall nach }t\right\}
            =(t,\infty)\]
            \[\p(A)=E_\frac{1}{2}\left((t,\infty)\right)=e^{-\frac{t}{2}}-0 !\]
        \end{Bsp}
    }
\end{description}
\section{Bedingte Wahrscheinlichkeiten}
\index{Bedingte Wahrscheinlichkeiten}
    Urne mit 4 wei"sen und 3 schwarzen Kugeln. Man ziehe 2 Kugeln ohne Zurücklegen.
    $\Omega=\left\{(s,s),(s,w),(w,s),(w,w)\right\}$\\
    Wir suchen z.B. $\p(\left\{(s,w)\right\})=$ ?\\
    $A := \left\{\text{Erste Kugel schwarz}\right\}
    =\left\{(s,s),(s,w)\right\}$\\
    $B := \left\{\text{Zweite Kugel weiß}\right\}
    =\left\{(w,w),(s,w)\right\}$\\
    Was ist berechenbar?
    \begin{enumerate}
        \item{$\p(A)=\frac{3}{7}$}
        \item{$\p(B)$ unter der Bedingung, dass A eingetreten ist $=\p(A|B)$}
    \end{enumerate}
    \[\p(\left\{(s,w)\right\})=\p(A)\cdot\p(B|A)
    =\frac{3}{7}\cdot\frac{2}{3}=\frac{2}{7}\]
    \begin{Def}
        Sei $(\Omega,\A, \p)$ ein Wahrscheinlichkeitsraum;$\quad B \in \A$
        mit $\p(B)>0$, dann ist
        \begin{center}\begin{boxedminipage}[c]{7.5cm}\Large
            \[\p(A|B):=\frac{\p(A\cap B)}{\p(B)}\]
        \end{boxedminipage}\end{center}
        die Wahrscheinlichkeit des Eintretens von A, unter der Bedingung, dass
        B bereits eingetreten ist.
    \end{Def}
    \setcounter{Bsp}{0}
    \begin{Bsp}
        $E_\lambda([0,5])|[2,\infty])$\\
        Wahrscheinlichkeit, dass ein Teilchen vor Erreichen des Alters 5 stirbt,
        unter der Bedingung, mindestens 2 Jahre alt geworden zu sein:
        \[ \frac{E_\lambda([0,5]\cap[2,\infty])}{E_\lambda([2,\infty])}
        =\frac{e^{-2\lambda}-e^{-5\lambda}}{e^{-2\lambda}}=1-e^{-3\lambda}=
	E_{\lambda}([0,3])\]
        ist die Wahrscheinlichkeit, dass ein neugeborenes Teilchen höchstens 3
        Jahre alt wird. (nicht altert)
    \end{Bsp}
    \begin{Satz}
        \begin{enumerate}
            \item{Die Zuordnung $ A \to \p(A|B)$ ist Wahrscheinlichkeitsmaß auf $(\Omega,\A)$}
            \label{satz:141}
            \item{$\p(B|B)=1;\quad \p(B^C|B)=0$}
        \end{enumerate}
    \end{Satz}
    \underline{Beweis:\\}
    \begin{enumerate}
        \item{$\p(\emptyset|B)=\frac{\p(\emptyset\cap B)}{\p(B)}=0\\
            \p(\Omega|B)=\frac{\p(\Omega\cap B)}{\p(B)}=1\\
            A_1,A_2,\ldots$ disjunkt $\to$\\
            \begin{align*}
                \p(\bigcup_{j=1}^\infty A_j |B) 
                &= \frac{\p(\bigcup_{j=1}^\infty A_j \cap B)}{\p(B)}
                = \frac{\p(\bigcup_{j=1}^\infty (A_j \cap B))}{\p(B)}\\
                &= \frac{\sum_{j=1}^\infty \p(A_j \cap B)}{\p(B)}
                = \sum_{j=1}^\infty \p(A_j | B)\\
                &\to \sigma-\text{Addidivität} \to (1)
            \end{align*}
        }
        \item{\[\p(B|B)=\frac{\p(B\cap B)}{\p(B)}=1\]
            \[\p(B^C|B)=\frac{\p(B^C\cap B)}{\p(B)}=\frac{\p(\emptyset)}{\p(B)}=0\]
        }
    \end{enumerate}   
    \begin{Bsp}
        Gegeben sind zwei Urnen $U_1$ und $U_2$. In der ersten Urnen befinden sich
        zwei weiße und eine schwarze Kugel, in der zweiten eine weiße und zwei
        schwarze Kugeln, wobei die Wahrscheinlichkeit, dass die erste Urne gezogen
        wird gleich $\frac{1}{3}$, die der zweiten gleich $\frac{2}{3}$ ist.
        Als erstes wird eine Urne ausgewählt und dann eine Kugel
        aus dieser Urne gezogen. Gesucht ist die Wahrscheinlichkeit, dass die
        gezogene Kugel weiß ist.\\
        $\Omega=\left\{w_1,w_2,s_1,s_2\right\}$ mit
        $w_1$ ist aus $U_1$\\
        $U_1=\lb w_1,s_1\rb\qquad U_2=\lb s_2,w_2\rb\qquad W=\lb w_1,w_2\rb\qquad
        S=\lb s_1,s_2\rb\\
        \p(U_1)=\frac{1}{3}\qquad \p(U_2)=\frac{2}{3} \qquad
        \p(W|U_1)=\frac{2}{3}\qquad \p(W|U_2)=\frac{1}{3}$\\
        Wir suchen $\p(W)$\\
        $\Omega=U_1\cup U_2$\\
        $\p(W)=\p(U_1)\cdot\p(W|U_1)+\p(U_2)\cdot\p(W|U_2)
        =\frac{1}{3}\cdot\frac{2}{3}+\frac{2}{3}\cdot\frac{1}{3}=\frac{4}{9}$\\
    \end{Bsp} 
    \begin{Bsp}
        Nun umgekehrte Fragestellung:\\
        Wir haben weiß beobachtet. Wie groß ist die Wahrscheinlichkeit, dass die
        gezogene Kugel aus Urne $U_1$ stammt?\\
        Wir suchen also die Wahrscheinlichkeit $\p(U_1|W)$\\
        Am Anfang vorgegebene Wahrscheinlichkeiten für $U_1,U_2$\\
        $\qquad\to$ \emph{a priori} Wahrscheinlichkeit (in unserem Fall
        $\frac{1}{3},\frac{2}{3}$)\\
        \index{a priori}\index{priori|see{a priori}}
        Versuch durchgeführt und weiß beobachtet:\\
        $\p(U_1|W)\qquad \p(U_2|W) \qquad\to $\emph{a posteriori} 
        Wahrscheinlichkeit\\
        \index{a posteriori}\index{posteriori|see{a posteriori}}
        \underline{Allgemeine Situation:}\\
        $\Omega=\bigcup\limits_{j=1}^n B_j$ (disjunktiv)\\
        $\p(B_1),\ldots,\p(B_n)$ a priori Wahrscheinlichkeiten\\
        $A \in \A$ eingetreten\\
        $\p(B_1|A),\ldots,\p(B_n|A)$ a posteriori Wahrscheinlichkeiten
    \end{Bsp}
    \begin{Satz}[Formel über die totale Wahrscheinlichkeit]
        \index{totale Wahrscheinlichkeit}
        \index{Formel über die totale Wahrscheinlichkeit}
        $(\Omega,\A,\p),\quad B_1,\ldots,B_n \in \A$\\
        $\p(B_j)>0,\quad$ disjunkt und $\bigcup_{j=1}^\infty B_j := \Omega$\\
        \begin{center}\begin{boxedminipage}[c]{7.5cm}\Large
            \[\p(A)=\sum_{j=1}^n \p(B_j)\cdot \p(A|B_j)\]
        \end{boxedminipage}\end{center}
    \end{Satz}
    \underline{Beweis:}\\
    $\sum_{j=1}^n \p(B_j)\cdot \p(A|B_j)=\sum_{j=1}^n \p(B_j)\cdot
    \frac{\p(A\cap B)}{\p(B_j)}
    =\sum_{j=1}^n \p(\underbrace{A\cap B_j}_{\text{disjunkt}})
    =\p(\bigcup_{j=1}^n(A\cap B_j))\\
    =\p(A \cap \underbrace{\bigcup\nolimits_{j=1}^n B_j}_{
    \text{nach Vorr.}=\Omega})=\p(A)\qquad\boxed{}$
    \begin{Satz}[Formel von Bayes]
        \index{Formal von Bayes@{Formel von \emph{Bayes}}}
        \begin{center}\begin{boxedminipage}[c]{10cm}\Large
            \[\p(B_j|A)=\frac{\p(B_j)\cdot\p(A|B_j)}
            {\sum_{i=1}^n\p(B_i)\cdot\p(A|B_i)}\]
        \end{boxedminipage}\end{center}
    \end{Satz}
    \underline{Beweis:}\\
    $\p(A)=\sum_{j=1}^n\p(B_j)\p(A|B_j)\\
    \to \text{Rechte Seite}=\frac{\p(B_j)\p(A|B_j)}{\p(A)}
    =\frac{\p(B_j)\cdot\frac{\p(A\cap B_j)}{\p(B_j)}}{\p(A)}
    =\frac{\p(A\cap B_j)}{\p(A)}=\p(B_j|A)\qquad\boxed{}$\\
    \underline{Bemerkungen:}\\
    \begin{enumerate}
        \item{Kennt man bereits $\p(A)$, so vereinfacht sich obige Formel:
            \[\p(B_j|A)=\frac{\p(B_j)\p(A|B_j)}{\p(A)}\]}
        \item{$\Omega=B\cup B^C$
            \begin{center}\begin{boxedminipage}[c]{12cm}\Large
                \[\p(B|A)=\frac{\p(B)\p(A|B)}{\p(B)\p(A|B)+\p(B^C)\p(A|B^C)}
                \]
            \end{boxedminipage}\end{center}}
    \end{enumerate}
    \begin{Bsp}[TBC-Test]
        Person hat TBC $\to$ Test ist in 96\% der Fälle positiv\\
        Person hat kein TBC $\to$ Test ist in 94\% der Fälle negativ\\
        $0.4\%$ der Bevölkerung hat TBC.\\
        Wir suchen Wahrscheinlichkeit, dass eine zufällige Person mit positiven
        Test wirklich TBC hat?\\
        $A:=\{$Test positiv$\};\quad B:=\{$Person hat TBC$\}$
        Wir suchen $\p(B|A)$!\\
        $\p(B)=0.004 \quad\to\quad\p(B^C)=0.996\\
        \p(A|B)=0.96;\qquad \p(A|B^C)=0.06\\
        \p(B|A)=\frac{\p(B)\p(A|B)}{\p(B)\p(A|B)+\p(B^C)\p(A|B^C)}
        =\frac{0.004\cdot 0.96}{0.004\cdot 0.96+0.996\cdot 0.06}=0.06$\\
        Nur 6\% der positiv getesteten Personen haben TBC.
    \end{Bsp}

    %\subsection*{Veranschaulichung von bedingten Wahrscheinlichkeiten}
    %Anschauliche Abbildung???

    \section{Unabhängigkeit von Ereignissen}
    \index{Unabhängigkeit|(}
    \underline{Ziel:} Mathematische Formulierung der Unabhängigkeit von 
    Ereignissen\\
    \begin{Bsp}
        2-maliges Würfeln\\
        $\Omega=\lb(i,j):1\leq i,j\leq 6\rb\\
        \p$ Gleichverteilung\\
        $A:=\lb\text{1. Wurf gerade Zahl}\rb\\
        B:=\lb\text{2. Wurf ist $\geq$ 3}\rb$\\
        Intuitiv sind A und B unabhängig, d.h. Eintreten von B ist unabhängig
        davon, ob A eintritt;
        \[\p(B|A)\stackrel{!}{=}\p(B)\]
    \end{Bsp}
    \begin{Bsp}
        Graswachstum und Mondphasen abhängig oder unabhängig?\\
        $\p($Gras wächst pro Tag $\leq$ 1 cm $|$ Vollmond$)
        =\p($Gras wächst pro Tag 1 cm$)$\\
        B unabhängig von A, falls $\p(B|A)=\p(B)$\\
        \[\p(B)=\frac{\p(A\cap B)}{\p(A)}=\p(B|A)\quad\to\quad
        \p(A\cap B)=\p(A)\cdot\p(B)\]
    \end{Bsp}
    \begin{Def}
        $(\Omega,\A,\p)$ Wahrscheinlichkeitsraum,$\quad A,B\in\A$\\
        A und B heißen stochastisch unabhängig, wenn gilt:
        \[\p(A\cap B)=\p(A)\cdot\p(B)\]
    \end{Def}
    \begin{Satz}
        \begin{enumerate}
            \item{$A$ unabhängig $B \Leftrightarrow B$ unabhängig $A$}
            \item{$\emptyset,\Omega$ sind  unabhängig von jedem $A\in\A$}
            \item{$A,B$ unabhängig$\to A,B^C$ unabhängig $\to A^C,B$ unabhängig}
        \end{enumerate}
    \end{Satz}
    \underline{Beweis:}
        \begin{enumerate}
            \item{$\p(A\cap\emptyset)=\p(\emptyset)=0=\p(\emptyset)\cdot\p(A)\\
                    \p(A\cap\Omega)=\p(A)=1\cdot\p(A)=\p(\Omega)\cdot\p(A)$}
            \item{$\p(A\cap B^C)=\p(A)\cdot\p(B^C)=\p(A)(1-\p(B))
                    =\p(A)-\p(A)\cdot\p(B)=\p(A)-\p(A\cap B)
                    =\p(A\setminus A\cap B)=\p(A\cap B^C)$}
        \end{enumerate}
    Wir wissen: $B^C,A$ unabhängig $\to B^C,A^C$ unabhängig (analog zu
    obigem Beweis!)\\
    \begin{Bsp}
        Zahlenlotto 6 aus 49:\\
        $A:=\lb\text{1. gezogene Zahl ist gerade}\rb\\
        B:=\lb\text{2. gezogene Zahl ist ungerade}\rb\\
        \p(A\cap B)\stackrel{!}{=}\p(A)\cdot\p(B)$\quad ?\\
        $\p($1. Zahl gerade und 2. Zahl ungerade$)
        =\frac{24\cdot 25}{49\cdot 48}=\frac{25}{98}$\\
        $\p($1. Zahl gerade$)=\frac{24}{49}$\\
        $\p($2. Zahl ungerade$)=\p(B|A)\cdot\p(A)+\p(B|A^C)\cdot\p(A^C)
        =\frac{25}{48}\cdot\frac{24}{49}+\frac{24}{48}\cdot\frac{25}{49}
        =2\cdot\frac{24\cdot 25}{48\cdot 49}=\frac{25}{49}$\\
        $\p(A\cap B)=\frac{24\cdot 25}{49\cdot 48}\quad
        \not=\quad\frac{24\cdot 25}{49\cdot 49}=\p(A)\cdot\p(B)$
    \end{Bsp}
    \begin{Bsp}
        n-facher Münzwurf mit fairer Münze:\\
        $a:=\lb\text{1. Wurf 0}\rb\qquad B:=\lb\text{n. Wurf 1}\rb$\\
        $A:=\lb(0,\omega_2,\ldots,\omega_n):\omega_j\in\lb0,1\rb\rb\\
        \p(A)=\frac{2^{n-1}}{2^n}=\frac{1}{2}=\p(B)\\
        A\cap B =\lb(0,\omega_2,\ldots,\omega_{n-1},1)\rb\\
        \p(A\cap B)=\frac{2^{n-2}}{2^n}=\frac{1}{4}=\frac{1}{2}\cdot\frac{1}{2}
        =\p(A)\cdot\p(B)\qquad \to $A und B unabhängig!
    \end{Bsp}
    
    \subsection*{Unabhänigkeit von n-Ereignissen}
    Gegeben: $A_1,\ldots,A_n \in \A$\qquad
    Wann heißen $A_1,\ldots,A_n$ unabhängig?\\
    \begin{itemize}
        \item{Falls $\p(A_i\cap A_j)=\p(A_i)\cdot\p(A_j);\quad i\not=j
            \to$ paarweise unabhängig\\\underline{aber nicht}\quad
            $\p(A_1\cap\ldots\cap A_n)=\p(A_1)\cdot\ldots\cdot\p(A_n)$}
        \item{$\p(A_1\cap\ldots\cap A_n)=\p(A_1)\cdot\ldots\cdot\p(A_n)
            \to$ folgt nicht die paarweise Unabhängigkeit!}
        \item{beides ungeeignet, müsste vereint werden!}
    \end{itemize}
    \begin{Def}
        $A_1,\ldots,A_j\in \A$ heißen unabhängig,wenn  für alle 
        $1\leq i_1<\ldots<i_m\leq n$ und $m=2,\ldots,n$ gilt:
        \[ \p(A_{i_1}\cap\ldots\cap A_{i_m})
        =\p(A_{i_1})\cdot\ldots\cdot\p(A_{i_m})\]
    \end{Def}
    \begin{Bsp}[n=3]$.\\\left.
        \begin{array}{lllll}
            m=2 & i_1=1 & i_2=2 & &\p(A_1\cap A_2)=\p(A_1)\cdot\p(A_2)\\
            & i_1=1 & i_2=3 & &\p(A_1\cap A_3)=\p(A_1)\cdot\p(A_3)\\
            & i_1=2 & i_2=3 & &\p(A_2\cap A_3)=\p(A_2)\cdot\p(A_3)\\[0.3cm]
            m=3 & i_1=1 & i_2=2 & i_3=3 &
                \p(A_1\cap A_2\cap A_3)=\p(A_1)\cdot\p(A_2)\cdot\p(A_3)\\
        \end{array}\right\{$ 
            (*)\\[0.2cm]
        (*) alle müssen erfüllt sein, keine folgt aus der anderen!
    \end{Bsp}
    \begin{Bsp}
        2-faches Würfeln:\\
        $A_1:=\lb\text{1. Würfel gerade}\rb\\
        A_2:=\lb\text{2. Würfel ungerade}\rb\\
        A_3:=\lb\text{beide Würfe gerade oder beide Würfe ungerade}\rb\\
        \p(A_1)=\p(A_2)=\frac{1}{2}\\
        A_3=\lb(1,1),(1,3),(1,5),(3,1),(3,3),(3,5),(5,1),(5,3),(5,5),
        (2,2),(2,4),\ldots\rb\\
        \p(A_3)=\frac{18}{36}=\frac{1}{2}$\\
        $\p(A_1\cap A_3)=\p(A_1)\cdot\p(A_3)\\
        A_1\cap A_3=\lb(2,2),(2,4),(2,6,(4,2),(4,4),(4,6),(6,2),(6,4),(6,6)\rb\\
        \to \p(A_1\cap A_3)=\frac{1}{4}=\frac{1}{2}\cdot\frac{1}{2}\quad$o.k.\\
        analog $A_1\cap A_2$ und $A_2\cap A_3 \quad \to $paarweise unabhängig!\\
        $\p(A_1\cap A_2\cap A_3)=0\qquad \not=\qquad
        \p(A_1)\cdot\p(A_2)\cdot\p(A_3)=\frac{1}{8}\\
        \to A_1,A_2,A_3$ nicht unabhängig!\\
    \end{Bsp}
    \begin{Bsp}[Veranschaulichung]
        Maschine M, n Bauteile, $B_1,\ldots,B_n$ Ausfall unabhängig!\\
        $p(B_j $fällt aus$)=p_j\qquad 0\leq p_j\leq 1$
        \begin{enumerate}
            \item{M fällt aus, wenn mindestens ein Bauteil ausfällt\\
                $\p($M fällt nicht aus$)=\p(B_1,\ldots,B_n$ fällt nicht aus$)
                =\p(B_1\text{ nicht})\cdot\ldots\cdot\p(B_n\text{ nicht})
                =\prod_{j=1}^n(1-p_j)\\
                \to \p($M fällt aus$)=1-\prod_{j=1}^n(1-p_j)\\
                p_j$ nahe bei 1:$\to 1-p_j$ nahe 0$\to \prod$ nahe 0
                $\to \p($M fällt aus$)\approx 1$}
            \item{Maschine fällt aus, wenn alle Bauteile ausfallen\\
                $\p($M fällt aus$)=\p(B_1$ fällt aus$,\ldots,B_n$ fällt aus)
                $=\p(B_1$ fällt aus$)\cdot\ldots\cdot\p(B_n$ fällt aus$)
                =\prod_{j=1}^np_j$\\
                $p_j$ nahe 0$\to \prod$ nahe $0\to\p(M$ fällt aus$)\approx 0$}
        \end{enumerate}
    \end{Bsp}
    \index{Unabhängigkeit|)}

    \subsection*{\emph{Bernoulli}-Schema}
    \index{Bernoulli-Schema@{\emph{Bernoulli}-Schema}}
Man betrachte ein stochastiches Experiment, bei dem es nur die
zwei Ergebnisse Erfolg (=1) und Mißerfolg (=0) gibt. Die
Wahrscheinlichkeit für Erfolg sei $p\in[0,1]$ und entsprechend ergibt
sich die Wahrscheinlichkeit für Mißerfolg als $1-p$. Für $n$ unabhängige
Experimente (Idee/Gedanke von \emph{Bernoulli}) erhält man so einen
Vektor $\omega=(\omega_1,\ldots,\omega_n)$, wobei die
$\omega_j\in\lb0,1\rb$ sind, und $\Omega=\lb0,1\rb^n\qquad\A=\PR(\Omega)$

    \begin{Bsp}[Bernoulli-Schema für $p=\frac{1}{2}$]
      Legt man für $\p$ die Gleichverteilung zugrunde, also
      $p=\frac{1}{2}$, so bekommt man für die Wahrscheinlichkeit des
      Ereignisses $\omega$
      \begin{gather*}
        \p(\lb\omega\rb) =\frac{1}{2^n}
      \end{gather*}
    \end{Bsp}

    \begin{Bsp}[Bernoulli-Schema für $p>\frac{1}{2}$]
      Ist eines der Teilergebnisse wahrscheinlicher als das andere
      ($p>\frac{1}{2}$), wird das Ereignis \linebreak[4]
      $(1,\ldots,1)$
      wahrscheinlicher als das Ereignis $(0,\ldots,0)$ und $\p$ ist keine
      Gleichverteilung!

      Bei $n=4$ Schritten ist beispielsweise
      $\p\big((0,1,0,1)\big)=p^2(-p)^2$ oder
      $\p\big((0,0,0,1)\big)=p(1-p)^3$. Allgemein gilt:
      \begin{gather*}
        p^k(1-p)^{n-k}=\p(A)\qquad k=\sharp\lb j:\omega_j=1\rb \text{ bzw. } 
	k=\sum_{i}^{n} w_{i}
      \end{gather*}
    \end{Bsp}
    $\Omega=\lb0,1\rb^n\qquad 0\leq p\leq 1\\
    \p(\lb\omega\rb)=p^k(1-p)^{n-k}\\
    \omega=(\omega_1,\ldots,\omega_n),\quad k=\omega_1+\ldots+\omega_n$\\
    Probe: $\p$ ist Wahrscheinlichkeitsmaß
    \begin{enumerate}
        \item{$p^k(1-p)^{n-k}\geq 0$}
        \item{\begin{eqnarray*}
              \sum\limits_{\omega\in\mathbb{R}}p(\lb\omega\rb)\stackrel{!}{=}1
            &=&\sum\limits_{k=0}^n\sum\limits_{\omega:\omega_1+,\ldots,+\omega_n=k}
            \underbrace{p(\lb\omega\rb)}_{p^k(1-p)^{k-n}}\\
            &=&\sum_{k=0}^np^k(1-p)^{n-k}\underbrace
            {\sharp\lb\omega:\omega_1+,\ldots,+\omega_n=k\rb}_{\binom{n}{k}}\\
            &=&\sum_{k=0}^n\binom{n}{k}p^k(1-p)^{n-k}=(p+(1-p))^n=1
            \end{eqnarray*}}
    \end{enumerate}
    $A:=\lb\text{n-ter Versuch} = 1\rb\subseteq\lb0,1\rb^n\\
    A=\lb(\omega_1,\ldots,\omega_{n-1},1):\omega_j\in\lb0,1\rb\rb\\$
    \begin{align*}
        \p(A) 
        &= \sum_{\omega\in A}\p(\lb\omega\rb)
        =\sum_{k=1}^n\sum_{\omega\in A;\omega_1+\ldots+\omega_n=k}p^k(1-p)^{n-k}\\
        &=\sum_{k=1}^np^k(1-p)^{n-k}\cdot
        \underbrace{\sharp\lb\omega\in\A:\omega_1+\ldots+\omega_n=k\rb}_
        {\binom{n-1}{k-1}}\\
        &=\sum_{k=1}^n\binom{n-1}{k}p^{n-k}(1-p)^{n-1-k}
	=p\sum_{k=1}^{n}\binom{n-1}{k}p^{k-1}(1-p)^{n-1-(k-1)}\\
        &=p\sum_{k=0}^{n-1}\binom{n-1}{k}p^k(1-p)^{n-1-k}\\
        &=p(p+(1-p))^{n-1}=p=\p(A)
    \end{align*}
    $\p(\omega_1=\stackrel{0}{1},\ldots,\omega_n=\stackrel{0}{1})
    =\p(\omega_1=\stackrel{0}{1})\cdot\ldots\cdot\p(\omega_n=\stackrel{0}{1})$\\
    unabhängig von Ereignissen, deren Eintreten nur vom j-ten Versuch abhängt.\\
    \begin{Bsp}.\\
        $\left.\begin{array}{l}
            A=\lb\text{2. Versuch 0}\rb\\
            B=\lb\text{4. Versuch 1}\rb\\
            C=\lb\text{7. Versuch 0}\rb
        \end{array}\qquad\rb$
        \begin{minipage}[c]{2.5cm}
            unabhängig
        \end{minipage}
    \end{Bsp}
    $A:=\lb\text{genau k mal Erfolg}\rb\\
    \p(A)=\sum\limits_{\omega_1+\ldots+\omega_n=k}p^k(1-p)^{n-k}
    =\binom{n}{k}p^k(1-p)^{n-k}$\\
    \index{Binminialverteilung}
    Binominialverteilung $B_{n,p}$ beschreibt folgendes Experiment:\\
    Führe n unabhängige Versuche durch: 1 mit p und 0 mit 1-p:
    \[B_{n,p}(\lb k\rb)=\p(\text{Genau k-mal Erfolg})\]

    \section*{Geometrische Verteilungen}
    \index{Geometrische Verteilung|(}
    Eins erscheint mit Wahrscheinlichkeit $p$, Null mit Wahrscheinlichkeit $1-p$\\
    Gesucht ist $\p($Im $(k+1)$-ten Versuch erscheint erstmals eine Eins)\\
    Wir führen Hilfsraum ein:\\
    \[\Omega=\lb\omega:=(\omega_1,\omega_2,\ldots),\omega_j\in\lb0,1\rb\rb\]
    \[A=\lb\omega:\omega_1=a_1,\ldots,\omega_n=a_n,\omega_{n+1} \text{ beliebig}\rb
    \]für vorgegebene $a_1,\ldots,a_n \in \lb0,1\rb$
    \[\p(A):=p^k(1-p)^{n-k}\qquad k=a_1+\ldots+a_n \]
    $\p$ lässt sich eindeutig zu einem Wahrscheinlichkeitsmaß auf der von solchen Mengen $A$
    erzeugten $\sigma$-Algebra fortsetzen (ohne Beweis!)\\
    \underline{Spezialfall:}
    \[A=\lb\omega:\omega_1=0,\ldots,\omega_n=0,\omega_{n+1}=1\rb
    =\lb\text{im $(n+1)$-ten Versuch das erste Mal Eins}\rb\]
    $\to \p(A)=p(1-p)^n$\\
    \begin{Def}
    	$\p(\lb n\rb)=\p(\text{im }(n+1)\text{. Versuch erstmals Erfolg})$\\
        $0<p<1,\quad \Omega=\mathbb{N}_0=\lb0,1,2,\ldots\rb$\\
        Das Wahrscheinlichkeitsmaß von $\p$ auf $\PR(\mathbb{N}_0)$ mit:
        \[\p(\lb n\rb):=p(1-p)^n\]
        heisst geometrische Verteilung mit Parameter p.
    \end{Def}
    \underline{Problem:}\\
    zu zeigen: $\sum_{n=0}^\infty \p(\lb n\rb)\stackrel{?}{=}1$\\
    \underline{Beweis:}\\
    $\sum_{n=0}^\infty p(1-p)^n=p\sum_{n=0}^\infty(1-p)^n
    =p\cdot\frac{1}{1-(1-p)}=1\quad\to$ Wahrscheinlichkeitsmaß\qquad\boxed{}\\
    \setcounter{Bsp}{0}
    \begin{Bsp}
        Wahrscheinlichkeit, dass beim Würfeln die 6 erstmals im 10. Versuch
        erscheint:\\
        $p=\frac{1}{6};\quad 1-p=\frac{5}{6}\\
        \p(\lb9\rb)=\frac{1}{6}\cdot(\frac{5}{6})^9\approx 0.0323\ldots$
    \end{Bsp}
    \begin{Bsp}[Roulette]
        $\p($Im 88. Versuch erstmals rot$)=\p(\lb87\rb)
        \qquad p=\frac{18}{37};\qquad 1-p=\frac{19}{37}\\
        \to \p(\lb87\rb)=\frac{18}{37}\cdot(\frac{19}{37})^{87}
        \approx3.19951\cdot 10^{-26}$
    \end{Bsp}
    \index{Geometrische Verteilung|)}
\section{Verteilungsfunktion}
    $\p$ sei ein Wahrscheinlichkeitsmaß auf $\mathbb{R}$ (besser $\Ll(\mathbb{R})$),
    stetig oder diskret\\
    \begin{Def}
        Die Funktion $F:\mathbb{R}\to\mathbb{R}$ mit 
        \[ F(t):=\p((-\infty,t]),\quad t\in\mathbb{R} \]
        heisst Verteilungsfunktion des Wahrscheinlichkeitsmaßes $\p$.
    \end{Def}
    \setcounter{Bsp}{0}
    \begin{Bsp}
        \label{Bsp:vf01}
        $\p(\lb0\rb)=1-p\qquad\p(\lb1\rb)=p$
        \begin{figure}[h]
            \centering\input{figures/vf01.pictex}
            \caption{Verteilungsfunktion zu Beispiel \ref{Bsp:vf01}}
            \label{fig:vf01}      
        \end{figure}
    \end{Bsp}
    \begin{Bsp} 
        \label{Bsp:vf02}
        $\p=\N(0,1)$ (Standardnormalverteilung)\\
        $F(t)=\p((-\infty,t])
        =\frac{1}{\sqrt{2\pi}}\int\limits_{-\infty}^te^{-\frac{x^2}{2}}\;dx$
        \begin{figure}[h]
            \centering\input{figures/vf02.pictex}
            \caption{Verteilungsfunktion zu Beispiel \ref{Bsp:vf02}}
            \label{fig:vf02}      
        \end{figure}
    \end{Bsp}
    \begin{Satz}
        Sei $F$ die Verteilungsfunktion eines Wahrscheinlichkeitsmaßes
        \begin{enumerate}
            \item{$F$ ist monoton wachsend}
            \item{$F(-\infty):=\lim\limits_{t\to-\infty}F(t)=0;\\
                F(\infty):=\lim\limits_{t\to\infty}F(t)=1$}
            \item{$F$ ist rechtsseitig stetig}
        \end{enumerate}
    \end{Satz}
    \underline{Beweis:}
    \begin{enumerate}
        \item{$t\leq s\to (-\infty,t] \subseteq (-\infty,s]\quad
         \stackrel{\text{Monotonie der W.-Maße}}{\to}\quad \p((-\infty,t])\leq \p((-\infty,s])
         \quad\to\quad$ 1)}
        \item{$t_n\searrow -\infty,\quad A_n:=(-\infty,t_n]\quad\to\quad
         A_1\supseteq A_2\supseteq\ldots$ und $\bigcap_{n=1}^\infty A_n=\emptyset\\
         \to\quad
         \p(A_n)\quad\to_{n\to\infty}\quad\p(\emptyset)=0\to\quad\to
         F(t)\to_{t\to-\infty}0\\
         t_n\nearrow\infty,\quad A_n:=(-\infty,t_n]\quad\to\quad
         A_1\subseteq A_2 \subseteq\ldots$ und $
         \bigcup_{n=1}^\infty A_n=(-\infty,\infty)\\
         \to\quad\p(A_n)\to_{n\to\infty}\p(\mathbb{R})=1\quad\to\quad
         F(\infty)=1$}
        \item{zu zeigen: $t_n\searrow t\quad\to\quad F(t_n)\to F(t)\\
         t_n\searrow t,\quad A_n:=(-\infty,t_n]\quad
         A_1\supseteq A_2\supseteq \ldots$ und $
         \bigcap_{n=1}^\infty A_n=(-\infty,t]\\ \to\quad
         \p(A_n)\to_{n\to\infty}\p(-\infty,t]=F(t)$}
    \end{enumerate}\boxed{}
    \underline{Ohne Beweis:}\\
    Sei $F:\quad\mathbb{R}\to\mathbb{R}$ mit 1),2),3). Dann existiert ein eindeutig
    bestimmtes Wahrscheinlichkeitsmaß $\p$ auf $\mathbb{R}$ mit $F(t)=\p((-\infty,t])$\\
    
    \subsection*{Weitere Eigenschaften}
    \begin{enumerate}
        \item{$b>a\quad F(b)-F(a) = \p((-\infty,b])-\p((-\infty,a])
            =\p((-\infty,b]\setminus(-\infty,a])
            =\p((a,b))$}
        \item{$\p(\lb t_0\rb)=\lim\limits_{n\to\infty}\p((t_0-\frac{1}{n},t_0])
            =\lim\limits_{n\to\infty}\left[F(t_0)-F(t_0-\frac{1}{n})\right]
            =F(t_0)-F(t_0-0)\\
            F$ ist stetig in $t_0 \Leftrightarrow F(t_0-0)=F(t_0)
            \Leftrightarrow \p(\lb t_0\rb)=0\\
            F$ hat einen Sprung der Höhe $h>0 \Leftrightarrow \p(\lb t_0\rb)=h$\\
            Wenn $\p$ stetig $\to$ F stetig\\
            Wenn $\p$ diskret $\to$ F hat nur Sprünge (dazwischen konstant)
      \begin{Bsp}
        \label{Bsp:vf03}
        $\p$ \emph{Poisson}-Verteilung
        \[ \p(\lb n\rb)=\frac{\lambda^n}{n!}e^{-\lambda} \]
        \begin{figure}[h]
            \centering\input{figures/vf03.pictex}
            \caption{Verteilungsfunktion zu Beispiel \ref{Bsp:vf03}}
            \label{fig:vf03}      
        \end{figure}
    \end{Bsp}
    \begin{Bsp}
        Sei $F(t)=\lb\begin{array}{l@{\quad : \quad}c}
            0 & -\infty < t < 1 \\
            \frac{1}{4} & 1 \leq t < 2 \\
            1 & t \geq 2
        \end{array}\right.\\
        \p([\frac{1}{2},4])=1 \qquad \p([\frac{1}{2},\frac{3}{2})=\frac{1}{4}\qquad
        \p([\frac{3}{2},\infty))=\frac{3}{4}$
    \end{Bsp}}
    \item{$\p$ habe eine Dichte $p\\
    F(t)=\p((-\infty,t])=\int\limits_{-\infty}^t p(x)\;dx$\\
    \begin{boxedminipage}[c]{5cm}        \large
        $F'(t)=\frac{d}{dt}F(t)=p(t)$
    \end{boxedminipage}
    \qquad(p stetig integrierbar)
    \begin{Bsp}
        \qquad$F(t):=\lb\begin{array}{l@{\quad :\quad}l}
            0 & t \leq 0\\
            1 - e^{-t^2} & t > 0
        \end{array}\right.\quad\to\quad
        p(t)=\lb\begin{array}{l@{\quad : \quad}l}
            0 & t \leq 0\\
            2te^{-t^2} & t > 0
        \end{array}\right.$
    \end{Bsp}}
  \end{enumerate}
    

\input{chapter2.tex}
	
\input{chapter3.tex}

\printindex
\end{document}
