\chapter{Zufällige Größen}
\index{Zufällige Größen}

\section{Definition und Verteilungsgesetz}
\index{Zufällige Größen!Definition}
\index{Zufällige Größen!Verteilungsgesetz}

    Zufälliges Experiment, Beschreibung erfolgt durch $(\Omega,\A,\p)$;
    \quad Wir beobachten $\omega \in \Omega$\\
    Transformieren $\omega:$
    \[\text{Gegeben sei Abbildung } X:\Omega\to\mathbb{R}\qquad \text{(fest)}\]
    \[\text{transformiert } \omega\to X(\omega)\in\mathbb{R}\]
    \[\text{beobachte am Ende den Wert } \X(\omega)\]

    \setcounter{Bsp}{0}
    \begin{Bsp}
        $\Omega=\mathbb{R}^n,\quad \omega=(\omega_1,\ldots,\omega_n)$\qquad
        (n Versuchsergebnisse)\\
        $\X(\omega):=\frac{1}{n}\sum\limits_{j=1}^n\omega_j$\qquad
        (Mittelwert)
        \index{Mittelwert}
    \end{Bsp}
    \begin{Bsp}
        Würfel 2 mal\\
        $\Omega=\lb1,\ldots,6\rb^2;\qquad \p$ Gleichverteilung\\
        $\X(\omega_1,\omega_2):=\omega_1+\omega_2$\qquad (Summe)
    \end{Bsp}
    \begin{Bsp}
        $\Omega=[0,1];\qquad \p$ Gleichverteilung\\
        $\X(t):=t^2$\\
        es tritt $t\in[0,1]$ ein, transformiere zu $t^2$.
    \end{Bsp}
    Beobachtete $\omega$'s treten mit gewissen Wahrscheinlichkeiten auf.\\
    $\to \X(\omega)$'s treten mit gewissen Wahrscheinlichkeiten auf.\\
    $\p(\alpha\leq \X(\omega)\leq\beta)=$?
    \begin{Def}
        Eine Abbildung $\X:\Omega\to\mathbb{R}$ heisst zufällige Größe
        (oder "`reellwertige Zufallsvariable"' oder "`zufällige reelle Zahl"'),
        falls für jede Zahl $t\in\mathbb{R}$ stets gilt:
        \[\lb\omega\in\Omega:\X(\omega)\leq t\rb\in \A \]
    \end{Def}
    \underline{Bemerkungen:}
    \begin{enumerate}
        \item{$B\in\L(\mathbb{R})\qquad \X$ sei Zufallsgröße\\
            $\X^{-1}(B)=\lb\omega\in\Omega:\X(\omega)\in B\rb\in\A$\\
            (Wir wissen dies nur für $B=(-\infty,t],\quad t\in\mathbb{R})$}
        \item{Nehme $\X$ nur die Werte $x_1,x_2,\ldots \in\mathbb{R}$ an\\
            Dann ist $\X$ Zufallsgröße $ \Leftrightarrow\lb\omega\in\Omega:\X(\omega)=x_k\rb
            \in \A,\quad k=1,2,\ldots$}
        \item{Gilt $\A=\PR(\Omega)\to$ \underline{jede} Abbildung $\X$ von
            $\Omega$ nach $\mathbb{R}$ ist Zufallsgröße}
    \end{enumerate}
    Sei $\X:\Omega\to\mathbb{R}$ eine Zufallsgröße, \quad $B\in\L(\mathbb{R})$.
    \[\p_X(B):=\p(\lb\omega\in\Omega:\X(\omega)\in B\rb)
    =\p(\X^{-1}(B))=\p(\X\in B)\text{ (Kurzschreibweise)}\]
    \begin{Satz}
        $\p_X$ ist Wahrscheinlichkeitsmaß auf $(\mathbb{R},\L(\mathbb{R}))$.\\
        $\p_X$ nennt man das Verteilungsgesetz der Zufallsgröße $  \X$
    \end{Satz}
    \setcounter{Bsp}{0}
    \begin{Bsp}
        $\Omega=\lb1,\ldots,6\rb^2;\qquad \p$ Gleichverteilung\\
        $\X(\omega_1,\omega_2):=\max\lb\omega_1,\omega_2\rb$\\
        Werte von \X? Zahlen von 1 bis 6 $(1,\dots,6)$\\
        $\p_X(\lb1\rb)=\p(\X=1)=\frac{1}{36}\\
        \p_X(\lb6\rb)=\p(\X=6)=\frac{11}{36}\\
        \p(\omega\in\Omega:\X(\omega)=6)=\p((1,6),\ldots,(6,6),(6,1),\ldots,(6,5))
        =\frac{11}{36}$
    \end{Bsp}
    \begin{Bsp}
        $\Omega=\mathbb{R};\qquad \p=\N(0,1);\qquad \X(x):=x^2$\\
        \begin{align*}
            \p(\X\leq t) &=\lb\begin{array}{l@{\quad :\quad}l}
                0 & t\leq 0\\
                \N(0,1)\lb x\in\mathbb{R}:x^2\leq t\rb & t > 0
            \end{array}\right.\\
            &= \N(0,1)([-\sqrt{t},\sqrt{t}])
            =\frac{1}{\sqrt{2\pi}}\int\limits_{-\sqrt{t}}^{\sqrt{t}}
            e^{-\frac{x^2}{2}}\;dx\\
            &=\frac{2}{\sqrt{2\pi}}\int\limits_0^{\sqrt{t}}e^{-\frac{x^2}{2}}\;dx
        \end{align*}
    \end{Bsp}
    $\X:\Omega\to\mathbb{R}\qquad \bigwedge\limits_{x\in\mathbb{R}}$ gilt:
    \[ \lb \X \leq t\rb=\X^{-1}((-\infty,t])
    =\lb\omega\in\Omega:\X(\omega)\leq t\rb\in\A\]
    \[\X \text{ Zufallsgröße}\]
    \[\p_X(B)=\p(\X\in B)=\p(\X^{-1}(B)) \text{ Verteilungsgesetz von \X}\]
    \begin{Satz}
        $\p_X$ ist Wahrscheinlichkeitsmaß auf $(\mathbb{R},\L(\mathbb{R}))$
    \end{Satz}
    \underline{Beweis:}\\
    $\p_X(\emptyset)=\p\lb\omega:\X(\omega)\in\emptyset\rb=\p(\emptyset)=0\\
    \p_X(\mathbb{R})=\p\lb\omega:\X(\omega)\in\mathbb{R}\rb=\p(\Omega)=1\\
    \X^{-1}(A\cap B)=\X^{-1}(A)\cap\X^{-1}(B)\\
    \X^{-1}(\bigcup\limits_{j=1}^\infty B_j)
    =\bigcup\limits_{j=1}^\infty\X^{-1}(B_j)$\\
    dann seien $B_1,B_2$ disjunkte Ordnungen\\
    $i\not=j\quad\emptyset=\X^{-1}(\underbrace{B_i\cap B_j}_{=\emptyset})
    =\X^{-1}(B_j)\cap\X^{-1}(B_i)\\
    \to \X^{-1}(B_i)$ disjunkte Teilmengen von $\Omega$\\[0.5cm]
    $\p_X(\bigcup\limits_{j=1}^\infty B_j)=\p(\X^{-1}(\bigcup\limits_{j=1}^\infty
    B_j))=\p(\bigcup\limits_{j=1}^\infty\underbrace{\X^{-1}(B_j)}_\text{disjunkt})
    =\sum\limits_{j=1}^\infty\p(\X^{-1}(B_j))=\sum\limits_{j=1}^\infty
    \p_X(B_j)\\
    \to \p_X$ Wahrscheinlichkeitsmaß $\quad\to\p_X$ Verteilungsgesetz von \X
    \setcounter{Bsp}{0}
    \begin{Bsp}
        Würfel 2 mal\qquad $\Omega=\lb1,\ldots,6\rb^2\\
        \X\lb\omega_1,\omega_2\rb:=\omega_1-\omega_2,\qquad \p_X=?\\
        \X$ hat Werte in $\lb-5,\ldots,0,\ldots,5\rb\\
        \p_X(\lb-5\rb)=\p(\X=-5)=\p(X^{-1}(\lb5\rb))=\p((1,6))=\frac{1}{36}\\
        \p_X(\lb0\rb)=\frac{1}{6}\qquad\X^{-1}(\lb0\rb)=\lb(1,1),\ldots,(6,6)\rb$
    \end{Bsp}
    \begin{Bsp}
        $\p$ sei Gleichverteilung auf $[0,1]$!\\
        $\omega=(\omega_1,\omega_2)\qquad\X(\omega):=\omega_1+\omega_2\qquad
        \p(\X\leq t)=\p\lb(\omega_1,\omega_2:\omega_1+\omega_2\leq t\rb\\
        \p(\X\leq t)=\lb\begin{array}{l@{\quad :\quad}l}
            0 & t\leq 0\\
            1 & t\geq 2
        \end{array}\right.\\
        0\leq t\leq 1\qquad \p(\X\leq t)=\frac{t^2}{2}\\
        1\leq t\leq 2\qquad \p(\X\leq t)=1-\frac{(2-t)^2}{2}=2t-1-\frac{t^2}{2}$
    \end{Bsp}

    \subsection*{Sprechweisen}
    \begin{enumerate}
        \item{Eine Zufallsgröße \X \ heisst gleichverteilt auf
            $\lb x_1,\ldots,x_n\rb\subseteq\mathbb{R}$, falls $\p_X $ die
            Gleichverteilung auf $\lb x_1,\ldots,x_n\rb$ ist, das heisst
            \[\p_X(\lb x_i\rb)=\frac{1}{N}\qquad
            \p(\X=x_i)=\frac{1}{N}\qquad j=1,\ldots,N\]}
        \item{\X $\sim B_{n,p}$, das heisst $\p_X=B_{n,p}$, das heisst
            \[\p(\X=k)=\binom{n}{k}p^n(1-p){n-k}\qquad k=0,\ldots,n\]
            insbesondere ist $\p(\X\in\lb0,\ldots,n\rb)=1$}
        \item{\X ist \emph{Poisson}verteilt mit $\lambda>0$,wenn gilt:
            \[\p(\X=k)=\frac{\lambda^k}{k!}e^{-\lambda}\qquad k=0,1,\ldots\]
            insbesondere ist $\p(\X\in\mathbb{N}_0)=1$}
        \item{$\X\sim\N(a,\sigma^2)$, das heisst
            \[\underbrace{\p(\alpha\leq x\leq\beta)}_{
            =\p(\omega:\alpha\leq\X(\omega)\leq\beta)}
            =\frac{1}{\sqrt{2\pi}\sigma}
            \int_\alpha^\beta e^{-\frac{(t-a)^2}{2\sigma^2}}\;dt\]}
        \item{\X exponentialverteilt mit $\lambda>0$, falls gilt:
            \[\p(\X\geq t)=e^{-\lambda t};\quad \geq 0\]
            insbesondere gilt: $\p(X\geq 0)=1$}
    \end{enumerate}
    
    \subsubsection*{Bemerkung 1:}
    \X heisst diskret bzw. stetig, falls $\p_X$ diskret bzw. stetig\\
    \X \ diskret $\Leftrightarrow \bigcup\limits_{D\subseteq\mathbb{R}}$
    abzählbar, mit $\p(\X\leq D)=1$\\
    zum Beispiel: \emph{Poisson}verteilt $\to$ \X diskret\\[.5cm]
    \X \ stetig $\Leftrightarrow\bigcup\limits_{\text{W-Dichte p}}$ mit
    $\p(\alpha\leq\X\leq\beta)=\int\limits_\alpha^\beta p(s)\;ds$\\
    zum Beispiel: $\X\sim\N(0,1)\to\X$ stetig

    \subsubsection*{Bemerkung 2:}
    $F_X(t):=\p_X((-\infty,t])=\p(\X\leq t)$ Verteilungsfunktion von \X

\section{Gemeinsame Verteilung}
\index{Gemeinsame Verteilung}

	$(\Omega,\A,\p)$ Wahrscheinlichkeitsraum\\
	$\left.\begin{array}{l}
		\X_1 : \Omega \to \mathbb{R} \\
		\vdots\\
		\X_n : \Omega\to\mathbb{R} \\
	\end{array}\right\} n $ zufällig
	\begin{Bsp}
		3 mal würfeln\\
		$\X_1(\omega):=\max\lb\omega_1,\omega_2,\omega_3\rb\\
		\X_2(\omega):=\min\lb\omega_1,\omega_2,\omega_3\rb\\
		\X_3(\omega):=\omega_1+\omega_2+\omega_3$\\
	\end{Bsp}
	\begin{Def}
		Die Abbildung $\overrightarrow{\X}=(\X_1\ldots\X_n)$ mit
		\[\overrightarrow{\X}=(\X_1(\omega)\ldots\X_n(\omega))\in\mathbb{R}^n\]
		heisst n-dimensional zufälliger Vektor mit Kardinate $\X_1\ldots\X_n$
	\end{Def}
	\addtocounter{Bsp}{-1}
	\begin{Bsp}[obiges Beispiel]
		Würfel: \[(1,1,4)\stackrel{\overrightarrow{\X}}{\to} (4,1,6)\]
				\[(2,3,6)\to (6,2,11)\]
				\[\overrightarrow{\X}:\Omega\to\mathbb{R}^n\]
	\end{Bsp}
	\begin{Def}
		Die Abbildung $\p_{\overrightarrow{\X}}\to\p_{(\X_1\ldots\X_n)}$ mit:
		\[\p_{\overrightarrow{\X}}(B)=\p\lb\omega\in\Omega:
		\overrightarrow{\X}(\omega)\in B\rb\]
		heisst geimeinsames Verteilungsgesetz von $\X_1\ldots\X_n$.\\
		$\p_{\overrightarrow{\X}}$ ist Wahrscheinlichkeitsmaß auf
		$(\mathbb{R}^n,\L(\mathbb{R}^n))$.
	\end{Def}
	\setcounter{Bsp}{0}
	\begin{Bsp}
		$B=[\alpha_1,\beta_1]\times\ldots\times[\alpha_n,\beta_n]$ Quader\\
		\[\p_{\overrightarrow{\X}}(B)=\p(\alpha_1\leq\X_1\leq\beta_1,\ldots,
		\alpha_n\leq\X_n\leq\beta_n)\]\\
		\[\left[\begin{array}{c}
			\text{gleichtzeitig muss $\alpha_1\leq\X_1\leq\beta_1$ und $\ldots$
			und $\alpha_n\leq\X_n\leq\beta_n$ erfüllt sein}
		\end{array}\right]\]
	\end{Bsp}
	\begin{Bsp}
		Würfel 2 mal:
		\[\X_1(\omega_1,\omega_2):=\min\lb\omega_1,\omega_2\rb\]
		\[\X_2(\omega_1,\omega_2):=\max\lb\omega_1,\omega_2\rb\]
		\[\p_{\overrightarrow{\X}}(\lb(1,4)\rb)=\p(\X_1=1,\X_2=4)=\frac{1}{18}\]
		\[\p_{\overrightarrow{\X}}(\lb(4,1)\rb)=\p(\X_1=4,\X_2=1)=0\]
		\[\p_{\overrightarrow{\X}}(\lb(3,3)\rb)=\p(\X_1=3,\X_2=3)=\frac{1}{36}\]
		\[\begin{array}{l||l|l|l|l|l|l|l|}
			& &\multicolumn{6}{c|}{\X_1}\\ \hline
			& & 1 & 2 & 3 & 4 & 5 & 6\\ \hline
			& 1 & \frac{1}{36} & 0 & 0 & 0 & 0 & 0\\ \cline{2-8}
			& 2 & \frac{1}{18} & \frac{1}{36} & 0 & 0 & 0 & 0\\ \cline{2-8}
			\X_2&3&\frac{1}{18}&\frac{1}{18}&\frac{1}{36}&0&0&0\\\cline{2-8}
			&4&\frac{1}{18}&\frac{1}{18}&\frac{1}{18}&\frac{1}{36}&0&0\\\cline{2-8}
			&5&\frac{1}{18}&\frac{1}{18}&\frac{1}{18}&\frac{1}{18}&\frac{1}{36}
			&0\\\cline{2-8}
			&6&\frac{1}{18}&\frac{1}{18}&\frac{1}{18}&\frac{1}{18}&
			\frac{1}{18}&\frac{1}{36}\\ \hline
		\end{array}\]
	\end{Bsp}
	$\X_1\ldots\X_n$ gegeben\\
	$\p(\X_1\ldots\X_n)$ Wahrscheinlichkeitsmaß auf $\mathbb{R^n}$ (gemeinsame Verteilung)\\
	$\p_{\X_1\ldots\X_n}$ n Wahrscheinlichkeitsmaße auf $\mathbb{R}$
	(Randverteilungen)\\[1ex]
	\underline{Frage:}\\
	Was ist informativer? n Randverteilungen oder eine gemeinsame Verteilung?\\
	\setcounter{Bsp}{0}
	\begin{Bsp}
		$\omega$ ist zufällig herausgenommener Student:
		\[\X_1(\omega) \quad\text{Alter}\]
		\[\X_2(\omega) \qquad\text{m oder w}\]
		\[\p_{\X_1}(\lb 22\rb)=\frac{\text{Anzahl der 22-Jährigen}}{N}\]
		\[\p_{\X_2}(\lb w\rb)=\frac{\text{Anzahl der Mädchen}}{N}\]
		\[\p_{\overrightarrow{\X}}((22,w))=\p(\X_1=22,\X_2=w)=
		\frac{\text{Anzahl der 22-jährigen Mädchen}}{N}\]
	\end{Bsp}
	\begin{Satz}
		Die gemeinsame Verteilung $\p(\X_1\ldots\X_n)$ bestimmt die
		Randverteilung von $\p_{\X_1\ldots\X_n}$.
	\end{Satz}
	\underline{Beweis:}\\
	\begin{align*}
		\p_{\X_1}(B)&=\p\lb\omega\in\Omega:\X_1(\omega)\in B\rb\\
		&=\p(\omega\in\Omega:\X_1(\omega)\in B,\X_2(\omega)\in \mathbb{R},
		\ldots,\X_n(\omega)\in \mathbb{R})\\
		&=\p(\omega\in\Omega:\overrightarrow{\X}(\omega)\in B\times\mathbb{R}
		\times\ldots\times\mathbb{R})\\
		&=\p_{\overrightarrow{\X}}(B\times\mathbb{R}\times\ldots\times\mathbb{R})
	\end{align*}
	
	\subsubsection*{Konkrete Rechenregeln}
	\begin{enumerate}
		\item{$a=2$, X und Y zufällig und beide diskret:
			$\bigvee\limits_{x_1,x_2\ldots\in\mathbb{R}} 
			\bigvee\limits_{y_1,y_2\ldots\in\mathbb{R}}$ mit :
			\[\sum_{i=1}^\infty \p(\X=x_i)=1\text{ und }
			\p(\Y\in\lb y_1,y_2,\ldots\rb)=1\]
			\[p_{ij} := \p(\X=x_i,\Y=y_j)=\p_{(\X,\Y)} (\lb(x_i,y_j)\rb)\]
			\[p_{ij}\geq 0\qquad \sum_{i,j=1}^\infty p_{ij} = 1\]
			\[p_i := \p(\X=x_i)=\p(\X=x_i,\Y\in\lb y_1,y_2,\ldots\rb)
			=\sum_{j=1}^\infty\p(\X=x_i,\Y=y_j)=\sum_{j=1}^\infty p_{ij}\]
			\[p_j := \p(\X=x_j)=\sum_{i=1}^\infty\p(\X=x_i,\Y=y_j)
			=\sum_{i=1}^\infty p_{ij}\]
			\[\begin{array}{l||l|l|l|l|l|l|l|l|l|}
				& &\multicolumn{8}{c|}{\X}\\ \hline
				& & 1 & 2 & 3 & 4 & 5 & 6 &&\\ \hline
				& 1 & &   &   &   &   & \p_{61}&\p_{01}&\frac{1}{36}\\
				\cline{2-10}
				& 2 & &   & \p_{33}  & & &&\p_{02}&\frac{3}{36} \\ \cline{2-10}
				\Y&3&&&&&&&\p_{03}&\frac{5}{36}\\\cline{2-10}
				&4&&&&&&&\p_{04}&\frac{7}{36}\\\cline{2-10}
				&5&&&&&&&\p_{05}&\frac{9}{36}\\\cline{2-10}
				&6&&&&&&&\p_{06}&\frac{11}{36}\\ \hline
				&&\p_{10}&\p_{20}&\p_{30}&\p_{40}&\p_{50}&\p_{60}&&\\ \hline
				&&\frac{11}{36}&\frac{9}{36}&\frac{7}{36}&\frac{5}{36}
				&\frac{3}{36}&\frac{1}{36}&&\\ \hline
			\end{array}\]
			\[\p(\Y=6)=\p_{06}=\frac{11}{36}\qquad
			\p(\X=6,\Y=1)=\p_{61}=0\]
			\[\p(\X=4)=\p_{40}=\frac{5}{36}\qquad
			\p(\X=2,\Y=2)=\p_{22}=\frac{1}{36}\]
			$\X_1\ldots\X_n :\quad\Omega\to\mathbb{R}$ \qquad n zufällige Größen\\
			$(\X_1\ldots\X_n)\quad\Omega\to\mathbb{R}^n$\qquad zufälliger Vektor
			\[\omega\to(\X_1(\omega)\ldots\X_n(\omega))\]
			$\p_{(x_x,x_2)}$ gemäß Verteilung, Wahrscheinlichkeitsmaß auf $\L(\mathbb{R}^n)$\\
			$\to\quad\p_{\X_1}\ldots\p_{\X_n}$ Wahrscheinlichkeitsmaße auf
			$\mathbb{R}\quad$ Randverteilungen}
		\item{stetiger Fall:\\
			$\exists$ Dichte $p:\quad \mathbb{R}^n\to\mathbb{R}$ mit
			\[\p(\alpha_1\leq\X_1\leq\beta_1,\ldots,\alpha_n\leq\X_n\leq\beta_n)
			=\int\limits_{\alpha_1}^{\beta_1}\cdots\int\limits_{\alpha_n}^{\beta_n}
			p(t_1,\ldots,t_n)\;dt_1\ldots dt_n\]
			Welche Dichten haben die Randverteilungen?
			\begin{align*}
				\p_{\X_j}(\left[\alpha,\beta\right])
				&=\p(\alpha\leq\X_j\leq\beta)\\
				&=\p(-\infty<\X_1<\infty,\ldots,\alpha\leq\X_j\leq\beta,\ldots,
					-\infty<\X_n<\infty)\\
				&=\int\limits_\alpha^\infty 
					\underbrace{\int\limits_{-\infty}^\infty\cdots
					\int\limits_{-\infty}^\infty
					p(t_1,\ldots,t_n)\;dt_1\ldots dt_n}_{q(t_j)} dt_j
			\end{align*}
			\[\to \p_\X\text{ hat Dichte } q\]
			$\p_{\X_j}$ hat die Dichte
			\[t = \int\limits_{-\infty}^\infty\cdots
					\int\limits_{-\infty}^\infty
					p(t_1,\ldots,t_j,\ldots,t_n)\;dt_1\ldots dt_j \ldots dt_n\]}
	\end{enumerate}
	
	\setcounter{Bsp}{0}
	\begin{Bsp}
		\label{bsp:gvek}
		$\p_{(\X,\Y)}$ sei Gleichverteilung auf Einheitskreis\\
		\[p(t,s)=\lb\begin{array}{l@{\quad}c}
			\frac{1}{\pi} & t^2 < s^2 \leq 1\\
			0 & \text{sonst}
		\end{array}\right.\]
		$\to \p_\X$ hat Dichte $q$ mit
		\[q(t)=\int\limits_{-\infty}^\infty p(t,s)\;ds
		=\frac{1}{\pi}\int\limits_{-\sqrt{1-t^2}}^{\sqrt{1-t^2}}\;ds
		=\frac{2}{\pi}\sqrt{1-t^2} \text{ für }
		|t|\leq 1\]
		\[\to \p(\alpha\leq\X\leq\beta)
		=\frac{2}{\pi}\int\limits_\alpha^\beta\sqrt{1-t^2}\;dt\]
		$-1\leq\alpha\leq\beta\leq 1$\\
		\begin{figure}[h]
            \centering\input{figures/gvek.pictex}
            \caption{Dichte von $\p_\X$ (Beipiel \ref{bsp:gvek})}
            \label{fig:gvek}      
        \end{figure}
	\end{Bsp}
	
	\underline{Frage:}
	Bestimmen die Randverteilungen die gemeinsame Verteilung?
	\begin{Bsp}
		In einer Urne befinden sich zwei Kugeln mit Wert 0 und zwei Kugeln mit
		Wert 1. Wir ziehen zwei Kugeln ohne zurücklegen:\\
		X Wert Kugel 1\\ Y Wert Kugel 2\\
		\[\p(\X=0,\Y=0)=\p(X=0)\cdot\p(\Y=0|\X=0)
		=\frac{1}{2}\cdot\frac{1}{3}=\frac{1}{6}\]
		\[\begin{array}{l||l|l|l|l}
				& &\multicolumn{3}{c}{\X}\\ \hline
				  &   & 0           & 1 &\\ \hline
				  & 0 & \frac{1}{6} & \frac{1}{3} & \frac{1}{2}\\	\cline{2-5}
				\Y& 1 & \frac{1}{3} & \frac{1}{6} & \frac{1}{2}\\ \cline{2-5}
				  &   & \frac{1}{2} & \frac{1}{2} &\\		
		\end{array}\qquad
		\begin{array}{c}
			\p_\X=\p_{\tilde{\X}}\\
			\p_\Y=\p_{\tilde{\Y}}\\
			\text{aber: } \p_{(\X,\Y)}\not= \p_{(\tilde{\X},\tilde{\Y})} 
		\end{array}\]
		
		mit zurücklegen:
		\[\begin{array}{l||l|l|l|l}
				& &\multicolumn{3}{c}{\X}\\ \hline
				  &   & 0           & 1 &\\ \hline
				  & 0 & \frac{1}{4} & \frac{1}{4} & \frac{1}{2}\\	\cline{2-5}
				\Y& 1 & \frac{1}{4} & \frac{1}{4} & \frac{1}{2}\\ \cline{2-5}
				  &   & \frac{1}{2} & \frac{1}{2} &\\		
		\end{array}\]
		Randbedingungen bestimmen im Allgemeinen \underline{nicht} die
		gemeinsamen Verteilungen!
	\end{Bsp}
	
\section{Unabhängigkeit zufälliger Größen}
\index{Unabhängigkeit!zufälliger Größen}
	
	\setcounter{Bsp}{0}
	\begin{Bsp}
		Würfel 3 mal\\
		X Wert 1. Wurf\qquad Y Summe 2. und 3. Wurf\\
		Frage: X und Y unabhängig?
	\end{Bsp}
	\begin{Def}
		n zufällige Größen $\X_1,\ldots,\X_n$ heißen unabhängig, wenn für alle
		$B_1,\ldots,B_n \in \L(\mathbb{R})$ stets gilt:
		\[\tag{*}\label{eq:uzg01}\p(\X_1\in B_1,\ldots,\X_n\in B_n)
		=\p(X_1\in B_1)\cdot\ldots\cdot\p(\X_n\in B_n)\]
	\end{Def}
	
	\underline{Bemerkung:}\\
	\begin{enumerate}
		\item{es reicht aus, wenn (\ref{eq:uzg01}) für Intervalle gilt.}
		\item{es reicht aus, wenn (\ref{eq:uzg01}) für Intervalle der Form
			$(-\infty,\X]$ gilt, d.h. wenn 
			$\bigwedge\limits_{t_j\in\mathbb{R}}:$
			\[\p(\X_1\leq t_1,\ldots,\X_n\leq t_n)
			=\prod\limits_{j=1}^n\p(\X_j\leq t_j)\]}
		\item{$\X_1,\ldots,\X_n$ sind unabhängig $\Leftrightarrow
			\bigwedge\limits_{B_1,\ldots,B_n}\in\L(\mathbb{R})$ stehts
			$\lb\X_1\in B_1\rb,\ldots,\lb\X_n\in B_n\rb$ unabhängig sind
			(nicht trivial! ;-) )}
	\end{enumerate}
	
	\subsubsection*{Konkrete Fälle}
	
	\begin{enumerate}
		\item{Dikreter Fall, $n=2$\\
			X hat Werte $\X_1,\X_2,\ldots$\\
			Y hat WErte $\Y_1,\Y_2,\ldots$\\
			\[p_{ij}=\p(\X=x_i,\Y=y_i)\]
			\[p_{i0}=\p(\X=x_i)=\sum\limits_{j=1}^\infty p_{ij}\]
			\[p_{0j}=\p(\Y=y_j)=\sum\limits_{i=1}^\infty p_{ij}\]
			\begin{Satz}
				Die zufälligen Größen X und Y sind dann und nur dann
				unabhängig, wenn gilt:
				\[p_{ij}=p_{i0}\cdot p_{0j}\qquad \bigwedge\limits_{i,j}\]
			\end{Satz}
			\underline{Beweis: "`$\Rightarrow$"'}\\
			\begin{align*}
				p_{ij}&=\p(\X\in\lb x_i\rb\setminus\Y\in\lb y_j\rb)\\
				&\stackrel{\text{unabh.}}{=}\p(\X\in\lb x_i\rb)\cdot
				\p(\Y\in\lb y_i\rb)=p_{i0}\cdot p_{0j}
			\end{align*}
			\underline{Beweis: "`$\Leftarrow$"'}\\
			\begin{align*}
				\p(\X\in B_1,\Y\in B_2)
				&=\sum\limits_{x_i\in B_1,y_j\in B_2}p_{ij}
				=\sum\limits_{x_i\in B_1,y_j\in B_2}p_{i0}\cdot p_{0j}\\
				&=\sum\limits_{x_i\in B_1}p_{i0}\cdot
				\sum\limits_{y_j\in B_2}p_{0j}
				=\p(\X\in B_1)\cdot\p(\Y\in B_2)\\
				&\Rightarrow \text{unabhängig}\qquad\qquad	\boxed{}			
			\end{align*}	}
		\item{Stetiger Fall\\
			$\p(\X_1,\ldots,\X_n)$ hat Dichte $p:\mathbb{R}^n
			\to\quad[0,\infty)$
			\begin{itemize}
				\item{Randverteilungen $\p_{\X_1},\ldots,\p_{\X_n}$}
				\item{dann sind $\X_1,\ldots,\X_n$ genau dann unabhängig, wenn
				\[p(t_1,\ldots,t_n)=p_1(t_1)\cdot\ldots\cdot p_n(t_n)\]}
			\end{itemize}
			\underline{Beweis: "`$\Rightarrow$"'}\\
			\begin{align*}
				(*) &= \p(\alpha_1\leq\X_1\leq\beta_1,\ldots,
					\alpha_n\leq\X_n\leq\beta_n)\\
				&= \p(\alpha_1\leq\X_1\leq\beta_1)\cdot\ldots\cdot
					\p(\alpha_n\leq\X_n\leq\beta_n)\\
				&= \int\limits_{\alpha_1}^{\beta_1} p_1(t_1)\;dt_1\cdot\ldots
					\cdot \int\limits_{\alpha_n}^{\beta_n} p_n(t_n)\;dt_n\\
				&= \int\limits_{\alpha_1}^{\beta_1}\cdots
					\int\limits_{\alpha_n}^{\beta_n}
					p_1(t_1)\cdot\ldots\cdot p_n(t_n)\;dt_n\ldots dt_1\\
				(*) &= \int\limits_{\alpha_1}^{\beta_1}\cdots
					\int\limits_{\alpha_n}^{\beta_n}
					p(t_1,\ldots,t_n)\;dt_n\ldots dt_1\\
				&\bigwedge\limits_{\alpha_i<\beta_i}\qquad
				p(t_1\ldots t_n)=p_1(t_1)\cdot\ldots\cdot p_n(t_n)\\
				&\text{Umkehrung analog}\qquad\qquad\boxed{}
			\end{align*}
		}
	\end{enumerate}
	
\section{Transformation zufälliger Größen}
\index{Transformation}
\index{Transformation!zufälliger Größen}

	\[\X:\Omega\quad\to\mathbb{R}\text{ Zufallsgröße},\quad f:\mathbb{R}\quad\to\mathbb{R}\]
	\[\Y:=f(\X)\]
	
	\underline{\emph{(Prüfungs-)}Frage:}\\
	Wie berechnet sich $\p_\Y$ aus $\p_\X$?
	
	\setcounter{Bsp}{0}
	\begin{Bsp}
		$\X$ Sei gleichverteilt auf $\lb 1\ldots 6\rb$\\
		\[f:\mathbb{R}\quad\to\mathbb{R} \text{ sei gegeben durch }
		f(x)=\lb\begin{array}{l@{\quad:\quad}l}
			1 & x \geq 4 \\
			0 & x < 4
		\end{array}\right.\]
		\[Y:=f(\X)\]
		\[\p(\Y=1)=\p(\X\geq 4)=\frac{1}{2}\]
		\[\p(\Y=0)=\p(\X<4)=\frac{1}{2}\]
		\[\p(\Y)=B_{1,\frac{1}{2}}\]
	\end{Bsp}
	
	\begin{Bsp}
		\[\X\sim\mathcal{N}(0,1)\qquad Y=\X^2\]
		\begin{align*}
			\p(\Y\leq t)
			&=\p(\X^2\leq t)\\
			&=\p(-\sqrt{t}\leq\X\leq\sqrt{t})\\
			&=\frac{1}{\sqrt{2\pi}}\int\limits_{-\sqrt{t}}^{\sqrt{t}}
				e^{-\frac{\lambda^2}{2}}\;dx\\
			&=\frac{2}{\sqrt{2\pi}}\int\limits_0^{\sqrt{t}}
				e^{-\frac{\lambda^2}{2}}\;dx\\
		\end{align*}
		\[F_\Y(t)=\p(\Y\leq t)=\sqrt{\frac{2}{\pi}}\int\limits_0^{\sqrt{t}}
			e^{-\frac{\lambda^2}{2}}\;dx\]
		\[q \text{ Dichte von }\p_\Y\to q(t)=\frac{d}{dt}F_\Y(t)\]
		\[F_\Y(t)=H(\sqrt{t})\qquad
			H(n)=\sqrt{\frac{2}{\pi}}\int\limits_0^n
			e^{-\frac{\lambda^2}{2}}\;dx	\qquad
			H'(n)=\sqrt{\frac{2}{\pi}} e^{-\frac{n^2}{2}}\;dx\]
		\begin{align*}
			\frac{d}{dt}H(\sqrt{t})
			&=H'(\sqrt{t})\cdot\frac{1}{2}\cdot	t^{-\frac{1}{2}}\\
			&=\frac{1}{\sqrt{2\pi}}t^{-\frac{1}{2}}e^{-\frac{t}{2}}
				,\qquad t> 0\\
			q(t)&=\lb\begin{array}{l@{\quad:\quad}l}
				\frac{1}{\sqrt{2\pi t}}e^{-\frac{t}{2}} & t > 0\\
				0 & t \leq 0
			\end{array}\right.
		\end{align*}
	\end{Bsp}
	
\subsection*{Lineare Transformationen}
\index{Lineare Transformationen}

	\[f(t)=at+b\qquad \to\qquad \Y=a\cdot\X+b\]
	
	\begin{itemize}
		\item{1. Fall $a>0$:
			\[\p(\Y\leq t)=\p(a\X+b\leq t)=\p(\X\leq\frac{t-b}{a})\]
			\[F_\Y(t)=F_\X(\frac{t-b}{a})\]}
		\item{2. Fall $a<0$:
			\[F_\Y(t)=\p(a\X+b\leq t)=\p(\X\geq\frac{t-b}{a})
			=1-\p(\X<\frac{t-b}{a})\]
			\[\text{falls X stetig}\to\quad
			1-\p(\X\leq\frac{t-b}{a})=1-F_\X(\frac{t-b}{a})\]
		}
	\end{itemize}
	
	X hat Verteilungsdichte p
	\begin{align*}
		\to q(t)=\frac{d}{dt}F_\Y(t)
		&\stackrel{a>0}{=}\frac{d}{dt}F_\X(\frac{t-b}{a})
			=\frac{1}{a}p(\frac{t-b}{a})\\
		&\stackrel{a<0}{=}\frac{d}{dt}(1-F_\X(\frac{t-b}{a}))
			=-\frac{1}{a}p(\frac{t-b}{a})
	\end{align*}
	
	q Dichte von $a\X+b$
	\[q(t)=\frac{1}{|a|}p(\frac{t-b}{a})\]
	
	\setcounter{Bsp}{0}
	\begin{Bsp}
		\[\X\sim\mathcal{N}(0,1)\]
		\[\Y=\sigma\X+b\qquad \sigma>0\]
		\[p(t)=\frac{1}{\sqrt{2\pi}}e^{-\frac{t^2}{2}}\]
		\[q(t)=\frac{1}{\sigma}p(\frac{t-b}{a})=\frac{1}{\sqrt{2\pi}\sigma}
		e^{-\frac{(t-b)^2}{2\sigma^2}}\]
		\[\sigma\X+b\sim\mathcal{N}(b,\sigma^2)\]
	\end{Bsp}
	
	\begin{Bsp}
		\[p(t)=\lb\begin{array}{l@{\quad:\quad}l}
			\lambda e^{-\lambda t} & t > 0\\
			0 & t \leq 0
		\end{array}\right.\]
		\[\Y=a\X \qquad a > 0\]
		\[q(t)=\frac{1}{a}p(\frac{t}{a})=\frac{\lambda}{a}
			e^{-\frac{\lambda}{a}t}\qquad t > 0\]
		\[\text{Y ist exponentialverteilt mit Parameter }\frac{\lambda}{a}\]
	\end{Bsp}
	
\subsection*{Simulation zufälliger Größen}
\index{Simulation!zufälliger Größen}

	\underline{1. Schritt}\\
	
	Simulation auf einer $[0,1]$ gleichverteilten Zufallsgröße. Unabhängigkeit
	wählt\\	Zahlen
	 $\omega_1,\omega_2,\ldots\in\lb0,1\rb$ mit\\
	\[\p\lb\omega_j=0\rb=\p(\omega_j=1)=\frac{1}{2}\]
	Erhalten zufällige Folge $\omega_1,\omega_2,\ldots$ von Nullen und Einsen
	$\omega=(\omega_1,\omega_2,\ldots)$,\\ setzen
	\[U(\omega):=\sum\limits_{j=1}^\infty\frac{\omega_j}{2^j}\]
	dass heisst, $U(\omega)=0,\omega_1\omega_2\ldots$ im Binärsystem\\
	$0,0,1,1,1,0,1 \quad\rightsquigarrow\quad
	\frac{1}{2^3}+\frac{1}{2^4}+\frac{1}{2^5}+\frac{1}{2^7}+\ldots\\
	U(\omega)\in[0,1]\quad\to\quad$ U gleichverteilt auf $[0,1]$,d.h.
	\[\p(\alpha\leq U\leq\beta)=\beta=\alpha\]
	für $0\leq\alpha\leq\beta\leq 1$.\\
	$U(\omega)$ ist eine gleichverteilte zuf. Zahl aus $[0,1]$.\\
	
	\underline{2. Schritt}\\
	
	$Q:\quad$ Wahrscheinlichkeitsmaß auf $\mathbb{R}$,\\
	Q habe Dichte q mit $q(x)>0,\quad x\in (a,b),\quad q(x)=0$ für
	$x\not\in[a,b]\\
	a=-\infty,\quad b=\infty$ möglich!
	\[F(t)=Q((-\infty,t])=\int\limits_{-\infty}^\infty q(x)\;dx\]
	$\to$ F streng monoton wachsend auf $[a,b]$:\\
	
	\begin{figure}[h]
    	\centering\input{figures/sim01.pictex}
		\caption{$F$}
        \label{fig:sim01}      
    \end{figure}
		
	$\to F^{-1}:\quad (0,1)\to (a,b)$ existiert:
	
	\begin{figure}[h]
    	\centering\input{figures/sim02.pictex}
		\caption{$F^{-1}$}
        \label{fig:sim02}      
    \end{figure}
	
	\begin{Satz}
		Sei Q wie oben mit Verteilungsfunktion F und sei U gleichverteilt auf $[0,1]$\\
		Sei $\X:=F^{-1}(U)$, so folgt
		\[\p_\X=Q\]
	\end{Satz}
	
	\underline{Beweis:}\\
	\[\p(U\leq S)=\lb\begin{array}{l@{\quad:\quad}l}
		0 & s < 0\\
		s & 0\leq s\leq 1\\
		1 & s > 1
	\end{array}\right.\]
	\begin{align*}
		\p(\X\leq t)&=\p(F^{-1}(U)\leq t)\stackrel{F^{-1}\text{ wachs.}}{=}
		\p(U\leq\underbrace{F(t)}_{\in[0,1]})=F(t)\\
		&=Q((-\infty,t])\quad\to\quad \bigwedge t \to \p_\X=Q \qquad\boxed{}
	\end{align*}
	
\subsubsection*{Anwendung}

	\begin{enumerate}
		\item{Wollen ein $x \in \mathbb{R}$ wählen gemäß $\mathcal{N}(0,1)$
			\[\Phi(t)=\frac{1}{\sqrt{2\pi}}\int\limits_{-\infty}^t
				e^{-\frac{x^2}{2}}\;dx\]
			\[\Phi^{-1}(t):\quad(0,1)\to\mathbb{R}\]
			\begin{figure}[ht]
    			\centering\input{figures/sim03.pictex}
				\caption{$\Phi^{-1}$}
        		\label{fig:sim03}      
		    \end{figure}
			Ist U gleichverteilt auf $[0,1]$, so ist $\Phi^{-1}(U)$ gemäß 
			$\mathcal{N}(0,1)$-verteilt.\\
			Suchen $x\in\mathbb{R}$ mit $\p(\alpha\leq x\leq\beta)=
			\int\limits_\alpha^\beta e^{-\frac{s^2}{2}}\;ds$\\
			Im 1. Schritt $u\in[0,1]$ gleichverteilt,
			\[x := \Phi^{-1}(u)\quad\to\quad\text{x ist }
			\mathcal{N}(0,1)\text{-verteilt}\]
			Suchen unabhängige $\X_1,\ldots,\X_n$ normalverteilt
			\[\left.\begin{array}{l}
				\omega_1^{(1)},\omega_2^{(1)},\ldots \in\lb 0,1\rb \\
				\omega_1^{(2)},\omega_2^{(2)},\ldots \in\lb 0,1\rb \\
				\qquad \vdots\\
				\omega_1^{(n)},\omega_2^{(n)},\ldots \in\lb 0,1\rb 
			\end{array}\rb
			u_1,u_2,\ldots,u_n\text{ gleichverteilt und unabhängig}\]
			\[x_1:=\Phi^{-1}(u_1);\ldots;x_n:=\Phi^{-1}(u_n)\]
			\emph{Bemerkung:}
			\[\Y_1:=\sigma x_1+a;\ldots;\Y_n=\sigma
			x_n+a,\quad\sigma>0,a\in\mathbb{R}\]
			\[\to \Y_1,\ldots,\Y_n\text{ unabhängig und }
			\mathcal{N}(a,\sigma^2)\text{-verteilt!}\]
		}
		\item{Man konstruiert n unabhängige exponentialverteilte Zahlen
			$t_1,\ldots,t_n$ mit Parameter $\lambda>0$\\
			\underline{Im 1.Schritt:} $u_1,\ldots,u_n$ wie oben
			\[F(t)=\int\limits_0^t\lambda e^{-\lambda x}\;dx=1-e^{-\lambda t}\]
			$1-e^{-\lambda t}=s\quad (0<s<1)\qquad \to$
			\begin{align*}
				e^{-\lambda t} &= 1-s\\
				-\lambda t &=\ln{(1-s)}\\
				t &= \frac{1}{\lambda}\ln{(\frac{1}{1-s})}
			\end{align*}
			\[F^{-1}(s)=\frac{1}{\lambda}\ln{(\frac{1}{1-s})}\]
			U gleichverteilt auf $[0,1]\quad\to\quad\ln{(\frac{1}{1-n})}$
			ist exponential verteilt mit Parameter $\lambda>0$. $1-U$ ist
			ebenfalls gleichverteilt auf $[0,1]. \quad\to\quad 
			\frac{1}{\lambda}\ln{(\frac{1}{n})}$ ist exponential verteilt mit
			$\lambda>0$\\
			$u_1,\ldots,u_n$ unabhängig gleichverteilte Zahlen aus $[0,1]$
			\[x_j := \frac{1}{\lambda}\ln{(\frac{1}{n})},\quad 1\leq j\leq n\]
			\[\to\quad t_1,\ldots,t_n\text{ unabhängig exponential verteilt}\]
		}
	\end{enumerate}
	
	Sei Q ein diskretes Wahrscheinlichkeitsmaß. Wie simuliert man Q?
	
	\setcounter{Bsp}{0}
	\begin{Bsp}
		Wollen eine $B_{n,p}$-Verteilung simulieren. Suchen ein
		$k\in\lb0,\ldots,n\rb$ gemäß $B_{n,p}$ verteilt.
		\begin{figure}[ht]
    		\centering\input{figures/sim04.pictex}
			\caption{Simulation einer zuf. Größe}
        	\label{fig:sim04}      
		\end{figure}		
	\end{Bsp}
	
\section{Rechnen mit zufälligen Größen}

\subsection*{Problem}

	\[\X,\Y \text{ unabhängige Zufallsgrößen}\]
	\[Z := \X + \Y\]
	
\subsection*{Frage}
	Wie berechnet sich das Verteilungsgesetz von Z aus denen von X und Y?\\
	
	\setcounter{Bsp}{0}
	\begin{Bsp}
		X,Y beide gleichverteilt auf $\lb1,\ldots,6\rb$
		\[\p(\X+\Y=2)=\frac{1}{36};\qquad\p(\X+\Y=7)=\frac{1}{6}\]
	\end{Bsp}
	
	\begin{Satz}
		X,Y seine Zufallsgrößen mit Werten in $\mathbb{N}_0=\lb0,1,\ldots\rb$,
		X,Y sind unabhängig, dann gilt:
		\[\p(\X+\Y=k)=\sum\limits_{i=0}^k\p(\X=i)
		\cdot\p(\Y=k-i)\]
	\end{Satz}
	
	\underline{Beweis:}\\
	\begin{align*}
		B_k&:=\lb(i,j):\quad i,j\in\mathbb{N}_0,\quad i+j=k\rb\\
		\p(\X+\Y=k)&=\p((\X,\Y)\in B_k)=\p_{\X,\Y}(B_k)\\
		B_k&:=\bigcup\limits_{i=0}^k\lb(i,k-i)\rb
			=\sum\limits_{i=0}^k\p_{\X,\Y}(\lb(i,k-i)\rb)\\
		&=\sum\limits_{i=0}^k\p(\X=i,\Y=k-i)\\
		&\stackrel{\text{unabh.}}{=}
			\p(\X=i)\cdot\p(\Y=k-i)
		\qquad\qquad\boxed{}	
	\end{align*}
	
	\begin{Bsp}
		$\p(\X=i)=\frac{1}{6};\quad i=1,\ldots,6;\quad$ Null sonst\\
		$\p(\Y=i)=\frac{1}{6};\quad i=1,\ldots,6;\quad$ Null sonst\\
		$\p(\X+\Y=3)=\p(\X=0)\p(\X=3)+\p(\X=1)\p(\Y=2)
			+\p(\X=2)\p(\Y=1)\\
			\qquad+\p(\X=3)\p(\Y=0)=0+\frac{1}{6}\cdot\frac{1}{6}+
			\frac{1}{6}\cdot\frac{1}{6}+0=\frac{1}{18}$
	\end{Bsp}
	
	\begin{Satz}
		Sei X Poissonverteilt mit $\lambda>0$ und Y Poissonverteilt mit
		$\mu>0$
		\[\text{X,Y unabhängig }\Rightarrow X+Y\text{ Poissonverteilt
		mit }\lambda+\mu\]
	\end{Satz}
	
	\underline{Beweis:}\\
	\begin{align*}
		\p(\X+\Y=k)
			&=\sum\limits_{i=0}^k\p(\X=i)\p(\Y=k-i)\\
			&=\sum\limits_{i=0}^k\frac{\lambda^i}{i!}e^{-\lambda}\cdot
				\frac{\mu^{k-i}}{(k-i)!}e^{-\mu}\\
			&=\frac{e^{-(\lambda+\mu)}}{k!}\sum\limits_{i=0}^k
				\underbrace{\frac{k!}{i!(k-i)!}}_{\binom{k}{i}}\cdot
				\lambda^i\mu^{k-i}\\
			&=\frac{e^{-(\lambda+\mu)}}{k!}(\lambda+\mu)^k\qquad \boxed{}
	\end{align*}
	
\subsection*{Deutung}
	
	Telefonzentralen in A und B\\
	Anzahl der Anrufe in A (B bzw. A+B) sein Poissonverteilt mit
	Parameter $\lambda>0$ (	$\mu>0$ bzw. $\lambda+\mu>0$)\\
	
	\begin{Lemma}
		Für $k=0,1,\ldots,m+n$ gilt:
		\[\sum\limits_{i=0}^k\binom{n}{i}\binom{m}{k-i}
			=\binom{n+m}{k}\qquad\text{s.o.}\]
	\end{Lemma}
	
	\begin{Satz}
		$\X\sim B_{n,p},\quad\Y\sim B_{m,p}$
		\[\X,\Y\text{ unabh.}\quad\to\quad\X+\Y\sim B_{n+m,p}\]
	\end{Satz}
	
	\underline{Beweis:}\\
	\begin{align*}\p(\X+\Y=k)
		&=\sum\limits_{i=0}^k\binom{n}{i}p^i(1-p)^{n-i}
			\binom{m}{k-i}p^{k-i}(1-p)^{m-(k-i)}\\
		&=p^k(1-p)^{n+m-k}\sum\limits_{i=0}^k\binom{n}{i}\binom{m}{k-i}\\
		&\stackrel{\text{2.8.}}{=}\binom{n+m}{k}p^k(1-p)^{n+m-k};\quad
			k=0,\ldots,n\\
		&\to \X+\Y \text{ ist }B_{n+m,p}\text{-verteilt}\qquad\boxed{}
	\end{align*}
	
\subsection*{Folgerung}
	
	$\X_1,\ldots,\X_N$ unabhängig, $\p(\X_j=1)=p;\quad
		\p(X_j=0)=1-p$\\
	$\to \X_j\sim B_{1,p}$\\
	$\stackrel{\text{2.9.}}{\Rightarrow}
		\X_1+\ldots+\X_n\sim B_{n,p}$
	\[\p(\X_1+\ldots+\X_n=k)=\binom{n}{k}p^k(1-p)^{n-k}\]
	\[\p\lb\omega: \text{Genau k der }\X_j(\omega)\text{ sind 1}\rb\]
	
\section*{Addition stetiger Zufallsgrößen}
	\[\p(\alpha\leq\X\leq\beta)=\int\limits_\alpha^\beta p(t)\;dt\]
	\[\p(\alpha\leq\Y\leq\beta)=\int\limits_\alpha^\beta q(s)\;ds\]	
	\[\p(\alpha\leq\X+\Y\leq\beta)=\int\limits_\alpha^\beta r(z)\;dz\]
	
\subsubsection*{Frage}
	Wie berechnet sich r aus p und q?
	
	\begin{Theorem}
		X habe Verteilungsdichte p, Y q und X,Y unabhängig. Dann hat $\X+\Y$
		die Verteilungsdichte r mit $r=p*q$ (Faltung) und
		\[r(x)=\int\limits_{-\infty}^\infty p(x-y)\;q(y)\;dy
			=\int\limits_{-\infty}^\infty p(x)\;q(x-y)\;dy\]
	\end{Theorem}
	
	\underline{Beweis:}\\
	$Z:=\X+\Y,\quad t\in\mathbb{R},\\
	B_t:=\lb(x,y):\quad x+y\leq t\rb\subseteq\mathbb{R}^2\\
	\p(Z\leq t)=\p((x,y)\in B_t)=\p_{\X,\Y}(B_t)=(*)$\\
	
	\emph{entscheidend:}\\
	X,Y unabhängig: $\p_{\X,\Y}$ hat Dichte $p(x)q(y)$, d.h.
	\[\p_{\X,\Y}(B)=\iint\limits_B p(x)\;q(y)\;dx\;dy\]
	\[(*)\qquad=\iint\limits_{B_t}p(x)\;p(y)\;dx\;dy
		=\int\limits_{-\infty}^\infty
		\underbrace{\left[\int\limits_{-\infty}^{t-x}
		q(y)\;p(x)\;dy\right]}_{(1)}dx\]
	\[(1)\qquad -\infty<y\leq t-x\quad\to\quad-\infty<y+x\leq t
	\qquad u:=y+x\]
	\[\Rightarrow \qquad \qquad \qquad \qquad \qquad \qquad 
		=\int\limits_{-\infty}^\infty\int\limits_{-\infty}^t
		q(u-x)\;du\;p(x)\;dx\]
	\[\Rightarrow \qquad \qquad \qquad \qquad \qquad \qquad 
		=\int\limits_{-\infty}^t\underbrace{
		\left[\int\limits_{-\infty}^\infty p(x)\;q(u-x)\;dx\right]}_{(2)}du\]
	\[(2)\qquad =r(u)=(p*q)(u)\]
	\[\p(Z\leq t)=\int_{-\infty}^t r(u)\;du\quad\to\quad
		\text{r Verteilungsdichte von Z.}\]
	Rest durch Substitution$\qquad \boxed{}$\\[0.5cm]
	Sei $\p(\X\leq t)=\int\limits_{-\infty}^t p(x)\;dx\qquad
	\p(\Y\leq t)=\int\limits_{-\infty}^t q(y)\;dy$\\
	\[\text{X,Y unabhängig }\quad\to\quad
	\p(\X+\Y\leq t)=\int\limits_{-\infty}^t r(z)\;dz\]
	wobei $r=p*q$, d.h.
	\[r(z)=\int\limits_{-\infty}^\infty p(z-x)\;q(x)\;dx
		=\int\limits_{-\infty}^\infty p(x)\;q(z-x)\;dx\]
		
	\setcounter{Bsp}{0}
	\begin{Bsp}
		Zwei Bauteile gleicher Art, Lebensdauer exponential verteilt
		\begin{itemize}
			\item{nehmen 1. Bauteil in Betrieb}
			\item{bei Ausfall ersetzen durch 2. Bauteil}
		\end{itemize}
		\subsubsection*{Frage}
		$\p($2. Bauteil in $[1,b]$ ausfällt)=?\\
		$\X_i$ Lebenszeit des i-ten Bauteils $(i=1,2)$\\
		\begin{figure}[ht]
    		\centering\input{figures/sim05.pictex}
			\caption{Beispiel 1}
        	\label{fig:sim05}      
		\end{figure}	
		Dichten: $p(x)=\lambda e^{-\lambda x}\qquad x>0\qquad
		q(y)=\lambda e^{-\lambda y}\qquad y>0$
		\[\to r(z)=\int\limits_{-\infty}^\infty p(z-x)\;q(x)\;dx
		=\lambda^2\int\limits_0^t e^{-\lambda(z-x)}e^{-\lambda x}\;dx
		=\lambda^2\int\limits_0^t e^{-\lambda z}\;dx
		=\lambda^2 z e^{-\lambda z}\quad z>0\]
		\[\to\p(\X_1+\X_2\geq t)=\lambda^2\int\limits_t^\infty z e^{\lambda z}
			\;dz=\lambda(\lambda+t)e^{-\lambda t}\qquad t>o\]
	\end{Bsp}
	
	\begin{Bsp}
		$\X\sim\mathcal{N}(a,\sigma^2),\quad
		 \Y\sim\mathcal{N}(b,\mu^2),\quad
		 \X,\Y$ unabhängig\\
		\[p(x)=\frac{1}{\sqrt{2\pi}\sigma}
			e^{-\frac{\frac{1}{2}(x-a)^2}{\sigma^2}}\qquad
		q(x)=\frac{1}{\sqrt{2\pi}\mu}
			e^{-\frac{\frac{1}{2}(y-b)^2}{\mu^2}}\]
		\[r(z)=\frac{1}{2\pi\sigma\mu}\int\limits_{-\infty}^\infty
			e^{\frac{-\frac{1}{2}(z-x-a)^2}{\sigma^2}}
			e^{\frac{-\frac{1}{2}(x-b)^2}{\mu^2}}\;dx\]
		\[\X+\Y\sim\mathcal{N}(a+b,\sigma^2+\mu^2)\]
	\end{Bsp}
	
\section{Erwartungswert}
\index{Erwartungswert}

	Gegeben sei eine Zufallsgröße X, suchen einen "`mittleren"' Wert von X
	
\subsection*{Analyse}

	X nimmt nur die Werte $x_1,\ldots,x_n\in\mathbb{R}$ an
	\[\p(\X=x_k)=p_k,\quad 1\leq k\leq n\]
	N unabhängige Versuche gemäß X, dann nimmt X ungefähr $N\cdot p_k$ den
	Wert $x_n$ an\\
	\begin{align*}
		\text{Durchschnitt}&=\frac{1}{N}\lb x_1\cdot\text{ Eintreten Zahl von }
		 x_1+\ldots+x_n\cdot\text{ Eintreten Zahl von }x_n\rb\\		
		 &=\frac{1}{N}\lb x_1 N p_1+\ldots+x_n N p_n\rb\\
		 &=\sum\limits_{j=1}^n x_j p_j
		 =\sum\limits_{j=1}^n x_j\p(\X=x_j)
	\end{align*}
	
	\setcounter{Bsp}{0}
	\begin{Bsp}
		Würfel\\
		$\p(\X=1)=\ldots=\p(\X=6)=\frac{1}{6}$\\
		Durchschnitt$=1\cdot\p(\X=1)+\ldots+6\cdot\p(\X=6)
		=\frac{1+\ldots+1}{6}=3.5$
	\end{Bsp}	
	
	\begin{Bsp}
		$\p(\X=2)=\frac{1}{3}\qquad \p(\X=-4)=\frac{2}{3}$\\
		Durchschnitt$=2\cdot\frac{1}{3}+(-4)\frac{2}{3}=-2$
	\end{Bsp}
	
	\begin{Def}
		Sei X eine Zufallsgröße mit möglichen Werten $x_1,x_2,\ldots$ aus $\mathbb{R}$
		\begin{enumerate}
			\item{gilt $x_k\geq 0$ für $k=1,2,\ldots$, so setzt man:
				\[\EX:=\sum\limits_{k=1}^\infty x_k\cdot\p(\X=x_k)\qquad
				(\EX=\infty \text{ möglich})\]}
			\item{Sind die $x_n\in\mathbb{R}$ beliebig und gilt:
				\[\sum\limits_{k=1}^\infty|x_k|\p(\X=x_k)<\infty\]
				so setzt man:
				\[\EX:=\sum\limits_{k=1}^\infty x_k\cdot\p(\X=x_k)\]
				$\EX$ heisst Erwartungswert der Zufallsgröße X}
		\end{enumerate}
	\end{Def}
	
	\setcounter{Bsp}{0}
	\begin{Bsp}
		Münzwurf, 0 oder 1 mit $p=\frac{1}{2}$\\
		x Euro Einsatz $0\to$ verloren ($x=0)\qquad 1\to$ Gewinn $2x$\\
		\underline{Strategie:}\\
		1. Spiel 1 Euro Einsatz\\
		bei Verlust\\
		2. Spiel 2 Euro Einsatz\\
		bei Verlust\\
		3. Spiel 4 Euro Einsatz\\
		bei Verlust\\
		$\vdots$\\
		k. Spiel $2^{k-1}$ Euro Einsatz\\
		Im k-ten Spiel Gewinn: $\to 2^k$ Euro Gewinn $\quad\to\quad
		1+2+3+\ldots+2^{k-1}$ Einsatz bis dato$=2^k-1\quad\to\quad$
		Gewinn: $2^k-(2^k-1)=1$ Euro\\
		$\lb\right.$ Einsatz $\left.2^k-1\rb=\lb\right.$ Im k-ten Spiel eine 1$\left.\rb$\\
		X benötigter Einsatz
		\[\EX=\sum\limits_{k=1}^\infty(2^k-1)\cdot
			\underbrace{\p(\X=2^k-1)}_{2^{\frac{1}{k}}}
			=\sum\limits_{k=1}^\infty \frac{2^k-1}{2^k}=\infty!\]
		(deshalb: Höchsteinsatz)
	\end{Bsp}
	
	\begin{Bsp}
		$\X\sim B_{n,p}$\\
		Mögliche Werte von X sind $0\ldots n$
		\[\p(\X=k)=\binom{n}{k}p^k(1-p)^{n-k}\]
		\begin{align*}
			\to\EX &=\sum\limits_{k=0}^n k\binom{n}{k}p^k(1-p)^{n-k}\\
			&=\sum\limits_{k=1}^n k \frac{n!}{k!(n-k)!}p^k(1-p)^{n-k}\\
			&=np\sum\limits_{k=1}^n\frac{(n-1)!}{(k-1)!(n-k)!}p^k(1-p)^{n-k}\\
			&=np\sum\limits_{k=0}^n\frac{(n-1)!}{k!(n-1-k)!}p^k(1-p)^{n-1-k}\\
			&=np\sum\limits_{k=0}^{n-1}\binom{n-1}{k}p^k(1-p)^{n-1-k}\\
			&=np(p+1-p)^{n-1}=np
		\end{align*}
		$\Rightarrow$ bei einem verfälschten Münzwurf tritt im Durchschnitt $np$ oft die 1 ein
	\end{Bsp}
	
	\begin{Bsp}
		X Sei gleichverteilt auf $\lb x_1\ldots x_n\rb$
		\[\EX=\sum\limits_{k=1}^n x_k\underbrace{\p(\X=x_k)}_{\frac{1}{n}}=\frac{1}{n}\sum\limits_{k=1}^n x_k\]
		arithmetisches Mittel
	\end{Bsp}
	
	\begin{Bsp}
		X Poissonverteilt
		\[\EX=\sum\limits_{K=0}^\infty k\frac{\lambda^k}{k!}e^{-\lambda}
		=\lambda\left(\sum\limits_{k=0}^\infty \frac{\lambda^{k-1}}{(k-1)!}\right)e^{-\lambda}
		=\lambda e^{-\lambda}\underbrace{\sum\limits_{k=0}^\infty\frac{\lambda^k}{k!}}_{e^\lambda}=\lambda\]
		Deutung: Zugriff auf eine Seite\\
		im Schnitt pro Tag 1000 Zugriffe\\
		$\to\p($k Zugriffe pro Tag$)=\frac{1000^k}{k!}e^{-^1000}$
	\end{Bsp}
	
	\begin{Bsp}
		$\p(\X=k)=p(1-p)^k\quad k=0,1,\ldots\\
		\X=k \Leftrightarrow$ im $(k+1)$. Versuch erstmals eine 1\\
		\begin{align*}
			\EX &=\sum\limits_{k=0}^\infty pk(1-p)^k\qquad k=0\Rightarrow 0\\
			&= p\sum\limits_{k=1}^\infty k(1-p)^k\\
			&=p(1-p)\sum\limits_{k=1}^\infty k(1-p)^{k-1}\\
		\end{align*}
		\[f(p):=\underbrace{\sum\limits_{K=0}^\infty(1-p)^k}_
			{f'(p)=-\sum\limits_{k=0}^\infty k(1-p)^{k-1}}
		=\frac{1}{1-(1-p)}=\underbrace{\frac{1}{p}}_{f'(p)=-\frac{1}{p^2}}\]
		\[\to\quad \sum\limits_{k=1}^\infty k(1-p)^{k-1}=\frac{1}{p^2}\]
		\[\EX=\frac{p(1-p)}{p^2}=\frac{1-p}{p}\]
	\end{Bsp}
	
	\setcounter{Bsp}{0}
	\begin{Bsp}
		Würfeln bis zum ersten Erscheinen einer 6\\
		Wie viele Würfe sind im Durchschnitt nötig, bis zum ersten Erscheinen der 6?\\
		$p=\frac{1}{6};\qquad1-p=\frac{5}{6}\\
		\EX=5\qquad$ Im Durchschnitt erscheint die 6 im 6. Wurf
	\end{Bsp}

	\begin{Bsp}
		Erstmals Rot im Roulette\\
		$p_{rot}=\frac{18}{37};\qquad 1-p=\frac{19}{37}\\
		\EX=\frac{\frac{10}{37}}{\frac{18}{37}}=\frac{19}{18}$
	\end{Bsp}	
	
\subsection*{Erwartungswert stetiger Zufallsgrößen}
\index{Erwartungswert!stetiger Zufallsgrößen}

	\[\p(\X\leq t)=\int\limits_{-\infty}^t p(s)\;ds\qquad \EX=?\]
	
\subsubsection*{Analyse}
	
	\begin{figure}[ht]
    	\centering\input{figures/ew01.pictex}
		\caption{Erwartungswert einer stetigen Zufallsgröße}
       	\label{fig:ew01}      
	\end{figure}		
	
	\[\p(t_1\leq\X\leq t_2)=\int\limits_{t_1}^{t_2}p(s)\;ds\sim(t_2-t_1)p(t_1)\]
	\[\sum\limits_{k=1}^n t_k\p(t_{k-1}\leq\X\leq t_k)\sim
	\sum\limits_{k=1}^n t_k(t_k-t_{k-1})p(t_{k-1})\quad\to
	\int\limits_{-\infty}^\infty tp(t)\;dt\]
	
	$\EX$ Erwartungswert oder auch Mittelwert\\
	Wenn X höchstens abzählbar viele Werte annimmt,
	$x_1,x_2,\ldots\in\mathbb{R}$, dann ist der (diskrete) Erwartungswert (falls
	er existiert):
	\[\EX:=\sum\limits_{k=1}^\infty x_k\p(\X=x_k)\]
	
	X stetige Zufallsgröße, d.h. es existiert eine Verteilungsdichte $p:\mathbb{R}
	\to[0,\infty)$ mit\\
	\[\p(\X\leq t)=\int\limits_{-\infty}^t p(s)\;ds,\quad t\in\mathbb{R}\]
	$\EX=?$\\
	Approximation von X durch diskrete Zufallsgröße
	
	\begin{Def}
		X mit Verteilungsdichte p besitzt ein Erwartungswert, wenn gilt:
		\[\int\limits_{-\infty}^\infty |t|p(t)\;dt<\infty\]
		\[\text{Stetiger Erwartungswert: }
		\EX=\int\limits_{-\infty}^\infty t p(t)\;dt\]
	\end{Def}
	
	\setcounter{Bsp}{0}
	\begin{Bsp}
		X sei gleichverteilt auf $[a,b]$, d.h. Verteilungsdichte p hat die
		Gestalt:
		\[p(t)=\lb\begin{array}{l@{\quad:\quad}l}
			\frac{1}{b-a} & a \leq t \leq b\\
			0 & \text{sonst}
		\end{array}\right.\]
		\[\EX=\int\limits_{-\infty}^\infty t p(t)\;dt
			=\int\limits_a^bt\frac{1}{b-a}\;dt
			=\frac{b^2-a^2}{2}\frac{1}{b-a}
			=\frac{a+b}{2}\]
		\[\text{Mitte des Intervalls}\]
	\end{Bsp}
	
	\begin{Bsp}
		$\X \sim \mathcal{N}(a,\sigma^2)$
		\begin{align*}
			\EX &= \frac{1}{\sqrt{2\pi}\sigma}\int\limits_{-\infty}^\infty
				t e^{-\frac{t-a)^2}{2\sigma^2}}\;dt\qquad
				\text{Substitution: } t-a := s\\
			&= \frac{1}{\sqrt{2\pi}\sigma}\int\limits_{-\infty}^\infty
				(s+a)e^{-\frac{s^2}{2\sigma^2}}\;ds\\
			&=\frac{1}{\sqrt{2\pi}\sigma}\int\limits_{-\infty}^\infty
				se^{-\frac{s^2}{2\sigma^2}}\;ds
				+a \frac{1}{\sqrt{2\pi}\sigma}\int\limits_{-\infty}^\infty
				e^{-\frac{s^2}{2\sigma^2}}\;ds\\
			&= 0 + a\cdot 1 = a
		\end{align*}
	\end{Bsp}
	
	\begin{Bsp}
		X exponentialverteilt mit $\lambda>0$\\
		\[p(t)=\lb\begin{array}{l@{\quad:\quad}l}
			\lambda e^{-\lambda t} & t>0\\
			0 & t < 0
		\end{array}\right.\]
		\[\to\EX=\lambda\int\limits_0^\infty t e^{-\lambda t}\;dt
		=\frac{1}{\lambda}\int\limits_0^\infty s e^{-s}\;ds
		=\frac{1}{\lambda}\cdot 1=\frac{1}{\lambda}\]
	\end{Bsp}
	
	Die Lebensdauer eines Bauteils sei exponentialverteilt. Im Durchschnitt
	arbeitet das Bauelement 10 Zeiteinheiten.\\
	\[\to \frac{1}{\lambda}=10\qquad
	\lambda=\frac{1}{10}\]
	\[
	\to\p(\text{Bauelement arbeitet t Zeiteinheiten oder mehr})=
	e^{-\frac{t}{10}}\]

	\begin{figure}
                \noindent
                %\begin{minipage}[b]{.46\linewidth}
                        \centering\input{figures/ew02.pictex}
                        \caption{Erwartungswert (zu Beispiel 3)}
                        \label{fig:ew02}
                %\end{minipage}
        \end{figure}
        \begin{figure}
                %\begin{minipage}[b]{.46\linewidth}
                        \centering\input{figures/ew03.pictex}
                 	 \caption{Erwartungswert (zu Beispiel 3)}
                        \label{fig:ew03}
                %\end{minipage}
	\end{figure}
	
	\begin{Bsp}
		X sei \emph{Cauchy}-verteilt, d.h.
		\index{Cauchy@{\emph{Cauchy}}}
		\[p(t)=\frac{1}{\pi}\frac{1}{1+t^2};\quad t\in\mathbb{R}\]
		\[\int\limits_{-\infty}^\infty|t|p(t)\;dt
			=\frac{2}{\pi}\int\limits_0^\infty t\frac{1}{1+t^2}\;dt=\infty\]
			$\Rightarrow$ X besitzt \underline{keinen} Erwartungswert
	\end{Bsp}
	
\subsection*{Eigenschaften von Erwartungswerten}

	\begin{enumerate}
		\item{\underline{Linerarität}\\
		\index{Linerarität}
			$\X,\Y:\Omega\to\mathbb{R}$ zufällige Größen,$\qquad
			\alpha,\beta\in\mathbb{R}$
			\[\mathbb{E}(\alpha\X+\beta\Y)=\alpha\EX+\beta\mathbb{E}\Y\]
			Anwendung:\\
			Erwartungswert beim Würfeln ist $3.5$\\
			Würfel 3 mal, Summe der drei Würfe\\
			Erwartungswert: $3\cdot 3.5=10.5$}
		\item{\underline{Transformationssatz}\\
		\index{Transformationssatz}
			$f:\mathbb{R}\to\mathbb{R}$
			\[\mathbb{E}f(\X)\begin{array}{l@{\qquad}l}
				=\sum\limits_{k=1}^\infty f(x_k)\p(\X=x_k)&\text{(diskret)}\\
				=\int\limits_{-\infty}^\infty f(t)p(t)\;dt&\text{(stetitg)}
			\end{array}\]
			\setcounter{Bsp}{0}
			\begin{Bsp}
				X sei $B_{n,p}$-verteilt
				\[\EX^2=\sum\limits_{k=1}^n f(k^2)\binom{n}{k}p^k(1-p)^{n-k}\]
			\end{Bsp}
			\begin{Bsp}
				X sei exponential verteilt
				\[\mathbb{E}\log{\X}=\int\limits_0^\infty (\log{t})
					\lambda e^{-\frac{\lambda}{t}}\;dt\]
				\[\mathbb{E}\frac{1}{\X}=\int\limits_0^\infty
					\frac{1}{t}\lambda e^{-\frac{\lambda}{t}}\;dt=\infty\]
			\end{Bsp}}
		\item{\underline{Multiplikationsformel}\\
		\index{Multiplikationsformel}
			X,Y unabhängig
			\[\mathbb{E}(\X\cdot\Y)=(\EX)\cdot(\mathbb{E}\Y)\]}
		\item{\underline{Monotonie}\\
		\index{Monotonie}
			\[\X\leq\Y,\text{ d.h. } \X(\omega)\leq\Y(\omega),\quad
			\bigwedge\limits_{\omega\in\Omega}\]
			\[\to\quad \EX\leq\mathbb{E}\Y\]}
	\end{enumerate}
	\[\mathbb{E}(\X+c)=\EX+\mathbb{E}c=\EX+c\qquad\text{(c ist Konstante)}\]
	
\section{Varianz und Kovarianz}
\index{Varianz}
\index{Kovarianz}
	
	\begin{Def}
		Eine zufällige Größe X hat ein \emph{2. Moment}, wenn gilt:
		\index{Moment}
		\[\mathbb{E}|\X|^2<\infty,\text{ d.h. }
			\begin{array}{l@{\qquad}l}
				\sum\limits_{k=1}^\infty
					x^2_k\p(\X=x_k)<\infty&\text{(diskret)}\\
				\int\limits_{-\infty}^\infty t^2 p(t)\;dt<\infty
					&\text{(stetig)}
			\end{array}\]
	\end{Def}
	
	\begin{Satz}
		Besitzt X ein 2. Moment, so existiert $\EX$.
	\end{Satz}
	
	\underline{Beweis:}\\
	\[(a-b)^2\geq 0\quad\to\quad\frac{(a^2+b^2)}{2}\geq a\cdot b \quad a,b>0\]
	\[b=1\quad\to\quad\frac{a^2+1}{2}\geq a\quad\to\quad
	|\X(\omega)\leq \frac{1}{2}|\X(\omega)|^2+\frac{1}{2}\]
	\[\mathbb{E}|X|\leq \frac{1}{2}\mathbb{E}|\X|^2+\frac{1}{2}<\infty
	\quad\to\quad\mathbb{E}|X|=\lb\begin{array}{l}
		\int\limits_{-\infty}^\infty |t|p(t)\;dt\\
		\sum\limits_{k=1}^\infty|x_k|\p(\X=x_k)
	\end{array}\rb\text{ Def. EW. ex.}\]
	$\boxed{}$
	
\subsubsection*{Aufgabe}
	
	Man konstruiere X mit $\EX$ aber ohne 2. Moment!
	
\subsubsection*{Folgerung}

	X habe 2. Moment,$\quad a =\EX$
	\[\mathbb{E}(\X-a)^2=\EX^2-2a\EX+a^2<\infty\]
	
	\begin{Def}
		Sei X eine Zufallsgröße mit 2. Moment. Die Varianz (Streuung, Dispersion)
		\index{Varianz}
		\index{Streuung|see{Varianz}}
		\index{Dispersion|see{Varianz}}
		\[\mathbb{V}\X:=\mathbb{E}(\X-\EX)^2\]
		ist der mittlere quadratische Abstand von X zum Erwartungswert. Wenn
		$\mathbb{V}\X$ groß: Im Mittle nimmt X Werte weit entfernt von $\EX$ an.
	\end{Def}
	
	Wichtigste Kenngröße von X ist Erwartungswert, zweitwichtigste ist die
	Varianz!\\
	
\subsection*{Rechenregeln}

	\begin{enumerate}
		\item{$a=\EX\quad\to\quad\mathbb{V}\X=\mathbb{E}(\X-a)^2=
			\mathbb{E}[\X^2-2a\X+a^2]\stackrel{\text{Linearität}}{=}
			\EX^2-2a\EX+a^2$
			\[=\EX^2-(\EX)^2=\mathbb{V}\X\]}
		\item{Sei X diskret,$\quad a=\EX$
			\[\to\mathbb{V}\X=\sum\limits_{K=1}^\infty(x_k-a)^2\p(\X=x_k)\]}
		\item{Sei X stetig, p Dichte
			\[\to\mathbb{V}\X=\int\limits_{-\infty}^\infty(t-a)^2p(t)\;dt\]}
		\item{$\p(\X=c)=1\qquad \EX=c$
			\[\to \p(\X-c=0)=1\quad\to\quad\mathbb{V}\X=0\cdot\p(\X=c)=0\]}
		\item{\[\mathbb{V}(\alpha\X+\beta)=\mathbb{E}((\alpha\X+\beta)
			-\underbrace{\mathbb{E}(\alpha\X+\beta)}_{=\alpha\EX+\beta})^2
			=\mathbb{E}\alpha^2(\X-\EX)^2=\alpha^2\mathbb{V}\X\]
			\[\mathbb{V}(\alpha\X+\beta)=\alpha^2\mathbb{V}\X\]}
		\item{X,Y sind unabhängig,$\quad a=\EX,b=\mathbb{E}\Y$
			\begin{align*}
				\mathbb{V}(\X+\Y)&=\mathbb{E}(\X+\Y)
				-\underbrace{\mathbb{E}(\X+\Y)}_{a+b})^2\\
				&=\mathbb{E}(\X-a)^2-2\mathbb{E}(\X-a)(\Y-b)+\mathbb{E}(\Y-b)^2\\
				&=\mathbb{V}\X-(*)+\mathbb{V}\Y
			\end{align*}
			da X,Y unabhängig $\quad\to\quad X-a,Y-a$ sind unabhängig\\
			$\to\quad\mathbb{E}(X-a)(\Y-b)=\mathbb{E}(\X-a)\mathbb{E}(\Y-b)
			=0^2$
			\[\mathbb{V}(\X+\Y)=\mathbb{V}\X+\mathbb{V}\Y\qquad
			\text{für X,Y unabhängig}\]}
	\end{enumerate}	
	
	\setcounter{Bsp}{0}
	\begin{Bsp}
		X sei gleichverteilt auf $\lb x_1,\ldots,x_n\rb$
		\[a=\EX=\frac{1}{N}\sum\limits_{j=1}^N x_j
		\quad\to\quad \mathbb{V}\X=\frac{1}{N}\sum\limits_{j=1}(x_j-a)^2\]
		X sei gleichverteilt auf $\lb1,\ldots,6\rb\quad\to\quad a=3.5$
		\begin{align*}
			\mathbb{V}\X&=\frac{1}{6}[(1-\frac{7}{2})^2+(2-\frac{7}{2})^2
				+\ldots+(6-\frac{7}{2})^2]\\
			&=\frac{1}{6}(\frac{25}{4}+\frac{9}{4}+\frac{1}{4}+
				\frac{1}{4}+\frac{9}{4}+\frac{25}{4})\\
			&=\frac{1}{6}\cdot\frac{70}{4}=\frac{35}{12} \qquad
			\text{(Varianz beim Würfeln)}
		\end{align*}
	\end{Bsp}
	
	\begin{Bsp}
		X sei gleichverteilt auf $[a,b]$
		\[\EX=\frac{a+b}{2}\]
		\[\EX^2=\frac{1}{a-b}\int\limits_a^b t^2\;dt
			=\frac{1}{3}\frac{b^3-a^3}{b-a}=\frac{a^2+ab+b^2}{4}\]
		\[\mathbb{V}\X=\EX^2-(\EX)^2=\frac{a^2+ab+b^2}{3}-\frac{a^2+2ab+b^2}{4}
			=\frac{a^2}{12}+\frac{b^2}{12}-\frac{ab}{6}=\frac{(b-a)^2}{12}\]
	\end{Bsp}
	
	\begin{Bsp}
		X ist $B_{1,p}$-verteilt\\
		$\to\quad\p(\X=1)=p;\quad\p(\X=0)=1-p$
		\[\EX=p\]
		\[\EX^2=0^2(1-p)+1^2p=p\]
		\[\mathbb{V}\X=p-p^2=p(1-p)\]
		$\X_1,\ldots,\X_n$ unabhängig $B_{1,p}$-verteilt\\
		$\X=\sum\limits_{i=1}^n\X_i\quad\to\quad\X\sim B_{n,p}$
		\[\mathbb{V}\X=\mathbb{V}\X_1+\ldots+\mathbb{V}\X_n
			=n\cdot p(1-p)\]
		Varianz wird maximal für $p=\frac{1}{2}$ 
	\end{Bsp}
	
	\begin{Bsp}
		X Poissonverteilt mit $\lambda>0$
		\[\EX=\lambda\]
		\begin{align*}
			\EX^2&=\sum\limits_{k=0}^\infty k^2\frac{\lambda^k}{k!}\\
			&=\sum\limits_{k=1}^\infty k\frac{\lambda^k}{(k-1)!}e^{-\lambda}\\
			&=\lambda\sum\limits_{k=0}^\infty (k+1)\frac{\lambda^k}{k!}
				e^{-\lambda}\\
			&=\lambda\left[\sum\limits_{k=0}^\infty k\frac{\lambda^k}{k!}
				e^{-\lambda}+\sum\limits_{k=0}^\infty
				\frac{\lambda^k}{k!} e^{-\lambda}\right]\\
			&=\lambda\left[\EX+1\right]\\
			&=\lambda^2+\lambda
		\end{align*}
		\[\to\quad\mathbb{V}\X=\lambda^2+\lambda-\lambda^2=\lambda\]
	\end{Bsp}
	
	\begin{Bsp}
		X sei $\mathcal{N}(a,\sigma^2)$-verteilt
		\[\EX=a\]
		\[\mathbb{V}\X=\frac{1}{\sqrt{2\pi}\sigma}\int\limits_{-\infty}^\infty
			(x-a)^2 e^{-\frac{\frac{1}{2}(x-a)^2}{\sigma^2}}\;dx
			\qquad (*)\]
		\[y := \frac{(x-a)}{\sigma}\qquad dx=\sigma dy\]
		\[\to (*)=\frac{1}{\sqrt{2\pi}}\int\limits_{-\infty}^\infty
			y^2\sigma^2 e^{-\frac{y^2}{\sigma^2}}\;dy\]
		\[\stackrel{\text{2-malige part. Integration}}{=}
			\frac{\sigma^2}{\sqrt{2\pi}}\int\limits_{-\infty}^\infty
			y^2 e^{-\frac{y^2}{\sigma^2}}\;dy=\sigma^2\cdot 1\]
			\[\X\sim\mathcal{N}(a,\sigma^2)\qquad\text{a Erwartungswert, $\sigma^2$
			Varianz}\]
		\begin{figure}[ht]
    		\centering\input{figures/var01.pictex}
			\caption{Verschieden Varianzen der Normalverteilung}
       		\label{fig:var01}      
		\end{figure}	
	\end{Bsp}
	
\subsection*{Kovarianz}
\index{Kovarianz}
	
	Gegeben seien Zufallsgrößen X und Y. Im Allgemeinen sind X und Y 
	\underline{nicht} unabhängig. Wir suchen ein Maß für die Abhängigkeit
	
	\setcounter{Bsp}{0}
	\begin{Bsp}
		X sei Körpergröße einer Person, Y sei Gewicht\\
		"`Wie"' abhängig sind X und Y?
	\end{Bsp}	
	
\subsubsection*{Vorbetrachtung}

	Seien X,Y unabhänig,$\quad a=\EX,b=\mathbb{E}\Y$
	\[\mathbb{E}(\X-a)(\Y-b)\stackrel{\text{unabh.}}{=}
		\mathbb{E}(\X-a)\mathbb{E}(\Y-b)=(a-a)(b-b)=0\]
		
	\begin{Def}
		X,Y seien zufällige Größen mit 2. Moment,$\quad a=\EX,b=\mathbb{E}\Y$
		\[cov{(\X,\Y)}=\mathbb{E}(\X-a)(\Y-b)\]
		die Kovarianz von X und Y
	\end{Def}
	
\subsection*{Eigenschaften}
	
	\begin{enumerate}
		\item{$cov(\X,\Y)=cov(\Y,\X)$}
		\item{X und X heißen unkorrelliert, wenn $cov(\X,\Y)=0$ \\
			unabhängig $\Rightarrow$ unkorrelliert $\not\Leftarrow$}
		\item{\[cov(\X,\Y)\leq (\mathbb{V}\X)(\mathbb{V}\Y)\]
			\[\varrho(\X,\Y):=\frac{cov(\X,\Y)}
				{\sqrt{\mathbb{V}\X\cdot\mathbb{V}\Y}}
				\qquad\text{(Korrelationskoeffizient)}\]
			\[-1\leq\varrho(\X,\Y)\leq1\]
			$\varrho(\X,\Y)$ nahe bei 1 oder -1: Starke Korrelation
			\[\varrho(\X,\X)=1\qquad\varrho(\X,-\X)=-1\qquad
				\varrho(\X,\frac{\X}{2})=1\]}
		\item{$p_{ij}:=\p(\X=x_i,\Y=y_j)\qquad$ (diskreter Fall)
			\[cov(\X,\Y)=\sum\limits_{i,j=1}^\infty
				p_{ij}(x_i-a)(y_j-b)\qquad\begin{array}{l}
					a=\EX=\sum\limits_{i=1}^\infty p_{i.}\cdot x_i\\
					b=\mathbb{E}\Y=\sum\limits_{j=1}^\infty p_{.j}\cdot x_j
				\end{array}\]}
		\item{Stetiger Fall:$\p_{(\X,\Y)}$ hat eine Dichte von 
			$p:\mathbb{R}^2\to[0,\infty)$
			\[cov(\X,\Y)=\iint\limits_{-\infty}^\infty 
				p(t,s)(t-a)(s-b)\;dt\;ds\]
			$a=\EX;\quad b=\mathbb{E}\Y$
			\[a=\int\limits_{-\infty}^\infty t
				\left[\int\limits_{-\infty}^\infty t
					p(t,s)\;ds\right]\;dt\]
			\[b=\int\limits_{-\infty}^\infty s
				\left[\int\limits_{-\infty}^\infty 
					p(t,s)\;ds\right]\;dt\]}				
	\end{enumerate}
	
	\setcounter{Bsp}{0}
	\begin{Bsp}
		Urne mit vier Kugeln $(0,0,1,1)$\\
		Ziehen zwei Kugeln \underline{ohne} zurücklegen\\
		X (Y) ist der Wert der ersten (zweiten) Kugel\\
		\[\begin{array}{l|l|l|ll}
			X\backslash Y & 0 & 1 && \qquad\EX
				=\frac{1}{2}\cdot0+\frac{1}{2}\cdot1=\frac{1}{2}\\ \cline{1-4}
			0 & \frac{1}{6} & \frac{1}{3} & \frac{1}{2} &
				\qquad\EX=\frac{1}{2}\\ \cline{1-4}
			1 & \frac{1}{3} & \frac{1}{6} & \frac{1}{2} &
				\qquad\mathbb{V}\X=\frac{1}{2}(0-\frac{1}{2})^2
				+\frac{1}{2}(1-\frac{1}{2})^2=\frac{1}{4}\\ \cline{1-4}
			&\frac{1}{2} &\frac{1}{2} &&\qquad\mathbb{V}\Y=\frac{1}{4}
		\end{array}\]
		\[cov(\X,\Y)=\frac{1}{6}(0-\frac{1}{2})(0-\frac{1}{2})+
			\frac{1}{3}(0-\frac{1}{2})(1-\frac{1}{2})+
			\frac{1}{3}(1-\frac{1}{2})(0-\frac{1}{2})+
			\frac{1}{6}(1-\frac{1}{2})(1-\frac{1}{2})=-\frac{1}{12}\]
			\[\varrho(\X,\Y)=\frac{-\frac{1}{12}}
				{\sqrt{\frac{1}{4}}\sqrt{\frac{1}{4}}}
				=-\frac{4}{12}=-\frac{1}{3}\]
	\end{Bsp}
	
	\begin{Bsp}
		Zweimaliges Würfeln, X ist Minimum der beiden Würfe, Y ist das Maximum
		\[\begin{array}{l|cccccccl}
			X\backslash Y&1&2&3&4&5&6&&\qquad
				\EX=1\frac{11}{36}+2\frac{9}{36}+\ldots+
				6\frac{1}{36}=\frac{91}{36}\approx2.528\\ \cline{1-8}
			1 &\frac{1}{36}&\frac{1}{18}&\multicolumn{4}{c}{\cdots}&
				\frac{11}{36}&\qquad
				\mathbb{E}\Y=1\frac{1}{36}+2\frac{3}{36}+\ldots
				+6\frac{11}{36}=\frac{161}{36}\approx 4.472\\ 
			2&0&\frac{1}{36}&\frac{1}{18}&\multicolumn{3}{c}{\cdots}&
				\frac{9}{36}&\qquad
				\mathbb{V}\X=\frac{11}{36}(1-\frac{91}{36})^2+\ldots
				+\frac{1}{36}(6-\frac{91}{36})^2\\
			3&0&0&\frac{1}{36}&\frac{1}{18}&\multicolumn{2}{c}{\cdots}
				&\frac{7}{36}&\qquad\qquad=\frac{2555}{1296}
				\approx 1.97=\mathbb{V}\Y\\
			4&0&0&0&\frac{1}{36}&\frac{1}{18}&{\cdots}&\frac{5}{36}\\
			5&0&0&0&0&\frac{1}{36}&\frac{1}{18}&\frac{3}{36}\\
			6&0&0&0&0&0&\frac{1}{36}&\frac{1}{36}\\
			&\frac{1}{36}&\frac{3}{36}&\frac{5}{36}&\frac{7}{36}&\frac{9}{36}&
			\frac{11}{36}
		\end{array}\]
		\begin{align*}
			cov(\X,\Y)&=\mathbb{E}(\X-\frac{91}{36})(\Y-\frac{161}{36})\\
			&=\frac{1}{36}(1-\frac{91}{36})(1-\frac{161}{36})
				+\frac{1}{18}(1-\frac{91}{36})(2-\frac{161}{36})\\
				&+\ldots+\frac{1}{36}(6-\frac{91}{36})(6-\frac{161}{36})
				=\frac{1225}{1296}
		\end{align*}
		\[\varrho(\X,\Y)=\frac{\frac{1225}{1296}}{\frac{2555}{1296}}
			=\frac{1225}{2555}=\frac{35}{73}\approx0.479\]
	\end{Bsp}
	
	\begin{Bsp}
		Der Vektor (X,Y)  sei gleichverteilt auf dem Einheitskreis
		\[V:=\lb(t,s):t^2+s^2\leq 1\rb\]
		\[A\subseteq K,\quad \p((\X,\Y)\in A)=\frac{Vol_2(A)}{\pi}\]
		Wissen: X;Y sind abhängig
		\[p(t,s)=\lb\begin{array}{l@{\quad:\quad}l}
			\frac{1}{\pi} & t^2+s^2\leq 1\\
			0 & \text{sonst}
		\end{array}\right.\]
		\[\EX=\mathbb{E}\Y=0\]
		\begin{align*}
			cov(\X,\Y)&=\iint\limits_{-\infty}^\infty
				(t-0)(s-0)\;p(t,s)\;dt\;ds\\
			&=\frac{1}{\pi}\iint\limits_{t^2+s^2\leq 1}ts\;dt\;ds\\
			&=\frac{1}{\pi}\int\limits_{-1}^1 t\left[
				\underbrace{\int\limits_{-\sqrt{1-t^2}}^{\sqrt{1-t^2}} s\;ds}
				_0\right] dt=0
		\end{align*}
		X,Y abhängig, aber unkorrelliert!
	\end{Bsp}
