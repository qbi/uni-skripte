Definition: (LATENZ)
* Zeit zwischen Beginn und Ende einer Aktion, auch: (execution time).



Übersicht über Rechnerarchitektur 1

1. Kapitel: Was ist Rechnerarchitektur?

- 3 Definitionen für RA
- Historische Entwicklung

2. Kapitel: Formale Entwurfsmethoden

- Nutzen von FEM
- Hierarchie

2.1. Automaten

- Nutzen, Definition, Moore/Mealy Automat
- Was ist ein nichtdeterministischer Automat?
- Vergleich Moore/Mealy
- Überführung Moore <> Mealy
- Minimaler endlicher Automat
- Schwachpunkte der Modellierung mittels endlicher Automaten
- Erweiterungen (Statecharts, SDF, CSP)

- Statecharts
  - Eigenschaften (Hierarchiebildung, Nebenläufigkeit)

- Petrinetze
	- Was sind Petrinetze, wozu sind sie gut?
	- Definition + Beispiel
	- Modellierung eines Mealy-Automaten durch ein Petrinetz
 
- Synchrone Datenflussgraphen (SDF)
	- Beschreibung der Kommunikationsregel auf Basis der von Petrinetzen
	- Anwendungsgebiet
	- Definition
	- Inkonsistenz (nicht-periodische Abläufe!)
	- minimaler Vektor (-> Repetitionsvektor)
	- Verklemmungen, Wie kann man die Berechnen, Algorithmus von LEE
	- Schwachpunkte von SDF und Erweiterungen

- Communicating Sequential Process (CSP)
	- Wozu dient es?
	- Grundidee, Grundbegriffe
	- Einzelne Prozesse, Parallele Prozesse
	- Darstellung mittels Prozessbaum

- Rechner- und Systementwurfssprachen (RuS)
	- Sechs Ebenen der Rechnerbeschreibung
	- Unterschied Rechner-/Systementwurfssprache
	- Aufgaben von RuS
	- VHDL
		- Vorteile von VHDL
		- Grobe und feinere Strukturierung einer VHDL-Beschreibung
		- Syntax u. Semantik:
		- Datenfluss-, Struktur- und Verhaltensbeschreibung
		- Konfigurationen (Was leisten diese?)
		- Unterschied Signal/Variablen
		- Aufbau eines VHDL-Simulationssystems:
		- Analyse und Synthese
		- Interner Ablauf einer VHDL-Simulation
		- Zusammenfassung VHDL: mächtige Sprache -> schwierige Synthese
	  - Synthetisierbarkeit
		- Abstraktionsebenen
		- -> Architektursynthese, Register-Transfersynthese,
		  Logiksynthese, Schaltungssynthese
		- Automatisierung ist teilweise problematisch
		- Unterscheidung in kombinatorische und sequentielle Schaltung
		  -> Anwendung von Inferenzregeln
	- Technologieabbildung
		- Abbildung einer technologieunabhängigen Netzliste (boolsche
		  Netzliste) auf eine Zielstruktur (Abhängig von der Technologie
		  des Schaltkreisherstellers) 
		- Abbildung unter Verwendung einer Kostenfunktion (Zeit+Fläche)
		- Strategie: (1) Rückführung der Netzliste auf standardisierte
		  Form (2) Versuch der Überdeckung durch Bibliothekselemente
		- Optimale Technologieabbildung mit minimalen Kosten (TODO:
		  Formel einfügen!)
		- ^^ in der Gleichung bleibt ein Problem: Ein Gatterausgang kann
		  nicht als Eingang weiterverwendet werden, Lösung: weitere
		  Bedingung: Verfügbarkeitsbedingung

3. Halbleitertechnologie
	- FET(spannungsgesteuert) vs. Bipolartransistor(stromgesteuert)
	  (Leistungsaufnahme!)
	- Aufbau von MOS
	- Funktionsweise des Anreicherungstyps
	- Schaltverhalten n-Kanal, p-Kanal-Mosfet
	- Gatterlogik und Komplexgatter
	- prinzipieller Aufbau von CMOS-Gattern
	- Komplexgatter (TODO: Was ist das?) erlauben einstufige
	  Realisierung
	- Abbildung in dichte Layouts
	- Gesetz von NOYCE/MOORE:
		- Anteil der Geschwindigkeit der Entwicklung der Technologie an
		  der Entwicklung des Mikroprozessors
		- Schrumpfung der Bauelemente durch Skalierung
		- alle 18-24 Monate erfolgt eine Verdopplung der Bauelemente auf
		  einem Chip (empirisch gewonnene Aussage von Moore in den
		  60igern)
	- natürliche Grenze: Leitungen nicht dünner als die sich darin
	  bewegenden Elektronen
	- Technologie: 1.-4. Generation, 5. Generation hat sich nicht
	  durchgesetzt (-> Real World Computing, Earth-Simulator!)
	- Mikroelektronik dominiert durch planare Halbleitertechnologie
	  SKALIERUNG (1):
	- Welche Parameter gelten für die Bauelemente: + Skalierung mit
	  einem Faktor /alpha > 1 Realistisch: nicht alle Parameter werden
	  mit dem gleichen Faktor skaliert
	- Versorgungsspannung konstant (Kompatibilität!)
	- Welche Vorteile hat die Skalierung? (Verzögerungszeit, Fläche,
	  Verlustleistung, Kosten)
	- Welche Probleme gibt es bei der Skalierung? (Bsp. Gatelänge, Weite
	  der Verarmungsschichten von Source/Drain), Folgen und Maßnahmen!
	  SKALIERUNG (2): SCHWIERIGKEITEN BEI VERBINDUNGEN:
	- "interconnect crisis" - langsame globale Verbindungen, wenig
	  externe Verbindungen; Herkunft dieser Probleme
	- Laufzeitverzögerungen (lange Leitung ;-) -- Abnahme der
	  Kanallängen um den Faktor /alpha
	  - Gatterschaltzeiten nehmen ab, Laufzeitverzögerung nimmt zu bei
	  	gleich langer Leitung
	- Quadratische Zunahme der # der Bauelemente (durch Skalierung
	  UND/ODER Chipvergrößerung) 
	- Limitationen durch # der Pins -> Regel von RENT: Anzahl der Pins
	  vs. Anzahl der verwendeten Gatter, P=B*N^s (B,s
	  schaltkreisspezifisch) -> s ca. 0,7: Bedarf an externen
	  Anschlüssen steigt stärker als die # der Pins
	  - Lösung: explizite Laufzeitverzögerung durch spezielle
	  	Werkstoffe, um die RC-Konstante zu erniedrigen
	- Roadmap der SIA (Silicon Industry  Association)
	- Zunkunftsentwicklung: SOI (Silicon on Insulator)
	- Zusammenfassung/Technologie

4. Komponenten eines Rechners
  - URA, 7 Prinzipien des Konzepts 
	- 1. Der Rechner besteht aus 4 Werken. (Speicher, Rechen, Leitwerk,
	  E/A-Werk) 
	- 2. Die Struktur des Rechners ist unabhängig vom Problem
	  (programmgesteuert).  
	- 3. Programme und Daten im selben Speicher 
	- 4. Hauptspeicher ist in Zellen gleicher Größe eingeteilt, die
	  fortlaufend addressiert sind 
	- 5. Prinzip der Sequentialität (Programm besteht aus Folge von
	  Befehlen) 
	- 6. Abweichungen von der Sequentialität mit bedingten und
	  unbedingten Sprungbefehlen 
	- 7. Verwendung des dualen Zahlensystems
  - Maschinenbefehlszyklus (Neumann UND Zuse!) 
	- 1. Befehl holen 			BH [IF] (instruction fetch)
	- 2. Dekodieren 			DE [ID] (instruction decode and register
	  fetch)
	- 3. Operanden holen		OP [ID] 
	- 4. Ausführung 			BA [EX] (execution and effective adress
	  calculation)
	-  							   [MEM] (memory access)
	- 5. Rückschreibephase 		RS [WB] (write back)
	- 6. Addressierungsphase	AD 
	-
	- | BH | DE | OP | BA | RS       | AD |
	- | IF | ID      | EX | MEM | WB |
  - Alternativen zu URA: Neuronale Rechner, Datenflussrechner
  - Abweichungen vom URA: Systolische Rechner (Kombination aus
  	Datenflussrechnern und SIMD)
  - Abweichungen zur Leistungssteigerung:
	- Vervielfachung einzelner oder mehrerer Teilwerke
	- Mehrstufige Speicherhierarchie (Caches)
	- Prinzip der Selbstmodifikation aufgegeben 
		- Programme und Daten liegen in demselben Speicher (URA), aber:
		  Programme und Daten getrennt im Speicher (Harvard-Architektur)
  - CISC: Complex Instruction Set Computers (2. u. 3. Generation)
	- Umfangreicher Befehlssatz wegen Speicherknappheit
	- Mikroprogrammierung
  - RISC: Reduced Instruction Set Computers (4. Generation)
	- elementare kleine Befehlssätze
	- festverdrahtete Leitwerke (Mealy-Automat)
	- konsequentes Pipelining
  - Pipelining:
	- überlappte Bearbeitung von Arbeitsteilschritten
	- mindestens ein Dutzend Stufen (aktuelle Implementierungen)
  - Superskalares Pipelining:
	- Gruppieren von mehreren Befehlen (mehrere Rechenwerke)
	- Gleichzeitige Anwendung von Operationen auf einzelne Komponenten
	  eines Vektors, aber: auch skalare Operationen müssen durchgeführt
	  werden
	- benötigt Befehlsgruppierer, dynamische Parallelisierung (Umordnung
	  sequentiell einlaufender Befehle)
	- Allgemeines Prinzip: Keine direkte Parallelität! Herausziehen von
	  Parallelität aus dem sequentiellen Befehlsstrom!
  - Pipelining: Welche Leistungssteigerung ist (theoretisch) möglich?
  	(TODO: Werte herausfinden!)
	- Gesamtzeit Tk, Speed-Up Sk (in Abhängigkeit der # stufen, bzw #
	  Instruktionen)
  - Hazards: (Struktur, Steuerung, Daten) -- Lösung per
  	Rechnerarchitektur oder per Compiler (Codegenerierung)
	- Strukturhazard: Bsp. Nur ein Speicherport, gemeinsamer Zugriff,
	  Lösung: idlen der Instruktion
	- Steuerungshazard: Bei Sprüngen, Verzweigungen, Aufrufen und
	  Rücksprüngen; explizites Laden des Folgebefehls -> könnte erst
	  spät bekannt sein, Folge: Aussetzen des Teilwerkes bis Ziel
	  bestimmt
	- Lösung für Steuerungshazards: spekulative Befehlsausführung: 
	(i) mehrere Befehlsströme 
		- Ein Ergebnis wird behalten, das andere verworfen
	(ii) Vorabspeichern des Sprungziels + (iii) Puffer für Verzweigungsziele 
	 	- branch target cache (Idee: Einmal angesprungenes Ziel wird
		  nochmals angesprunge) 
		- Fifo-Befehlsspeicher zwischen Befehlscache und
		  Instruktionsregister
		TODO: Unterschied zum "normalen" Cache? FIFO!
	(iv) stat./dyn. Verzweigungsvorhersage (branch prediction)
		STATISCH:
		- "branch not taken" ; "branch taken" ; "predict by opcode"  
		- Zusätzliches Berechnungshardware
		DYNAMISCH:
		- Aufzeichnen der Vorgeschichte
		- "Taken/not taken"-Schalter ; "Branch History Table"
	(v) verzögerte Verzweigung
		- verzögerte Ausführung von Befehlen, die der Verzweigung folgen
		- "delayed slots" - Ausfüllung mit von der Verzweigung
		  unabhängigen Befehlen
	- Probleme bei mehrfacher Ausführung (TODO: Rausfinden)
  	- Datenhazards: 3 Typen: RAW, WAR, WAW
		- RAW: Instr2 liest Operanden, den Instr1 noch nicht geschrieben
		  hat
		- WAR: Instr2 überschreibt Operanden, bevor Instr1 ihn gelesen
		  hat
		- WAW: Instr2 schreibt Operanden, der durch Instr1 überschrieben
		  wird
	- Gegenmaßnahme: Forwarding
  		- Rückführung der Ergebnisse an die Eingänge der ALU (bypass)
  		- komplexe, aber verkürzte Datenpfade!
  		- Umordnung des Codes (Code Scheduling) (EPIC-Architektur)
	- Gegenmaßnahmen in HW (Dynamic Scheduling)
  		- Vorteile: 
  			- einfacher Compileraufbau
  			- Platformunabhängigkeit des Codes
  			- Berücksichtigung von zur Compilezeit unbekannten
  			  Abhängigkeiten
  		- Grundprinzip:
  			- out-of-order execution/completion
  			- Verhindern des Anhaltens der Pipeline durch Ändern des
  			  ursprünglichen Ablaufplans
  		- Nachteil:
  			- Gefahr von WAR und WAW
	- SCOREBOARDS: (part of dynamic scheduling)
		- HW-Tabelle zur Verwaltug von Instruktionsfolgen
		- Instruktionsausführung ohne Rücksicht auf ihre Reihenfolge im
		  Code
		- Vorraussetzung: Struktur- und Datenhazardfrei!
		- Zweiteilung der Dekodierphase:
			- (1) (DE1) (issue stage): Instruktionen dekodieren,
			  Strukturhazards ausschliessen
			- (2) (DE2) (read ops):   Datenhazards ausschliesen, Operanden
			  lesen
		- Gefahr von WAR und WAW durch Änderung des Planes;
		  Gegenmaßnahmen:
		  	- für WAR: 
		  		- Kopie der Operanden bei der Operation mitführen
		  		- Register *nur* während der OP auslesen
		  	- für WAW:
		  		- Hazard erkennen und warten bis dieser aufgelöst ist
		- Scoreboard überwacht
			- Datenabhängigkeiten
			- auszuführende Ops
			- Instruktionszustände
		- Scoreboard unterteilt ID in
			- DE1 und DE2
		- Vierstufige Ausführung:
			- 1. DE1: 
				- Instruktion lesen und auf Strukturelle Hazards prüfen
					- freie Funktionseinheit (FE) && keine Instruktion
					  mit gleichem Zielregister?
					- ja: Instruktion an FE senden, update Scoreboard
					- nein: stalls für aktuelle Instruktion, keine
					  weiteren Instruktionen aktivieren
			- 2. DE2:
				- Operanden lesen && warten bis Datenhazards
				  ausgeschlossen -> Lesen der Register
				  	- Quelloperand nutzbar? (d.h. früher aktivierte
				  	  Instruktion, die ihn benutzte, hat geendet ||
				  	  unbenutztes Op-Register! -> Ausschluss von RAW)
				  	- ja: SB veranlasst Lesen des Registers
			- 3. AS: (Operation ausführen)
				- FE startet Operation
				- bei längertaktigen Operation: Scoreboard informieren
				  falls fertig
			- 4. RS: (Rückschreibephase)
				- auf WAR-Hazards testen
				- ja: stalls, bis aufgelöst

		- Scoreboard Datenstruktur:
		enum TYPE_STATE = { issue, read_op, fe_ready, write_result };
		
		typedef struct InstructionT {
			TYPE_STATE instr_state; 	// which state are we in
			typedef struct FunctionEntityT {
				boolean busy; 			// FE active/inactive
				TYPE_OP op; 			// type of operation
				TYPE_REG dr; 			// destination register
				TYPE_REG sr1, sr2;		// source registers 1 and 2
				FunctionEntityT *fe1,*fe2;// FE, which create sr1 and
										// sr2's data
				boolean	fsr1, fsr2;		// indicate if sr1 and sr2 are
										// usable
			}
		}

		FunctionEntityT reg_state[NumberOfRegisters]; // shows which FE
													 // accesses a reg
		- Scoreboard Algorithmus:
		
		InstructionT instr;
		issue_stage(instr); 
		
		FunctionEntityT	fe;
		
		switch (instruction) {
		case issue:
			wait_until(!fe.busy && !reg_state(dr));
			fe.busy=TRUE; fe.op=instr.op;
		...
		...
		
	- Fazit Scoreboard:
		- einfache HW-Strukur, erhöhte Tendenz zu WAR- und WAW-Hazards
		  durch out-of-order commit
		  
	- TOMASULO-Algorithmus: (Basis für alle heutigen dynamischen
	  Ablaufpläne, ab P2)
		- Verhindern der Steigerung von WAR- und WAR-Hazards
		- Registerumbennung + Scoreboard
		- Unterschied Scoreboard:
			- Hazarderkennung und Ausführungssteuerung getrennt
			- Ergebnisse gehen direkt an die Funktionseinheiten
			  (Umgehung der Register)
	- Struktur:
		- Reservierungsstationen
			- Reservierungstabellen an jeder Funktionseinheit triggern
			  den Beginn einer Instruktion (Signal an Steuerung)
		- Registerumbenennung
		- gemeinsamer Datenbus
	- dreistufige Ausführung:
		- 1. Befehl installieren (BH+DE) (hole nächste Instruktion)
			- Reservierungsstation frei?
			- ja: d.h. kein Strukturhazard, Instruktion starten und Operanden
			  übertragen (Register umbennen)
		- 2. Ausführung (BA) (führe Operation aus)
			- Beide Operanden nutzbar?
			- ja: starte Ausführung
			- nein: beobachte gemeinsamen Datenbus
		- 3. Rückschreiben (RS) (schliesse Operation ab)
			- Ergebnis über gemeinsamen Datenbus an alle wartenden
			  Funktionseinheiten senden
			- markiere nutzbare Reservierungsstation
			- normaler Datenbus: Daten + Zieladresse
			- gemeinsamer Datenbus: Daten + Quelladresse
	- Vorteil Tomasulu:
		- Vermeidung von WAR, WAW durch Registerumbenennung
		- Abkürzende Datenpfade durch Forwarding (gemeinsamer Datenbus
		  ermöglicht Anliegen des Ergebnisses einen Taktzyklus früher
		  als bei Scoreboard)
	- Nachteil:
		- komplexe Hardware: komplexere Kontrolllogik, assoziative
		  Speicherung (TODO: Assoziative Speicherung? Schlecht?)
	- RISC/CISC- Vergleich
		- CISC: 
			- Kosten für Software übersteigen die der Hardware
			- Komplexität bei Hochsprachen
			- Semantische Lücke
				- In many layered systems, some conflicts when concepts
				  at a high level of abstraction need to be translated
				  into lower, more concrete artifacts. This mismatch is
				  often called semantic gap.

				- For example, semantic gap denotes the difference
				  between the complex operations performed by high-level
				  language constructs and the simple ones provided by
				  computer instruction sets. It was in an attempt to try
				  to close this gap that computer architects designed
				  increasingly complex instruction set computers.
				- Divergenz zwischen komplexen Softwareinstruktionen bei
				  Programmen und Betriebssystemen und den einfachen
				  Hardwareinstruktionen
			- damit:
				- große # Befehle, mehrere Adressierungsarten,
				  Hardwareunterstützung für Hochsprachenkonstrukte
			- Intention:
				- einfachere Implementierung von Compilern
				- Verbesserung der Ausführungseffizienz
				  (Komplexoperationen als Mikrocode)
				- Unterstützung von Hochsprachenkonstrukten
		- RISC:
			- Pattersenstudie 1982
				- Untersuchung von bestimmten Eigenschaften bei der
				  Befehlsausführung von Hochsprachenprogrammen
				- Operationen
					- 1. Zuweisungen, 2. Bedingungen
					- Transport und Verzweigung auf Maschinenebene
					  optimieren
				- Operanden
					- 1. lokale, skalare Variablen
					- Optimieren des Zugriffs auf lokale Variablen
				- Wichtige Lösung: lokale Variablen in Registern halten
				  ( => Reduzierung der Speicherzugriffe )
		- Notwendigkeit für RISC: großer Registersatz
			- Hardwarelösung
				- viele Register
				- hohe # lokaler Variablen kann in Registern gehalten
				  werden
			- Softwarelösung
				- Compiler allokiert Register optimal
				- Allokierung basiert auf der Feststellung der höchsten
				  Verwendung von bestimmten Variablen in einer Zeit
				- komplexe Programmanalyse
				- Bsp. Graphfärbungsalgorithmus
					- Optimierung der # der verwendeten Register
					- TODO: Wie funktioniert der?
				- Bsp. Registerfenster
					- bezüglich Prozeduraufrufen
					- wenige Parameter, begrenzte Aufruftiefe
					- kleinere Registermenge
					- Aufruf: Umschalten auf eine andere Registermenge
					- Rücksprung: Rückschalten auf eine vorherige
					  Registermenge
					- Überlappende Registerfenster sind Lösung
					- TODO: Wie funktionieren die?
		- RISC-Zusammenfassung:
			- Ansatz: 1 Instruktion pro Takt
			- Operationen nur auf Registern (Load/Store-Architektur)
			- wenige, einfache Adressierungsmodi (TODO: Genauer, was
			  sind Adressierungsmodi?)
			- wenige, einfache Befehlsformate
			- festes Befehlsformat
			- kein Mikrocode (festverdrahteter Befehlsentwurf)
			- mehr Compilezeit erforderlich (schärfere Analyse)
		- CISC, warum nur, CISC?!?!
			- Vereinfachter Compiler? Umstritten!
				- komplexe Maschinenbefehle schwierig auszunützen
				- schwierigere Optimierung
			- Kleinere Programme? 
				- weniger Speicherbedarf (Speicher jedoch billig!)
				- viele Befehle -> lange Opcodes
			- Schnellere Programme?
				- Trend zur Verwendung einfacher Anweisungen
				- komplexere Leitwerke nötig
				- Mikroprogrammspeicher ist größer -> Ausführung
				  einfacher Programme benötigt mehr Zeit!
			- Fazit: Unklar, ob CISC eine vernünftige Lösung ist!
		- RISC-Prozessoren:
			- sehr leistungsstark, Verzicht auf Kompatibilität
		- CISC-Prozessoren:
			- Kompatibilität im Vordergrund
			- trotz geringerer Leistungsfähigkeit durch
			  Mikroprogrammierung Marktführer!
		- Kombination RISC/CISC:
			- Ziel: Hohe Leistung && Hohe Kompatibilität
			- RISC Techniken in CISC eingeführt
				- Sprungzielspeicher
				- Befehlssatz auf RISC-Ebene herunterbrechen und
				  Teilmenge nach dem RISC-Prinzip abarbeiten, andere
				  nach Mikroprogrammierung
				- interne Dekodierung von CISC-Befehlen in elementare
				  RISC-Befehle
				- Betriebssystemerweiterung (erweiterte E/A mit
				  CISC-Instruktionen)
		- Ausblick:
			- Derzeitige RISC-Prozessoren nähern sich CISC an
			- Kompatibilität und On-Chip-Funktionalität erhöhen
			- feinkörnige Parallelität bei sowohl RISC, als auch CISC
				- verstärkte Nutzung von Pipelining (Superpipelining)
					- höhere # Stufen, kürzere Befehlszyklen, höherer
					  Takt
				- mehrere Spezialisierte ALU's (Superskalarität)
					- FP, Int, Adressberechnungseinheiten mehrfach!
			- vier Entwicklungen:
				- (1) VLIW (Very long instruction word)-Architekturen
					- statische oder explizite Parallelisierung
				- (2) Multithreading
					- Hyperthreading
				- (3) Netzwerkprozessor
					- basieren auf JVM
				- (4) Chipmultiprozessoren
			- Ziel von VLIW und Multithreading:
				- Beschränkungen des Parallelismus bei superskalaren
				  Architekturen beseitigen
				- dynamische Paral. (immer nur ein Ausschnitt des
				  Programmkodes)
				- statische Paral. (im Prinzip das gesamte Programm
				  verfügbar)
		- (1) VLIW-Architekturen:
			- Parallelisierung nicht zur Laufzeit sondern während
			  Compilephase (Codeoptimierung)
			- Compiler erzeugt lange Instruktionen (jeder ALU einen
			  Maschinenbefehl zuordnen)
				- Analyse mittels DAG (Datenabhängigkeitsgraph)
			- PRO:
				- Zeitaufwand nur in der Übersetzungsphase (Optimierung)
				- schlankere Leitwerke (Steuerlogik vereinfacht sich)
			- CON:
				- Parallelisierung nicht so flexibel wie im Dynamischen
				- Redundanz im Code
				- Programme superskalarer Rechner sind inkompatibel zu
				  VLIW-Rechnern
		- EPIC-Architektur: (IA-64 HP+Intel), Ist eine
		  VLIW-Implementierung
			- Verzweigungen:
				- spekulativ (superskalar)
					- beide Pfade werden ausgeführt, der falsche wird
					  später verworfen
			- spekulatives Laden
				- noch nicht benötigte Daten werden willkürlich aus
					  dem Speicher geladen
			- Gleitkommaverarbeitung
				- MAC(?)-Operationen, "Multiply-and-Accumulate"
			- Kompatibilität
				- Einmal übersetzter Code wird im Speicher gehalten
		- (2) Multithread-Architekturen
			- Idee: Programm durch Programmierer oder Compiler in von
			  einander unabhängige Teile (Fäden) zerlegen
			- von einander unabhängige Befehle verschiedener Prozesse
			  mischen
			- Pro Prozessor ein Thread (Faden)
			- Globaler Speicher zur Synchronisation
			- Compiler ist für Synchronisierung zuständig
			- jeder Thread hält lokalen Speicher
			- einfacher Prozesskontext pro Thread 
		- aktuelle Variante: Hyperthreading (synchrones Multithreading)
			- mehrere logische Prozessoren auf einem physikalischen Prozessor
			- überproportionaler Anstieg von elektrischer Leistung und
			  Chipfläche gegenüber Zuwachs an Rechenleistung
		- Parallelismus auf Threadebene:
			- time slice multithreading
				- Zeitscheibenmechanismus
			- event driven multithreading
				- Schalten bei Ereignissen, die lange Latenzzeiten nach
				  sich ziehen
			- simultaneous multithreading
				- kein Schalten, sondern auswählen
				- logische Prozessoren durch Architekturzustand gegeben
					- eigener Registersatz, Kontrollregister,
					  Maschinenstatusregister
					- eigenes Steuerregister für Interrupts (APIC)

	- Das Rechenwerk
		- Prozessor besteht aus Leitwerk und Rechenwerk
		- IEEE754: Spezifikation:	
			- vier Fliesskommazahlenformate
				- single, double prec, single, double extended
			- -> Genauigkeitsanforderungen für die Formate
			- | Vz | HB | Ex | .. | Ex | Mt | .. | Mt |
			-   31   30   29        23   22        0
			- TODO: Wie genau funktioniert die Darstellung?
		- Schnelle Addierer
		- Grundlage 1-Bit FA:
			- S = ~AB~C v A~B~C v ~A~BC v ABC
				= ~C(~AB v A~B) v C(~A~B v AB) 
				= ~C(A x B)		v C( ~(A x B) )
				= not(C) and ( xor (a,b) ) or C and ( not(xor(a,b) ) )
			- C = AB v AC v BC (alternativ: C=AB v C(AxB) )
		- Serieller Addierer mit FA:
			- Schiebe-Register A, B geben pro Takt ihre Werte an den FA,
			  der gibt sum aus und legt Carry für den nächsten Takt in
			  FlipFlop ab (für Eingang am FA)
		- Ripple-Carry-Addierer
			- n-Bit-Wörter A(1..n) und B(1..n) legen ihre Werte jeweils
			  an FA(1..n) an
			- das von FA(c) berechnete carry wird dabei an den Eingang
			  von FA(c+1) angelegt (Latenz!)
			- Vorteil:
				- einfache Struktur
				- gut für VLSI: Transmission-Gate, Manchester-Addierer
			- Nachteil:
				- hohe Latenzzeit
		- drei Mechanismen zum schnellen Addieren:
			- (1) schneller Übertragsdurchlauf
				- Transmissiongate Addierer (TODO: Wie arbeitet das
				  Ding, was bedeuten die Eingänge Pi und ~Pi?)
			- (2) parallele Übertragsberechnung
			- (3) hierarchische Addiererstrukturen
		- Conditional-Sum-Addierer
			- Bsp. Carry-Look-Ahead
			- Alternative: Carry-Select-Addierer
				- bestehend aus Conditional-Sum-Addierer
				- hierbei werden zwei Fälle berechnet:
					- Fall 1: Kein Übertrag entsteht
						- S(0) = A x B, C(0) = A ^ B
					- Fall 2: Übertrag entsteht
						- S(1) = ~(A x B), C(1) = A v B
				- in Abhängigkeit der tatsächlichen Situation werden die
				  Bits gewählt (TODO: WIE???)
		- Mehr-Operanden-Addierer (Carry-Save-Adder)
			- TODO: WIE???

		- Multiplikation: Reduzierung der # der Teilprodukte
			- Bsp. Radix-4-Multiplication
				- Reduzierung der Teilprodukte auf m/2
				- Gleichzeitige Auswertung von 2 Bit des Multiplikators
			- Probleme: 
				- erhöhter Hardwareaufwand
				- größere Latenz der Einzelschritte
			- Bsp. Feldmultiplizierer
				- Pipeliningprinzip (Höherer Durchsatz)
				- Operandenbits liegen in Matrixform vor:
-				 					a3		a2		a1		a0     | 
-				                    -------------------------------+---
-									a3b0	a2b0	a1b0	a0b0   |b0
-							a3b1	a2b1	a1b1	a0b1		   |b1
-					a3b2	a2b2	a1b2	a0b2				   |b2
-			a3b3	a3b3	a2b3	a1b3						   |b3
-			-------------------------------------------------------+--
-	P7		P6		P5		P4		P3		P2		P1		P0	   |
			- Bsp, für Feldmultiplizierer: Carry-Save-Array-Multiplier
				- Funktionalität eines FA um ein AND erweitert
				- S = (ab)x s' x c' , C= abs' v abc' v s'c

	- Speicherwerk
		- entscheident für Leistungsfähigkeit und Kosten eines Rechners
		- Ideal: (aus wirtschaftl. Gründen nicht realisierbar) 
			- ausreichende Kapazität
			- Zugriffszeit in der Größenordnung der
			  Prozessorgeschwindigkeit
		- Lösung: mehrstufige Speicherhierarchie (Cache!)
		- jeder Speicher einer niedrigeren Hierarchiestufe hält den
		  Ausschnitt des Speicher des nächstgrößeren
	- Charakteristika eines Speichers:
		- Ort
			- Prozessor, Intern, Extern
		- Performanz
			- Zugriffszeit, Zykluszeit, Transferrate
		- Kapazität
			- Wortbreite, # der Wörter
		- Physischer Typ
			- Halbleiter, Magnetisch, Optisch, Magneto-Optisch
		- Transfereinheit
			- Wort, Block
		- Zugriffsmethode
			- Sequentiell, Direkt, Zufällig, Assoziativ
		- Physische Charakteristika
			- flüchtig, nicht-flüchtig
	- Prozessorzugriff auf schnelleren Speicher überhaupt möglich, da
	  eine zeitliche und räumliche Lokalität von Daten oder Befehlen
	  vorliegt!
	- Cache:
		- kleiner, schneller Pufferspeicher zwischen Register und
		  Hauptspeicher
		- Funktion: Überbrückung der Prozessor/Speicherlücke bzgl.
		  Leistung
		- Struktur: Blöcke ähnlich dem  Hauptspeicher
		- Typen: Primär- und Sekundärcache, (L3- Tertiärcache)
			- Primär: Daten und Befehle getrennt, kurze Blöcke bis 64
			  Byte (Harvard-Cache)
			- Sekundär: Daten und Befehle gemeinsam, längere Blöcke
			  (unified cache)
		- Zugriff: 
			- Steuerwerk überprüft anhand Adresse, ob das Datum im
			  Speicher vorhanden ist
			- Vorhanden? HIT: Datum auslesen
			- Nicht vorhanden? MISS: Wort aus Hauptspeicher in den Cache
			  kopieren und angefordertes Datum lesen
		- Organisationsprobleme:
			- (1) Platzierungsproblem (in welchem Cacheblock wird der
			  Hauptspeicherblock abgebildet)
			- (2) Identifikationsproblem (Wiederauffinden eines Datums
			  im Cache)
			- Möglichkeiten für Platzierung:
				- (1) direct mapping (einfach assoziativ)
					- jeder Adresse B eines Hauptspeicherblocks wird
					  direkt ein Block m bestehend aus N Cache-Blöcken
					  zugewiesen (zbsp. m = B % N )
				- (2) full associative (vollassoziativ)
					- jede Adresse eines Hauptspeicherblocks kann in
					  einen beliebigen Cache-Speicherblock abgebildet
					  werden
				- (3) n-way associative (n-fach assoziativ)
					- Cache Blöcke in s-Mengen mit jeweils n Blöcken
					  unterteilen ( s = N/n )
					- Hauptspeicherblock nach "direct mapping" in
					  eine CacheBlock-Menge abbilden, innerhalb der
					  Menge beliebig 
					- n=N: voll-assoziativ, n=1: einfach assoziativ
			- Abbildung ist surjektiv
				- Kennung zur Identifikation der Adresse des Hauptspeicherblocks
				  notwendig (TAG)
					- | Tag-Index 24Bit | Index 6Bit | BlockOffset 2Bit|
				- mit steigender Assoziativität verschiebt sich die
				  Tag/Index-Grenze nach Rechts
				- Zusätzlich noch ein (V)alidy-Bit -> Eintrag gültig?
				- n-fach assoziativ -> n-Komparatoren benötigt
				- direct mapping -> nur ein Komparator, ABER:
					- mehrere Adressen bilden auf den selben Block ab:
					  viele Kollisionen (häufiges Umladen)
				- ergo: Assoziativität verringert die Wahrscheinlichkeit
				  von Kollisionen, optimal: voll-assoziativ, aber
				  langsam/teuer
				- real: 2,4 oder 8fach-assoziativ
			- Aktualisierungsstrategie:
				- Inkonsistenz zwischen Hauptspeicher und Cache
					- Wann/Wie Hauptspeicher aktualisieren?
				- (1) write through
					- jede Änderung sofort im Hauptspeicher
					  aktualisieren
					- Pro: Konsistenz gegeben
					- Con: Hohe Last für CPU/Speicherbus
					- Anwendung in Primärcaches
				- (2) write back
					- Aktualisierung bei Verdrängung,
					  Ausgabeoperation, Zugriff eines anderen
					  Prozessors (SMP)
					- dirty bit -> Rückschreiben nicht-modifizierter
					  Einträge vermeiden
					- Anwendung in Sekundärcaches
			- Ersetzungsstrategie:
				- cache miss -> Fehlzugriff im Cache tritt auf
					- Nachladen des Datums aus dem Hauptspeicher
				- Ersetzen von vorhandenen Daten (möglicherweise) nötig 
					- direct mapping: easy
					- assoziativ:
						- LRU (least recently used)
							- Alterungsinformationen mitführen
						- LFU (least frequently used)
							- Benutzungsstatus (Zähler o.ä.)
						- FIFO (first in - first out)
							- z.bsp. durch Ringpuffer realisierbar
							- ersetzen der am längstem im Puffer
							  befindlichen Zeile
						- random 
							- geringer Hardwareaufwand durch Wegfall von
							  Stapel- oder Pufferstrukturen
							- pseudo random -> ermöglicht auch debugging
			- Leistungsbetrachtungen
				- mittlere (effektive) Speicherzugriffszeit:
					-
					- T_a = T_h + m * T_m
					-
					- m - miss rate, T_m - miss penalty (Nachladezeit),
					  T_h - hit time (mittlere Zugriffszeit)
				- Optimierung von T_a
					- Reduzierung von T_h, m und T_m
					- Aber: Reduzierung von einer Größe bedeutet häufig
					  Verschlechterung der beiden anderen
					- Kompromiss finden
				- Reduzierung von m (miss rate)
					- Erhöhung der Kapazität oder der Assoziativität
						- Erhöht T_h (Zugriffszeit)
					- Erhöhung der Blockgröße
						- Erhöht T_m (Nachladezeit)
					- Maßnahme für direkt abbildende Caches:
						- victim cache (voll-assoziativer Nebencache)
						  für zuletzt verdrängte Blöcke
					- prefetching (vorrausgreifendes Laden)
				- Reduzierung von T_h (Zugriffszeit)
					- bei Primärcache: entscheident für die
					  Prozessortaktrate
					- bei Sekundärcache: entscheident für die
					  Wartezyklen
					- kleinerer Cache -> besser, aber: erhöht wiederum
					  die miss rate m
				- Reduzierung von T_m (Nachladezeit)
					- maßgeblich durch Prozessor-/Systembus bestimmt
					- Einführung eines Sekundärcaches 
						- T_m wird dann ebenfalls wie T_a berechnet
					- Einführung eines non-blocking cache
						- Nachladen und Zugriff gleichzeitig möglich bei
						  Treffern
						- mehrere ausstehende Speicherzugriffe
						  gleichzeitig
				- Verhältnis 2-Ebenen-Speicher S2/S1 (TODO: Formel
				  nachtragen)
				- Zugriffseffizienz T1/T2 (TODO: Formel nachtragen)
			- Klassifikation von Fehlzugriffen:
				- (1) compulsory
					- erster Zugriff trifft nicht den Block
					- Block muss nachgeladen werden
					- first reference miss
				- (2) capacity
					- cache ist zu klein um alle Blöcke der aktuellen
					  Befehlsfolge zu enthalten
				- (3) conflict 
					- collision or interference misses
					- in n-way associative oder direct mapping caches
					  möglich
					- Adresskonflikte führen zum Überschreiben von
					  Blöcken (und müssen ggfs. später nachgeladen
					  werden)
				- # der Fehlzugriffsraten kann durch steigenden
				  Kapazität vermieden werden
	- Hauptspeicher
		- Zykluszeit = Zeit, bis nächste Adresse angelegt werden kann
		- SRAM (static RAM -> Cache und Hochleistungsspeicher)
			- Speicherzelle: FlipFlop
				- zerstörungsfreies Lesen
				- 6-8 Transistoren
				- schneller (8fach)
				- geringere Kapazität (8fach)
				- Zugriffszeit = Zykluszeit = 0.3 - 0.5ns
					- DRAM: 5-6ns Zykluszeit
				- Größere Wortbreiten: parallele Anordnung
		- DRAM (breiter Einsatz)
			- Speichermatrix mit einer oder einigen 1Bit Speicherzellen
			  an Knotenpunkten
			- Vorteil:
				- Kompakt
			- Nachteil:
				- zerstörendes Lesen, benötigt refresh cycle (Leckströme
				  bedingen 8ms Zyklus)
			- Adressierung via Zeile/Spalte im Multiplexbetrieb
				- Einsparung von Pins
				- RAS (Row Adress Strobe), CAS (Column Adress Strobe)
		- Aufbau von Speicher blockorientiert
			- byte-adressierbarer 16MByte-Speicher mit 32Bit-Wortbreite
			  aus 4x1-Bit-DRAM
			- | 31-24 | 23 - 2 | 1 0 |
			-          ^^ADR^^^ ^Byte^
		- memory controler zur
			- Adressinterpretation
			- Wortadressierung
			- Auswahl einer oder mehrerer byte-Blöcke
		- memory bank
			- parallel angeordnete Speicherbausteine + memory controller
		- Speicherverschränkung (memory interleave)
			- Zykluszeit bremst Prozessor
				- Lösung: Benachbarte Worte liegen in unterschiedlichen
				  Bänken -> Speicherzugriffe auf unterschiedliche Bänke
				  können überlappen (TODO: genauer angucken)
		- Fehlerkorrektur in Halbleiterspeichern
			- Verwendung von K zusätzlichen Prüfbits
			- (TODO: Fehlerkorrektur in HLS! Wie funktioniert das?)
		- memory gap
			- Latenzzeit verringert sich jährlich nur um 10%, langsamer
			  als die der CPU
			- Lösung: (weitere Architekturmaßnahmen)
				- Nibble-, Page- oder Static-Column-Modus (beim
				  Speicherzugriff gleich mehrere Folgebits in der
				  aktiven Zeile auslesen)
				  	- EDO-Ram (Extended Data Out) DRAM
				  		- PageMode mit zusätzlichem Zyklus zum einlesen,
				  		  Überlappung bringt Vorteile im Pipelining Stil
				  	- PageMode: 
				  		- row im DRAM wird offengelassen um nocheinmal
				  		  gelesen zu werden (Column, Nibble sind
				  		  Varianten hiervon)
				- E(nhanced)DRAM, C(ached)DRAM
					- Cache auf dem Speicherchip
				- S(ynchron)DRAM
					- Betrieb synchron zum CPU-/Speicherbus (nicht
					  asynchron wie normaler DRAM)
					- zusätzliche Speichermatrizen (memory interleaving
					  erhöhen)
					- burst mode (schnelle Blockübertragung)
						- mehrere Adressen "gleichzeitig" auslesen, mit
						  adressinkrementeller logik on-chip
					- bei 100MHz -> 10ns für Folgezugriffe (Latenz)
					- Taktsignal treibt endlichen Automaten on chip an,
					  der Pipelining ermöglicht
				- D(ouble)D(ata)Ram
					- Datenübertragung bei fallender und steigender
					  Taktflanke
					- DDR, DDR-2, DDR-3 Standards
						- fallende Versorgungsspannung 2.5V -> 1.6V
						- unterschiedliche Geschwindigkeit
				- D(irect)R(ambus)DRAM (a.k.a. RIMM)
					- ähnlich DDR, jedoch unterschiedliche Signalgebung,
					  die höhere Taktraten ermöglicht
					- besteht aus mehreren Kompononenten
					  (RAMBUS-Controller, RDRAM-Speichermodule,
					  RAMBUS-Kanal)
					- das Design arbeitet mit bis zu 400MHz -> zwei
					  Taktflanken ermöglichen 800MHz
					- kritisch: Mainboarddesign (hohe Taktraten müssen
					  erzeugt werden), 
						- Technik:
							- kurze Signalwege, nur 16 Bit Wortbreite
							- Entflechtung der Leiterbahnen, weniger
							  Pins
			- non-volatile memory (nicht-flüchtig)
				- Flash-Eprom (TODO: Wie funktioniert?)
			- MRAM: (neue Technologie)
				- Speicherung wird realisiert durch die Ausrichtung
				  magnetischer Momente in benachbarten magnetisierten
				  Schichten
				- Speicherzelle als 3-lagiges "Sandwitch"
					- Oben/Unten Fe, Mitte Isolator, Dicke ca 3-6nm
					- GMR: Mitte = Nicht-Magnetischer Leiter
					- TMR: Mitte = Isolator
				- Speicherung beruht auf magneto-resistance
					- elektrischer Widerstand ändert sich durch
					  Magnetfeld (Lorentzkraft)
					- anti-parallel: hoher Widerstand: logisch 0
					- parallel: niedriger  Widerstand: logisch 1
					- GMR-Prinzip: spin-abhängige Streuung
					- TMR-Prinzip: spin-abhängige Tunnelung
	- E/A-Werk
		- externe Speicher (magnetisch, optisch, magneto-optisch)
		- Bussysteme
			- alle an einer Leitung
			- Alternative: P2P
			- funktionelle Unterteilung in Steuerbus, Adressbus,
			  Datenbus
			- strukturelle Unterteilung in 
				- Cachebus, Systembus, Peripheriebus
			- Notwendig: Chipsets (Buskontroller)
				- steuern den Busverkehr
				- Anliegen: Entlasten der CPU von Zugriff auf Peripherie
				  bzw. Hauptspeicher
				- benötigt wird ein Busprotokoll
			- Busprotokoll
				- asynchrones Protokoll:
					- Handshake (req,ack)
					- skalierbar (laufzeiten unerheblich)
					- langsamer als synchrone Protokolle
					- meist für langsamere Peripherie genutzt (Drucker)
				- synchrones Protokoll:
					- taktgesteuert, keine Handshakes nötig
					- nicht skalierbar (Geräte müssen im Takt
					  mitarbeiten)
					- Einsatz über kürzere Distanzen, Cachebus,
					  Systembus und schnelle Peripheriebusse
			- Cachebus
				- paralleler Zugriff auf Cache- und Systembus
				- Cachebusse breiter und schneller getaktet als
				  Systembusse
				- führt zu Problemen bei Multiprozessorsystemen
				  (Cache-Kohärenz)
			- Systembus (a.k.a. CPU-Bus)
				- Verbindet CPU mit Hauptspeicher/Peripherie bzw.
				  Chipset
				- entweder als 
					- 1 Systembus oder
					- Front-Side und Back-Side-Bus
						- BSB: Verbindung zu Cache
						- FSB: Verbindung zu Hauptspeicher/Periph.
				- als 1 Systembus:
					- doppelt so breite Wortbreite als CPU
					- keine ständige Anpassung an steigende
					  CPU-Taktfrequenzen
					  	- Lösung mit Datenpufferung und Zugriff auf
				  	  größere Datenblöcke
					- Verwendung von burst access
						- 1x Adresse übergeben
						- Sender/Empfänger erhöhen die Adresse pro
						  Taktzyklus
						- Übertragung (meist) 4 Datenblöcke in der
						  Busbreite
						- Angabe nach wievielen Takten ein
						  Datenblock eintrifft: (2-1-1-1, oder 3-2-2-2)
			- CPU-nahe/schnelle Peripheriebusse sind AGP,PCI,PCI-X,PCIe
			- AGP:
				- grundsätzlich auf 66MHz-Basis (Durchsatz: 266MB/s) und
				  kennt zwei Betriebsmodi:
				  	- AGP-1x: nur steigende Taktflanken
				  	- AGP-2x: + fallende TF
				  	- AGP-4x: niedrigere Spannung(TODO: ?), höherer Takt
			- PCI-Bus:
				- Bustakt synchron zum CPU-Takt: max. 33/66MHz
				- Busbreite 32 oder 64Bit
				- Adress- und Datenmultiplexing
					- (TODO: Wie gehtn das hier?)
					- bei 32Bit Busbreite max. 66MB/s (schreiben) und
					  44MB/s (lesen)
				- PCI-bursts ermöglichen Steigerung des Durchsatzes auf
				  133MB/s (32Bit), oder 266MB/s (64Bit)
				- Einsatz von Bridges (PCI-to-ISA-Bridge) zur Verbindung
				  zu anderen Bussen
				- Bus-Master, Slave-Prinzip
					- PCI-BusMaster kann R/W-Zugriffe auf den Speicher
					  tätigen, ohne CPU-Einsatz
					- Slave -> nur Empfänger (Bsp. Grafikkarte,
					  Soundkarte)
				- Plug & Pray - Prinzip
					- Konfiguration der Karte via ROM-Bios
					- Konflikte von Interrupts oder Adressen beantwortet
					  das ROM-Bios durch Änderung der Werte oder
					  Abschalten bei Fehlfunktionen
			- Hierarchischer Aufbau Systembus-PCIBus
			- PCI-Express:
				- AGP und PCI haben ausgedient
				- neue, schnelle serielle Verbindungen
				- höherer Takt
				- schnellerer Speicher und langsamerer I/O-Controller
				  ersetzt durch einen einzigen Datenpuffer (genannt
				  Bridge)
				- wenige, schnell-multigeplexte Leitungen (lanes in
				  links)
			- USB: (universal serial bus)	
				- Stern-Topologie mit bis zu 127 Endgeräten
				- Steuerung durch USB-Controller (Host), keine direkte
				  Verbindung zwischen Endgeräten, Host ist einziger
				  Interrupt-Träger
				- Geschwindigkeit: USB 1.0 (1.5Mbit), USB 1.1 (12Mbit),
				  USB 2.0 (240MBit)
				- hot-plugging
			- FireWire:
				- Alternative zu USB2.0
				- IEEE1394
				- 800MBit
			
5. Leistungsbewertung
	- Was ist Leistung?
		- Instruktionen pro Zeit
		- Antwortzeit
		- Kommunikation
		- Durchsatz
		- Genauigkeit,
		- ...
	- Was ist Bewertung?
		- Zuteilung quantitativer Werte
	- Was ist Leistungsbewertung?
		- Versuch, objektive Aussagen über Rechensysteme anhand
		  messbarer Größen zu erwerben
	- Schwierigkeit der Leistungsfeststellung:
		- keine eindeutigen objektiven Vergleichskriterien
			- Leistung für bestimmte Rechnerkonfiguration unter
			  Verwendung bestimmter Nebenbedingungen + Software
			- subjektives Empfinden
		- Einflüsse durch:
			- Algorithmen
			- Software
			- Hardwarekonfiguration
			- Betriebssysteme
			- Netzwerk/Kommunikation
	- Was will man also mit Leistungsbewertung erreichen?
		- Entwurf, Optimierung, Weiterentwicklung von Rechnersystemen
			- Auffinden von Flaschenhälsen
			- ungezielte Aufrüstung von Rechnerteilen sinnlos
		- Analyse, Auswahl und Konfiguration von Gesamtsystemen aus
		  HW/SW
		  	- standardisierte Messprogramme benötigt (-> Benchmarking)
	- 4 Aspekte der Leistungsbewertung:
		- (1) zu untersuchendes System
		- (2) Leistungskenngrößen
		- (3) Belastung oder Last
		- (4) Methode zur Ermittlung der Leistungskenngrößen
		- Siehe getexte Ausarbeitung	
6. Fehlertoleranz

