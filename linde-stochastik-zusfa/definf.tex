% Einige zusätzliche Informationen für rubber
%  rubber erkennt nicht, dass die Datei weg kann, daher sagen wir es ihm
% rubber: clean $base.thm
%  rubber soll nach Änderungen an der Datei nochmal bauen
% rubber: watch $base.thm
% rubber: module          index
% rubber: index.tool      xindy
% rubber: index.language  german-din

\RequirePackage[l2tabu,orthodox]{nag}  % nag überprüft den Text auf veraltete
                   % Befehle oder solche, die man nicht in LaTeX verwenden
                   % soll -- l2tabu-Checker in LaTeX

\documentclass[ngerman,draft,parskip=half,twoside]{scrartcl}

\usepackage{ifthen}
\usepackage{xcolor}
\usepackage[draft=false,colorlinks,bookmarksnumbered,linkcolor=blue,breaklinks]{hyperref}

\usepackage[utf8]{inputenc}
\usepackage{babel}

\usepackage[T1]{fontenc}        % T1-Schriften notwendig für PDFs
\usepackage{lmodern}		% Latin Modern
\usepackage{textcomp}           % wird benötigt, damit der \textbullet
                                % für itemize in lmodern gefunden wird.

\usepackage[intlimits]{amsmath}
\usepackage[all,warning]{onlyamsmath}  % warnt bei Verwendung von nicht
                                       % amsmath-Umgebungen z.\,B. $$...$$
\usepackage{amssymb}     % wird für \R, \C,... gebraucht
\usepackage{fixmath}     % ISO-konforme griech. Buchstaben
\usepackage[euro]{isonums} % definiert Komma als Dezimaltrennzeichen

\usepackage[amsmath,thmmarks,hyperref]{ntheorem} % für die Theorem-Umgebungen
                                                 % (satz, defini, bemerk)
\usepackage{svn}         % Zum Auswerten und ordentlichen Darstellen der
                         % SVN-Schlüsselwörter (s. vor \begin{document})
                         % dafür muss in SVN noch das Flag svn:keywords
                         % auf "LastChangedRevision LastChangedDate"
                         % gesetzt werden
\usepackage{ellipsis}    % Korrektur für \dots
\usepackage{fixltx2e}
\usepackage[final,babel]{microtype} % Verbesserung der Typographie
\usepackage[babel,german=guillemets]{csquotes} % für Anführungszeichen
\usepackage{enumitem}
\usepackage{scrindex}
\usepackage{mathtools}   % Zur Definition von \abs und \norm
\usepackage{nicefrac}

% Damit auch die Zeichen im Mathemode in Überschriften fett sind
% <news:lzfyyvx3pt.fsf@tfkp12.physik.uni-erlangen.de>
\addtokomafont{sectioning}{\boldmath}

\newtheorem{thm}{Satz}[section]

% Hier die Definition, wie \autoref die Umgebungen nennen soll, die mit
% \newtheorem definiert wurden
\newcommand*{\thmautorefname}{Satz}
% Zwischen Unter- und Unterunterabschnitten sollte nicht unterschieden
% werden.
\renewcommand*{\subsectionautorefname}{Abschnitt}
\renewcommand*{\subsubsectionautorefname}{Abschnitt}

\pagestyle{headings}

% Um sicherzustellen, dass jeder Betrag/jede Norm links und rechts die
% Striche bekommt, sind diese Befehle da. Damit kann man nicht die
% rechten Striche vergessen und es wird etwas übersichtlicher. Aus
% mathtools.pdf, z. B. \abs[\big]{\abs{a}-\abs{b}} \leq \abs{a+b}
\DeclarePairedDelimiter{\abs}{\lvert}{\rvert}

% Um wichtige Begriffe im Text überall gleich vorzuheben (gleiches
% Markup), sollte dieser Befehl verwendet werden. Das Argument wird
% automatisch als Indexeintrag verwendet. Dieser kann aber auch als
% optionales Argument selbst bestimmt werden.
\newcommand*{\highl}[2][]{\textbf{\boldmath{#2}}%
  \ifthenelse{\equal{#1}{}}{\index{#2}}{\index{#1}}%
}

% Befehl für die Darstellung der Gliederungsüberschriften im Index
\newcommand*{\lettergroup}[1]{\minisec{#1}}

\newcommand*{\R}{\mathbb{R}}      % reelle Zahlen
\newcommand*{\C}{\mathbb{C}}      % komplexe Zahlen
\newcommand*{\N}{\mathbb{N}}      % natürliche Zahlen
\newcommand*{\Q}{\mathbb{Q}}      % gebrochene Zahlen
\newcommand*{\Z}{\mathbb{Z}}      % ganze Zahlen

\newcommand*{\Algeb}{\mathcal{A}}   % Algebra
\newcommand*{\BorelM}{\mathcal{B}}  % Borelmenge
\newcommand*{\PotM}{\mathcal{P}}    % Potenzmenge
\newcommand*{\E}{\mathbb{E}}        % Erwartungswert
\newcommand*{\V}{\mathbb{V}}        % Varianz
\newcommand*{\WKM}{\mathbb{P}}      % Wahrscheinlichkeitsmaß
\newcommand*{\NormVert}{\mathcal{N}} % Normalverteilung

\DeclareMathOperator{\cov}{cov}     % Kovarianz
\DeclareMathOperator{\card}{card}   % Kardinalität
\DeclareMathOperator{\vol}{vol}     % Volumen einer Menge

% http://www.tug.org/TUGboat/Articles/tb18-1/tb54becc.pdf
\newcommand*{\ez}{\mathrm{e}}               % eulersche Zahl
\newcommand*{\diff}[1]{%                    % Differentialoperator d (wie bei
                                            % \int ... dx)
  \mathop{\mathrm{\mathstrut d}}%
  \ifx#1(\else%
  \ifx#1[\else%
  \ifx#1\{\else%
    \!%
  \fi\fi\fi#1%
}

\SVN $LastChangedRevision$
\SVN $LastChangedDate$

\makeindex

\setlist[enumerate,1]{label=\arabic*.}
\setlist[enumerate,2]{label=\theenumi\arabic*}

\newlist{eigenschaften}{enumerate}{1}
\setlist[eigenschaften]{label=(\roman*)}

\begin{document}

\title{Eine Auswahl wichtiger Definitionen und Aussagen
 zur Vorlesung
  \enquote{Stochastik für Informatiker und Regelschullehrer}}
\date{WS 2008/09}
\author{Werner Linde}
\maketitle

\section{Wahrscheinlichkeiten}
\subsection{Wahrscheinlichkeitsräume}

\subsubsection{Grundraum}
Der \highl{Grundraum} (meist mit $\Omega$ bezeichnet) ist eine Menge,
die mindestens alle bei einem stochastischen Versuch oder Vorgang
auftretenden Ergebnisse enthält. Die Teilmengen von $\Omega$ heißen \highl[Ereignis]{Ereignisse},
die einpunktigen Teilmengen nennt man \highl[Elementarereignis]{Elementarereignisse}.

\subsubsection{Eintreten eines Ereignisses}
Ein Ereignis $A\subseteq \Omega$ \highl{tritt ein}, wenn das beim Versuch oder dem Vorgang
beobachtete zufällige Ergebnis in der Menge
$A$ liegt.

\subsubsection{\texorpdfstring{$\sigma$}{sigma}-Algebra}
Auf dem Grundraum $\Omega$ wird ein System $\Algeb\subseteq \PotM(\Omega)$  von Ereignissen
ausgezeichnet, denen man in sinnvoller Weise die
Wahrscheinlichkeit ihres Eintretens zuordnen kann. Aus naheliegenden Gründen fordert man,
dass $\Algeb$ eine \highl[sigma-Algebra@$\sigma$-Algebra]{$\sigma$-Algebra} bildet, d.\,h.~$\Algeb$ erfüllt
folgende Eigenschaften:
\begin{eigenschaften}
 \item $\emptyset\in\Algeb$.
 \item Aus $A\in\Algeb$ folgt $A^c\in \Algeb$.
 \item $A_1,A_2,\dotsc\in \Algeb$ impliziert $\bigcup_{j=1}^\infty A_j\in\Algeb$.
\end{eigenschaften}
Ist $\Omega$ höchstens abzählbar unendlich, so kann man als $\sigma$-Algebra stets die
Potenzmenge $\PotM(\Omega)$ von $\Omega$ nehmen.
\subsubsection{Wahrscheinlichkeitsmaß}
Ein \highl{Wahrscheinlichkeitsmaß} (oder eine \highl{Wahrscheinlichkeitsverteilung})
 $\WKM$ ist eine Abbildung von
$\Algeb$ nach $[0,1]$, die jedem Ereignis $A\in \Algeb$ die Wahrscheinlichkeit seines
Eintretens zuordnet und folgende Eigenschaften besitzt:
\begin{eigenschaften}
 \item Es gilt $\WKM(\emptyset)=0$ und $\WKM(\Omega)=1$.
 \item $\WKM$ ist $\sigma$-additiv, d.\,h.~für disjunkte $A_j\in\Algeb$ folgt
  \begin{gather*}
    \WKM\Big(\bigcup_{j=1}^\infty A_j\Big)=\sum_{j=1}^\infty\WKM(A_j)\;.
  \end{gather*}
\end{eigenschaften}
\subsubsection{Wahrscheinlichkeitsraum}
Das Tripel $(\Omega,\Algeb,\WKM)$ heißt \highl{Wahrscheinlichkeitsraum}. Zufällige
Experimente werden durch geeignete Wahrscheinlichkeitsräume  beschrieben.
\subsubsection{Eigenschaften von Wahrscheinlichkeitsmaßen}
%Wahrscheinlichkeitmaße besitzen
%folgende wichtigen Eigenschaften:
\begin{eigenschaften}
 \item
Jedes Wahrscheinlichkeitsmaß ist auch \highl{endlich additiv}, d.\,h.~sind
$A_1,\dotsc,A_n$ aus $\Algeb$ disjunkt, so folgt
 \begin{gather*}
   \WKM\Big(\bigcup_{j=1}^n A_j\Big)=\sum_{j=1}^n\WKM(A_j)\;.
 \end{gather*}
 \item
Wahrscheinlichkeitsmaße sind \highl{monoton}, d.\,h.~gilt für $A,B\in\Algeb$ die Inklusion
$A\subseteq B$, so impliziert dies $\WKM(A)\le\WKM(B)$.
 \item
Für $A,B\in\Algeb$ mit $A\subseteq B$ folgt $\WKM(B\setminus A)=\WKM(B)-\WKM(A)$. Insbesondere ergibt sich hieraus
$\WKM(A^c)=\WKM(\Omega\setminus A)=1-\WKM(A)$ für $A\in\Algeb$.
 \item
Wahrscheinlichkeitsmaße sind \highl[stetig!von oben]{stetig von oben}, d.\,h.~gilt für $A_j\in\Algeb$
die Aussage $A_1\supseteq A_2\supseteq\dotsb$,
so folgt
 \begin{gather*}
   \WKM\Big(\bigcap_{j=1}^\infty A_j\Big)=\lim_{j\to\infty}\WKM(A_j)\;.
 \end{gather*}
 \item
Wahrscheinlichkeitsmaße sind auch \highl[stetig!von unten]{stetig von unten}, d.\,h.~gilt für $A_j\in\Algeb$
die Aussage $A_1\subseteq A_2\subseteq\dotsb$,
so folgt
  \begin{gather*}
    \WKM\Big(\bigcup_{j=1}^\infty A_j\Big)=\lim_{j\to\infty}\WKM(A_j)\;.
  \end{gather*}
\end{eigenschaften}
\subsection{Typen von Wahrscheinlichkeitsmaßen}
\subsubsection{Wahrscheinlichkeitsmaße auf höchstens abzählbar unendlichen Grundräumen}
Bei einem Experiment seien höchstens abzählbar unendlich viele Versuchsergebnisse
möglich. Dann kann man entweder $\Omega=\{\omega_1,\dotsc,\omega_N\}$ oder
aber $\Omega=\{\omega_1,\omega_2,\dotsc\}$ wählen. Als $\sigma$-Algebra nimmt man in diesen
Fällen stets die Potenzmenge $\PotM(\Omega)$. Setzt man
\begin{gather}
\label{zu}
p_i :=\WKM(\{\omega_i\})\,,\quad 1\le i\le N\quad\mbox{bzw.}\quad i=1,2,\dotsc,
\end{gather}
dann erhält man Zahlen mit den Eigenschaften
\begin{eigenschaften}
 \item $p_i\ge 0$ und
  \label{p1}
 \item $\sum_{i=1}^N p_i =1$ bzw. $\sum_{i=1}^\infty p_i =1$.
  \label{p2}
\end{eigenschaften}
Für eine Menge $A\subseteq \Omega$ folgt dann
\begin{gather}
\label{diskret}
\WKM(A):= \sum_{\{i\colon \omega_i\in A\}} p_i\;.
\end{gather}
Umgekehrt, gibt man eine Folge $(p_i)_{i\ge 1}$ reeller Zahlen mit \ref{p1} und \ref{p2} vor,
so wird durch (\ref{diskret}) ein Wahrscheinlichkeitsmaß $\WKM$ auf $\PotM(\Omega)$ definiert. Für
endliche oder abzählbar unendliche Grundräume $\Omega$ hat man also folgende Äquivalenz:
\begin{gather*}
  \{\WKM\colon \WKM\;\mbox{Wahrscheinlichkeitsmaß auf}\;\PotM(\Omega)\}
     \Longleftrightarrow\{(p_i)_{i\ge 1}\colon (p_i)_{i\ge 1}\;\mbox{erfüllen (\ref{p1}) und (\ref{p2})}\}
\end{gather*}
Die Zuordnung erfolgt über (\ref{zu}) bzw.~(\ref{diskret}).

\subsubsection{Diskrete Wahrscheinlichkeitsmaße}
Sei nunmehr $\Omega$ ein beliebiger Grundraum (nicht notwendig endlich
oder abzählbar unendlich). Ein Wahrscheinlichkeitsmaß $\WKM$ auf $(\Omega,\PotM(\Omega))$
heißt \highl{diskret}, wenn es eine höchstens abzählbar unendliche Teilmenge $D\subseteq \Omega$
mit $\WKM(D)=1$ gibt. Mit $D=\{\omega_1,\omega_2,\dotsc\}$ gilt dann für $A\subseteq \Omega$ wie zuvor
\begin{gather*}
  \WKM(A):= \sum_{\{i\colon \omega_i\in A\}} p_i\;,
\end{gather*}
wobei $p_i:=\WKM(\{\omega_i\})$. Auf höchstens abzählbar unendlichen Grundräumen ist somit \textbf{jedes}
Wahrscheinlichkeitsmaß diskret.
\subsubsection{Wahrscheinlichkeitsdichten}
Eine stückweise stetige Funktion $p\colon\R\mapsto\R$ heißt
\highl{Wahrscheinlichkeitsdichte}, wenn
\begin{eigenschaften}
 \item $p(x)\ge 0$ für $x\in\R$ und
 \item $\int_{-\infty}^\infty p(x)\diff{x}=1$
\end{eigenschaften}
gelten.
\subsubsection{Borel-\texorpdfstring{$\sigma$}{sigma}-Algebra}
Mit $\BorelM(\R)$ bezeichnet man die kleinste $\sigma$-Algebra von Mengen aus $\R$, die
die halboffenen Intervalle enthält. Man nennt $\BorelM(\R)$ die $\sigma$-Algebra der
\highl[Borelmenge]{Borelmengen}. Elemente von $\BorelM(\R)$ sind z.\,B. alle offenen oder abgeschlossenen Mengen,
deren abzählbaren Vereinigungen und Durchschnitte usw.
\subsubsection{Stetige Wahrscheinlichkeitsmaße}
Gegeben sei eine Wahrscheinlichkeitsdichte $p$. Dann existiert ein eindeutig bestimmtes
Wahrscheinlichkeitsmaß $\WKM \colon\BorelM(\R)\mapsto [0,1]$ mit
\begin{gather*}
  \WKM([\alpha,\beta])=\WKM((\alpha,\beta])=\int_\alpha^\beta\,p(x)\diff{x}
\end{gather*}
für alle reelle Zahlen $\alpha<\beta$. Das so erzeugte Wahrscheinlichkeitsmaß $\WKM$ heißt \highl{stetig}
und $p$ nennt man die \highl{Dichte} von $\WKM$. Stetige Wahrscheinlichkeitsmaße beschreiben Vorgänge,
bei denen überabzählbar viele reelle Zahlen als Ergebnis auftreten können (z.\,B. Lebenszeiten etc.).
\subsection{Die wichtigsten diskreten Wahrscheinlichkeitsverteilungen}

\subsubsection{Einpunktverteilung}
Gegeben sei ein $\omega_0\in \Omega$, fest aber beliebig. Dann wird
durch
\begin{gather*}
  \delta_{\omega_0}(A)
     := \begin{cases}
          1 &\colon \omega_0\in A\\
          0 &\colon \omega_0\notin A
        \end{cases}
\end{gather*}
die \highl{Einpunktverteilung} in $\omega_0$ (oder das \highl{Diracsche $\delta$-Maß} in
$\omega_0$) definiert. Der Wahrscheinlichkeitsraum $(\Omega,\PotM(\Omega),\delta_{\omega_0})$
beschreibt Vorgänge, bei denen mit Wahrscheinlichkeit $1$ genau $\omega_0$ eintritt (deterministische
Vorgänge).


\subsubsection{Gleichverteilung auf \texorpdfstring{$N$}{N} Punkten}
Gegeben seien $N$ Punkte $\omega_1,\dotsc,\omega_N\in\Omega$.
Das Maß $\WKM$ auf $\PotM(\Omega)$ mit
\begin{gather*}
  \WKM:=\frac{1}{N}\sum_{i=1}^N \delta_{\omega_i}
\end{gather*}
heißt \highl{Gleichverteilung} auf $\{\omega_1,\dotsc,\omega_N\}$. Für ein Ereignis $A$ gilt dann
\begin{gather*}
  \WKM(A)=\frac{\card\{ i\le N \colon \omega_i\in A\}}{N}=
     \frac{\mbox{Anzahl der günstigen Fälle für A}}{\mbox{Anzahl der möglichen Fälle}}\;.
\end{gather*}
\subsubsection{Binomialverteilung}
Sei $\Omega=\{0,\dotsc,n\}$ und sei $p\in[0,1]$ vorgegeben. Dann wird durch
\begin{gather*}
  B_{n,p}(\{k\}):={n\choose k} p^k(1-p)^{n-k},\quad k=0,\dotsc,n\;,
\end{gather*}
ein Wahrscheinlichkeitsmaß $B_{n,p}$ auf $\PotM(\Omega)$ definiert. Man nennt $B_{n,p}$
\highl{Binomialverteilung} mit den Parametern $n$ und $p$. Die Zahl
$B_{n,p}(\{k\})$ gibt die Wahrscheinlichkeit an, dass man bei $n$ unabhängigen Versuchen genau $k$-mal
Erfolg hat. Dabei ist die Erfolgswahrscheinlichkeit in jedem einzelnen Versuch $p$, die für
Misserfolg $1-p$ .
\subsubsection{Hypergeometrische Verteilung}
Gegeben seien Zahlen $M,N,n\in\N_0$ mit $M,n\le N$. Dann wird durch
\begin{gather*}
  H_{N, M ,n}(\{m\}) :=\frac{{M\choose m}{N-M\choose n-m}}{{N\choose n}}
\end{gather*}
ein Wahrscheinlichkeitsmaß $H_{N,M,n}$ auf $\PotM(\{0,\dotsc,n\})$
definiert. Man nennt $H_{N,M,n}$ \highl[Verteilung!hypergeometrische]{hypergeometrische Verteilung} mit den Parametern $N,M$ und $n$.
Sind in einer Lieferung von $N$ Geräten $M$ Stück defekt, so beschreibt $H_{N,M,n}(\{m\})$
die Wahrscheinlichkeit, dass man in einer zufällig entnommenen Stichprobe vom Umfang $n$ genau
$m$ defekte Geräte beobachtet.
\subsubsection{Poissonverteilung}
Es sei $\Omega=\N_0=\{0,1,2,\dotsc\}$. Für eine Zahl $\lambda>0$ definiert
man die \highl{Poissonverteilung} mit Parameter $\lambda$ durch
\begin{gather*}
  P_\lambda(\{k\}):= \frac{\lambda^k}{k !}\,\ez^{-\lambda}\quad\mbox{für}\quad k\in\N_0\;.
\end{gather*}
Die Bedeutung der Poissonverteilung ergibt sich aus folgendem Satz:
\begin{thm}
Gegeben sei eine Zahl $\lambda>0$. Für $n\in\N$ setze man
$p_n:=\nicefrac{\lambda}{n}$. Dann folgt für alle $k\in\N_0$
stets
  \begin{gather*}
    \lim_{n\to\infty} B_{n,p_n}(\{k\})= P_\lambda(\{k\})\;.
  \end{gather*}
\end{thm}
Inhaltlich bedeutet dies: Führt man sehr viele unabhängige Versuche durch ($n$ Stück), bei denen jeweils
nur mit sehr kleiner
Wahrscheinlichkeit $p$ Erfolg eintreten kann, so ist die Anzahl der insgesamt beobachteten Erfolge
approximativ gemäß $P_\lambda$ verteilt, wobei $\lambda= n\cdot p$.
\subsubsection{Geometrische Verteilung}
Bei einem einzelnen Versuch trete Erfolg wieder mit Wahrscheinlichkeit $p$ und Misserfolg
mit Wahrscheinlichkeit $1-p$ auf. Man führt nun so lange unabhängige Versuche durch, bis
man erstmals Erfolg beobachtet. Die Wahrscheinlichkeit, dass dies im $(k+1)$-ten Versuch mit
$k\in\N_0$ geschieht, wird durch die \highl[Verteilung!geometrische]{geometrische Verteilung} mit Parameter $p\in(0,1]$
beschrieben:
\begin{gather*}
  \WKM(\{k\}):= p\cdot(1-p)^k\,,\quad k\in\N_0\;.
\end{gather*}
\subsection{Die wichtigsten stetigen Wahrscheinlichkeitsverteilungen}

\subsubsection{Gleichverteilung auf einem Intervall}
Es sei $[a,b]$ ein endliches Intervall. Durch
\begin{gather*}
  p(x)
     := \begin{cases}
          \frac{1}{b-a} &\colon x\in [a,b]\\
          0 &\colon x\notin [a,b]
        \end{cases}
\end{gather*}
wird eine Wahrscheinlichkeitsdichte auf $\R$ definiert. Damit berechnet sich die Wahrscheinlichkeit
eines Intervalls $[\alpha,\beta]$ durch
\begin{gather}
\label{gleich}
\WKM([\alpha,\beta])=\int_\alpha^\beta p(x)\diff{x}= \frac{\mbox{Länge von}\;([\alpha,\beta]\cap[a,b])}
{b-a}\;.
\end{gather}
Insbesondere ergibt sich im Fall $[\alpha,\beta]\subseteq [a,b]$ die Formel
\begin{gather*}
  \WKM([\alpha,\beta])= \frac{\beta-\alpha}{b-a}\;,
\end{gather*}
d.\,h.~die Wahrscheinlichkeit des Eintretens von $[\alpha,\beta]\subseteq[a,b]$
 hängt nur von seiner Länge, nicht aber von
seiner speziellen Lage innerhalb $[a,b]$ , ab.
Das durch (\ref{gleich}) erzeugte Wahrscheinlichkeitsmaß heißt \highl{Gleichverteilung} auf dem
Intervall $[a,b]$ .
\subsubsection{Exponentialverteilung}
Gegeben sei eine Zahl $\lambda>0$. Man definiert die
\highl{Exponentialverteilung} $E_\lambda$ mit Parameter $\lambda>0$ durch
ihre Dichte
\begin{gather*}
  p(x)
     := \begin{cases}
          \lambda\,\ez^{-\lambda x} &\colon x>0\\
          0 &\colon x\le 0
        \end{cases}\;.
\end{gather*}
Für ein Intervall $[\alpha,\beta]\subseteq [0,\infty)$ berechnet sich damit
die Wahrscheinlichkeit seines Eintretens durch
\begin{gather*}
  E_\lambda([\alpha,\beta])=\lambda \int_\alpha^\beta \ez^{-\lambda x}\diff{x}
     = \ez^{-\lambda\alpha}- \ez^{-\lambda\beta}\;.
\end{gather*}
\subsubsection{Normalverteilung}
Gegeben seien Zahlen $\mu\in\R$ und $\sigma>0$. Die
Funktion
\begin{gather*}
  p_{\mu,\sigma^2}(x):= \frac{1}{\sqrt{2\pi}\sigma}\,\ez^{-\nicefrac{(x-\mu)^2}{2\sigma^2}}\;,
     \quad x\in\R\;,
\end{gather*}
erzeugt ein Wahrscheinlichkeitsmaß $\NormVert(\mu,\sigma^2)$, das
man \highl{Normalverteilung} mit Mittelwert $\mu$ und Varianz $\sigma^2$ nennt. Es gilt dann
\begin{gather*}
  \NormVert(\mu,\sigma^2)([\alpha,\beta])=\frac{1}{\sqrt{2\pi}\sigma}
     \int_\alpha^\beta \ez^{-\nicefrac{(x-\mu)^2}{2\sigma^2}}\diff{x}\;.
\end{gather*}
Im Fall $\mu=0$ und $\sigma=1$ erhält man die \highl{Standardnormalverteilung}
$\NormVert(0,1)$ . Wahrscheinlichkeiten des Eintretens von Intervallen berechnen sich in diesem Fall durch
\begin{gather*}
  \NormVert(0,1)([\alpha,\beta])=\frac{1}{\sqrt{2\pi}}
     \int_\alpha^\beta \ez^{-\nicefrac{x^2}{2}}\diff{x}\;.
\end{gather*}

\subsubsection{Gleichverteilung auf einer Menge im \texorpdfstring{$\R^n$}{Rn}}
Es sei $E\subseteq \R^n$ eine beschränkte und abgeschlossene
Teilmenge, deren $n$-dimensionales Volumen $\vol_n(E)$ man
berechnen kann. Man definiert die \highl[Gleichverteilung!auf $E$]{Gleichverteilung auf $E$} durch den Ansatz
\begin{gather*}
  \WKM(A)=\frac{\vol_n(A\cap E)}{\vol_n(E)}\;.
\end{gather*}
Insbesondere ergibt sich für $A\subseteq E$ die Aussage
\begin{gather*}
  \WKM(A)=\frac{\vol_n(A)}{\vol_n(E)}\;,
\end{gather*}
d.\,h., wie im eindimensionalen Fall hängt die Wahrscheinlichkeit des Eintretens einer Menge $A\subseteq E$
nur von deren Volumen ab, nicht aber von deren Lage innerhalb $E$ noch von ihrer Gestalt.
\subsection{Verteilungsfunktion}
\subsubsection{Definition}
Für ein Wahrscheinlichkeitsmaß $\WKM$ auf $(\R,\BorelM(\R))$ wird die
\highl{Verteilungsfunktion} $F\colon\R\mapsto\R$ durch
\begin{gather}
\label{F0}
F(t):=\WKM((-\infty,t])\,,\quad t\in\R  \;,
\end{gather}
definiert.\\
\textit{Hinweis:} Ist $\WKM$ ein diskretes Wahrscheinlichkeitsmaß auf $(\Omega,\PotM(\Omega))$ mit $\Omega\subseteq\R$,
so modifiziert sich die Definition zu
\begin{gather*}
  F(t):=\WKM((-\infty,t]\cap\Omega)\,,\quad t\in\R  \;.
\end{gather*}
\subsubsection{Eigenschaften der Verteilungsfunktion}
\begin{thm}
\label{VF}
Die Verteilungsfunktion $F$ eines Wahrscheinlichkeitsmaßes besitzt folgende Eigenschaften:
  \begin{eigenschaften}
   \item $\lim_{t\to -\infty} F(t)=0$ und $\lim_{t\to\infty} F(t)=1$,
   \item die Funktion~$F$ ist nichtfallend und
   \item die Funktion~$F$ ist rechtsseitig stetig.
  \end{eigenschaften}
\end{thm}
\subsubsection{Weitere Eigenschaften von Verteilungsfunktionen}
\begin{enumerate}[label=(\alph*)]
 \item
Für jedes halboffene Intervall $(\alpha,\beta]$ gilt
  \begin{gather*}
    \WKM((\alpha,\beta])= F(\alpha)-F(\beta)\;.
  \end{gather*}
 \item
Die Funktion $F$ besitzt in einem Punkt $t_0\in\R$ genau dann einen Sprung der Höhe
$h>0$ (man hat $F(t_0)-F(t_0-0)=h$) , wenn $\WKM(\{t_0\})=h$ gilt. Insbesondere hat die
Verteilungsfunktion eines diskreten Maßes Sprünge in den Punkten, wo die Masse
des Maßes konzentriert ist. Dazwischen ist sie konstant.
 \item
Ist $F$ Verteilungsfunktion eines stetigen Wahrscheinlichkeitsmaßes $\WKM$ mit Dichte $p$, so berechnet
sich $F$ aus
  \begin{gather*}
    F(t)=\int_{-\infty}^t\,p(x)\diff{x}\,,\quad t\in\R\;.
  \end{gather*}
Insbesondere gilt für alle $t\in\R$, in denen $p$ stetig ist, die Gleichung
  \begin{gather*}
    F'(t)=\left(\frac{\diff{F}}{\diff{t}} \right)(t)= p(t)\;.
  \end{gather*}
\end{enumerate}
\subsection{Bedingte Verteilungen}
\subsubsection{Definition}
Es sei $(\Omega,\Algeb,\WKM)$ ein Wahrscheinlichkeitsraum. Dann wird
für $B\in \Algeb$ mit $\WKM(B)>0$ die \highl[Wahrscheinlichkeit!bedingte]{bedingte Wahrscheinlichkeit} $\WKM(\,\cdot\,|B)$
(oder die Wahrscheinlichkeit von $A$ unter der Bedingung $B$)
durch
\begin{gather}
\label{Bed}
 \WKM(A|B):=\frac{\WKM(A\cap B)}{\WKM(B)}\quad\mbox{für}\;\;A\in\Algeb
\end{gather}
definiert. Sie gibt die Wahrscheinlichkeit dafür an, dass $A$
eintritt, unter der Bedingung, dass $B$ bereits eingetreten ist. Häufig verwendet man
Formel (\ref{Bed}) auch in der Form
\begin{gather*}
  \WKM(A\cap B)= \WKM(B)\,\WKM(A|B)\;.
\end{gather*}
\subsubsection{Eigenschaften}
\begin{thm}
Die Abbildung
  \begin{gather*}
    A\mapsto \WKM(A|B)
  \end{gather*}
von $\Algeb$ nach $[0,1]$ ist ein Wahrscheinlichkeitsmaß mit den zusätzlichen Eigenschaften
  \begin{gather*}
    \WKM(B|B)=1\quad\mbox{und}\quad\WKM(B^c|B)=0\;.
  \end{gather*}
\end{thm}
\subsubsection{Formel über die totale Wahrscheinlichkeit}
\begin{thm}
\label{total}
Gegeben seien disjunkte Mengen $B_1,\dotsc,B_n$ in $\Algeb$ mit
$\WKM(B_j)>0$. Dann gilt für $A\in \Algeb$ mit $A\subseteq\bigcup_{j=1}^n B_j$
die Aussage
  \begin{gather*}
    \WKM(A)=\sum_{j=1}^n\WKM(B_j)\cdot\WKM(A|B_j)\;.
  \end{gather*}
\end{thm}
\textit{Bemerkung:} Insbesondere gilt der Satz im Fall $\bigcup_{j=1}^n B_j=\Omega$
für alle $A\in\Algeb$.
\subsubsection{Formel von Bayes}
Zur Berechnung von a posteriori Wahrscheinlichkeiten ist die Formel von
Bayes wichtig. Sie besagt das folgende:
\begin{thm}
Unter den Voraussetzungen aus Satz~\ref{total} an $B_1,\dotsc,B_n$ und $A$ folgt
für
$\WKM(A)>0$ die Identität
\begin{gather}
\label{Bayes}
\WKM(B_k|A)=\frac{\WKM(B_k)\cdot\WKM(A|B_k)}{\sum_{j=1}^n
\WKM(B_j)\cdot\WKM(A|B_j)}\quad\mbox{für}\;\;k=1,\dotsc,n\;.
\end{gather}
\end{thm}
\textit{Bemerkung:} Den Nenner in Formel (\ref{Bayes}) kann man (falls bekannt) durch $\WKM(A)$
ersetzen.
\subsection{Unabhängigkeit von Ereignissen}
\subsubsection{Unabhängigkeit von zwei Ereignissen}
Gegeben seien zwei Ereignisse $A,B$ aus einem Wahrscheinlichkeitsraum $(\Omega,\Algeb,\WKM)$.
Dann heißen $A$ und $B$ (stochastisch) \highl{unabhängig}, wenn
\begin{gather*}
  \WKM(A\cap B)=\WKM(A)\,\WKM(B)
\end{gather*}
gilt.
\subsubsection{Eigenschaften}
Die $\emptyset$ und $\Omega$ sind von jeder Menge $A\in\Algeb$ unahängig. Sind
$A$ und $B$ unahängig, dann gilt dies auch für die Paare $A$ und $B^c$ bzw.~$A^c$ und $B^c$.
\subsubsection{Unabhängigkeit von \texorpdfstring{$n$}{n} Ereignissen}
Die Ereignisse $A_1,\dotsc,A_n$ aus $\Algeb$ heißen (stochastisch) \highl{unabhängig},
wenn für alle Teilmengen $I\subseteq\{1,\dotsc,n\}$ stets
\begin{gather}
\label{unab1}
\WKM\Bigl(\bigcap_{i\in I} A_i\Bigr)= \prod_{i\in I}\WKM(A_i)
\end{gather}
gilt. Man kann dies auch wie folgt formulieren: Für alle $m\ge 2$ und alle
$1\le i_1<\dotsb<i_m\le n$ hat man
\begin{gather}
\label{unab2}
\WKM(A_{i_1}\cap\dotsb\cap A_{i_m})= \WKM(A_{i_1})\dotsm\WKM(A_{i_m})\;.
\end{gather}
Die Ereignisse $A_1,\dotsc,A_n$ aus $\Algeb$ heißen \highl[unabhängig!paarweise]{paarweise unabhängig}, wenn
jeweils zwei Ereignisse aus $A_1,\dotsc,A_n$ unabhängig sind, d.\,h.~die Gleichungen
(\ref{unab1}) bzw.~(\ref{unab2}) müssen nur für $\card(I)=2$ bzw.~für $m=2$ erfüllt sein.
\subsubsection{Eigenschaften}
Unabhängige Mengen $A_1,\dotsc,A_n$ sind auch paarweise unabhängig. Die Umkehrung ist
i.a.~falsch. Ebenso falsch ist, dass aus
\begin{gather*}
  \WKM(A_{1}\cap\dotsb\cap A_{n})= \WKM(A_{1})\dotsm\WKM(A_{n})
\end{gather*}
stets die Unabhängigkeit der $A_j$ folgt.

Sind $A_1,\dotsc, A_n$ unabhängig, so gilt dies auch für $(A_j)_{j\in J}$  mit
$J\subseteq \{1,\dotsc,n\}$.

\section{Zufallsvariable}
\subsection{Definition und Verteilungsgesetz}

\subsubsection{Das vollständige Urbild}
Für eine Abbildung $X\colon\Omega\mapsto\R$ und eine Teilmenge $B\subseteq\R$ wird das
\highl[Urbild!vollständiges]{vollständige Urbild} von $B$ unter $X$ durch
\begin{gather*}
  X^{-1}(B):=\{\omega\in\Omega \colon X(\omega)\in B\}
\end{gather*}
definiert. Verkürzend schreibt man auch $X^{-1}(B)=\;\{X\in B\}$.
\subsubsection{Zufällige Größen}
Sei $\Omega$ eine Menge, die mit einer $\sigma$-Algebra $\Algeb$ versehen ist. Eine Abbildung
$X\colon\Omega\mapsto\R$ heißt \highl[zufällige!Größe]{zufällige Größe} oder \highl[Zufallsvariable!reellwertige]{reellwertige Zufallsvariable}
oder \highl[zufällige!reelle Zahl]{zufällige reelle Zahl}, wenn für jedes $t\in\R$ die Menge $\{\omega\in\Omega\colon X(\omega)\le t\}$
zur $\sigma$-Algebra $\Algeb$ gehört.\\
\textit{Bemerkung:} In diesem Fall gilt dann auch $X^{-1}(B)\in\Algeb$ für jede Borelmenge $B\subseteq \R$.

\subsubsection{Verteilungsgesetz einer zufälligen Größe}
Sei $(\Omega,\Algeb,\WKM)$ ein Wahrscheinlichkeitsraum.
Für eine zufällige Größe $X\colon\Omega\mapsto\R$ ist die Abbildung
$\WKM_X \colon \BorelM(\R)\mapsto [0,1]$ mit
\begin{gather*}
  \WKM_X(B)=\WKM\big(X^{-1}(B)\big)=\WKM\{\omega\in\Omega \colon X(\omega)\in B\}=\WKM(\{X\in B\})= \WKM(X\in B)
\end{gather*}
sinnvoll definiert.
\begin{thm}
Die Abbildung $\WKM_X$ ist ein Wahrscheinlichkeitsmaß auf $(\R,\BorelM(\R))$.
\end{thm}
Man nennt $\WKM_X$ das \highl{Verteilungsgesetz} von $X$ (bzgl.~$\WKM$).
\subsubsection{Typen von zufälligen Größen}
Eine zufällige Größe $X$ heißt \highl{diskret}, wenn $\WKM_X$ ein diskretes
Wahrscheinlichkeitsmaß ist. Damit hat $\WKM_X$ die Gestalt
\begin{gather*}
  \WKM_X(B)=\sum_{\{i\colon x_i\in  B\}} p_i
\end{gather*}
mit geeigneten $x_i\in\R$ und $p_i\ge 0$. Die $x_i$ sind die möglichen Werte von $X$, d.\,h.~es
gilt\\ $\WKM(X\in\{x_1,x_2,\dotsc\})=1$,
und
\begin{gather*}
  p_i=\WKM\{\omega\in\Omega \colon X(\omega)=x_i\}\;.
\end{gather*}
Eine zufällige Größe $X$ heißt \highl{stetig}, falls $\WKM_X$ ein stetiges Wahrscheinlichkeitsmaß
ist. Das gilt genau dann, wenn mit einer Wahrscheinlichkeitsdichte $p$ für alle $\alpha<\beta$
die Gleichung
\begin{gather*}
  \WKM_X([\alpha,\beta])=\WKM\{\omega\in\Omega \colon \alpha\le X(\omega)\le\beta\}=\int_\alpha^\beta\,p(x)
     \diff{x}
\end{gather*}
erfüllt ist. Die Funktion $p$ nennt man auch \highl{Verteilungsdichte} (oder einfach
\highl{Dichte}) von $X$.
\subsubsection{Speziell verteilte diskrete zufällige Größen}
Eine zufällige Größe $X$ heißt \highl{gleichverteilt}
 auf einer endlichen Menge oder \highl{binomialverteilt}
oder \highl{Poissonverteilt} etc., wenn $\WKM_X$ von diesem Typ ist. In allen diesen Fällen
ist $X$ diskret. Zum Beispiel ist $X$ gemäß $B_{n,p}$ verteilt (man schreibt auch
$X\sim B_{n,p}$), falls für $0\le k\le n$ stets
\begin{gather*}
  \WKM_X(\{k\})=\WKM\{\omega\in\Omega \colon X(\omega)=k\} = {n \choose k} p^k(1-p)^{n-k}
\end{gather*}
gilt. Analog ist $X$ gemäß $P_\lambda$ verteilt, sofern für $k\in\N_0$
\begin{gather*}
  \WKM_X(\{k\})=\WKM\{\omega\in\Omega \colon X(\omega)=k\}=\frac{\lambda^k}{k!}\ez^{-\lambda}\;.
\end{gather*}
\subsubsection{Speziell verteilte stetige zufällige Größen}
Eine zufällige Größe $X$ heißt \highl{gleichverteilt} auf einem Intervall,
oder \highl{exponentialverteilt} oder \highl{normalverteilt} etc., wenn $\WKM_X$ von diesem Typ
ist.
Alle diese zufälligen Größen sind stetig.
Zum Beispiel ist $X$ gleichverteilt auf $[a,b]$, falls für alle $\alpha<\beta$
stets
\begin{gather*}
  \WKM_X([\alpha,\beta])=\WKM\{\omega\in \Omega \colon \alpha\le X(\omega)\le \beta\}
     =\frac{\mbox{Länge von}\, ([\alpha,\beta]\cap[a,b])}{b-a}
\end{gather*}
gilt. Oder $X$ ist $\NormVert(\mu,\sigma^2)$-verteilt (man schreibt $X\sim \NormVert(\mu,\sigma^2)$),
sofern
\begin{gather*}
  \WKM_X([\alpha,\beta])=\WKM\{\omega\in \Omega \colon \alpha\le X(\omega)\le \beta\}=
     \frac{1}{\sqrt{2\pi}\sigma}\int_\alpha^\beta \ez^{-\nicefrac{(x-\mu)^2}{2\sigma^2}}\diff{x}\;.
\end{gather*}
\subsubsection{Identisch verteilte zufällige Größen}
Zwei zufällige Größen $X$ und $Y$ sind \highl[verteilt!identisch]{identisch verteilt}, wenn $\WKM_X=\WKM_Y$ gilt,
d.\,h.~für alle $B\in\BorelM(\R)$ hat man
\begin{gather*}
  \WKM\{\omega\in \Omega \colon X(\omega)\in B\}= \WKM\{\omega\in \Omega \colon Y(\omega)\in B\}\;.
\end{gather*}
Man schreibt dann $X\stackrel{d}{=}Y$.
\subsubsection{Verteilungsfunktion einer zufälligen Größe}
Die \highl{Verteilungsfunktion} $F_X$ einer zufälligen Größe ist die Verteilungsfunktion
ihres Verteilungsgesetzes, d.\,h., es gilt
\begin{gather*}
  F_X(t)=\WKM_X\big((-\infty,t]\big)=\WKM\{\omega\in\Omega \colon X(\omega)\le t\}\,,\quad t\in \R\;.
\end{gather*}
Für zwei zufällige Größen $X$ und $Y$ gilt genau dann $X\stackrel{d}{=}Y$, wenn man
$F_X=F_Y$ hat.

Die Funktion $F_X$ besitzt die Eigenschaften aus Satz \ref{VF}.

\subsection{Zufällige Vektoren und Unabhängigkeit zufälliger Größen}
\subsubsection{Zufällige Vektoren}
Sei $\Omega$ eine Menge mit einer $\sigma$-Algebra $\Algeb$. Eine Abbildung $\vec X \colon \Omega\mapsto\R^n$
heißt ($n$-dimensionaler) \highl[zufällige!Vektor@\nobreak-r Vektor]{zufälliger Vektor}, wenn seine Koordinatenabbildungen
$X_j \colon\Omega\mapsto \R$ alle zufällige Größen sind. Dabei sind wie üblich die $X_j$ durch
\begin{gather*}
  \vec X(\omega)=(X_1(\omega),\dotsc,X_n(\omega))\;,\quad \omega\in\Omega\,,
\end{gather*}
definiert.

\subsubsection{Gemeinsames Verteilungsgesetz}
Sei $(\Omega,\Algeb,\WKM)$ ein Wahrscheinlichkeitsraum. Dann definiert
man wie im eindimensionalen Fall das Verteilungsgesetz $\WKM_{\vec X}$ von $\vec X$
durch
\begin{gather*}
  \WKM_{\vec X}(B):=\WKM\big(\vec X^{-1}(B)\big)=\WKM\{\omega\in\Omega \colon (X_1(\omega),\dotsc,X_n(\omega))\in B\}\;.
\end{gather*}
Im Spezialfall $B=B_1\times\dotsb\times B_n$ für Borelmengen $B_j\subseteq\R$ folgt
\begin{gather*}
  \WKM_{\vec X}(B)=\WKM(X_1\in B_1,\dotsc, X_n\in B_n)\;.
\end{gather*}
Deshalb nennt man $\WKM_{\vec X}$ auch \highl[Verteilungsgesetz!gemeinsames]{gemeinsames Verteilungsgesetz} der zufälligen
Größen $X_1,\dotsc,X_n$.
\subsubsection{Randverteilungen}
Für einen zufälligen Vektor $\vec X$ nennt man die Verteilungsgesetze $\WKM_{X_j}$, $1\le j\le n$,
die \highl[Randverteilung]{Randverteilungen} von $\vec X$. Hierbei sind wie zuvor die zufälligen Größen $X_j$ die
zugehörigen Koordinatenabbildungen.
\begin{thm}
Die Randverteilungen berechnen sich aus der gemeinsamen Verteilung durch
  \begin{gather*}
    \WKM_{X_j}(B)= \WKM_{\vec X}(\R\times\dotsb\times \underbrace{B}_j\times\dotsb\times\R)\;,\quad B\in\BorelM(\R)\;.
  \end{gather*}
Damit bestimmt die gemeinsame Verteilung die zugehörigen Randverteilungen.
\end{thm}
\textit{Bemerkung:} Die Umkehrung der obigen Aussage ist i.a.~falsch, d.\,h.~es existieren zufällige
Vektoren $\vec X=(X_1,\dotsc,X_n)$ und $\vec Y=(Y_1,\dotsc, Y_n)$ mit $\WKM_{X_j}=\WKM_{Y_j}$,
$1\le j\le n$, aber mit $\WKM_{\vec X}\not=\WKM_{\vec Y}$.
\subsubsection{Randverteilungen diskreter Vektoren}
\label{disk}
Wir betrachten hier nur den Fall $n=2$. Ein zufälliger $2$-dimensionaler Vektor hat die Gestalt
$(X,Y)$ mit vorgegebenen zufälligen Größen $X$ und $Y$. Weiterhin seien $X$ und $Y$ diskret und die
Folgen
$(x_i)_{i\ge 1}$ bzw.~$(y_j)_{j\ge 1}$ von reellen Zahlen bezeichnen  die möglichen Werte von $X$ bzw.~$Y$.
Dann nimmt der Vektor $(X,Y)$ die Werte $(x_i,y_j)_{i,j\ge 1}$ an und für das Verteilungsgesetz
von $\WKM_{(X,Y)}$, d.\,h.~die gemeinsame Verteilung von $X$ und $Y$, gilt
\begin{gather*}
  \WKM_{(X,Y)}(B)=\sum_{\{(i,j)\colon (x_i,y_j)\in B\}} p_{ij}\,,\quad B\in\PotM(\R^2)\,,
\end{gather*}
wobei
\begin{gather*}
  p_{ij}= \WKM_{(X,Y)}(\{(x_i,y_j)\})=\WKM(X=x_i,Y=y_j)\;.
\end{gather*}
Für die Randverteilungen ergibt sich dann
\begin{gather*}
  \WKM_X(B)=\sum_{\{i\colon x_i\in B\}} q_i \qquad\mbox{und}\qquad
     \WKM_Y(B)=\sum_{\{j\colon y_j\in B\}} r_j\,,\quad B\in\PotM(\R)\,,
\end{gather*}
mit
\begin{gather*}
  q_i=\sum_{j=1}^\infty p_{ij}\qquad\mbox{und}\qquad r_j=\sum_{i=1}^\infty p_{ij}\;\;\;.
\end{gather*}
\subsubsection{Randverteilungen stetiger Vektoren}
\label{stet}
Zur besseren Übersichtlichkeit betrachten wir auch hier nur den Fall $n=2$. Der
$2$-dimensionale Vektor $(X,Y)$ sei wie oben definiert. Diesmal nehmen wir aber an, dass
$\WKM_{(X,Y)}$ eine Dichte hat, es also eine Funktion $p \colon\R^2\mapsto\R$ gibt, so
dass für alle $\alpha<\beta$ und $\gamma<\delta$ stets
\begin{gather*}
  \WKM_{(X,Y)}\big([\alpha,\beta]\times[\gamma,\delta]\big)
     =\WKM\{\omega\in \Omega \colon \alpha\le X(\omega)\le\beta,\,\gamma\le Y(\omega)\le\delta\}
     =\int_\alpha^\beta\int_\gamma^\delta p(x,y)\diff{y} \diff{x}
\end{gather*}
gilt. Dann haben $X$ bzw.~$Y$ Verteilungsdichten $q$ und $r$ mit
\begin{gather*}
  q(x):=\int_{-\infty}^\infty p(x,y)\diff{y}\qquad\mbox{und}\qquad
     r(y):=\int_{-\infty}^\infty p(x,y)\diff{x}\;.
\end{gather*}
\subsubsection{Unabhängigkeit von zufälligen Größen}
Gegeben seien $n$ zufällige Größen $X_1,\dotsc,X_n$ auf $(\Omega,\Algeb,\WKM)$. Gilt für beliebige
Borelmengen $B_1,\dotsc,B_n\in\BorelM(\R)$ stets
\begin{gather}
\label{unab}
\WKM(X_1\in B_1,\dotsc,X_n\in B_n)=\WKM(X_1\in B_1)\dotsm\WKM(X_n\in B_n)\;,
\end{gather}
so heißen $X_1,\dotsc,X_n$ \highl{unabhängig}.\\
\textit{Bemerkung 1:} Die Unabhängigkeit der $X_j$ ist äquivalent zu folgender Aussage: Für
beliebige Borelmengen $B_j\in\BorelM(\R)$ sind die Ereignisse $\left(X_j^{-1}(B_j)\right)_{j=1}^n$
unabhängig. Das folgt aus der Tatsache, dass man in Gleichung (\ref{unab}) für gewisse vorgegebene $B_j$ auch die
reellen Zahlen $\R$ einsetzen kann.\\
\textit{Bemerkung 2:} Es reicht aus, wenn Gleichung (\ref{unab}) mit Intervallen $B_j$ der Form
$(-\infty,t_j]$ für alle $t_j\in\R$ gilt. Die zufälligen Größen $X_1,\dotsc,X_n$ sind also
dann und nur dann unabhängig, wenn für alle $t_j\in\R$ stets
\begin{gather*}
  \WKM(X_1\le t_1,\dotsc,X_n\le t_n)=\WKM(X_1\le t_1)\dotsm\WKM(X_n\le t_n)
\end{gather*}
folgt.\\
\textit{Bemerkung 3:} Aufgrund von (\ref{unab}) ist die gemeinsame Verteilung von $X_1,\dotsc,X_n$
im Fall der Unabhängigkeit eindeutig durch
ihre Randverteilungen $P_{X_j},$ $1\le j\le n$, bestimmt.
\subsubsection{Spezialfälle}
Besitzen $X$ und $Y$ die Eigenschaften aus \ref{disk}, so sind $X$ und $Y$ dann und nur  dann
unabhängig, wenn
\begin{gather*}
  p_{ij}=q_i\cdot r_j\,,\quad 1\le i,j<\infty\;.
\end{gather*}
Im stetigen Fall \ref{stet} sind $X$ und $Y$ genau dann unabhängig, wenn
\begin{gather*}
  p(x,y)=q(x)\cdot r(y)\,,\quad x,y\in\R\;.
\end{gather*}
\subsection{Rechnen mit zufälligen Größen}
\subsubsection{Transformationen}
Eine Abbildung $f\colon\R\mapsto\R$ heißt \highl{messbar}, wenn für jedes $t\in\R$ die
Menge $\{x\in \R \colon f(x)\le t\}$ eine Borelmenge ist. Stetige Funktionen, Grenzwerte stetiger
Funktionen oder auch monotone Funktionen besitzen diese Eigenschaft.
\begin{thm}
Sei $X$ eine zufällige Größe und sei $f\colon\R\mapsto\R$ messbar. Dann ist $Y:=f(X)$ ebenfalls
eine zufällige Größe.
\end{thm}
\textit{Allgemeine Aufgabe:} Man bestimme $\WKM_Y$ mit Hilfe von $\WKM_X$ und $f$.
Folgendes Beispiel illustriere die Situation: Sei $U$ gleichverteilt auf $[0,1]$, so ist mit
$f(s):=1-s$ auch $Y:=f(U)=1-U$ gleichverteilt auf $[0,1]$.
\subsubsection{Simulation stetiger zufälliger Größen}
Sei $X$ eine stetige zufällige Größe mit Verteilungsfunktion $F_X$. Wir nehmen an,
dass mit zwei Zahlen
$-\infty\le a<b\le\infty$ die Verteilungsfunktion $F_X(a)=0$, $F_X(b)=1$ erfülle  und
auf $(a,b)$ streng wachsend sei. Dann
existiert die inverse Funktion von $F_X$, die mit $F_X^{-1}$ bezeichnet wird, und es
gilt $F_X^{-1}\colon(0,1)\mapsto (a,b)$.
\begin{thm}
Sei $U$ eine auf $[0,1]$ gleichverteilte zufällige Größe. Unter den
obigen Voraussetzungen gilt dann für $Y:=F_X^{-1}(U)$ die Aussage
$X\stackrel{d}{=} Y$.
\end{thm}
\textit{Anwendung:} Sind $u_1,\dotsc,u_n$ unabhängig erzeugte reelle Zahlen, die gemäß der
Gleichverteilung aus $[0,1]$ gewählt wurden, so sind die Zahlen $x_j:= F_X^{-1}(u_j)$ ebenfalls unabhängig
und gemäß $\WKM_X$ verteilt.
\subsubsection{Lineare Transformationen}
Für reelle Zahlen $a\not=0$ und $b\in\R$ betrachte man die lineare Transformation
\begin{gather*}
  Y:=a\,X+ b
\end{gather*}
einer zufälligen Größe $X$.
\begin{thm}
Im Fall $a>0$ folgt
  \begin{gather*}
    F_Y(t)=F_X\left(\frac{t-b}{a}\right)\;.
  \end{gather*}
Ist $a<0$, so ergibt sich
  \begin{gather*}
    F_Y(t)=1-\WKM\left(X<\frac{t-b}{a}\right)\;,
  \end{gather*}
also
  \begin{gather*}
    F_Y(t)=1-F_X\left(\frac{t-b}{a}\right)
  \end{gather*}
im Fall stetiger $X$.
\end{thm}
\textit{Folgerung:} Besitzt $X$ die Verteilungsdichte $p$, so hat $Y=a\,X+b$ eine Dichte $q$,
die sich aus $p$ durch
\begin{gather*}
  q(t)=\frac{1}{\abs{a}}\;p\left(\frac{t-b}{a}\right)\,,\quad t\in\R\,,
\end{gather*}
ergibt.
\subsubsection{Addition zufälliger Größen}
Für zwei zufällige Größen $X$  und $Y$ wird ihre Summe $X+Y$ durch
\begin{gather*}
  (X+Y)(\omega):=X(\omega)+Y(\omega)\;,\qquad \omega\in\Omega\,,
\end{gather*}
definiert.
\begin{thm}
Sind $X$ und $Y$ zufällige Größen, so gilt dies auch für $X+Y$ .
\end{thm}
Das Verteilungsgesetz der Summe $X+Y$ kann man für unabhängige zufällige Größen in einigen
Fällen in einfacher Form angeben.
\begin{thm}~
Es seien $X$ und $Y$ unabhängige zufällige Größen.
\begin{enumerate}
\item
Nehmen $X$ und $Y$ Werte in den ganzen Zahlen $\Z$ an, so folgt
  \begin{gather*}
    \WKM(X+Y=k)=\sum_{i=-\infty}^\infty\WKM(X=i)\,\WKM(Y=k-i)\;,\quad k\in \Z\;.
  \end{gather*}
\item
Besitzen $X$ und $Y$ Werte in $\N_0$, so ergibt sich
  \begin{gather*}
    \WKM(X+Y=k)=\sum_{i=0}^k\WKM(X=i)\,\WKM(Y=k-i)\;,\quad k\in \N_0\;.
  \end{gather*}
\end{enumerate}
\end{thm}
Im Fall stetiger zufälliger Größen gilt folgender Satz:
\begin{thm}
Seien $X$ und $Y$ unabhängig mit Verteilungsdichten $p$ und $q$. Dann besitzt $X+Y$
die Verteilungsdichte $r$  mit
  \begin{gather*}
    r(x)=\int_{-\infty}^\infty p(x-y)\,q(y)\diff{y} = \int_{-\infty}^\infty p(y)\,q(x-y)\diff{y} \;.
  \end{gather*}
\end{thm}
Man nennt $r$ die \highl{Faltung} von $p$ und $q$ und schreibt $r=p*q$.
\subsubsection{Addition speziell verteilter zufälliger Größen}
Im folgenden seien $X$ und $Y$ stets als unabhängig vorausgesetzt. Dann gilt:
\begin{thm}~
  \begin{enumerate}[label=(\alph*)]
   \item
Aus $X\sim B_{n,p}$ und $Y\sim B_{m,p}$ folgt $X+Y\sim B_{n+m,p}$  .
   \item
Aus $X\sim P_\lambda$ und $Y\sim P_\mu$ erhält man $X+Y\sim P_{\lambda+\mu}$ .
   \item
Aus $X\sim\NormVert(\mu_1,\sigma_1^2)$ und $Y\sim\NormVert(\mu_2,\sigma_2^2)$ folgt
$X+Y\sim \NormVert(\mu_1+\mu_2,\sigma_1^2+\sigma_2^2)$ .
  \end{enumerate}
\end{thm}
\subsection{Erwartungswert}
\subsubsection{Erwartungswert diskreter zufälliger Größen}
Eine zufällige Größe $X$ nehme Werte $x_1,x_2,\dotsc$ aus $[0,\infty)$ an. Dann
definiert man den \highl{Erwartungswert} von $X$ durch
\begin{gather*}
  \E X :=\sum_{i=1}^\infty x_i\,\WKM(X=x_i)\;.
\end{gather*}
Es gilt dann $0\le \E X \le \infty$ .

Sind nunmehr die Werte von $X$ beliebige reelle Zahlen (nicht notwendig $\ge 0$)
, so sagt man, dass $X$ einen \highl[besitzt Erwartungswert]{Erwartungswert
besitzt}, wenn
\begin{gather*}
  \sum_{i=1}^\infty \abs{x_i}\,\WKM(X=x_i)<\infty\;.
\end{gather*}
In diesem Fall ist der Erwartungswert von $X$ mit
\begin{gather*}
  \E X :=\sum_{i=1}^\infty x_i\,\WKM(X=x_i)
\end{gather*}
eine wohldefinierte reelle Zahl.

\subsubsection{Erwartungswert stetiger zufälliger Größen}
Sei $p$ die Verteilungsdichte einer zufälligen Größe $X$. Dann
\highl[besitzt Erwartungswert]{besitzt $X$ einen Erwartungswert}, wenn
\begin{gather*}
  \int_{-\infty}^\infty \abs{x}\,p(x)\diff{x} <\infty\;,
\end{gather*}
und man definiert den \highl{Erwartungswert} von $X$ durch
\begin{gather*}
  \E X := \int_{-\infty}^\infty x \,p(x)\diff{x}\;.
\end{gather*}
\subsubsection{Beispiele zur Berechnung von Erwartungswerten}
\medskip

{\renewcommand{\arraystretch}{1.4}
\begin{center}
\begin{tabular}{|c|l|}\hline
\bf Verteilung von $X$& \bf Erwartungswert von $X$\\ \hline\hline
$X$ gleichverteilt auf $x_1,\dotsc,x_N$& $\E X=\frac{1}{N}\sum_{i=1}^N x_i$\\ \hline
$X\sim B_{n,p}$& $\E X= n p$\\ \hline
$X\sim P_\lambda$&$\E X= \lambda$\\ \hline
$X$ geometrisch verteilt mit Parameter $p$& $\E X = \frac{1-p}{p}$\\ \hline
$X$ gleichverteilt auf $[a,b]$& $\E X= \frac{a+b}{2}$\\ \hline
$X\sim E_\lambda$& $\E X = \frac{1}{\lambda}$\\ \hline
$X\sim \NormVert(\mu,\sigma^2)$&$ \E X = \mu$\\ \hline
\end{tabular}
\end{center}
}
\subsubsection{Eigenschaften des Erwartungswertes}
Der Erwartungswert einer zufälligen Größe hat folgende Eigenschaften:
\begin{thm}~
\begin{enumerate}
\item
Der Erwartungswert ist linear, d.\,h.~für alle $a,b\in\R$ und zufällige Größen $X$ und $Y$
gilt
  \begin{gather*}
    \E(a X+ b Y) = a\,\E X + b\, \E Y\;.
  \end{gather*}
\item
Sei  $X$ diskret mit möglichen Werten $x_1,x_2,\dotsc$ aus $\R$ .
Dann existiert für eine Funktion $f \colon\R\mapsto\R$
der Erwartungswert $\E f(X)$ genau dann, wenn
  \begin{gather*}
    \sum_{i=1}^\infty \abs{f(x_i)}\,\WKM(X=x_i)<\infty\;,
  \end{gather*}
und es gilt
  \begin{gather*}
    \E f(X)=\sum_{i=1}^\infty f(x_i)\,\WKM(X=x_i)\;.
  \end{gather*}
\item
Ist $X$ stetig mit Verteilungsdichte $p$ , so existiert für eine messbare
Abbildung $f \colon\R\mapsto\R$ genau dann der Erwartungswert von $f(X)$ , wenn
  \begin{gather*}
    \int_{-\infty}^\infty \abs{f(x)}\,p(x)\diff{x}<\infty\;,
  \end{gather*}
und man hat
  \begin{gather*}
    \E f(X)=\int_{-\infty}^\infty  f(x) \,p(x)\diff{x}\;.
  \end{gather*}
\item
Sind $X$ und $Y$ unabhängige zufällige Größen deren Erwartungswert existiert,
so existiert auch der Erwartungswert von $X\cdot Y$, und es gilt
  \begin{gather*}
    \E(X\cdot Y)= \E X \cdot \E Y\;.
  \end{gather*}
\end{enumerate}
\end{thm}

\subsection{Varianz und Kovarianz}
\subsubsection{Momente}
Sei $n\in\N$. Eine zufällige Größe $X$ besitzt ein \highl{$n$-tes Moment}, wenn
$\E\abs{X}^n<\infty$ . Im diskreten Fall bedeutet dies
\begin{gather*}
  \sum_{i=1}^\infty \abs{x_i}^n\WKM(X=x_i)<\infty
\end{gather*}
und im stetigen
\begin{gather*}
  \int_{-\infty}^\infty \abs{x}^n\,p(x)\diff{x}<\infty\;.
\end{gather*}
Insbesondere hat $X$ ein erstes Moment, genau dann, wenn $\E X$ existiert.
\begin{thm}
Sei $1\le m\le n$. Hat eine zufällige Größe $X$ ein $n$-tes Moment, so besitzt sie auch ein $m$-tes Moment.
Insbesondere hat jede zufällige Größe mit zweitem Moment einen Erwartungswert.
\end{thm}
\subsubsection{Varianz}
Es sei $X$ eine zufällige Größe mit zweitem Moment. Sei $a:=\E X$. Dann definiert man
die \highl{Varianz} (oder \highl{Streuung}) von $X$ durch
\begin{gather*}
  \V X:= \E(X-a)^2\;.
\end{gather*}
Die Varianz gibt den mittleren quadratischen Abstand einer zufälligen Größe $X$ von ihrem
Erwartungswert an. Sie ist ein Maß dafür, wie sehr die Werte von $X$ um $\E X$ schwanken.

\subsubsection{Eigenschaften der Varianz}
Im folgenden seien $X$ und $Y$ zufällige Größen mit zweiten Momenten. Dann gelten die
folgenden Aussagen:
\begin{thm}~
\begin{enumerate}
\item
Mit $a:=\E X$ berechnet sich die Varianz für diskrete zufällige Größen in der Form
  \begin{gather*}
    \V X = \sum_{i=1}^\infty (x_i-a)^2\,\WKM(X=x_i)\;,
  \end{gather*}
und im stetigen Fall hat man
  \begin{gather*}
    \V X =\int_{-\infty}^\infty (x-a)^2\,p(x)\diff{x}\;.
  \end{gather*}
\item
Es besteht die Identität
  \begin{gather*}
    \V X = \E X^2 -(\E X)^2\;.
  \end{gather*}
\item
Für eine konstante zufällige Größe $X$ folgt $\V X=0$ .
\item
Für $\alpha\in\R$ erhält man
  \begin{gather*}
    \V(\alpha\,X)=\alpha^2\,\V X\;.
  \end{gather*}
\item
Sind $X$ und $Y$ unabhängig, dann gilt
  \begin{gather*}
    \V(X+Y)=\V X + \V Y\;.
  \end{gather*}
\end{enumerate}

\end{thm}
\subsubsection{Beispiele zur Berechnung von Varianzen}

\medskip

{\renewcommand{\arraystretch}{1.4}
\begin{center}
\begin{tabular}{|c|l|}\hline
\bf Verteilung von $X$& \bf Varianz von $X$\\ \hline\hline
$X$ gleichverteilt auf $x_1,\dotsc,x_N$& $\V X=\frac{1}{N}\sum_{i=1}^N (x_i-\E X)^2$\\ \hline
$X\sim B_{n,p}$& $\V X= n\,p\,(1-p)$\\ \hline
$X\sim P_\lambda$&$\V X= \lambda$\\ \hline
$X$ geometrisch verteilt mit Parameter $p$& $\V X = \frac{1-p}{p^2}$\\ \hline
$X$ gleichverteilt auf $[a,b]$& $\V X= \frac{(b-a)^2}{12}$\\ \hline
$X\sim E_\lambda$& $\V X = \frac{1}{\lambda^2}$\\ \hline
$X\sim \NormVert(\mu,\sigma^2)$&$ \V X = \sigma^2$\\ \hline
\end{tabular}
\end{center}
}
\subsubsection{Kovarianz}
Gegeben seien zwei zufällige Größen $X$ und $Y$ mit zweiten Momenten.
Seien $a:=\E X$ und $b:=\E Y$ . Dann wird die \highl{Kovarianz} von $X$ und $Y$ durch
\begin{gather*}
  \cov(X,Y):= \E(X-a)(Y-b)
\end{gather*}
definiert.

\textbf{Eigenschaften:}

\begin{enumerate}
\item
Sind $X$ und $Y$ diskret mit möglichen Werten $x_1,x_2,\dotsc$ bzw.~$y_1,y_2,\dotsc$ aus $\R$,
so berechnet sich die Kovarianz aus der Formel
  \begin{gather*}
    \cov(X,Y)=\sum_{i,j=1}^\infty (x_i-a)(y_j-b)\, p_{ij}
  \end{gather*}
wobei
  \begin{gather*}
    p_{ij}=\WKM(X=x_i, Y=y_j)\;.
  \end{gather*}
\item
Hat die Verteilung des zufälligen Vektors $(X,Y)$ eine Dichte $p \colon\R^2\mapsto\R$, so
ergibt sich die Kovarianz von $X$ und $Y$ aus
  \begin{gather*}
    \cov(X,Y)=\int_{-\infty}^\infty \int_{-\infty}^\infty (x-a)(y-b)\,p(x,y)\diff{x}\diff{y}\;.
  \end{gather*}
\item
Sind $X$ und $Y$ unabhängig, so impliziert dies $\cov(X,Y)=0$, d.\,h.~$X$ und $Y$ sind
\highl{unkorreliert}. Man beachte, dass aus der Unkorreliertheit i.a.~nicht die Unabhängigkeit folgt.
\item
Man hat
\begin{gather}
\label{cov}
\abs{\cov(X,Y)}\le (\V X)^{\nicefrac{1}{2}}(\V Y)^{\nicefrac{1}{2}}\;.
\end{gather}
\subsubsection{Korrelationskoeffizient}
Für zwei zufällige Größen $X$ und $Y$ mit zweiten Momenten definiert man ihren
\highl[Korrelationskoeffizient]{Korrelationskoeffizienten} durch
  \begin{gather*}
    \rho(X,Y):=\frac{\cov(X,Y)}{(\V X)^{\nicefrac{1}{2}}(\V Y)^{\nicefrac{1}{2}}}\;.
  \end{gather*}
Aus (\ref{cov}) folgt
  \begin{gather*}
    -1\le \rho(X,Y)\le 1\;.
  \end{gather*}
Für unkorrelierte zufällige Größen gilt $\rho(X,Y)=0$.
 Der Korrelationskoeffizient ist ein Maß für den Grad der Abhängigkeit von
$X$ und $Y$. Je näher $\rho(X,Y)$ an $1$ oder $-1$ liegt, desto größer ist die
Abhängigkeit zwischen $X$ und $Y$. Im stärksten Fall
der Abhängigkeit von $X$ und $Y$, nämlich $Y=X$ bzw.~$Y=-X$, hat man $\rho(X,X)=1$ bzw.~$\rho(X,-X)=-1$ .
\end{enumerate}

\appendix
\clearpage
\pdfbookmark[1]{Index}{index}
\printindex

\end{document}
