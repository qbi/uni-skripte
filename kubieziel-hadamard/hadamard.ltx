% Einige zusätzliche Informationen für rubber
%  rubber erkennt nicht, dass die Datei weg kann, daher sagen wir es ihm
% rubber: clean $base.thm
%  rubber soll nach Änderungen an der Datei nochmal bauen
% rubber: watch $base.thm
% rubber: index.tool      xindy
% rubber: index.language  german-din


\RequirePackage[l2tabu,orthodox]{nag}  % nag überprüft den Text auf veraltete
                   % Befehle oder solche, die man nicht in LaTeX verwenden
                   % soll -- l2tabu-Checker in LaTeX

\RequirePackage[ngerman=ngerman-x-latest]{hyphsubst} % einbinden der neuen
                   % Trennmuster, diese korrigieren einige Fehler der alten
                   % und bieten mehr Trennstellen

\documentclass[ngerman,12pt,DIV=calc,a4paper]{scrreprt}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[ngerman]{babel}
\usepackage[table]{xcolor}
\usepackage{xfrac}           % xfrac erfüllt einen ähnlichen Zweck wie
			       % nicefrac. Jedoch macht nicefrac bei einigen
			       % Schriften Probleme. Dies behebt xfrac. Daher
			       % sollte eher das Paket verwendet werden.
                               % xfrac muss vor mathtools geladen werden!
\usepackage{lmodern}
\usepackage{textcomp}           % wird benötigt, damit der \textbullet
                                % für itemize in lmodern gefunden
                                % wird.

% Beide Definitionen müssen vor den unten stehenden Schriften
% stehen. Sonst entstehen Fehler wegen bereits definierter Zeichen.
\usepackage{amssymb}     % wird für \R, \C,... gebraucht
\usepackage{fixmath}     % ISO-konforme griech. Buchstaben

% Schriften
\usepackage{charter}
\usepackage{berasans}
\usepackage{luximono}
\usepackage[charter]{mathdesign}

\usepackage[intlimits,leqno]{amsmath}
\usepackage[all,warning]{onlyamsmath}  % warnt bei Verwendung von nicht
                                       % amsmath-Umgebungen z.\,B. $$...$$
\usepackage[euro]{isonums} % definiert Komma als Dezimaltrennzeichen
\usepackage[draft=false,colorlinks,bookmarksnumbered,linkcolor=blue,breaklinks]{hyperref}

\usepackage[amsmath,thmmarks,hyperref]{ntheorem} % für die Theorem-Umgebungen
                                                 % (satz, defini, bemerk)
\usepackage{xspace}      % wird weiter unten gebraucht

\usepackage{ellipsis}    % Korrektur für \dots
\usepackage{fixltx2e}
\usepackage[final,babel]{microtype} % Verbesserung der Typographie
\usepackage{mathtools}   % Zur Definition von \abs und \norm
\usepackage{enumerate}
\usepackage{todonotes}   % definiert den Befehl \todo{} um sich leicht
                         % Markierungen für offene Aufgaben zu setzen; wird
                         % auch für \help (s.u.) verwendet

\usepackage{braket}
\usepackage[backend=biber,citestyle=alphabetic,bibstyle=alphabetic]{biblatex}  % Bibliography
\bibliography{hadamard}

\usepackage[autostyle,german=guillemets]{csquotes}

\usepackage{siunitx}

\usepackage[alwaysformat]{nameauth}

% Pakete für das Zeichnen der Hadamard-Matrizen
\usepackage{pgfplotstable}
\usetikzlibrary{calc}
% \pgfplotsset{compat=1.8}

%% tikz und onlyamsmath sind nicht 100%ig kompatibel. Daher wurde der
%% untige Hack eingebaut. Quelle: https://tex.stackexchange.com/a/31863
\usepackage{etoolbox}
\preto\tikzpicture{\catcode`$=3 }
\preto\tikz{\catcode`$=3 }


%%%% Namen der verwendeten Autoren
\begin{nameauth}
  \<Sylvester & James Joseph & Sylvester & >
  \<Hadamard & Jacques Solomon & Hadamard & >
  \<Hall & Marshall & Hall junior & >
  \<Kimura & Hiroshi & Kimura & >
  \<Kharaghani & Hadi & Kharaghani & >
  \<Tayfeh & Behruz  & Tayfeh-Rezaie & >
  \<Orrick & William P. & Orrick & >
  \<Seberry & Jennifer & Seberry & >
  \<Yamada & Mieko & Yamada & >
  \<Paley & R.\,E.\,A.\,C. & Paley & >
  \<Williamson & John & Williamson & >
  \<Dagum & Paul & Dagum & >
  \<Luby & Michael & Luby & >
  \<Wanless & Ian M. & Wanless & >
  \<Brualdi & Richard A. & Brualdi & >
  \<Cathain & Padraig & \'O Cath\'ain & >
  \<Sloane & Neil J.\,A. & Sloane & >
  \<Butson & Alton T. & Butson & >
  \<Koukouvinos & Christos & Koukouvinos & >
  \<Stylianou & Stella & Stylianou & >
  \<Goethals & Jean-Marie & Goethals & >
  \<Seidel & Johan Jacob & Seidel & >
  \<Scarpis & Umberto & Scarpis & >
  \<Craigen & Robert & Craigen & >
  \<Agayan & Sos S. & Agayan & >
  \<Sarukhanyan & Hakob G. & Sarukhanyan & >
  \<Zhang & Xiang-Mo & Zhang & >
  \<DeLauney & Warwick & de Launey & >
  \<Gilman & Ray Edwin & Gilman & >
\end{nameauth}

\newcommand*{\R}{\mathbb{R}}      % reelle Zahlen
\newcommand*{\C}{\mathbb{C}}      % komplexe Zahlen
\newcommand*{\N}{\mathbb{N}}      % natürliche Zahlen
\newcommand*{\Q}{\mathbb{Q}}      % gebrochene Zahlen
\newcommand*{\Z}{\mathbb{Z}}      % ganze Zahlen
\newcommand*{\F}{\mathbb{F}}      % endliche Körper
\newcommand*{\PP}{\mathbb{P}}      % Primzahlen

\newcommand*{\CO}{\mathcal{O}}
\newcommand*{\perm}{\mathrm{perm}}
\newcommand*{\HM}{Hadamard-Matrix}
\newcommand*{\HMen}{Hadamard-Matrizen}

% nach dem Theoremkopf wird ein Zeilenumbruch eingefügt, die Schrift des
% Körpers ist normal und der Kopf wird fett gesetzt
\theoremstyle{break}
\theoremnumbering{arabic}
\theorembodyfont{\normalfont}
\theoremheaderfont{\normalfont\bfseries}

% Das Ende von Umgebungen, für die kein Beweis erbracht wurde, soll mit einer
% leeren Box gekennzeichnet werden. Wenn jedoch ein Beweis erbracht wurde,
% soll kein Zeichen ausgegeben werden (die ausgefüllte Box vom proof wird
% verwendet); man beachte die spezielle Definition von \theoremheaderfont für
% die Umgebung proof
% \newboolean{hasproof}
% \theoremheaderfont{\global\hasprooffalse\normalfont\bfseries}
% \theoremsymbol{\ifthenelse{\boolean{hasproof}}{}{\ensuremath{_\Box}}}

% Die folgenden Umgebungen werden einzeln nummeriert und am Ende jedes
% Kapitels zurückgesetzt
\newtheorem{satz}{Satz}[chapter]
\newtheorem{bemerk}{Bemerkung}[chapter]
\newtheorem{defini}{Definition}[chapter]
\newtheorem{bsp}{Beispiel}[chapter]
\newtheorem{festl}{Festlegung}[chapter]

% Die folgenden Theoremumgebungen bekommen keine Nummer
\theoremstyle{nonumberbreak}
\newtheorem{fakt}{Fakt}

% \theoremheaderfont{\global\hasprooftrue\scshape}
\theoremheaderfont{\scshape}
\theorembodyfont{\normalfont}
% Das Zeichen am Ende eines Beweises
\theoremsymbol{\ensuremath{_\blacksquare}}
% \theoremsymbol{q.\,e.\,d.}
\newtheorem{proof}{Beweis:}

% Hier die Definition, wie \autoref die Umgebungen nennen soll, die mit
% \newtheorem definiert wurden
\newcommand*{\satzautorefname}{Satz}
\newcommand*{\bemerkautorefname}{Bemerkung}
\newcommand*{\definiautorefname}{Definition}
\newcommand*{\bspautorefname}{Beispiel}
\newcommand*{\festlautorefname}{Festlegung}
% Zwischen Unter- und Unterunterabschnitten sollte nicht unterschieden
% werden.
%\renewcommand*{\subsectionautorefname}{Abschnitt}
%\renewcommand*{\subsubsectionautorefname}{Abschnitt}

% Um wichtige Begriffe im Text überall gleich vorzuheben (gleiches
% Markup), sollte dieser Befehl verwendet werden. Das Argument wird
% automatisch als Indexeintrag verwendet. Dieser kann aber auch als
% optionales Argument selbst bestimmt werden.
\newcommand*{\highl}[2][]{\textbf{\boldmath{#2}}%
  \ifthenelse{\equal{#1}{}}{\index{#2}}{\index{#1}}%
}

% Um sicherzustellen, dass jeder Betrag/jede Norm links und rechts die
% Striche bekommt, sind diese Befehle da. Damit kann man nicht die
% rechten Striche vergessen und es wird etwas übersichtlicher. Aus
% mathtools.pdf, z. B. \abs[\big]{\abs{a}-\abs{b}} \leq \abs{a+b}
\DeclarePairedDelimiter{\abs}{\lvert}{\rvert}
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}

\DeclareMathOperator*{\Sym}{Sym}       % Zeichen für symmetrische Gruppe

% Setup für die grafische Darstellung der Hadamard-Matrizen
% Das Beispiel stammt von TeX.SE:
% <URL:http://tex.stackexchange.com/a/123728/201>

\makeatletter
\tikzset{
    zero color/.initial=white,
    zero color/.get=\zerocol,
    zero color/.store in=\zerocol,
    one color/.initial=black,
    one color/.get=\onecol,
    one color/.store in=\onecol,
    cell wd/.initial=1ex,
    cell wd/.get=\cellwd,
    cell wd/.store in=\cellwd,
    cell ht/.initial=1ex,
    cell ht/.get=\cellht,
    cell ht/.store in=\cellht,
}

\newcommand{\drawgrid}[2][]{
\medskip
\begin{tikzpicture}[#1]
  \pgfplotstableforeachcolumn#2\as\col{
    \pgfplotstableforeachcolumnelement{\col}\of#2\as\colcnt{%
      \ifnum\colcnt=0
        \fill[\zerocol]($ -\pgfplotstablerow*(0,\cellht) + \col*(\cellwd,0) $) rectangle+(\cellwd,\cellht);
      \fi
      \ifnum\colcnt=1
        \fill[\onecol]($ -\pgfplotstablerow*(0,\cellht) + \col*(\cellwd,0) $) rectangle+(\cellwd,\cellht);
      \fi
    }
  }
\end{tikzpicture}
\medskip
}
\makeatother


% %% Legendre-Symbol
% \makeatletter
% \def\legendre@dash#1#2{\hb@xt@#1{%
%   \kern-#2\p@
%   \cleaders\hbox{\kern.5\p@
%     \vrule\@height.2\p@\@depth.2\p@\@width\p@
%     \kern.5\p@}\hfil
%   \kern-#2\p@
%   }}
% \def\@legendre#1#2#3#4#5{\mathopen{}\left(
%   \sbox\z@{$\genfrac{}{}{0pt}{#1}{#3#4}{#3#5}$}%
%   \dimen@=\wd\z@
%   \kern-\p@\vcenter{\box0}\kern-\dimen@\vcenter{\legendre@dash\dimen@{#2}}\kern-\p@
%   \right)\mathclose{}}
% \newcommand\legendre[2]{\mathchoice
%   {\@legendre{0}{1}{}{#1}{#2}}
%   {\@legendre{1}{.5}{\vphantom{1}}{#1}{#2}}
%   {\@legendre{2}{0}{\vphantom{1}}{#1}{#2}}
%   {\@legendre{3}{0}{\vphantom{1}}{#1}{#2}}
% }
% \def\dlegendre{\@legendre{0}{1}{}}
% \def\tlegendre{\@legendre{1}{0.5}{\vphantom{1}}}
% \makeatother
\newcommand*{\legendre}[2]{\ensuremath{\genfrac(){}{}{#1}{#2}}}

%% Für Matrizen mit mehr als 10 Spalten
\setcounter{MaxMatrixCols}{13}

\begin{document}
\title{Hadamard-Matrizen}
\author{Jens Kubieziel}
\maketitle

\begin{abstract}
  \HMen{} sind Matrizen deren Elemente aus $+1$ oder $-1$ bestehen und
  deren Zeilen oder Spalten orthogonal zueinander sind. Seit etwa
  150~Jahren sind \HMen{} Gegenstand mathematischer
  Forschung. \Sylvester{} legte die Grundlage und \Hadamard{}
  formulierte 1893 die zentrale Vermutung. Er stellte die Frage, ob
  eine $4k\times 4k$ \HM{} für jedes $k\in\N$ existiert. Bisher ist
  die Frage offen. Die mathematische Forschung bemüht sich über
  verschiedene Konstruktionsverfahren einer Antwort zu nähern. Das
  erste Verfahren und einige Eigenschaften von \HMen{} beschrieb
  \Sylvester{}. \Williamson{} und \Paley{} schufen später weitere
  Verfahren. Insbesondere das Konstruktionsverfahren von \Williamson{}
  erwies sich als reichhaltig. \Goethals{} und \Seidel{} benutzten
  das als Grundlage für ein weiteres Konstruktionsverfahren. Dieses
  Verfahren wurde in jüngerer Zeit immer wieder benutzt, um neue
  \HMen{} zu finden.

  Ziel dieser Arbeit ist es, anhand diese Verfahren vorzustellen und
  Beispiele für die Anwendung zu liefern. Abschließend wird ein
  Ausblick auf andere Verfahren gegeben, die Ansätze aus anderen
  Teilgebieten der Mathematik verwenden.
\end{abstract}

\tableofcontents

\listoftodos{}
\todo[inline]{Titelei strukturieren}

\addchap{Vorwort}
\label{chap:vorwort}


\begin{itemize}
\item Anlass, Stand zu Beginn und Ergebnisse
\item Danksagung
\end{itemize}\todo{Schreiben}


\chapter{Eine Einführung in Hadamard-Matrizen}
\label{chap:einf}

Das Ziel dieser Arbeit ist eine Einführung in \HMen{} und die
Vorstellung wichtiger Konstruktionsverfahren. Zu Beginn steht die
Definition des Begriffs sowie die Erläuterung wichtiger Eigenschaften
von \HMen{}. Die vorliegende Arbeit betrachtet \HMen{} mit Einträgen
aus $\pm1$ und stellt im \autoref{sec:hm-typen} weitere Arten von
\HMen{} vor. Einige dieser Arten dienen als Basis für die
Konstruktion. Schließlich lassen sich \HMen{} durch elementare
Umformungen ineinander überführen. Im \autoref{sec:aequi-hm} werden
diese Umformungen vorgestellt und der Begriff der \enquote{Äquivalenz}
definiert. Das \autoref{sec:weitere-begriffe} stellt Begriffe vor, die
für die Arbeit wichtig sind.

Das zweite Kapitel betrachtet wichtige Konstruktionsverfahren. Dabei
werden die Verfahren beschrieben und meist ein Anwendungsbeispiel
geliefert. Das Kapitel startet mit dem Verfahren von \Sylvester{} in
\autoref{sec:konst-sylvester}. Er nutzte das Kronecker-Produkt als
Basis seines Verfahrens. \Scarpis{} stellte 1898 das Verfahren aus
\autoref{sec:scarpis} vor. Dieses Verfahren ist heute in der Literatur
kaum noch zu finden und soll daher hier dokumentiert werden. Der Autor
der vorliegenden Arbeit benutzte heirfür eine Beschreibung im Weblog
des Mathematikers \Orrick{}. Die beiden Konstruktionsverfahren von
\Paley{} sind in \autoref{sec:konst-payley}. Dem schließt sich das
Verfahren von \Williamson{} an. Dieser Forscher benutzte verschiedene
Matrizen, um damit eine \HM{} \enquote{zusammenzustecken}. Später
zeigte sich, dass diese Bausteine von verschiedener Form sein können
und insbesondere das Verfahren von \Goethals -\Seidel{} wird heute für
die computergestützte Suche nach neuen \HMen{} verwendet. Den
Abschluss der Arbeit bildet ein Ausblick auf weitere Verfahren und
neuere Entwicklungen.

\section{Historischer Überblick}
\label{sec:geschichte}

Die Forschung zu \HMen{} begann im Jahr 1867. Der britische
Mathematiker \LSylvester{} veröffentlichte den Artikel
\citetitle{Sylvester1867}~\cite{Sylvester1867}. Darin stellte er
Beispiele und Konstruktionsverfahren vor.  In dieser Veröffentlichung
trugen die Matrizen noch nicht den Namen von \LHadamard{} stattdessen
verwendete \Sylvester{} den Begriff \enquote{anallagmatic
  pavement}. Der Begriff \enquote{anallagmatic} sollte ausdrücken,
dass die Matrix in etwa ihrem Inversen entspricht.

\Sylvester{} nutzte das Kronecker-Produkt, um aus einer bestehenden
\HM{} weitere zu konstruieren. Sein Verfahren erzeugt \HMen{} vom
Grad~$2^{n}$ für $n\geq1$. In der \autoref{fig:sylvester4} sind die
Grade $2$, $4$, $8$, $16$ und $32$ abgedruckt.

\begin{figure}[htb]
  \centering
  \pgfplotstableread{beispiele/had2}{\hzweisylvester}
  \pgfplotstableread{beispiele/had4}{\hviersylvester}
  \pgfplotstableread{beispiele/had8}{\hachtsylvester}
  \pgfplotstableread{beispiele/had16.sylvester}{\hsechszehnsylvester}
  \pgfplotstableread{beispiele/had32.sylvester}{\hzweidreissigsylvester}
  \drawgrid{\hzweisylvester}
  \drawgrid{\hviersylvester}
  \drawgrid{\hachtsylvester}
  \drawgrid{\hsechszehnsylvester}\hfill{}
  \drawgrid{\hzweidreissigsylvester}\hfill{}
  \caption{Fünf \HMen{} nach der Konstruktion von \Sylvester{}}
  \label{fig:sylvester4}
\end{figure}

\LHadamard{} erkannte 1893 einen Zusammenhang zwischen den
\enquote{anallagmatic pavements} und der Maximierung der
Determinante. In seiner Arbeit \citetitle{hadamard1893resolution} ging
er der Frage nach, wann die Determinante quadratischer Matrizen
Einträgen aus dem Einheitskreis maximal wird. Dabei fand er heraus,
dass die maximale Determinante $n^{\sfrac{n}{2}}$ beträgt und bei
$n\times n$ Matrizen mit $\pm1$"=Einträgen entsteht, der Zeilen oder
Spalten orthogonal sind. Neben diesem Beweis konstruierte \Hadamard{}
Matrizen des Grades $12$ und $20$. Schließlich zeigte er, dass der
Grad einer \HM{} $1$, $2$ oder ein Vielfaches von $4$ sein kann.

Die letzte Aussage wirft sofort die Frage auf, ob es für jedes
Vielfaches von $4$ eine \HM{} gibt. Viele Wissenschaftler gingen
seither dieser Frage nach. Eine Antwort ist noch offen und das Problem
ist heute unter dem Namen \Hadamard sches Problem bekannt. Es ist
eines der ältesten offenen Vermutungen. Ein Lösungsansatz liegt bei
Konstruktionsverfahren. Wenn es möglich ist, eines oder mehrere
Konstruktionsverfahren zu finden, die \HMen{} beliebiger Größe
erzeugen, so ist das Rätsel gelöst. Im weiteren Verlauf der Arbeit
werden einige Verfahren vorgestellt, die theoretisch alle \HMen{}
erzeugen könnten.

\LScarpis{} entdeckte als Erster einen Zusammenhang mit Primzahlen. Er
zeigte, dass sich mit Hilfe einer Primzahl~$p$ und einer
$(p+1)\times(p+1)$ \HM{} eine neue \HM{} vom Grad $p(p+1)$
konstruieren lässt. Sein Konstruktionsverfahren ist in
\autoref{sec:scarpis} genauer beschrieben und bildet eine
überraschende Verbindung zwischen Mersenne"=Primzahlen und
\HMen{}. Mersenne"=Primzahlen sind Zahlen der Form $2^{p}-1$ für eine
Primzahl~$p$. So ist beispielsweise $11$ eine Mersenne"=Primzahl und
eine $12\times12$ \HM{} ist durch die Konstruktion von \Hadamard{}
bekannt. Also lässt sich das Verfahren von \Scarpis{} nutzen, um eine
$132\times132$ \HM{} zu konstruieren.





\section{Einleitung}
\label{sec:einleitung}

Die Forschung zu \HMen{} begann im Jahr 1867. Der britische
Mathematiker \LSylvester{} veröffentlichte den Artikel
\citetitle{Sylvester1867}~\cite{Sylvester1867}. Darin stellte er
Beispiele und Konstruktionsverfahren vor. In dieser Veröffentlichung
trugen die Matrizen noch nicht den Namen von \LHadamard{} stattdessen
verwendete \Sylvester{} den Begriff \enquote{anallagmatic pavement}.  Erst im
Jahr 1893 bewies \Hadamard{} die
Ungleichung~\cite{hadamard1893resolution}\footnote{Eine
  englischsprachige Übersetzung des Werkes wurde von \Cathain{}
  angefertigt~\cite{cathainhada}.}
\begin{gather}\label{eq:had-ungl}
  \abs{\det (a_{ij})}\leq\prod_{j=1}^{n}\left(\sum_{i=1}^{n} \abs{a_{ij}}^{2}\right)^{\sfrac{1}{2}}
\end{gather}
Dabei sei $A=(a_{ij})_{i,j=1,\dots,n}$ eine reelle $n\times n$
Matrix. Die Determinante von $A$ kann als das Volumen des durch die
Spaltenvektoren von $A$ aufgespannten Parallelepipeds aufgefasst
werden. Bezeichne $a_{i}$ den $i$-ten Spaltenvektor und sei
$\norm{\cdot}_{2}^{2}$ die bekannte euklidische Norm. Der $i$-te
Spaltenvektor besitzt die Länge~$l_{i}= \norm{a_{i}}_{2}$. Damit ist das
Volumen eines Quaders mit den Seitenlängen~$l_{i}$ für $i=1,\dots,n$
eine obere Schranke für das Volumen des Parallelepipeds. Also haben
wir $\det(A)\leq\prod_{j=1}^{n} \norm{a_{j}}_{2}= \prod_{j=1}^{n}(\sum_{i=1}^{n}
\abs{a_{ij}}^{2})^{\sfrac{1}{2}}$ und die Behauptung ist gezeigt.

Dies ist als \Hadamard sches Problem der maximalen Determinante in die
Literatur eingegangen. Aufgrund des Beweis wird sofort klar, dass die
Gleichheit genau dann gilt, wenn die Spaltenvektoren senkrecht
zueinander sind. \Williamson{} verwendete in seiner Veröffentlichung
\citetitle{zbMATH03095564}~\cite{zbMATH03095564} erstmalig den Namen
\HM{}. Seither wird dieser für diese speziellen Matrizen verwendet.

\section{\HMen}
\label{sec:hm}

\begin{defini}[\HM]\label{def:hadamard-matrizen}
  Eine \highl{\HM} vom Grad~$n$ ist eine $n\times n$
  Matrix~$H$ mit Einträgen aus $\{\pm1\}$, die die  folgende
  Eigenschaft besitzt:
  \begin{gather}
    \label{eq:hm-eigensch}
    HH^{T}=nI_{n}
  \end{gather}
\end{defini}

Mit der Definition ist sofort klar, dass die Zeilen oder Spalten einer
\HM{} orthogonal sein müssen. Denn die Multiplikation zweier
Spalten~$i$ und $j$ für $i\neq j$ entspricht nach der
\autoref{def:hadamard-matrizen} der Multiplikation von Spalte~$i$ und
Zeile~$j$. Das ergibt aber $0$.

Weiterhin ist die transponierte \HM{} wiederum eine \HM{}. Wenn die
\autoref{eq:hm-eigensch} durch $n$ dividiert wird, ergibt sich
$\sfrac{H}{\sqrt{n}}\cdot\sfrac{H^{T}}{\sqrt{n}}= I_{n}$. Aus der
linearen Algebra ist bekannt, dass eine lineare Abbildung auf einem
endlich"=dimensionalen Vektorraum genau dann surjektiv
ist, wenn diese injektiv ist. Da aber $\sfrac{H}{\sqrt{n}}$ ein
Rechtsinverses hat, ist $H$ injektiv, hat also auch ein
Linksinverses. Damit lässt sich errechnen, dass das Linksinverse von
$\sfrac{H}{\sqrt{n}}$ der Term $\sfrac{H^{T}}{\sqrt{n}}$ ist. Also ist
$H^{T}H=nI_{n}$.

Die Zeilen oder Spalten einer \HM{} können beliebig
vertauscht werden. Da eine Vertauschung die Orthogonalitätseigenschaft
beibehält, ist das Ergebnis wieder eine \HM{}. Die
Multiplikation von Zeilen oder Spalten einer \HM{} mit $-1$
erzeugt wiederum eine \HM. Angenommen die $i$-te Zeile
wird mit $-1$ multipliziert. Das Skalarprodukt der Zeile mit sich
bleibt in dem Fall gleich. Das Skalarprodukt der Zeilen~$i$ und $j$
mit $i\neq j$ ist dann $\sum_{k=1}^{n} -h_{i,j}h_{k,j}=
-\sum_{k=1}^{n} h_{i,j}h_{k,j}=0$\todo{Indexierung fhcasl}, d.\,h. die Orthogonalität bleibt
erhalten.

\begin{satz}\label{satz:grad-hm}
  Der Grad~$n$ einer \HM{} ist $n=1$, $2$ oder $n=4k$ für ein $k\in
  \N$.
  \begin{proof}
    \HMen{} vom Grad~$1$ und $2$ sind in \autoref{bsp:hm} genannt. Im
    folgenden wird davon ausgegangen, dass die \HM{} aus mindestens
    drei Zeilen besteht. \OE{} bestehe die erste Zeile aus
    $+1$-Einträgen. Gegebenenfalls muss die Matrix durch die oben
    aufgeführten Umformungen transformiert werden. Die ersten drei
    Zeilen können nach geeigneter Spaltenvertauschung nun folgende
    Form haben:
    \begin{gather*}
      \begin{pmatrix}
        +1\cdots+1 & +1\cdots+1 & +1\cdots+1 & +1\cdots+1\\
        +1\cdots+1 & +1\cdots+1 & -1\cdots-1 & -1\cdots-1\\
        \underbrace{+1\cdots+1}_{a} & \underbrace{-1\cdots-1}_{b} & \underbrace{+1\cdots+1}_{c} & \underbrace{-1\cdots-1}_{d}
      \end{pmatrix}
    \end{gather*}
    Wegen der Orthogonalität ergibt die Summe folgendes Ergebnis:
    \begin{gather*}
      a+b=a+c=a+d=b+c=b+d=c+d=\sfrac{n}{2}
    \end{gather*}
    Also ist $a=b=c=d=\sfrac{n}{4}=k$.
  \end{proof}
\end{satz}

Die Umkehrung von \autoref{satz:grad-hm}, also die Frage, es für jedes
$n=4k$ eine \HM{} gibt, ist bisher unbeantwortet und wird als die
Vermutung von \Hadamard{} bezeichnet.

Eine Annäherung an die Frage bietet die Konstruktion von \HMen{}
(\autoref{chap:konstr}). In der Vergangenheit entstanden verschiedene
Verfahren zur Konstruktion und darüber konnte die Existenz einer
Vielzahl von \HMen{} nachgewiesen werden. Allerdings ist bereits im
Fall $n=668$ unklar, ob hierfür eine \HM{} existiert. Bis zum Jahr
2004 war der Fall $n=428$ offen und die entsprechende \HM{} von
\Kharaghani{} und \Tayfeh{} nachgewiesen~\cite{JCD:JCD20043}.

Eine weitere Annäherung an die \Hadamard sche Vermutung erfolgte über
asymptotische Abschätzungen. So gelang \Seberry{} der Nachweis, dass
es für jede ungerade Zahl $q\in\N$ eine Untergrenze
$t_{0}\in\N$ existiert, so dass es eine \HM{} des Grades~$2^{t}q$ mit
$t\geq t_{0}$ gibt~\cite{Wallis1976188}. Für den Beweis nutzte
\Seberry{} die so genannten Plugin"=Methoden, die auch beim
Konstruktionsverfahren nach \Williamson{}
(\autoref{sec:konstr-nach-williamson}) zum Einsatz kommen sowie
Mittel aus der Designtheorie. Der Beweis kann im Rahmen dieser Arbeit
nicht angeführt werden und daher sei der Leser an die oben genannte
Veröffentlichung verwiesen.

Wenn der Nachweis für $t_{0}=2$ gelänge, ist die \Hadamard"=Vermutung
gezeigt. Denn dann sagt die obige Aussage, dass es \HMen{} vom Grad
$2^{t}q$ für $t\geq2$ und beliebige natürliche Zahlen $q$
gibt. Verschiedene Forscher versuchten, sich an $t_{0}$ von oben
anzunähern. Die Originalarbeit von \Seberry{} schätzte $t_{0}=
(2\log_{2}(q-3))+1$ ab. Seither konnte \Craigen{} die Schranke einige
Male verbessern. In privater Kommunikation erfuhr der Autor, dass
derzeit eine Veröffentlichung in Vorbereitung ist, die $t_{0}=
\sfrac{1}{5}\log_{2}(\sfrac{q-1}{2}) +13$
setzt~\cite{Livinskyi2012}. Weiterhin ist \Craigen{} der Meinung, dass
zukünftig weitere Verbesserungen dieser Schranke zu erwarten sind.


\begin{bsp}\label{bsp:hm}
  Untenstehend sind Beispiele für \HMen{} vom Grad~$1$, $2$
  und $4$ aufgeführt:
  \begin{align*}
    H_{1} &=
    \begin{pmatrix}
      1
    \end{pmatrix} &
    H_{2} &=
    \begin{pmatrix*}[r]
      1 & 1\\
      1 & -1
    \end{pmatrix*} &
    H_{4} &= 
    \begin{pmatrix*}[r]
      1 & 1 & 1 & 1\\
      1 & 1 & -1 & -1\\
      1 & -1 & 1 & -1\\
      1 & -1 & -1 & 1
    \end{pmatrix*}
  \end{align*}
  Für höhere Grade wird die Struktur der Matrizen schnell
  unübersichtlich. Daher hat es sich eingebürgert, diese Beispiele
  grafisch darzustellen. In der \autoref{fig:had20} sind drei Beispiele von
  \HMen{} des Grades~$20$ aufgeführt.

  Dabei steht ein schwarzes Feld für einen Matrixeintrag $+1$ und ein
  weißes Feld kennzeichnet die $-1$. Die Beispiele wurden der
  Webseite\footnote{\url{http://neilsloane.com/hadamard/}} von
  \Sloane{} entnommen. Er listet \HMen{} bis zum Grad~$256$ auf~\cite{sloanehad}.
  \begin{figure}[htb]
    \centering
    \pgfplotstableread{beispiele/had20.paley}{\hzwanzigpaley}
    \pgfplotstableread{beispiele/had20.williamson}{\hzwanzigwill}
    \pgfplotstableread{beispiele/had20.toncheviv}{\hzwanzigton}
    \drawgrid{\hzwanzigpaley}\hfill{}
    \drawgrid{\hzwanzigwill}\hfill{}
    \drawgrid{\hzwanzigton}
    \caption{Drei \HMen{} vom Grad~$20$}
    \label{fig:had20}
  \end{figure}
\end{bsp}

\section{Weitere Arten von \HMen}
\label{sec:hm-typen}

Die ersten Arbeiten zu den Matrizen, die später als \HMen{} bekannt
wurden, bezogen sich auf komplexe Zahlen. In dieser Arbeit werden
hauptsächlich Matrixeinträge aus $\{\pm1\}$ betrachtet. Jedoch werden
\HMen{} mit komplexen Einträgen weiter erforscht. Eine Übersicht
verschiedener Ergebnisse bietet u.\,a. die Promotionsarbeit von
\citeauthor{2011PhDT378S}~\cite{2011PhDT378S}. Daneben benutzten
Forscher verschiedene Eigenschaften von \HMen{} und gaben Matrizen mit
diesen Eigenschaften Namen. Dieser Abschnitt soll eine Übersicht über
die verschiedenen Arten von \HMen{} geben.

\begin{defini}[Komplexe \HM{}]
  Sei $n\in\N$. Eine \highl[\HM|komplexe]{komplexe \HM{}} vom Grad~$n$
  ist eine $n\times n$ Matrix~$H$ mit Einträgen aus $\{\pm1, \pm i\}$
  und
  \begin{gather*}
    H\overline{H}^{T}=nI_{n}
  \end{gather*}
  Dabei bezeichnet $\overline{H}$ die komplexe Konjugation.
\end{defini}
Komplexe \HMen{} werden in der Literatur üblicherweise als Spezialfall
so genannter Butson"=Matrizen\footnote{In der Literatur wird für
  Butson"=Matrizen auch der Term \enquote{komplexe \HM{}} oder, wie in
  der Originalarbeit, \enquote{verallgemeinerte \HM{}} verwendet.}
verstanden. \Butson{} konstruierte Matrizen aus $m$-ten
Einheitswurzeln~\cite{zbMATH03178660}. Eine Vorstellung dieser
Matrizen führt im Rahmen dieser Arbeit zu weit und der Leser sei auf
die Veröffentlichung \citetitle{zbMATH03178660}~\cite{zbMATH03178660}
bzw. die oben vorgestellte Promotionsarbeit von
\textsc{\citeauthor{2011PhDT378S}} verwiesen.

\begin{defini}[Schiefe \HM{}]
  Sei $n\in\N$ und $1_{n}$ ein $1\times n$ Vektor, der nur aus
  Eins"=Einträgen besteht. Weiterhin sei $C$ eine schiefsymmetrische
  Matrix mit Einträgen aus $\{0,\pm1\}$ sowie $I_{n}$ die $n\times n$
  Einheitsmatrix. Dann heißt die $n\times n$ Matrix~$H$
  \highl[\HM|schiefe]{schief}, wenn diese wie folgt geschrieben werden
  kann:
  \begin{gather*}
    H= 
    \begin{pmatrix}
      1 & 1_{n-1}^{T}\\
      -1_{n-1} & C+I
    \end{pmatrix}
  \end{gather*}
\end{defini}
Eine gute Übersicht über diese Art von \HMen{} bietet die
Veröffentlichung von \Koukouvinos{} und \Stylianou{} mit dem Titel
\citetitle{zbMATH05280707}~\cite{zbMATH05280707}.\todo{Werden noch mehr
Eigenschaften der SHM gebraucht?}

Für Matrizen wie auch \HMen{} wird manchmal der Begriff
\enquote{amicable} benutzt. In der deutschsprachigen Literatur war
hierfür kein eindeutiger Begriff zu finden. Der Autor versuchte daher,
dass englische Wort in das Deutsche zu übertragen, indem der Begriff
\enquote{befreundet} verwendet wurde.

\begin{defini}[Befreundete Matrix]\label{def:befr-matrix}
  Seien $A$ und $B$ zwei Matrizen. Dann heißen $A$ und $B$
  \highl{befreundet}, wenn gilt, $AB^{T}=BA^{T}$.
\end{defini}

\begin{defini}[Befreundete \HMen{}]
  Sei $n\in\N$ und $H_{1}$ eine schiefe $n\times n$ \HM{} sowie
  $H_{2}$ eine \HM{} mit $H_{2}= H_{2}^{T}$.\footnote{In der
    Definition werden die Indizes an den \HMen{} nicht zur
    Kennzeichnung des Grades, sondern zur Unterscheidung der Matrizen
    verwendet.} Dann heißen $H_{1}$ und $H_{2}$
  \highl[\HM|befreundet]{befreundet}, wenn gilt
  \begin{enumerate}
  \item $H_{1}= I+S$ mit der Einheitsmatrix~$I$ und einer schiefsymmetrischen \HM{}~$S$
  \item $H_{1}H_{2}^{T}= H_{2}H_{1}^{T}$
  \end{enumerate}
\end{defini}
Befreundete \HMen{} können dazu benutzt werden, schiefe \HMen{} zu
konstruieren und letztere dienen zum Teil für die Konstruktion von
\HMen{}. Für zwei befreundete \HMen{} $H_{1}= I+S$ und $H_{2}$ wie
oben, gilt weiterhin $SH_{2}^{T}= H_{2}S^{T}$. Denn $H_{1}H_{2}^{T}=
(I+S)H_{2}^{T} = H_{2}^{T}+SH_{2}^{T}= H_{2}+SH_{2}^{T}$ und
$H_{2}H_{1}^{T}= H_{2}(I+S)^{T}= H_{2}+ H_{2}S^{T}$. Also ist
$H_{1}H_{2}^{T}= H_{2}+SH_{2}^{T}= H_{2}+ H_{2}S^{T}= H_{2}H_{1}^{T}$
und damit $SH_{2}^{T}= H_{2}S^{T}$.

\begin{defini}[Normalisierte \HM{}, Kern]
  Sei $n\in\N$. Eine $n\times n$ \HM{} heißt
  \highl[\HM|normalisierte]{normalisiert}, wenn alle Einträge in der
  ersten Spalte und Zeile $1$ sind. Die Untermatrix ohne die erste
  Zeile und Spalte heißt der \highl{Kern} der \HM{}.
\end{defini}

\section{Äquivalenz von \HMen}
\label{sec:aequi-hm}

Im \autoref{bsp:hm} ist eine \HM{} vom Grad~$2$
aufgeführt. Durch Bildung der Transponierten, Multiplikation von
Zeilen oder Spalten mit $-1$ oder Permutation der Zeilen oder Spalten
lassen sich andere \HMen{} erzeugen.
\begin{alignat*}{3}
  \begin{pmatrix*}[r]
    1 & 1\\
    1 & -1
  \end{pmatrix*} &
  \begin{pmatrix*}[r]
    1 & 1\\
    -1 & 1
  \end{pmatrix*} &
  \begin{pmatrix*}[r]
    -1 & 1\\
    1 & 1
  \end{pmatrix*} &
  \begin{pmatrix*}[r]
    1 & -1\\
    1 & 1
  \end{pmatrix*}\\
  \begin{pmatrix*}[r]
    -1 & -1\\
    -1 & 1
  \end{pmatrix*} &
  \begin{pmatrix*}[r]
    -1 & -1\\
    1 & -1
  \end{pmatrix*} &
  \begin{pmatrix*}[r]
    1 & -1\\
    -1 & -1
  \end{pmatrix*} &
  \begin{pmatrix*}[r]
    -1 & 1\\
    -1 & -1
  \end{pmatrix*}
\end{alignat*}
Durch die Betrachtung von \HMen{}, die durch die oben genannten
Umformungen enstanden sind, sind keine wesentlich neuen Erkenntnisse
zu erwarten. Andererseits sind in \autoref{fig:had20} drei
\HMen{} vom Grad~$20$ aufgeführt, die nicht durch
Umformungen entstanden sind. In den drei Fällen gibt es keine
Möglichkeit, die Matrizen durch Vertauschung oder Multiplikation mit
$-1$ ineinander zu überführen.

In der Literatur wird von äquivalenten \HMen{} gesprochen, wenn sich
zwei \HMen{} durch Vertauschung von Zeilen oder Spalten oder
Multiplikation von Zeilen oder Spalten mit $-1$ ineinander überführen
lassen. Diese Transformation kann ebenfalls durch Multiplikation mit
entsprechenden Permutationsmatrizen dargestellt werden. Im Rahmen
dieser Arbeit steht der Begriff
\enquote{Permutationsmatrix}\todo{Besser definieren} für eine
$n\times n$ Matrix mit Einträgen aus $0$ und $\pm 1$. Dabei gibt es in
genau einer Zeile und Spalte einen Eintrag, der von $0$ verschieden
ist. Der Begriff der Äquivalenz wird nun unter Ausnutzung dieser
Tatsache formuliert.
\begin{defini}
  Seien $H_{1}$ und $H_{2}$ zwei $n\times n$ \HMen{}. Die Matrizen $H_{1}$
  und $H_{2}$ heißen
  \highl[Hadamard-Matrix!äquivalent]{äquivalent}\index{äquivalent},
  wenn $n\times n$  Permutationsmatrizen $P$, $Q$ mit
  \begin{gather*}
    H_{1} = PH_{2}Q^{T}
  \end{gather*}
  existieren.
\end{defini}

Damit zerfallen die \HMen{} vom Grad~$n$ in Äquivalenzklassen. Für die
Grade~$1$, $2$, $4$, $8$ und $12$ existiert genau eine
Äquivalenzklasse. Für $n=16$ fand \Hall{} 1961 heraus, dass es fünf
Äquivalenzklassen gibt~\cite{hall1961hadamard} und 1965 zeigte er,
dass es 14~Klassen für $n=20$ gibt~\cite{zbMATH01321696}.  Die
Klassifikation von $n=24$ wurde 1989 durch \Kimura{}
abgeschlossen~\cite{zbMATH04135959}. Aufbauend auf einer Arbeit von
Ito et.\,al~\cite{zbMATH03749020} zeigte er, dass 60~Äquivalenzklassen
existieren. Schließlich existieren für \HMen{} vom Grad~$28$ insgesamt
487~Klassen~\cite{HoradamHM1951}. Bei höheren Graden ist die Anzahl
nicht mehr einfach ermittelbar. Die Literatur spricht hier von einer
algorithmischen Explosion und hat diese Fälle durch Abschätzungen nach
unten behandelt. Erst im Jahr 2013 gelang es \Kharaghani{} und
\Tayfeh{} die Anzahl der Äquivalenzklassen genau zu bestimmen. In
ihrer Arbeit \citetitle{JCD:JCD21323}~\cite{JCD:JCD21323} kommen sie
zu dem Ergebnis, dass genau \num{13710027}~Äquivalenzklassen
existieren. Zum Zeitpunkt der Niederschrift dieser Arbeit existierte
die aktuellste Abschätzung für den Grad~$n=36$ von
\Orrick{}~\cite{orrick2008}. Diese besagt, dass die Anzahl der
Äquivalenzklassen größer als \num{18292717} ist.

\Orrick{} definiert in seiner Arbeit
\citetitle{orrick2008}~\cite{orrick2008} den Begriff der
$Q$-Äquivalenz. Dies ist eine schwächere Form des
Äquivalenzbegriffs. Daneben gibt es weitere Versuche, eine schwächere
Definition zur Handhabung der Äquivalenzen zu finden. Hierauf soll im
folgenden nicht näher eingegangen werden.

\section{Weitere Begriffe}
\label{sec:weitere-begriffe}

Der folgende Abschnitt führt Begriffe ein, die für die weitere Arbeit
von Wichtigkeit sind.

\subsection{Kronecker-Produkt}
\label{sec:kronecker-produkt}

\begin{defini}
  Sei $R$ ein Ring, $A=(a_{ij})$ eine $m\times m$ Matrix und $B=(b_{kl})$ eine $n\times
  n$ Matrix mit $a_{ij}, b_{kl}\in R$ für $i,j=1,\dots,m$ und
  $k,l=1,\dots,n$. Das \highl{Tensorprodukt} $A\otimes B$ in
  \autoref{eq:kron-prod} wird als \highl{Kronecker-Podukt} bezeichnet.
  \begin{gather}
    \label{eq:kron-prod}
    A\otimes B=
    \begin{pmatrix}
      a_{11}B & a_{12}B & a_{13}B & \dots& a_{1m}B\\
      a_{21}B & a_{22}B & a_{23}B & \dots& a_{2m}B\\
      \hdots& \hdots&\ddots& \hdots& \hdots\\
      a_{m1}B & a_{m2}B & a_{m3}B & \dots& a_{mm}B
    \end{pmatrix}
  \end{gather}
\end{defini}

Das Kronecker"=Produkt stellt die Grundlage für viele
Konstruktionsverfahren von \HMen{} dar. Daher sind die
Koeffizienten von $A$ und $B$ in den folgenden Betrachtungen meist aus
$\Z$ bzw. aus der Menge $\{0, \pm1\}$. Weiterhin kann das
Kronecker"=Produkt allgemeiner für $m\times n$ und $p\times q$
Matrizen definiert werden. Da im Rahmen der Arbeit in der Regel nur
quadratische Matrizen betrachtet werden, wurde diese Einschränkung
vorgenommen.

Folgende Eigenschaften gelten für das
Kronecker"=Produkt:
\begin{itemize}
\item Assoziativität: $A\otimes(B\otimes C)= (A\otimes B)\otimes C$
  für Matrizen $A$, $B$ und $C$ mit Einträgen aus einem Ring~$R$.
\item Distributivität: $A\otimes(B+C)= (A\otimes B)+(A\otimes C)$ und
  $(A+B)\otimes C= (A\otimes C)+ (B\otimes C)$ für
  Matrizen $A$, $B$ und $C$  mit Einträgen aus einem Ring~$R$.
\item Seien $A$ eine $k\times l$ Matrix, $B$ eine $n\times o$ Matrix,
  $C$ eine $l\times m$ Matrix und $D$ eine $o\times p$ Matrix. Dann
  gilt, $(A\otimes B)(C\otimes D)= AC\otimes BD$. Denn $A\otimes B$
  ist eine $kn\times lo$ Matrix und $C\otimes D$ ist eine $lo\times
  mp$ Matrix. Das Produkt aus beiden ist eine $kn\times mp$
  Matrix. Das Produkt aus $A$ und $C$ ist eine $k\times m$ Matrix
  sowie aus $B$ und $D$ ist eine $n\times p$ Matrix. Schließlich
  ergibt $AC\otimes BD$ eine $kn\times mp$ Matrix.
\item Die transponierte Matrix aus dem Kronecker"=Produkt ist gleich
  dem Kronecker"=Produkt der transponierten Matrizen: $(A\otimes
  B)^{T}= A^{T}\otimes B^{T}$.
\item Für quadratische, reguläre Matrizen ist das Inverse des
  Kronecker"=Produkts gleich dem Kronecker"=Produkt der inversen Matrizen:
  $(A\otimes B)^{-1}= A^{-1}\otimes B^{-1}$.
\end{itemize}


\subsection{Quadratischer Rest und Legendre-Symbol}
\label{sec:quadr-resid}

\begin{defini}\label{def:quadr-rest}
  Seien $a\in\Z$ und $n\in\N$ teilerfremd. Dann heißt $a$
  \highl[Rest!quadratischer]{quadratischer Rest} modulo $n$, wenn die
  Kongruenz $b^{2}\equiv a\mod{n}$ für $b\in\Z$ lösbar
  ist. Andernfalls heißt $a$ \highl{Nichtrest}.
\end{defini}


\begin{defini}
  Sei $p>2$ eine Primzahl. Ist $a\in\Z$, so ist das
  Legendre-Symbol:
  \begin{gather*}
    \legendre{a}{p}\coloneqq
    \begin{cases}
      0 & p\mid a\\
      1 & a \text{ ist QR }\mod{p}\\
      -1 & a \text{ ist NR }\mod{p}\\
    \end{cases}
  \end{gather*}
  Dabei bedeutet QR quadratischer Rest und NR Nichtrest.
\end{defini}

Eine wichtige Eigenschaft des Legendre"=Symbols ist die
Multiplikativität. Dies wird später bei der Konstruktion von \HMen{}
nach den Methoden von \Paley{} benötigt (\autoref{sec:konst-payley})
und daher soll diese Eigenschaft hier nachgewiesen werden.

\begin{satz}[\textsc{Euler}sches Kriterium]
  Sei $p>2$ eine Primzahl. Dann gilt:
  \begin{gather}
    \label{eq:euler-krit}
    \legendre{a}{p}\equiv a^{\frac{p-1}{2}}\mod{p},\qquad a\in\Z
  \end{gather}
  \begin{proof}
    \begin{enumerate}[1.\,F{a}ll]
    \item Für $p\mid a$ ist $\legendre{a}{p}=0$ und
      $a^{\frac{p-1}{2}}\equiv0\mod{p}$. Daher gelte im folgenden
      immer $p\nmid a$.
    \item Sei $a$ ein quadratischer Rest modulo $p$. Nach der
      \autoref{def:quadr-rest} gibt es dann ein $b\in\Z$ mit
      $a\equiv b^{2}\mod{p}$. Also ist
      $a^{\frac{p-1}{2}}\equiv(b^{2})^{\frac{p-1}{2}}\equiv
      b^{p-1}\mod{p}$. Nach dem kleinen fermatschen Satz ergibt sich
      dann: $b^{p-1}\equiv1\mod{p}=\legendre{a}{p}$.\todo{Ggf. $\mod$ verschieben.}
    \item Sei $a$ ein quadratischer Nichtrest modulo $p$. In dem Fall
      hat die Kongruenz $b^{2}\equiv a\mod{p}$ für $b\in\Z$ keine
      Lösung.\\
      Sei nun $z$ eine Primitivwurzel modulo $p$. Dann gilt $a=z^{m}$
      für $m=2k+1$ und $m,k\in\N$. Es ist $a^{\frac{p-1}{2}}=
      (z^{m})^{\frac{p-1}{2}}= (z^{2k+1})^{\frac{p-1}{2}}=
      z^{\frac{2kp-2k+p-1}{2}}= z^{\frac{2k(p-1)}{2}+\frac{p-1}{2}}=
      z^{k(p-1)+\frac{p-1}{2}}= z^{k(p-1)}z^{\frac{p-1}{2}}$. Es ist
      $z^{k(p-1)}\equiv1\mod{p}$ und
      $z^{\frac{p-1}{2}}\equiv-1\mod{p}= \legendre{a}{p}$. Insgesamt
      ergibt sich damit die Behauptung.
    \end{enumerate}
  \end{proof}
\end{satz}

Damit ist klar, dass aus der Multiplikation zweier quadratischer Reste
oder zweier quadratischer Nichtreste ein quadratischer Rest
hervorgeht. Die Multiplikation eines quadratischen Rests mit einem
quadratischen Nichtrest führt wieder zu einem quadratischen
Nichtrest. Insgesamt gilt für eine Primzahl~$p>2$:
\begin{gather*}
  \legendre{a}{p}\legendre{b}{p}= \legendre{ab}{p}\qquad a,b\in\Z
\end{gather*}

\subsection{Permanente}
\label{sec:permanente}

Innerhalb der linearen Algebra ist die Determinante bekannt und gut
erforscht. Ein verwandter Begriff ist die Permanente. Sie wird
in der Kombinatorik häufig benutzt. Die Permanente ist wie die Determinante ein
Polynom in den Einträgen der Matrix und besitzt folgende Definition:
\begin{defini}[Permanente]
  Sei $n\in\N$ und $\Sym_{n}$ die symmetrische Gruppe aller Permutationen
  von $n$. Die \highl{Permanente} einer $n\times n$ Matrix~$A=(a_{ij})$ ist
  definiert durch:
  \begin{gather}
    \label{eq:permanente}
    \perm(A)\coloneqq\sum_{\sigma\in \Sym_{n}} \prod_{i=1}^{n} a_{i,\sigma(i)}
  \end{gather}
\end{defini}
Unter Zugrundelegung der Leibnizschen Formel unterscheidet sich die
obenstehende Definition nur durch die fehlende Signumsfunktion von der
Determinante einer Matrix.
\begin{bsp}
  \begin{align*}
    \det
    \begin{pmatrix}
      a_{11} & a_{12}\\
      a_{21} & a_{22}
    \end{pmatrix} &= a_{11}a_{22}-a_{12}a_{21}\\
    \perm
    \begin{pmatrix}
      a_{11} & a_{12}\\
      a_{21} & a_{22}
    \end{pmatrix} &= a_{11}a_{22}+a_{12}a_{21}
  \end{align*}
  \begin{align*}
  \det
    \begin{pmatrix}
      a_{11} & a_{12} & a_{13}\\
      a_{21} & a_{22} & a_{23}\\
      a_{31} & a_{32} & a_{33}
    \end{pmatrix} &= a_{11}a_{22}a_{33}+ a_{13}a_{21}a_{32} +
    a_{12}a_{23}a_{31}\\
    &\quad- a_{13}a_{22}a_{31}- a_{12}a_{21}a_{33}- a_{11}a_{23}a_{32}\\
    \perm
    \begin{pmatrix}
      a_{11} & a_{12} & a_{13}\\
      a_{21} & a_{22} & a_{23}\\
      a_{31} & a_{32} & a_{33}
    \end{pmatrix} &= a_{11}a_{22}a_{33}+ a_{13}a_{21}a_{32} +
    a_{12}a_{23}a_{31}\\
    &\quad+ a_{13}a_{22}a_{31}+ a_{12}a_{21}a_{33}+ a_{11}a_{23}a_{32}\\
  \end{align*}
\end{bsp}
Ein weiterer Unterschied der Permanente im Vergleich zur Determinante
besteht in der Berechnung des Wertes. Für die Ermittlung der
Determinante sind aus der Numerik verschiedene schnelle Verfahren
bekannt. Diese Verfahren benötigen $\CO(n^{3})$ Zeit. Die Forscher
\Dagum{} und \Luby{} konnten 1992 zeigen, dass die Berechnung der
Permanente in die Klasse der \#P"=vollständigen Probleme gehört. Das bedeutet,
dass dies mindestens in der Klasse NP liegt und es damit vermutlich
keinen Algorithmus gibt, der dies in polynomialer Zeit lösen
kann.

Die Permanente ist invariant gegenüber Vertauschungen von Zeilen und
Spalten. Denn durch die Vertauschung werden die Faktoren des Produkts
permutiert. Wegen der Kommutativität und da alle Elemente von
$\Sym_n$ durchlaufen werden, gibt es keine Änderung des
Ergebnisses. Ebenso ist die Permanente einer transponierten
Matrix~$A$ gleich der Permanente der ursprünglichen
Matrix~$A$.  \todo{Evtl. weitere Eigenschaften}

Zu den Eigenschaften der Permanente von \HMen{} ist wenig
bekannt. In der Veröffentlichung
\citetitle{MarcusNewman1962}~\cite{MarcusNewman1962} konnte gezeigt
werden, dass für
eine \HM~$H$ gilt, $\abs{\perm(H)}\leq \abs{\det(H)}=
n^{\sfrac{n}{2}}$. Weiterhin gelang es 2005, \Wanless{} die
Permanenten aller \HMen{} bis zum Grad~28 zu berechnen. Im
\autoref{sec:konst-sylvester} sollen weitere Ergebnisse für die Konstruktion
von \Sylvester{} vorgestellt werden.

Eine Vertauschung von Zeilen und Spalten einer \HM{} lässt die
Permanente konstant. Denn dadurch ändert sich nur die Reihenfolge der
Faktoren und durch die Kommutativität der Multiplikation bleibt das
Ergebnis gleich. Die Multiplikation einer Zeile oder Spalte mit $-1$
negiert den Wert der Permanente, denn jeder Multiplikator wird mit
$-1$ multipliziert. Damit lässt sich für die in \autoref{sec:aequi-hm}
vorgestellten  äquivalenten \HMen{} feststellen, dass der Betrag der
Permanente zweier äquivalenter \HMen{} $H_{1}$ und $H_{2}$ gleich ist:
\begin{gather*}
  \abs{\perm{(H_{1})}}= \abs{\perm{(H_{2})}}
\end{gather*}
Die Umkehrung gilt in der Regel nicht. Zwei Matrizen mit betragsmäßig
gleicher Permanente sind nicht äquivalent. Dazu betrachten sei $H_{4}$
eine $4\times4$ \HM{} und $A$ eine weitere $4\times4$ Matrix.
\begin{align*}
  H_{4} &= 
  \begin{pmatrix*}[r]
    1 &  1 &  1 &  1\\
    1 &  1 & -1 & -1\\
    1 & -1 &  1 & -1\\
    1 & -1 & -1 &  1
  \end{pmatrix*} &
  A &=
  \begin{pmatrix*}[r]
    -1 & 1 & 1 & 1\\
    1 & -1 & 1 & 1\\
    1 & 1 & 1 & 1\\
    1 & 1 & 1 & 1
  \end{pmatrix*}
\end{align*}
Es gilt, $\abs{\perm(H_{4})}=\abs{\perm(A)}=8$. Jedoch sind beide
Matrizen nicht äquivalent. Die Matrix~$A$ ist noch nicht einmal eine \HM{}.

\subsection{Zirkulante Matrix}
\label{sec:circulant}

Zirkulante Matrixen werden benutzt, um \HMen{} zu konstruieren. Daher
soll der Begriff hier mit eingeführt werden.
\begin{defini}[Zirkulante Matrix]
  Sei $n\in\N$. Eine $n\times n$ Matrix~$C=(c_{ij})_{0\leq i,j\leq n-1}$ heißt
  \highl[Matrix|zirkulante]{zirkulant}, wenn jede Zeile durch die
  Verschiebung aus der vorigen entsteht:
  \begin{gather*}
    C=
    \begin{pmatrix}
      c_{0} & c_{1} & c_{2} & \dots & c_{n-1}\\
      c_{n-1} & c_{0} & c_{1} & \dots & c_{n-2}\\
      c_{n-2} & c_{n-1} & c_{0} & \dots & c_{n-3}\\
      \vdots & \vdots & \vdots & \ddots & \vdots\\
      c_{1} & c_{2} & c_{3} & \dots & c_{0}
    \end{pmatrix}
  \end{gather*}
\end{defini}
Eine zirkulante Matrix kann vollständig durch einen Zeilenvektor
charakterisiert werden und es gilt, $C=c_{0}I_{n}+ c_{1}P+
c_{2}P^{2}+\dots+ c_{n-1}P^{n-1}$ für die Permutationsmatrix
\begin{gather*}
  P=
  \begin{pmatrix}
    0 & 1 & 0 & \dots & 0 & 0\\
    0 & 0 & 1 & \dots & 0 & 0\\
    \vdots & \vdots& \vdots &\ddots& \vdots& \vdots\\
    0 & 0 & 0 & \dots & 0 & 1\\
    1 & 0 & 0 & \dots & 0 & 0
  \end{pmatrix}
\end{gather*}

Neben der obigen allgemein bekannten Permutationsmatrix werden bei der
Konstruktion von \HMen{} verallgemeinerte Permutationsmatrizen
verwendet.
\begin{defini}[Verallgemeinerte Permutationsmatrix]
  Sei $n\in\N$. Eine
  \highl[Permutationsmatrix|verallgemeinerte]{verallgemeinerte
    Permutationsmatrix} ist eine $n\times n$ Matrix~$P$ über einem
  assoziativen Ring mit Einselement. In jeder Zeile und Spalte ist
  genau ein Element ungleich $0$.
\end{defini}
Falls die Nicht"=Null"=Einträge gleich $1$ sind, ergibt sich wieder
die bekannte Permutationsmatrix.

\subsection{Gewichtungsmatrix}
\label{sec:weighingmatrix}

Die Gewichtungsmatrizen\todo{Besseren Begriff für weighing matrix}
ähneln den \HMen{} und werden zur Konstruktion dieser verwendet.
\begin{defini}
  Sei $n\in\N$. Eine Gewichtungsmatrix ist eine $n\times n$
  Matrix~$W=W(n,k)$ mit Einträgen aus $\{0,\pm1\}$, die die Gleichung
  $WW^{T}= kI_{n}$ für $k\in\N$ erfüllt.
\end{defini}
Die Matrix $W(n,n)$ ist eine \HM{}.

\chapter{Konstruktion von \HMen}
\label{chap:konstr}

Eine Annäherung an das Problem von \Hadamard{} erfolgt über die
explizite Konstruktion von \HMen{}. So zeigte bereits
\Sylvester{}~\cite{Sylvester1867}, dass sich für $n\geq1$
\HMen{} vom Grad~$2^{n}$ konstruieren lassen. Nachdem
\Hadamard{} in seiner Arbeit einige Spezialfälle zeigen konnte, gelang
es \Paley{} zwei neue allgemeine Konstruktionen zu finden. Seither
wurden die Verfahren weiter verfeinert. Allerdings verbleiben auch in
diesen Verfahren offene Fälle. Die Ordnung~$668$ ist die derzeit
kleinste Zahl für die keine \HM{} gefunden werden konnte.

Im folgenden soll ein Überblick über existierende Verfahren gegeben
werden. Dabei werden Verfahren in deren historischem Erscheinen
angegeben. Das Ende des Kapitels versucht eine Kategorisierung der
Verfahren einzuführen. Diese richtet sich nach einem Vorschlag von
\Seberry{} und \Yamada{}. Diese schlugen vor, folgende Einteilung
vorzunehmen~\cite{zbMATH02128113}.
\begin{itemize}
\item Multiplikationstheoreme (Multiplication theorems)
\item Direkte Konstruktionen (Direct constructions)
\item Plug-In-Methoden (\enquote{Plug-in} methods)
\end{itemize}
Die Multiplikationstheoreme nutzen den Fakt, dass das
(Kronecker-)Produkt zweier \HMen{} wieder eine
\HM{} ist. \Sylvester{} nutzte dies in seiner
Konstruktion für Matrizen des Grads~$2^{k}$ für
$k\in\N$.

Die Konstruktionsverfahren nach \Paley{} sind direkte
Konstruktionen.\todo{ein wenig mehr zu Paley}

\Williamson{} verwendete verschiedene Matrizen und \enquote{steckte}
diese zu \HMen{} zusammen. Daher spricht man von
Plug"=In"=Methoden.

\section{Konstruktion nach \Sylvester}
\label{sec:konst-sylvester}

\Sylvester{} präsentierte als Erster ein direktes
Konstruktionsverfahren. Hierzu nutzte er das Kronecker"=Produkt
(\autoref{sec:kronecker-produkt}) um \HMen{} vom
Grad~$2^{n}$ für $n\geq 1$ zu konstruieren. Die Matrix~$H_{1}=(1)$ ist
die \HM{} aus dem \autoref{bsp:hm}.
\begin{defini}
  Sei $H_{n}$ eine \HM{} vom Grad~$n$ für eine natürliche
  Zahl~$n\geq1$. Dann sind \HMen{} nach \Sylvester{} $2n\times 2n$
  Matrizen der Form
  \begin{gather*}
    H_{2n}=
    \begin{pmatrix*}[r]
      1 & 1\\
      1 & -1
    \end{pmatrix*}
    \otimes H_{n}
  \end{gather*}
\end{defini}

\begin{bsp}
  Die $2\times2$ \HM{} aus dem \autoref{bsp:hm} wird benutzt, um eine
  $4\times4$ \HM{} zu konstruieren.
  \begin{align*}
    H_{2\cdot2} &=     \begin{pmatrix*}[r]
      1 & 1\\
      1 & -1
    \end{pmatrix*}
    \otimes H_{2}=     \begin{pmatrix*}[r]
      1 & 1\\
      1 & -1
    \end{pmatrix*} \otimes
    \begin{pmatrix*}[r]
      1 & 1\\
      1 & -1
    \end{pmatrix*}\\
    &=
    \begin{pmatrix*}[r]
      1    \begin{pmatrix*}[r]
      1 & 1\\
      1 & -1
    \end{pmatrix*} & 1    \begin{pmatrix*}[r]
      1 & 1\\
      1 & -1
    \end{pmatrix*} \\
      1    \begin{pmatrix*}[r]
      1 & 1\\
      1 & -1
    \end{pmatrix*}  & -1    \begin{pmatrix*}[r]
      1 & 1\\
      1 & -1
    \end{pmatrix*}
    \end{pmatrix*}
    =
    \begin{pmatrix*}[r]
      1 & 1& 1 & 1\\
      1 & -1 & 1& -1\\
      1 & 1 & -1 & -1\\
      1 & -1 & -1 & 1
    \end{pmatrix*}
  \end{align*}
\end{bsp}

Das Konstruktionsprinzip gilt sogar allgemein für \HMen{}, wie im
folgenden Satz zu sehen ist.
\begin{satz}
  Sei $A$ eine $n\times n$ und $B$ eine $m\times m$ \HM{}. Dann ist
  $A\otimes B$ eine $nm\times nm$ \HM{}.
  \begin{proof}
    Zum Nachweis der Eigenschaft muss die Matrix $A\otimes B$ mit
    ihrer transponierten Matrix multipliziert werden: $(A\otimes
    B)(A\otimes B)^{T}= (A\otimes B)(A^{T}\otimes B^{T})=
    AA^{T}\otimes BB^{T}= nI_{n}\otimes mI_{m}= mn I_{mn}$.
  \end{proof}
\end{satz}

Durch die Konstruktion von \Sylvester{} entstehen \HMen{} vom Grad
$2^{i}$ für natürliche Zahlen $i>1$. Allerdings bleibt hierbei unklar,
ob es \HMen{} zwischen $2^{i}$ und $2^{i+1}$ für $i\geq3$ gibt. Unter
anderem wurde von verschiedenen Wissenschaftlern versucht, die
Zweierpotenz im Ergebnis abzuschwächen. Ein Ansatz stammt von
\Agayan{} und \Sarukhanyan{}. Sie gehen von zwei \HMen{} $H_{1}$,
$H_{2}$ vom Grad $4k$ und $4l$ für $k,l\in\N$ aus und konstruieren
daraus eine \HM{} vom Grad~$8kl$.\footnote{Der Index an beiden \HMen{}
soll dabei der Unterscheidung der Matrizen und \emph{nicht} zur
Markierung des Grades dienen.} Dazu werden beide Matrizen zerlegt:
\begin{align*}
  H_{1} &=
  \begin{pmatrix}
    A & B\\
    C & D
  \end{pmatrix} &
  H_{2} &=
  \begin{pmatrix}
    E & F\\
    G & H
  \end{pmatrix}
\end{align*}
Da beide \HMen{} sind, gilt, $H_{1}H_{1}^{T}= 4kI_{4k}$ und
$H_{2}H_{2}^{T}= 4lI_{4l}$. Wie in \autoref{eq:saruk-t1} und \autoref{eq:saruk-t2} zu sehen ist,
errechnen sich die Diagonaleinträge durch $AA^{T}+BB^{T}= CC^{T}+DD^{T}= 2kI_{2k}$ und
$EE^{T}+FF^{T}= GG^{T}+HH^{T}= 2lI_{2l}$. Die Ergebnisse außerhalb der
Hauptdiagonalen sind $AC^{T}+BD^{T}= CA^{T}+DB^{T}=0$ und
$EG^{T}+FH^{T}= GE^{T}+HF^{T}=0$.
\begin{align}\label{eq:saruk-t1}
  H_{1}H_{1}^{T} &=   \begin{pmatrix}
    A & B\\
    C & D
  \end{pmatrix}
  \begin{pmatrix}
    A^{T} & C^{T}\\
    B^{T} & D^{T}
  \end{pmatrix}=
  \begin{pmatrix}
    AA^{T}+BB^{T} & AC^{T}+BC^{T}\\
    CA^{T}+DB^{T} & CC^{T}+DD^{T}
  \end{pmatrix}
\end{align}
\begin{align}\label{eq:saruk-t2}
H_{2}H_{2}^{T} &=
  \begin{pmatrix}
    E & F\\
    G & H
  \end{pmatrix}
  \begin{pmatrix}
    E^{T} & G^{T}\\
    F^{T} & H^{T}
  \end{pmatrix}=
  \begin{pmatrix}
    EE^{T}+FF^{T} & EG^{T}+FH^{T}\\
    GE^{T}+HF^{T} & GG^{T}+HH^{T}
  \end{pmatrix}
\end{align}

 Mit Hilfe des Kronecker"=Produkts
ergibt sich dann die \HM{} vom Grad $8kl$ wie folgt:
\begin{gather}\label{eq:saruk}
\rule[\dimexpr-4ex-\ht\strutbox]{0pt}{\dimexpr4ex+4ex+\baselineskip}
  H_{8kl}=
  \begin{pmatrix}
    \strut\smash{\overbrace{\sfrac{1}{2} (A+B)\otimes E + \sfrac{1}{2} (A-B)\otimes G}^{\mathclap{K}}} &
    \strut\smash{\overbrace{\sfrac{1}{2} (A+B)\otimes F + \sfrac{1}{2} (A-B)\otimes H}^{L}}\\
    \strut\smash{\underbrace{\sfrac{1}{2} (C+D)\otimes E + \sfrac{1}{2} (C-D)\otimes G}_{M}} &
    \strut\smash{\underbrace{\sfrac{1}{2} (C+D)\otimes F + \sfrac{1}{2} (C-D)\otimes H}_{M}}
  \end{pmatrix}
\end{gather}
In der \autoref{eq:saruk} wurden die resultierenden Teilmatrizen mit
$K$, $L$, $M$ und $N$ bezeichnet. Es ist klar, dass die vier
Teilmatrizen quadratisch sind und Einträge aus $\{\pm1\}$
haben. Weiterhin ist zu verifizieren, ob $H_{8kl}H_{8kl}^{T}=
8klI_{8kl}$ ist. Das erste Diagonalelement ergibt sich durch
$KK^{T}+LL^{T}= \sfrac{1}{2} (AA^{T}+BB^{T}+CC^{T}+DD^{T})\otimes
4lI_{4l}$ und $(AA^{T}+BB^{T}+CC^{T}+DD^{T})=4kI_{2k}$. Insgesamt ist
dann $KK^{T}+LL^{T}=8klI_{4kl}$ und das zweite Diagonalelement
berechnet sich nach einem ähnlichen Prinzip. Da das Produkt einer
Matrix aus $\{E,F,G,H\}$ mit einer anderen transponierten Matrix aus
dieser Menge Null ergibt, ist die Gesamtkonstruktion somit eine \HM{}.

Den Mathematiker \Craigen{}, \Seberry{} und \Zhang{} gelang später eine
Verbesserung~\cite{zbMATH00035956}. Sie konnten zeigen, dass aus vier \HMen{} mit den Graden
$4k$, $4l$, $4m$ und $4n$ für $k,l,m,n\in\N$ eine \HM{} mit dem Grad
$16klmn$ konstruiert werden kann. Für den Beweis arbeiten sie mit den
in \autoref{sec:weighingmatrix} definierten Gewichtungsmatrizen, die
befreundet und disjunkt sind. Dabei bedeutet disjunkt, dass das
komponentenweise Produkt der Matrizen $0$ ergibt. Die Autoren zeigen,
dass es zwei disjunkte Gewichtungsmatrizen $W(4kl,2kl)$ gibt, die mit
$X$ und $Y$ bezeichnet werden. Weiterhin gibt es zwei Matrizen $S$ und
$R$ mit Einträgen aus $\{\pm1\}$ vom Grad $4mn$, die die Eigenschaften
$SS^{T}+RR^{T}=8mnI_{4mn}$ und $SR^{T}=RS^{T}=0$ erfüllen. Die \HM{}
$H$ kann durch $H= X\otimes S+ Y\otimes R$ konstruiert werden. Denn
$HH^{T}= (X\otimes S+ Y\otimes R)(X\otimes S+ Y\otimes R)^{T}=
(X\otimes S+ Y\otimes R)((X\otimes S)^{T}+ (Y\otimes R)^{T})=
(X\otimes S+ Y\otimes R)(X^{T}\otimes S^{T}+ Y^{T}\otimes R^{T})=
(X\otimes S)(X^{T}\otimes S^{T})+ (Y\otimes R)(Y^{T}\otimes R^{T})=
XX^{T}\otimes SS^{T}+ YY^{T}\otimes RR^{T}= 2klI_{4kl}\otimes SS^{T}+
2klI_{4kl}\otimes RR^{T}= 2klI_{4kl}\otimes(SS^{T}+RR^{T})=
2klI_{4kl}\otimes 8mnI_{4mn}= 16klmnI_{16klmn}$. Das Ergebnis $XX^{T}=
YY^{T}= 2klI_{4kl}$ wurde von den Autoren in der Arbeit
gezeigt. Insgesamt stellt das eine weitere Verbesserung zu den oben
angeführten Ergebnissen dar.

Schließlich gelang es \DeLauney{} aus 12 \HMen{} der Grade $4k_{i}$
für $k_{i}\in\N$ und $i=1,\dots,12$ eine \HM{} vom Grad
$512\prod_{i=1}^{12} k_{i}=2^{9}\prod_{i=1}^{12} k_{i}$ zu
konstruieren~\cite{zbMATH00238429}. Dabei werden die obigen Verfahren
von \Agayan{} und \Sarukhanyan{} sowie von \Craigen, \Seberry{} und
\Zhang{} kombiniert. Die Verbesserung liegt dabei im Exponenten. Die
anderen Verfahren führen mindestens zu einem Faktor von $2^{10}$,
während der Ansatz von \DeLauney{} lediglich einen Faktor von $2^{9}$
hat. Der genaue Beweis kann in
\citetitle{zbMATH00238429}~\cite{zbMATH00238429} nachgelesen werden.


In \autoref{sec:permanente} wurde der Begriff der Permanente
eingeführt. Dabei stellt sich die Frage, ob für eine \HM~$H$ vom
Grad~$n>2$, gilt $\perm(H)=0$. \Wanless{} evaluierte dies für
alle Fälle bis $n<32$~\cite{zbMATH02206586}. Der folgende Satz gibt
eine hinreichende Bedingung. Damit kann im Fall des
Konstruktionsverfahrens nach \Sylvester{} eine negative Antwort
gegeben werden~\cite{2013arXiv1311.2427A}.
\begin{satz}
  Seien $m$ und $n$ natürliche Zahlen mit $m,n \geq2$. Es bezeichne
  $H_{2^{m}}$ und $H_{2^{n}}$ \HMen{}, die nach dem Verfahren
  von \Sylvester{} konstruiert ist sowie $I_{2^{m}}$ und $I_{2^{n}}$
  Einheitsmatrizen. Wenn
  \begin{gather}\label{eq:permungl}
    \perm((H_{2^{n}}\otimes I_{2^{m}})(I_{2^{n}}\otimes H_{2^{m}}))
    \geq \perm(H_{2^{n}}\otimes I_{2^{m}})\perm(I_{2^{n}}\otimes H_{2^{m}})
  \end{gather}
  dann ist die Permanente einer \HM{} vom Grad~$2^{k}$ für $k>2$
  nach dem Konstruktionsverfahren von \Sylvester{} immer größer als
  $0$.
  \begin{proof}
    Für zwei quadratische Matrizen $A$ und $B$ lässt sich das
    Kronecker-Produkt auch in der Form $A\otimes B= (A\otimes
    I_{m})(I_{n}\otimes B)$ schreiben. Weiterhin ist bekannt, dass für
    das Kronecker-Produkt die Assoziativität gilt. Damit folgt,
    $H_{2^{m+n}}= H_{2^{m}}\otimes H_{2^{n}}= (H_{2^{m}}\otimes
    I_{2^{n}})(I_{2^{m}}\otimes H_{2^{n}})$.

    Für die Permanente von quadratischen Matrizen $A$ und $B$ ist
    bekannt, dass gilt, $\perm(I_{n}\otimes A)=(\perm(A))^{n}$. Denn
    \begin{align}\label{eq:perm-laplace}
      \perm(I_{n}\otimes A) &=\perm\left(
      \begin{pmatrix}
        1 & 0 & 0 & \dots & 0\\
        0 & 1 & 0 & \dots & 0\\
        0 & 0 & 1 & \dots & 0\\
        \vdots & \vdots & \vdots & \ddots & \vdots\\
        0 & 0 & 0 & \dots & 1
      \end{pmatrix}\otimes A\right) = \perm
      \begin{pmatrix}
        A & 0 & 0 & \dots & 0\\
        0 & A & 0 & \dots & 0\\
        0 & 0 & A & \dots & 0\\
        \vdots & \vdots & \vdots & \ddots & \vdots\\
        0 & 0 & 0 & \dots & A
      \end{pmatrix}
    \end{align}
    Wird nun der Laplacesche Entwicklungssatz auf den Ausdruck in
    \autoref{eq:perm-laplace} angewendet, so ergibt sich die
    Behauptung.

    Weiterhin zeigte \Brualdi{}, dass gilt,
    $\perm(A\otimes B)= \perm(B\otimes A)$~\cite{zbMATH03229568}. Gelte nun die Bedingung
    aus \autoref{eq:permungl}, dann ergibt sich folgende Ungleichung:
    \begin{align*}
      \perm(H_{2^{m+n}}) &= \perm((H_{2^{m}}\otimes
      I_{2^{n}})(I_{2^{m}}\otimes H_{2^{n}}))\\
      &\geq\perm(H_{2^{m}}\otimes I_{2^{n}})\perm(I_{2^{m}}\otimes
      H_{2^{n}})\\
      &= (\perm(H_{2^{m}}))^{2^{n}}(\perm(H_{2^{n}}))^{2^{m}}
    \end{align*}
    Da bekannt ist, dass $\perm(H_{4})=8$ ergibt sich die Behauptung.
  \end{proof}
\end{satz}

\section{Konstruktion nach \Scarpis}
\label{sec:scarpis}

Fünf Jahre nach der Veröffentlichung von \Hadamard{} gab \Scarpis{}
ein neues Konstruktionsverfahren
an~\cite{zbMATH02667666}.\footnote{Die Veröffentlichung von \Scarpis{}
  lag für diese Arbeit nicht vor. \Orrick{} stellt \Scarpis{}' Inhalte
  auf einer Webseite vor~\cite{orrick-wp}. Diese wurde als Grundlage
  verwendet.} Ähnlich wie \Sylvester{} ging er von einer bestehenden
\HM{} aus und konstruierte durch geschickte Kombination der Zeilen
eine neue \HM{}.

\begin{satz}
  Sei $p$ eine Primzahl und $n=p+1$. Falls $H_{n}$ eine $n\times n$
  \HM{} ist, so lässt sich eine \HM{} vom Grad $np$ konstruieren.
  \begin{proof}
    Der Beweis erfolgt konstruktiv. Aus der \HM{} $H_{n}$ werden $p$
    Matrizen erzeugt, die schließlich zu der neuen \HM{}
    zusammengesetzt werden.

    \OE{} werde angenommen, dass die \HM~$H_{n}$ normalisiert
    vorliegt, d.\,h. die erste Zeile und Spalte besteht aus
    $1$-Einträgen. Weiterhin bestehe die zweite Zeile von $H_{n}$ aus
    alternierenden Einträgen von $+1$ und $-1$. Gegebenenfalls muss
    die \HM{} durch entsprechende Umformungen in die Form überführt
    werden. Damit hat $H_{n}$ eine Form wie in \autoref{eq:scapis-hm}.

    \begin{align}
      \label{eq:scapis-hm}
      H_{n} &=
      \begin{pmatrix}
        1 & 1 & 1 & \dots & 1\\
        1 & -1 & 1 &\dots & -1\\
        1 & h_{32}& h_{33} & \dots & h_{3n}\\
        \vdots & \vdots& \vdots& \ddots& \vdots\\
        1 & h_{n2} & h_{n3}& \dots& h_{nn}
      \end{pmatrix}
    \end{align}

    Es bezeichne $C=(c_{ij})_{0\leq i,j\leq p-1}$ den Kern der
    \HM~$H_{n}$, der durch das Entfernen der ersten Zeile und Spalte
    entsteht. Die $i$-te Zeile der $(n-1)\times(n-1)=p\times p$ Matrix $C$ werde
    mit $c_{i}$ bezeichnet (\autoref{eq:scarpis-c}). Weiterhin sei
    $H_{2.}$ die $(n-1)\times n=p\times n$\todo{Kann man hier mit dem
      $=$ arbeiten?} Matrix, die durch das Entfernen der zweiten Zeile mit
    den alternierenden $\pm1$-Einträgen von $H_{n}$ entsteht
    (\autoref{eq:scarpis-h2}). Schließlich sei $1_{p}$ der $p\times1$
    Vektor, der aus $1$-Einträgen besteht.

    \begin{align}
      \label{eq:scarpis-c}
      C &=
      \begin{pmatrix}
        -1 & 1 &\dots & -1\\
        h_{32}& h_{33} & \dots & h_{3n}\\
        \vdots& \vdots& \ddots& \vdots\\
        h_{n2} & h_{n3}& \dots& h_{nn}
      \end{pmatrix}=
      \begin{pmatrix}
        c_{0}\\
        c_{1}\\
        \vdots\\
        c_{n-1}
      \end{pmatrix}
    \end{align}
    \begin{align}
      \label{eq:scarpis-h2}
      H_{2.} &=
      \begin{pmatrix}
        1 & 1 & 1 & \dots & 1\\
        1 & h_{32}& h_{33} & \dots & h_{3n}\\
        \vdots & \vdots& \vdots& \ddots& \vdots\\
        1 & h_{n2} & h_{n3}& \dots& h_{nn}
      \end{pmatrix}
    \end{align}

    Für die \HM{} sind die Hilfsmatrizen $M$ und $M_{r}$ für $0\leq r\leq
    p-1$ wichtig. Aus diesen wird die \HM{} konstruiert.

    Die Matrix~$M$ entsteht durch das Kronecker-Produkt von $H_{2.}$
    mit $1_{p}$. Die Matrix~$M$ hat damit $p$ Zeilen und $np$ Spalten.
    \begin{align*}
      M &= H_{2.}\otimes 1_{p}^{T}=
      \begin{pmatrix}
        1      & 1      & 1      & \dots  & 1\\
        1      & h_{32} & h_{33} & \dots  & h_{3n}\\
        \vdots & \vdots & \vdots & \ddots & \vdots\\
        1      & h_{n2} & h_{n3} & \dots  & h_{nn}
      \end{pmatrix}
      \otimes
      \begin{pmatrix}
        1 & 1 & \dots & 1
      \end{pmatrix}\\
      &=
      \begin{pmatrix}
        1      &\dots &1      &1      &\dots &1      &1      &\dots &1      & \dots  & 1       &\dots &1\\      
        1      &\dots &1      &h_{32} &\dots &h_{32} &h_{33} &\dots &h_{33} & \dots  & h_{3n}  &\dots &h_{3n} \\
        \vdots &\ddots &\vdots &\vdots &\ddots &\vdots &\vdots &\ddots &\vdots & \dots & \vdots  &\ddots &\vdots \\
        1      &\dots &1      &h_{n2} &\dots &h_{n2} &h_{n3} &\dots &h_{n3} & \dots  & h_{nn}  &\dots &h_{nn}
      \end{pmatrix}
    \end{align*}
    Die Matrizen $M_{r}= (m_{ij}^{(r)})$ für $0\leq i,r\leq p-1$ und
    $0\leq j\leq n-1$ entstehen durch das Einsetzen der Zeilen $c_{i}$
    aus der Matrix~$C$ nach der untenstehenden Regel. Dabei werden die
    Indizes immer modulo $p$ gerechnet. Die $M_{r}$ sind
    somit $p\times np$ Matrizen.
    \begin{gather}\label{eq:scarpis-mij}
      m_{ij}^{(r)}=
      \begin{cases}
        c_{r} & j = 0\\
        (-1)^{j} c_{i+(j-1)r} & \text{sonst}
      \end{cases}
    \end{gather}
    Damit hat $M_{r}$ folgende Form:
    \begin{align*}
      M_{r} &=
      \begin{pmatrix}
        m_{0,0}^{(r)} & m_{0,1}^{(r)} & m_{0,2}^{(r)} & m_{0,3}^{(r)} &
        \dots & m_{0,(n-2)}^{(r)} & m_{0,(n-1)}^{(r)}\\
        m_{1,0}^{(r)} & m_{1,1}^{(r)} & m_{1,2}^{(r)} & m_{1,3}^{(r)} &
        \dots & m_{1,(n-2)}^{(r)} & m_{1,(n-1)}^{(r)}\\
        \vdots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots\\
        m_{(p-1),0}^{(r)} & m_{(p-1),1}^{(r)} & m_{(p-1),2}^{(r)} & m_{(p-1),3}^{(r)} &
        \dots & m_{(p-1),(n-2)}^{(r)} & m_{(p-1),(n-1)}^{(r)}\\
      \end{pmatrix}\\
      &=
      \begin{pmatrix}
        c_{r} & -c_{0} & c_{r} & -c_{2r} & \dots & c_{(p-2)r} & -c_{(p-1)r}\\
        c_{r} & -c_{1} & c_{r+1} & -c_{2r+1} & \dots & c_{(p-2)r+1} & -c_{(p-1)r+1}\\
        \vdots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots\\
        c_{r} & -c_{p-1} & c_{r+p-1} & -c_{2r+p-1} & \dots &
        c_{(p-2)r+p-1} & -c_{(p-1)r+p-1}
      \end{pmatrix}
    \end{align*}
    Wie bereits oben erwähnt, müssen die Indizes 
    $\mod{p}$ aufgefasst werden. Die Matrizen~$M$ und $M_{r}$
    werden nun zu einer neuen Matrix~$H_{np}$ zusammengesetzt. Diese
    neu konstruierte Matrix ist eine \HM{}:
    \begin{gather*}
      H_{np}=
      \begin{pmatrix}
        M\\
        M_{0}\\
        M_{1}\\
        \vdots\\
        M_{p-1}
      \end{pmatrix}
    \end{gather*}

    Schließlich ist zu prüfen, ob die oben konstruierte
    Matrix~$H_{np}$ eine \HM{} ist. Hierzu ist die Orthogonalität
    nachzuweisen.
    \begin{enumerate}[1.\,F{a}ll]
    \item Orthogonalität der Zeilen von $M$: Die Matrix~$M$ entstand
      aus der Matrix~$H_{2.}$, die wiederum aus der \HM~$H_{n}$ gebildet
      wurde. Weder das Weglassen der zweiten Zeile noch das
      Kronecker-Produkt mit dem $1$"=Vektor ändern die
      Orthogonalität. Daher sind die Zeilen von $M$ weiterhin
      orthogonal.
    \item Orthogonalität der Zeilen von $M_{r}$: Die Matrix~$M_{r}$
      wird aus den Zeilen von $C$, dem Kern der \HM~$H_{n}$
      gebildet. Aufgrund der Konstruktion ist der Eintrag~$c_{r}$
      zweimal enthalten. Die anderen Einträge sind verschieden. Es ist
      $c_{r}\cdot c_{r}^{T}= p$. Weiterhin gilt $c_{r}\cdot
      c_{s}^{T}=-1$ für $r\neq s$ und $0\leq r\leq p-1$. Denn
      $c_{r}\cdot c_{s}^{T}= h_{r}\cdot h_{s}-1=-1$ für die
      Zeilen~$h_{r}$ und $h_{s}$ aus der \HM~$H_{n}$. Das Produkt
      zweier Zeilen von $M_{r}$ ergibt somit $p$-mal $-1$ und einmal
      $p$. Die Summe ist also $0$ und damit sind zwei Zeilen orthogonal.
    \item Orthogonalität der Zeilen von $M$ zu den Zeilen von $M_{r}$: \todo{Ergänzen}
    \item Orthogonalität der Zeilen einer Matrix~$M_{r}$ zu denen einer
      Matrix~$M_{s}$ für $r\neq s$ und $0\leq r,s\leq p-1$: Für den
      Nachweis ist das Skalarprodukt je einer Zeile von $M_{r}$ und
      $M_{s}$ für $r\neq s$ zu bilden. Beide Zeilen wurden nach der
      \autoref{eq:scarpis-mij} aus den Zeilen des Kerns~$C$ gebildet.

      Seien $m_{k}^{(r)}$ und $m_{l}^{(s)}$ Zeilen aus den Matrizen
      $M_{r}$ und $M_{s}$ für $r\neq s$ und $0\leq k,l\leq p-1$. Das
      Skalarprodukt kann als Produkt von Zeilenvektoren von $C$
      dargestellt werden. Dabei verschwindet das alternierende $\pm1$,
      da der Exponent durch die untenstehende Multiplikation immer
      gerade ist.
      \begin{gather}\label{eq:ms-ms-mult}
        m_{k}^{(r)}\cdot m_{l}^{(s)}= c_{r}\cdot c_{s}+
        \sum_{i=0}^{p-1} c_{(k+ir)\mod{p}}\cdot c_{(l+is)\mod{p}}
      \end{gather}
      Die Summe enthält einen Index, für den gilt, $(k+ir)\mod{p}=
      (l+is)\mod{p}$, d.\,h. das Produkt dieser Zeilenvektoren ergibt
      $p$. Das Skalarprodukt der anderen Werte ergibt $-1$ und
      insgesamt ist damit das Ergebnis von \autoref{eq:ms-ms-mult}
      gleich $0$. Also sind die Zeilen zweier Matrizen $M_{r}$ und
      $M_{s}$ für $r\neq s$ zueinander orthogonal.
    \end{enumerate}
    Damit ist gezeigt, dass alle Zeilen von $H_{np}$ zueinander
    orthogonal sind, mithin ist $H_{np}$ eine \HM{}.
  \end{proof}
\end{satz}

Die Konstruktion nach \Scarpis{} soll im folgenden an einem Beispiel
erklärt werden. Zur einfacheren Darstellung erfolgte eine Ersetzung
von $1$ durch $+$ und von $-1$ durch $-$.
\begin{bsp}
  Aus einer $4\times4$ \HM{} wird eine $12\times12$ \HM{}
  konstruiert. Untenstehend sind die \HM~$H_{n}$, der Kern~$C$ dieser
  Matrix sowie die Matrix~$H_{2.}$ aufgeführt.
  \begin{align*}
    H &=
    \begin{pmatrix}
      + & + & + & +\\
      + & - & + & -\\
      + & + & - & -\\
      + & - & - & +
    \end{pmatrix} &
    C &=
    \begin{pmatrix}
      - & + & -\\
      + & - & -\\
      - & - & +
    \end{pmatrix} &
    H_{2.} &=
    \begin{pmatrix}
      + & + & + & +\\
      + & + & - & -\\
      + & - & - & +
    \end{pmatrix}
  \end{align*}
  Die Zeilenvektoren für die Berechnung der Matrizen~$M_r$ sind damit $c_{0}=
  \begin{pmatrix}
    - & + & -
  \end{pmatrix}$, $c_{1}=
  \begin{pmatrix}
    + & - & -
  \end{pmatrix}$ sowie $c_{2}=
  \begin{pmatrix}
    - & - & +
  \end{pmatrix}$ und die Matrizen~$M$ sowie $M_{r}$ errechnen sich wie
  folgt:
  \begin{align*}
    M &= H_{2.}\otimes 1_{p}^{T}=
    \begin{pmatrix}
      + & + & + & + & + & + & + & + & + & + & + & +\\
      + & + & + & + & + & + & - & - & - & - & - & -\\
      + & + & + & - & - & - & - & - & - & + & + & +
    \end{pmatrix}
  \end{align*}
  \begin{align*}
    M_{0} &=
    \begin{pmatrix}
      c_{0} & -c_{0} & c_{0} & -c_{0}\\
      c_{0} & -c_{1} & c_{1} & -c_{1}\\
      c_{0} & -c_{2} & c_{2} & -c_{2}
    \end{pmatrix}=
    \begin{pmatrix}
      - & + & - & + & - & + & - & + & - & + & - & +\\
      - & + & - & - & + & + & + & - & - & - & + & +\\
      - & + & - & + & + & - & - & - & + & + & + & -
    \end{pmatrix}\\
    M_{1} &=
    \begin{pmatrix}
      c_{1} & -c_{0} & c_{1} & -c_{2}\\
      c_{1} & -c_{1} & c_{2} & -c_{0}\\
      c_{1} & -c_{2} & c_{0} & -c_{1}
    \end{pmatrix}=
    \begin{pmatrix}
      + & - & - & + & - & + & + & - & - & + & + & -\\
      + & - & - & - & + & + & - & - & + & - & + & +\\
      + & - & - & + & + & - & - & + & + & + & + & -
    \end{pmatrix}\\
    M_{2} &=
    \begin{pmatrix}
      c_{2} & -c_{0} & c_{2} & -c_{1}\\
      c_{2} & -c_{1} & c_{0} & -c_{2}\\
      c_{2} & -c_{2} & c_{1} & -c_{0}
    \end{pmatrix}=
    \begin{pmatrix}
      - & - & + & + & - & + & - & - & + & - & + & +\\
      - & - & + & - & + & + & - & + & - & + & + & -\\
      - & - & + & + & + & - & + & - & - & + & - & +
    \end{pmatrix}
  \end{align*}
  Schließlich ergibt sich die $12\times12$ \HM{} durch das
  Zusammensetzen der vier oben konstruierten Matrizen:
  \begin{gather*}
    \begin{pmatrix}
      M\\
      M_{0}\\
      M_{1}\\
      M_{2}
    \end{pmatrix}=
    \begin{pmatrix}
      + & + & + & + & + & + & + & + & + & + & + & +\\
      + & + & + & + & + & + & - & - & - & - & - & -\\
      + & + & + & - & - & - & - & - & - & + & + & +\\
      - & + & - & + & - & + & - & + & - & + & - & +\\
      - & + & - & - & + & + & + & - & - & - & + & +\\
      - & + & - & + & + & - & - & - & + & + & + & -\\
      + & - & - & + & - & + & + & - & - & + & + & -\\
      + & - & - & - & + & + & - & - & + & - & + & +\\
      + & - & - & + & + & - & - & + & + & + & + & -\\
      - & - & + & + & - & + & - & - & + & - & + & +\\
      - & - & + & - & + & + & - & + & - & + & + & -\\
      - & - & + & + & + & - & + & - & - & + & - & +
    \end{pmatrix}
  \end{gather*}
\end{bsp}


\section{Konstruktionen nach \Paley}
\label{sec:konst-payley}

Bevor die Konstruktionen nach \Paley{} eingeführt werden können, ist
etwas Vorarbeit nötig. Die Begriffe des quadratischen Rests und
Legendre-Symbol wurden in \autoref{sec:quadr-resid} eingeführt. Mit
Hilfe dessen kann die Jacobsthal"=Matrix definiert werden.
\begin{defini}[Jacobsthal-Matrix]\label{def:jacobsthal-matrix}
  Sei $n\in\N$ eine ungerade Primzahlpotenz und $\F_{n}$ ein endlicher
  Körper mit den Elementen $g_{0}=0, g_{1}, \dots,
  g_{n-1}\in\F_{n}$. Eine \highl{Jacobsthal-Matrix} ist eine $n\times
  n$ Matrix~$Q=(q_{ij})_{0\leq i,j\leq n-1}$. Die Einträge von $Q$
  entstehen durch
  \begin{gather}\label{eq:jacobsthal}
    q_{ij} = \legendre{g_{i}-g_{j}}{n}\qquad0\leq i,j\leq n-1
  \end{gather}
\end{defini}

Im folgenden werden einige wichtige Eigenschaften der
Jacobsthal"=Matrix betrachtet.

Eine $n\times n$ Jacobsthal"=Matrix~$Q$ ist für den Fall
$n\equiv1\mod{4}$ symmetrisch und für $n\equiv3\mod{4}$ ist sie
schiefsymmetrisch. Hierzu wird das Matrixelement $q_{ji}$ aus
\autoref{eq:jacobsthal} betrachtet:
\begin{gather*}
  q_{ji}= \legendre{g_{j}-g_{i}}{n}=
  \legendre{-1}{n}\legendre{g_{i}-g_{j}}{n}= \legendre{-1}{n} q_{ij}
\end{gather*}
Wenn $g\in\F_{n}$ eine Primitivwurzel von $\F_{n}$ ist, so gilt
$g^{n-1}=1$ und $g^{\frac{n-1}{2}}=-1$. Somit ist $-1$ im Fall von
$n\equiv1\mod{4}$ ein quadratischer Rest und für $n\equiv3\mod{4}$ ein
quadratischer Nichtrest modulo~$4$. Insgesamt ergibt sich dann für den
ersten Fall $q_{ji}= \legendre{-1}{n}q_{ij}= q_{ij}$ (Symmetrie der
Jacobsthal"=Matrix) und $q_{ij}= \legendre{-1}{n} q_{ij}= -q_{ij}$
(Schiefsymmetrie der Jacobsthal"=Matrix) für den zweiten Fall.

Sei $Q$ eine $n\times n$ Jacobsthal"=Matrix und $1_{n\times n}$ eine
$n\times n$ Matrix für eine ungerade Primzahlpotenz $n\in\N$, die aus
$1$-Einträgen besteht. Dann gilt, $Q1_{n\times n}= 1_{n\times
  n}Q=0$. Nach der \autoref{eq:jacobsthal} besteht jede Zeile oder
Spalte aus einem $0$-Eintrag und gleich vielen $\pm1$-Einträgen. Die
Summe jeder Zeile und Spalte ist damit $0$.

Für die weiteren Ausführungen ist interessant, welche Struktur das
Produkt einer Jacobsthal"=Matrix~$Q$ mit ihrer transponierten Matrix
hat. Hierfür sei $Q$ und $1_{n\times n}$ wie oben definiert. Daneben
sei $I_{n}$ die $n\times n$ Einheitsmatrix. Dann ist
\begin{gather*}
  QQ^{T} = nI_{n}-1_{n\times n}
\end{gather*}
Dazu sei $QQ^{T}=(r_{ij})_{0\leq i,j\leq n-1}$. Die einzelnen $r_{ij}$
werden wie folgt aus $Q=(q_{ij})_{0\leq i,j\leq n-1}$ gebildet:
\begin{align*}
  r_{ij} &= \sum_{\substack{k=0\\k\neq i,j}}^{n-1} q_{ik}q_{jk}= \sum_{\substack{k=0\\k\neq i,j}}^{n-1}
  \legendre{g_{i}-g_{k}}{n} \legendre{g_{j}-g_{k}}{n}\\
  &= \sum_{\substack{k=0\\k\neq i,j}}^{n-1}
  \legendre{g_{i}-g_{k}}{n} \legendre{g_{j}-g_{i}+g_{i}-g_{k}}{n}= \sum_{\substack{k=0\\k\neq i,j}}^{n-1}
  \legendre{g_{i}-g_{k}}{n}^{2} \legendre{(g_{i}-g_{k})^{-1}
    (g_{j}-g_{i})+1}{n}\\
  &= \sum_{\substack{k=0\\k\neq i,j}}^{n-1} \legendre{(g_{i}-g_{k})^{-1} (g_{j}-g_{i})+1}{n}
\end{align*}
Für die Diagonalelemente, also $i=j$, reduziert sich die obige
Gleichung auf $\sum_{k=0}^{n-1}\legendre{1}{n}= n-1$. Für $i\neq j$
besteht die Menge $\Set{\legendre{(g_{i}-g_{k})^{-1} (g_{j}-g_{i})}{n}
| 0\leq k\leq n-1, k\neq i,j}$ aus allen Elementen von $\F_{n}$ außer
der $0$ und $-1$.

Damit lässt sich die obige Gleichung wie folgt umschreiben:
\begin{align*}
  r_{ij} &= \sum_{\substack{k=0\\k\neq i,j}}^{n-1}
  \legendre{(g_{i}-g_{k})^{-1} (g_{j}-g_{i})+1}{n}\\
  &= \sum_{\substack{g\in\F_{n}\\g\neq0,1}} \legendre{g}{n}=
  \sum_{g\in\F_{n}} \legendre{g}{n}-\legendre{0}{n}- \legendre{1}{n}= -1
\end{align*}
Insgesamt ergibt sich dann die Behauptung:
\begin{align*}
  QQ^{T} &=
  \begin{pmatrix}
    n-1 & -1 & -1 & \dots & -1\\
    -1 & n-1 & -1 & \dots & -1\\
    -1 & -1 & n-1 & \dots & -1\\
    \vdots & \vdots & \ddots & \vdots & \vdots\\
    -1 & -1 & -1 & \dots & n-1
  \end{pmatrix}=n I_{n}-1_{n\times n}
\end{align*}

\begin{bsp}\label{bsp:q5}
  Sei $n=5$. Dann sind die quadratischen Reste $1$ und $4$ und die
  Jacobsthal-Matrix~$Q$ ergibt sich:
  \begin{gather*}
    Q=
    \begin{pmatrix*}[r]
      0 & 1 & -1 & -1 & 1\\
      1 & 0 & -1 & -1 & -1\\
      -1 & 1 & 0 & 1 & -1\\
      -1 & -1 & 1 & 0 & 1\\
      1 & -1 & -1 & 1 &0
    \end{pmatrix*}
  \end{gather*}
\end{bsp}

\begin{bsp}\label{bsp:q7}
  Sei $n=7$. Die Zahlen $1$, $2$ und $4$ sind die quadratischen Reste
  und die Jacobsthal-Matrix~$Q$ ergibt sich:
  \begin{gather*}
    Q=
    \begin{pmatrix*}[r]
      0 & -1 & -1 & 1 & -1 & 1 & 1\\
      1 & 0 & -1 & -1 & 1 & -1 & 1\\
      1 & 1 & 0 & -1 & -1 & 1 & -1\\
      -1 & 1 & 1 & 0 & -1 & -1 & 1\\
      1 & -1 & 1 & 1 & 0 & -1 & -1\\
      -1 & 1 & -1 & 1 & 1 & 0 & -1\\
      -1 & -1 & 1 & -1 & 1 & 1 & 0
    \end{pmatrix*}
  \end{gather*}
\end{bsp}

\subsection{\Paley{} I}

\begin{satz}[Konstruktionsverfahren nach \Paley{} I]
  Sei $n\in\N$ eine Primzahlpotenz und $n+1\equiv0\mod{4}$ und die
  Jacobsthal"=Matrix~$Q$ berechne sich wie in
  \autoref{def:jacobsthal-matrix} angegeben und es sei $1_{n}$ ein
  Spaltenvektor aus Eins"=Einträgen. Dann ist
  \begin{gather}
    \label{eq:hm-paley-i}
    H_{n+1} =
    \begin{pmatrix}
      1 & -1_{n}^{T}\\
      1_{n} & Q+I_{n}
    \end{pmatrix}
  \end{gather}
  eine \HM{} vom Grad~$n+1$.
  \begin{proof}
    Zum Nachweis werden die Eigenschaften aus dem
    \autoref{sec:konst-payley} benutzt:
    \begin{align*}
      H_{n+1}H_{n+1}^{T} &=
    \begin{pmatrix}
      1 & -1_{n}^{T}\\
      1_{n} & Q+I_{n}
    \end{pmatrix}
    \begin{pmatrix}
      1 & 1_{n}^{T}\\
      -1_{n} & Q^{T}+I_{n}
    \end{pmatrix}=
    \begin{pmatrix}
      n+1 & 0\\
      0 & (n+1)I_{n}
    \end{pmatrix}
    =(n+1)I_{n+1}
    \end{align*}
  \end{proof}
\end{satz}

\begin{bsp}
  In \autoref{bsp:q7} wurde eine $7\times7$ Jacobsthal"=Matrix
  konstruiert. Daraus ergibt sich die folgende \HM{}:
  \begin{gather*}
    H_{8}=
    \begin{pmatrix*}[r]
      1 & -1 & -1 & -1 & -1 & -1 & -1 & -1\\
      1 &  1 & -1 & -1 & 1 & -1 & 1 & 1\\
      1 & 1 & 1 & -1 & -1 & 1 & -1 & 1\\
      1 & 1 & 1 & 1 & -1 & -1 & 1 & -1\\
      1 & -1 & 1 & 1 & 1 & -1 & -1 & 1\\
      1 & 1 & -1 & 1 & 1 & 1 & -1 & -1\\
      1 & -1 & 1 & -1 & 1 & 1 & 1 & -1\\
      1 & -1 & -1 & 1 & -1 & 1 & 1 & 1
    \end{pmatrix*}
  \end{gather*}
\end{bsp}

\subsection{\Paley{} II}

Zur Vorbereitung des zweiten Konstruktionsverfahrens nach \Paley{}
muss eine weitere Matrix definiert werden:
\begin{defini}\label{def:paley-ii-matrixs}
  Sei $n\in\N$ mit $n\equiv1\mod{4}$ und $Q=(q_{ij})_{0\leq i,j\leq
    n-1}$ eine $n\times n$ Jacobsthal"=Matrix wie in
  \autoref{def:jacobsthal-matrix} definiert. Weiterhin sei $1_{n}$ ein
  $n\times1$ Spaltenvektor, der aus Eins"=Einträgen besteht. Dann
  ergibt sich die
  $(n+1)\times(n+1)$ Matrix~$S$ wie folgt:
  \begin{gather*}
    S=
    \begin{pmatrix}
      0 & 1_{n}^{T}\\
      1_{n} & Q
    \end{pmatrix}
  \end{gather*}
\end{defini}

Die Matrix~$S$ ist symmetrisch. Denn wie bereits nachgewiesen, ist $Q$
symmetrisch und die Änderungen in \autoref{def:paley-ii-matrixs}
erhalten die Symmetrie"=Eigenschaft. Weiterhin ergibt sich aufgrund
der Ausführungen, dass $S^{2}= n I_{n+1}$ ist. Mit diesem Wissen kann
das Konstruktionsverfahren eingeführt werden.

\begin{satz}[Konstruktionsverfahren nach \Paley{} II]
  Sei $n\in\N$ eine Primzahlpotenz mit $n\equiv1 \pmod{4}$. Die
  Matrix~$S$ sei eine $(n+1)\times(n+1)$ Matrix, wie in
  \autoref{def:paley-ii-matrixs} definiert. Dann ist
  die Matrix
  \begin{gather*}
    H_{2(n+1)}=
    \begin{pmatrix}
      S+I_{n+1} & S-I_{n+1}\\
      S-I_{n+1} & -S-I_{n+1}
    \end{pmatrix}
  \end{gather*}
  eine \HM vom Grad $2(n+1)$. Dabei $I_{n}$ die Einheitsmatrix.
  \begin{proof}
    Sei $H_{2(n+1)}$ und $S$ wie oben definiert. Dann ergibt sich
    folgende Rechnung:
    \begin{align*}
      H_{2(n+1)}H_{2(n+1)}^{T} &=
    \begin{pmatrix}
      S+I_{n+1} & S-I_{n+1}\\
      S-I_{n+1} & -S-I_{n+1}
    \end{pmatrix}
    \begin{pmatrix}
      S+I_{n+1} & S-I_{n+1}\\
      S-I_{n+1} & -S-I_{n+1}
    \end{pmatrix}\\
    &=
    \begin{pmatrix}
      2(n+1)I_{n+1} & 0\\
      0 & 2(n+1)I_{n+1}
    \end{pmatrix}
    = 2(n+1)I_{2(n+1)}
    \end{align*}
  \end{proof}
  Für den Nachweis wird die Symmetrie von $S$ sowie die oben
  nachgewiesene Eigenschaft $S^{2}=nI_{n+1}$ benötigt.
\end{satz}

\begin{bsp}
  In \autoref{bsp:q5} wurde eine $5\times5$ Jacobsthal"=Matrix
  konstruiert. Die Matrix~$S$ hat folgende Gestalt:
  \begin{gather*}
    S=
    \begin{pmatrix*}[r]
      0 & 1 & 1 & 1 & 1 & 1\\
      1 & 0 & 1 & -1 & -1 & 1\\
      1 & 1 & 0 & -1 & -1 & -1\\
      1 & -1 & 1 & 0 & 1 & -1\\
      1 & -1 & -1 & 1 & 0 & 1\\
      1 & 1 & -1 & -1 & 1 &0
    \end{pmatrix*}
  \end{gather*}
  Damit ergibt sich die $12\times12$ \HM~$H_{12}$:\todo{prüfen}
  \begin{gather*}
    H_{12}=
    \begin{pmatrix*}[r]
      1 & 1  & 1  &  1 &  1 &  1 & -1 &  1 & 1  &  1 & 1  & 1\\
      1 & 1  & 1  & -1 & -1 &  1 &  1 & -1 & 1  & -1 & -1 & 1\\
      1 & 1  & 1  & -1 & -1 & -1 &  1 &  1 & -1 & -1 & -1 & -1\\
      1 & -1 & 1  &  1 &  1 & -1 &  1 & -1 &  1 & -1 & 1  & -1\\
      1 & -1 & -1 &  1 &  1 &  1 &  1 & -1 & -1 &  1 & -1 & 1\\
      1 & 1  & -1 & -1 &  1 &  1 &  1 &  1 & -1 & -1 &  1 & -1\\
      -1&  1 & 1  &  1 &  1 &  1 & -1 & -1 & -1 & -1 & -1 & -1\\
      1 & -1 & 1  & -1 & -1 &  1 &  1 & -1 &  1 & -1 & -1 & 1\\
      1 &  1 & -1 & -1 & -1 & -1 & -1 & -1 & -1 &  1 &  1 &  1\\
      1 & -1 &  1 & -1 &  1 & -1 & -1 &  1 & -1 & -1 & -1 & 1\\
      1 & -1 & -1 &  1 & -1 &  1 & -1 &  1 &  1 & -1 & -1 &  -1\\
      1 &  1 & -1 & -1 &  1 & -1 & -1 &  -1 & 1 & 1 &  -1 & -1
    \end{pmatrix*}
  \end{gather*}
\end{bsp}



Die \HMen{}, die durch die obigen Konstruktionsverfahren von \Paley{}
erzeugt wurden, sind üblicherweise nicht äquivalent. Die Äquivalenz
gilt genau dann, wenn $p=11$ im ersten Konstruktionsverfahren nach
\Paley{} und $q=5$ im zweiten Konstruktionsverfahren nach
\Paley{}~\cite[Corollary~4.1]{zbMATH05280728}.

\section{Konstruktion nach \Williamson}
\label{sec:konstr-nach-williamson}

\Williamson{} legte in seiner Arbeit
\citetitle{zbMATH03095564}~\cite{zbMATH03095564} den Grundstein für
eine weitere Klasse von Konstruktionsverfahren. Er definierte vier
Matrizen, die er zu einer \HM{} kombinierte. Diese Matrizen werden in
einer bestimmten Weise \enquote{zusammengesteckt}. In der
englischsprachigen Literatur werden die Verfahren, die auf diesem
Prinzip basieren, als \enquote{Plug-In-Verfahren} bezeichnet.
\begin{satz}
  Seien $A$, $B$, $C$ und $D$ Matrizen vom Grad~$k$ mit Einträgen
  aus $\{\pm1\}$ mit der Eigenschaft $XY^{T}= YX^{T}$ für
  $X,Y\in\{A,B,C,D\}$ und $X\neq Y$ sowie
  $AA^{T}+BB^{T}+CC^{T}+DD^{T}= 4kI_{k}$. Dann ergibt sich mit
  \begin{gather}\label{eq:williamson}
    H_{4k}=
    \begin{pmatrix*}[r]
      A & B & C & D\\
      -B & A & -D & C\\
      -C & D & A & -B\\
      -D & -C & B & A
    \end{pmatrix*}
  \end{gather}
  eine \HM{} vom Grad~$4k$.
  \begin{proof}
    Für den Beweis muss folgende Rechnung durchgeführt werden:
    \begin{align*}
      H_{4k}H_{4k}^{T} &=
    \begin{pmatrix*}[r]
      A & B & C & D\\
      -B & A & -D & C\\
      -C & D & A & -B\\
      -D & -C & B & A
    \end{pmatrix*}
    \begin{pmatrix*}[r]
      A^{T} & B^{T} & C^{T} & D^{T}\\
      B^{T} & A^{T} & D^{T} & -C^{T}\\
      C^{T} & -D^{T} & A^{T} & B^{T}\\
      D^{T} & C^{T} & -B^{T} & A^{T}
    \end{pmatrix*}\\
    &=
    \begin{pmatrix}
      4kI_{k} & 0 & 0 & 0\\
      0 & 4kI_{k} & 0 & 0\\
      0 & 0 & 4kI_{k} & 0\\
      0 & 0 & 0 & 4kI_{k}
    \end{pmatrix}
    =4kI_{4k}
    \end{align*}
    Die Einträge auf der Hauptdiagonale haben alle die Form
    $AA^{T}+BB^{T}+CC^{T}+DD^{T}$, wobei die Reihenfolge der Addition
    je nach Diagonaleintrag unterschiedlich ist. Nach Voraussetzung
    ist das Ergebnis für jeden Diagonaleintrag $4kI_{k}$. Die Einträge
    außerhalb der Hauptdiagonalen sind \OE{} jeweils von der Form
    $(-1)VW^{T}+WV^{T}+(-1)XY^{T}+YX^{T}$ für $V,W,X,Y\in\{A,B,C,D\}$
    und $V\neq W\neq X\neq Y$. Da aber
    $VW^{T}=WV^{T}$ bzw. $YX^{T}=XY^{T}$ gilt, ist der Gesamtausdruck
    jeweils $0$.
  \end{proof}
\end{satz}

\begin{bsp}
  Zur Konstruktion einer \HM{} nach \Williamson{} sollen fünf
  symmetrische zirkulante Matrizen (siehe \autoref{sec:circulant})
  betrachtet werden.
  \begin{align*}
    A &=
    \begin{pmatrix*}[r]
      1 & -1 & -1 & -1 & -1\\
      -1 & 1 & -1 & -1 & -1\\
      -1 & -1 & 1 & -1 & -1\\
      -1 & -1 & -1 & 1 & -1\\
      -1 & -1 & -1 & -1 & 1
    \end{pmatrix*}
    & A &= B\\
    C &=
    \begin{pmatrix*}[r]
      1 & 1 & -1 & -1 & 1\\
      1 & 1 & 1 & -1 & -1\\
      -1 & 1 & 1 & 1 & -1\\
      -1 & -1 & 1 & 1 & 1\\
      1 & -1 & -1 & 1 & 1
    \end{pmatrix*}
    & D &=
    \begin{pmatrix*}[r]
      1 & -1 & 1 & 1 & -1\\
      -1 & 1 & -1 & 1 & 1\\
      1 & -1 & 1 & -1 & 1\\
      1 & 1 & -1 & 1 & -1\\
      -1 & 1 & 1 & -1 & 1
    \end{pmatrix*}
  \end{align*}
  Die obigen Matrizen werden wie in \autoref{eq:williamson}
  angeordnet. Das Ergebnis wurde bereits in \autoref{fig:had20}
  vorgestellt. Die \autoref{fig:will20} zeigt die $20\times20$
  \HM{}, die aus der Konstruktion entsteht.
  \begin{figure}[htb]
    \centering
    \pgfplotstableread{beispiele/had20.williamson}{\hzwanzigwill}
    \drawgrid{\hzwanzigwill}
    \caption{\HM{} nach \Williamson{} vom Grad 20}
    \label{fig:will20}
  \end{figure}
\end{bsp}

Der Ansatz von \Williamson{} kann auch mit acht Matrizen verfolgt
werden. Dazu sei $n\in\N$ und $A_{i}$ seien befreundete $n\times n$
Matrizen (siehe \autoref{def:befr-matrix}) für $i=1,\dots,8$ mit
Einträgen aus $\{\pm1\}$. Die $A_{i}$ erfüllen die Bedingungen,
$\sum_{i=1}^{8} A_{i}A_{i}^{T}= 8nI_{n}$ und $A_{i}A_{j}^{T}=
A_{j}A_{i}^{T}$ für $i,j=1,\dots,8$. Dann ergibt sich mit folgender
Konstruktion eine \HM{}:
\begin{gather*}
  H_{8n}=
  \begin{pmatrix*}[r]
    A_{1} & A_{2} & A_{3} & A_{4} & A_{5} & A_{6} & A_{7} & A_{8}\\
    -A_{2}& A_{1} & A_{4} & -A_{3}& A_{6} & -A_{5}& -A_{8}& A_{7}\\
    -A_{3}& -A_{4}& A_{1} & A_{2} & A_{7} & A_{8} & -A_{5}& -A_{6}\\
    -A_{4}& A_{3} & -A_{2}& A_{1} & A_{8} & -A_{7}& A_{6} & -A_{5}\\
    -A_{5}& -A_{6}& -A_{7}& -A_{8}& A_{1} & A_{2} & A_{3} & A_{4}\\
    -A_{6}& A_{5} & -A_{8}& A_{7} & -A_{2}& A_{1} & -A_{4}& A_{3}\\
    -A_{7}& A_{8} & A_{5} & -A_{6}& -A_{3}& A_{4} & A_{1} & -A_{2}\\
    -A_{8}& -A_{7}& A_{6} & A_{5} & -A_{4}& -A_{3}& A_{2} & A_{1}
  \end{pmatrix*}
\end{gather*}
\todo[inline]{Ansatz mit $A_{i}$ sollte Schreibarbeit sparen. Wäre es
  besser dennoch $A$, $B$, \dots{} zu verwenden?}
Die Matrizen $A_{i}$ werden in der Literatur manchmal als
8"=Williamson"=Matrizen bezeichnet.

\section{Konstruktion nach Goethals-Seidel}

Die Arbeit von \Williamson{} erwies sich als sehr reichhaltig. Es
existieren einige Konstruktionsverfahren, die diese Methoden nutzen
oder sogar ausbauen. \Goethals{} und \Seidel{} konnten zeigen, dass
die ursprünglich von \Williamson{} gewählten Bedingungen zu restriktiv
sind und verallgemeinerten seine Ergebnisse~\cite{zbMATH03249824}.


\begin{defini}[Konstruktionsverfahren nach \Goethals-\Seidel{}]
  Seien $n\in\N$ sowie $A$, $B$, $C$ und $D$ zirkulante $n\times n$
  Matrizen mit der Eigenschaft $AA^{T}+BB^{T}+CC^{T}+DD^{T}=
  4nI_{n}$. Weiterhin sei $R$ eine $n\times n$ Matrix, die
  Eins"=Einträge auf der Nebendiagonale besitzt, also $r_{i,j}=1$ für
  $i+j=n+1$ und sonst $0$ für $i,j=1,\dots,n$. Dann ist die Matrix~$H$
  eine \HM{}:
  \begin{gather*}
    H=
    \begin{pmatrix*}[r]
      A & BR & CR & DR\\
      -BR & A & D^{T}R & B^{T}R\\
      -CR & -D^{T}R & A & B^{T}R\\
      -DR & D^{T}R & -B^{T}R & A
    \end{pmatrix*}
  \end{gather*}
\end{defini}



\section{Konstruktion nach Kimura}



\section{Kozyklische \HMen}





\sloppy{}
\printbibliography{}

\end{document}
