% Einige zusätzliche Informationen für rubber
%  rubber erkennt nicht, dass die Datei weg kann, daher sagen wir es ihm
% rubber: clean $base.thm
%  rubber soll nach Änderungen an der Datei nochmal bauen
% rubber: watch $base.thm
% rubber: makeidx.tool      xindy
% rubber: makeidx.language  german-din
% rubber: makeidx.modules   indexstyle.xdy
%
% scrreprt trifft am Besten die Bedürfnisse eines Skripts, das ganze wird
% zweiseitig (twoside), d.h. es wird zwischen linker und rechter Seite
% unterschieden, und wir verwenden zwischen den Absätzen einen Abstand
% von einer halben Zeile (halfparskip) und dafür keinen Absatzeinzug,
% wobei die letzte Zeile eines Absatzes zu min. 1/4 leer ist.

\RequirePackage[l2tabu,orthodox]{nag}  % nag überprüft den Text auf veraltete
                   % Befehle oder solche, die man nicht in LaTeX verwenden
                   % soll -- l2tabu-Checker in LaTeX

\documentclass[halfparskip*,ngerman,draft,twoside]{scrreprt}

\usepackage{ifthen}
\usepackage{makeidx}
\usepackage{color}
\usepackage[draft=false,colorlinks,bookmarksnumbered,linkcolor=blue,breaklinks]{hyperref}

\usepackage[latin1]{inputenc}
\usepackage[ngerman]{babel}

\usepackage{lmodern}		% Latin Modern
% \usepackage{type1ec}           % cm-super
\usepackage[T1]{fontenc}        % T1-Schriften notwendig für PDFs
\usepackage{textcomp}           % wird benötigt, damit der \textbullet
                                % für itemize in lmodern gefunden wird.

\usepackage[intlimits,leqno]{amsmath}
\usepackage[all,warning]{onlyamsmath}  % warnt bei Verwendung von nicht
                                       % amsmath-Umgebungen z.\,B. $$...$$
\usepackage{amssymb}     % wird für \R, \C,... gebraucht
\usepackage{fixmath}     % ISO-konforme griech. Buchstaben

\usepackage[amsmath,thmmarks,hyperref]{ntheorem} % für die Theorem-Umgebungen
                                                 % (satz, defini, bemerk)
\usepackage{xspace}      % wird weiter unten gebraucht
\usepackage{slashbox}    % für schräge Striche links oben in der
                         % Tabelle; s. texdoc slashbox

\usepackage{paralist}    % besseres enumerate und itemize und neue
                         % compactenum/compactitem; s. texdoc paralist

\usepackage{svn}         % Zum Auswerten und ordentlichen Darstellen der
                         % SVN-Schlüsselwörter (s. vor \begin{document})
                         % dafür muss in SVN noch das Flag svn:keywords
                         % auf "LastChangedRevision LastChangedDate"
                         % gesetzt werden
% \usepackage{ifpdf}       % Erkennung, ob PDF generiert wird; nützlich zur
                         % Unterscheidung bei Grafiken \input{XYZ.pdf_t}
\usepackage{ellipsis}    % Korrektur für \dots
\usepackage{fixltx2e}
\usepackage[final]{microtype} % Verbesserung der Typographie
\usepackage{nicefrac}
\usepackage{listings}
\usepackage{booktabs}

% Damit auch die Zeichen im Mathemode in Überschriften fett sind
% <news:lzfyyvx3pt.fsf@tfkp12.physik.uni-erlangen.de>
\addtokomafont{sectioning}{\boldmath}

% nach dem Theoremkopf wird ein Zeilenumbruch eingefügt, die Schrift des
% Körpers ist normal und der Kopf wird fett gesetzt
\theoremstyle{break}
\theorembodyfont{\normalfont}
\theoremheaderfont{\normalfont\bfseries}
\theoremnumbering{arabic}

% Die folgenden Umgebungen werden einzeln nummeriert und am Ende jedes
% Kapitels zurückgesetzt
\newtheorem{satz}{Satz}[chapter]
\newtheorem{bemerk}{Bemerkung}[chapter]
\newtheorem{defini}{Definition}[chapter]
\newtheorem{bsp}{Beispiel}[chapter]
%\newtheorem{festl}{Festlegung}[chapter]

% Die folgenden Theoremumgebungen bekommen keine Nummer
\theoremstyle{nonumberbreak}
%\newtheorem{fakt}{Fakt}

\theoremheaderfont{\scshape}
\theorembodyfont{\normalfont}
% Das Zeichen am Ende eines Beweises
\theoremsymbol{\ensuremath{_\blacksquare}}
% \theoremsymbol{q.\,e.\,d.}
\newtheorem{proof}{Beweis:}

% Hier die Definition, wie \autoref die Umgebungen nennen soll, die mit
% \newtheorem definiert wurden
\newcommand*{\satzautorefname}{Satz}
\newcommand*{\bemerkautorefname}{Bemerkung}
\newcommand*{\definiautorefname}{Definition}
\newcommand*{\bspautorefname}{Beispiel}
%\newcommand*{\festlautorefname}{Festlegung}
% Zwischen Unter- und Unterunterabschnitten sollte nicht unterschieden
% werden.
\renewcommand*{\subsectionautorefname}{Abschnitt}
\renewcommand*{\subsubsectionautorefname}{Abschnitt}

\pagestyle{headings}

\newcommand*{\R}{\mathbb{R}}      % reelle Zahlen
\newcommand*{\C}{\mathbb{C}}      % komplexe Zahlen
\newcommand*{\N}{\mathbb{N}}      % natürliche Zahlen
\newcommand*{\Q}{\mathbb{Q}}      % gebrochene Zahlen
\newcommand*{\Z}{\mathbb{Z}}      % ganze Zahlen

% Wenn irgendwo Unklarheiten zum Inhalt im Skript auftreten, können sie
% einfach mit \help{Ich verstehe das nicht} hervorgehoben werden. Dies
% macht es leichter sie alle zu finden und auch ganz einfach
% auszublenden, indem man den Befehl einfach leer definiert
\newcommand*{\help}[1]{\textcolor{green}{help: #1}}

% \todo ist das gleiche wie \help nur für offene Aufgaben
\newcommand*{\todo}[1]{\textcolor{red}{todo: #1}}

% Um wichtige Begriffe im Text überall gleich vorzuheben (gleiches
% Markup), sollte dieser Befehl verwendet werden. Das Argument wird
% automatisch als Indexeintrag verwendet. Dieser kann aber auch als
% optionales Argument selbst bestimmt werden.
\newcommand*{\highl}[2][]{\textbf{\boldmath{#2}}%
  \ifthenelse{\equal{#1}{}}{\index{#2}}{\index{#1}}%
}

% Definition für Xindy für die Trennung der einzelnen Abschnitte im
% Index. siehe auch die Datei indexstyle.xdy
\newcommand*{\indexsection}{\minisec}

% Für Leute, die nicht gern o.\,B.\,d.\,A. jedesmal eintippen wollen
%\newcommand*{\obda}{o.\,B.\,d.\,A.\xspace}

% Diese Befehle sind dafür gedacht, dass die Symbole für "genau dann wenn"
% im ganzen Dokument gleich aussehen. Außerdem erlaubt es eine schnelle
% Veränderung aller Stellen, falls der Prof. doch nicht mehr gdw nimmt,
% sondern \Leftrightarrow.
% \newcommand*{\gdw}{\ifthenelse{\boolean{mmode}}%
% 			       {\mspace{8mu}gdw\mspace{8mu}}%
% 			       {$gdw$\xspace}}
% \newcommand*{\gdwdef}{\ifthenelse{\boolean{mmode}}%
% 			       {\mspace{8mu}gdw_{def}\mspace{8mu}}%
% 			       {$gdw_{def}$\xspace}}

% Um sicherzustellen, dass jeder Betrag-/jede Norm links und rechts die
% Striche bekommt, sind diese Befehle da. Damit kann man nicht die
% rechten Striche vergessen und es wird etwas übersichtlicher. (Vorschlag
% ist aus amsldoc) \abs[\big]{\abs{a}-\abs{b}} \leq \abs{a+b}
%\newcommand*{\abs}[2][]{#1\lvert#2#1\rvert}
%\newcommand*{\norm}[2][]{#1\lVert#2#1\rVert}

% Das original Epsilon sieht nicht so toll aus
\renewcommand*{\epsilon}{\varepsilon}
% ... und mancheinem gefällt auch das Phi nicht
\renewcommand*{\phi}{\varphi}

\renewcommand*{\CK}{\mathcal{K}}
\makeindex

\SVN $LastChangedRevision$
\SVN $LastChangedDate$

\begin{document}

\title{Schnelle Löser für große lineare Gleichungssysteme}
\author{Prof.\,Dr.\,Gerhard Zumbusch}
\date{Semester: SS 2007}
\maketitle

\clearpage
\chapter*{Vorwort}

{\itshape
  Dieses Dokument wurde als Skript für die auf der
  Titelseite genannte Vorlesung erstellt und wird jetzt im Rahmen des
  Projekts
  "`\href{http://www.minet.uni-jena.de/~joergs/skripte/}
  {Vorlesungsskripte der Fakultät für Mathematik}
  \href{http://www.minet.uni-jena.de/~joergs/skripte/}{und Informatik}"'
  weiter betreut. Das
  Dokument wurde nach bestem Wissen und Gewissen angefertigt. Denoch
  garantiert weder der auf der Titelseite genannte Dozent, die Personen,
  die an dem Dokument mitgewirkt haben, noch die
  Mitglieder des Projekts für dessen Fehlerfreiheit. Für etwaige Fehler
  und dessen Folgen wird von keiner der genannten Personen eine Haftung
  übernommen. Es steht jeder Person frei, dieses Dokument zu lesen, zu
  verändern oder auf anderen Medien verfügbar zu machen, solange ein
  Verweis auf die Internetadresse des Projekts
  \url{http://www.minet.uni-jena.de/~joergs/skripte/}
  enthalten ist.

  Diese Ausgabe trägt die Versionsnummer~\SVNLastChangedRevision{} und ist vom
  \SVNDate{}. Eine neue Ausgabe könnte auf der Webseite des Projekts verfügbar
  sein.

  Jeder ist dazu aufgerufen Verbesserungen, Erweiterungen und
  Fehlerkorrekturen für das Skript einzureichen bzw. zu melden oder diese
  selbst einzupflegen -- einfach eine E-Mail an die
  \href{mailto:skripte@listserv.uni-jena.de}{Mailingliste
  \texttt{<skripte@listserv.uni-jena.de>}} senden. Weitere Informationen
  sind unter der oben genannten Internetadresse verfügbar.

  Hiermit möchten wir allen Personen, die an diesem Skript mitgewirkt
  haben, vielmals danken:
  \begin{itemize}
   \item \href{mailto:jens@kubieziel.de}{Jens Kubieziel
    \texttt{<jens@kubieziel.de>}} (2007)
  \end{itemize}
}

\clearpage
\pdfbookmark[0]{Inhaltsverzeichnis}{inhaltsverzeichnis}
\tableofcontents

\clearpage
\pdfbookmark[0]{Auflistung der Sätze}{theoremlist}
\chapter*{Auflistung der Theoreme}

\pdfbookmark[1]{Sätze}{satzlist}
\section*{Sätze}
\theoremlisttype{optname}
\listtheorems{satz}

\pdfbookmark[1]{Definitionen und Festlegungen}{definilist}
\section*{Definitionen und Festlegungen}
% \theoremlisttype{all}
\listtheorems{defini,festl}


%%% Start der Vorlesung
\chapter{Einleitung}

Einträge haben bestimmte Form und auch viele Nullen. Die bestimmte Form kann
man mathematisch beschreiben. Im modernen Teil betrachten wir PDGLs in
Einzelteilen und schaffen schnelle Löser. DGLs haben in physikalischen
Theorien einen großen Anteil. Weiterhin auch bei diskreten
Optimierungsproblemen. Wir eine Struktur einer DGL. Diese nutzen wir aus, um
das Gleichungssystem zu lösen.

\begin{itemize}
 \item Wir sprechen über klassische Iterationsverfahren (konjugierte
  Gradienten, Gauss-Seidel etc.). Kann man auf sehr viele Matrizen anwenden.
  Die Verfahren wurden bereits in früheren Vorlesungen besprochen.
 \item Gebietszerlegungsverfahren. Idee: DGL auf einem Gebiet ($-\Delta u=f$
  in $\Omega\subseteq \R^{2}$), evtl.lassen sich Teilprobleme besser lösen. Es
  existieren unterschiedliche Ansätze. eine Motivation sind Parallelrechner.
  Ein Prozessor kann einen kleinen Teil bearbeiten. Es wird ein Algorithmus
  geschaffen, der das Problem in kleine Teile zerlegt.
 \item Mehrgitterverfahren. Bauen auf Differentialgleichungen auf. Ein anderer
  Name sind Multi-Level-Verfahren. Die Idee ist, dass man eine kontinuierliche
  Differentialgleichung hat und diese diskretisiert. Die Diskretisierung wird
  mit einem Gitter gemacht.
 \item Parallele Algorithmen. 
\end{itemize}

\chapter{Grundbegriffe paralleler Algorithmen}
\section{Überblick}

Warum parallel? viele Unbekannte, viele Matrixeinträge $\Rightarrow$ viel
Speicher.
\begin{itemize}
 \item physikalische Grenzen sequentieller Speicher
 \item Verfügbarkeit paralleler Rechner
 \item Parallelität in vielen Anwendungen
\end{itemize}

\section{Modellproblem}

Seien $x,y\in\R^{n}$ zwei Vektoren. Wir wollen das Skalarprodukt $s=\langle
x,y\rangle= \sum_{i=0}^{n-1} x_{i}y_{i}$ berechnen. Das Ergebnis hängt davon
ab, in welcher Reihenfolge summiert wird. Es kann Auslöschungen geben.
Annahme: Dieser Effekt ist nicht dramatisch. Wie kann man das Ganze insgesamt
parallelisieren?
\begin{enumerate}
 \item Berechnung der $x_{i}y_{i}$. Dies ist für alle $i$ unabhängig. 
 \item Sei $P$ die Zahl der Recheneinheiten (Prozessoren) und $N\gg P$ (Wir
  haben deutlich weniger Prozessoren als Unbekannte.). wir verteilen die
  Indizes $\{0,\dotsc,n-1\}$ auf die Prozessoren $I_{P}\subset
  \{0,\dotsc,n-1\}$. Der Prozessor kann eine Teilsumme $S_{P}=\sum_{i\in
  I_{P}} x_{i} y_{i}$ bestimmen.
 \item Gesamtsumme bestimmen. Eine Idee ist, dass ein Prozessor alle diesen
  Zahlen addiert (sequentielle Arbeitsweise): $S=\sum_{j=0}^{n-1} S_{j}$.
  Weiterhin könnten jeweils zwei Zahlen addiert werden und diese Ergebnisse
  werden dann wieder summiert: $S=\underbrace{S_{0}+S_{1}}_{S_{01}} +
  \underbrace{S_{2}+S_{3}}_{S_{23}} + \underbrace{S_{4}+S_{5}}_{S_{45}} +
  \underbrace{S_{6}+S_{7}}_{S_{67}} = \dotsb=S_{01234567}$. Insgesamt werden
  hier nur drei Schritte benötigt. Dabei nutzen wir das Assoziativgesetz aus.
\end{enumerate}

Der Gesamtaufwand für das obige Verfahren berechnet sich im ersten und zweiten
Schritt durch jeweils $\nicefrac{n}{P}$ und im dritten Schritt durch $\log P$.
Also ergibt sich $O(\nicefrac{2n}{P}+\log P)$.
Das selbe Verfahren sequentiell durchgeführt würde einen Aufwand von $2n$
bedeuten.

Wir müssen nun jeweils die Werte für $P$ betrachten. Ist $P=1$ hat man wieder
ein sequentielles Verfahren. Für $P\rightarrow n$ ergibt sich $O(\log n)$.

Nun ergibt sich die Frage: Wie sage ich es meinem Prozessor? Im folgenden
werden ein paar Möglichkeiten aufgezeigt. Im wesentlichen gibt es zwei
verschiedene Standardvarianten.

\subsection{Kommunizierende sequentielle Prozesse}

Man hat verschiedene sequentielle Programme, die auf verschiedenen Prozessoren
laufen. Diese schicken Daten hin und her. Der Programierer muss für die
Kommunikation sorgen.

\begin{defini}[sequentieller Prozess]
  Ein sequentieller Prozess ist die Ausführung eines sequentielles Programms.
  Jederzeit klarer Zustand. Eine Operation wird nach der nächsten ausgeführt.
  Der Zustand wird durch den Befehlszähler und Variablen (Speicher, Register)
  bestimmt.
\end{defini}

\begin{defini}[paralleles Programm]
  Ein paralleles Programm sind interagierende sequentielle Prozesse. Sinnvoll
  auf mehreren Prozessoren. Gegebenenfalls zyklisches Umschalten eines
  Prozessors auf mehrere Prozesse. Dies wird als Multitasking bezeichnet.
\end{defini}

Vereinfachtes Muster:
Man kommuniziert über globale Variablen. Bezeichung:
\lstset{numbers=left,numberstyle=tiny,language=C}
\begin{lstlisting}
globale Variable
thread<name1>[Parameter]{
  lokale Variable\\
  Anweisung
  }
thread<name2>[Parameter]{
  lokale Variable\\
  Anweisung
  }  
\end{lstlisting}

\todo{Listing ordentlich machen}

Obiges ist ein Modell mit statischen Threads. Diese starten alle (unter
Umständen nicht gleichzeitig, aber zeitnah). Das parallele Programm
terminiert, wenn alle Prozesse terminieren. Die genauen Eigenschaften hängen
vom System ab. Üblicherweise hat der Prozess einen eigenen Daten- und
Adressraum. Dagegen hat ein Thread keinen eigenen Adressraum. Dadurch ist er
etwas billiger.

\todo{Vorlesung vom 2007-04-23}

\todo{Vorlesung vom 2007-04-24}


%% Vorlesung vom 2007-04-30
\chapter{Instruktionsparallelismus}
Bisher haben wir immer eine sequentielle Programmiersprache betrachtet. Die
Idee ist nun, dass man schon bei den Intruktionen Parallelität ausnutzt.

\section{von-Neumann-Modell}
In dem Modell gibt es Befehle und Daten. Alles steht in einem großen Speicher.
Die Befehle gehen in einen Befehlszähler und werden nacheinander abgearbeitet.
Seit den siebziger jahren ist bekannt, dass man an technische Grenzen stößt
und es wurde am Einsatz von Parallelität gearbeitet.

\section{Pipelining-Vektorrechner}
Man zerlegt Operationen in Teiloperationen und versucht diese, schneller
auszuführen. Das ganze geschieht am "`Fließband"'. Wir brauchen mehrere
Zeittakte um eine Operation zu beenden. Als Beispiel haben wir einen Befehl
mit vier Teiloperationen. Zuerst wird der erste Befehl ausgeführt. Der wird in
vier Takten bearbeitet. Wenn nach dem ersten Zeittakt die erste Operation
beendet ist, könnte man hier schon den nächsten Befehl bearbeiten. Wenn dieser
abgearbeitet ist, sind erst fünf Takte um. Für den dritten Befehl werden sechs
Takte benötigt usw. Insgesamt wird dann pro Takt eine Operation fertig.

Wir haben eine Pipeline der Länge $m$ und eine Operation dauert $m$ Takte. Für
$N$ Operationen dauert die Bearbeitung $m+N-1$ Takte. Die Beschleunigung
(Speedup) berechnet sich nach $S(N)=\frac{T_{S}(N)}{T_{P}(N)}= \frac{N\cdot
top\cdot m}{(m+N-1)\cdot top}= m\frac{N}{m+N-1}$. Es gilt $\lim_{N\rightarrow
\infty} S(N)=m$. Die Abhängigkeit liegt nur vor, wenn der Abstand der Operationen
kleiner als $m$ ist. \todo{Aussage nochmal genau prüfen und klarer
aufschreiben}

Man kann die Vektoroperationen $a[i]+b[i], a[i]+c, a[i]\cdot b[i]$ und
$a[i]\cdot c$ schnell ausführen. Andere Operationen sind vergleichsweise
langsam. Daher kommt der Name \emph{RISC} (Reduced instruction set computing).
Das Ziel ist, wenige, einfache Befehle zu haben, die schnell sind und sich
"`pipelinen"' lassen. Wenn man auf den Speicher zugreifen wollte, hat man
Laden-und-Speichern (load and store) gemacht. Es wird nur im Register
gerechnet. (Inzwischen ist das schon wieder etwas aufgeweicht.)
Schwierigkeiten gibt es immer dann, wenn die Pipeline nicht funktioniert,
d.\,h. wenn es nicht genügend Operationen gibt, die man unabhängig voneinander
ausführen kann. Eine zweite Problematik kann auftreten, wenn der Prozessor
nicht mehr weiß, wo es hin geht (bedingte Sprünge).

\begin{bsp}
%  \lstset{language=x86masm}
  % \begin{lstlisting}
  %   R1=N
  %   READ x[R1], R2
  %   MULT R2, A, R2
  %   WRITE R2, x[R1]
  %   DEC R1
  %   JMP, IF R1>0
  % \end{lstlisting}
\end{bsp}

Bei neueren Prozessoren gibt es Erweiterungen, die explizit parallel arbeiten.
Diese in der Regel als Multimediaerweiterungen beworben. Bei Intel heißt die
Technologie SSE2, bei AMD 3Dnow und beim PowerPC Altivec. Beispielsweise kann
man da mit vier Floats in 128 Bitregistern arbeiten.

Nach Abschätzungen von Wissenschaftlern kann man normale Anwendungen um den
Faktor 3 bis 5 beschleunigen. Numerische Anwendungen könnten hingegen mehr
beschleunigt werden.


\section{Superskalar}

Es gibt mehrfache Instruktionseinheiten, die Operationen ausführen können. Man
will mehr als einen Befehl pro Takt haben. Dabei versucht man, Befehle zu
finden, die nichts miteinander zu tun haben und diese parallel zu betreiben.
Beispielsweise kann man Integerarithmetik, Addition/Subtraktion und
Multiplikation von Gleitpunktzahlen in Einheiten zu packen. Wie wird sowas
programmiert? In der Regel wird einige Befehle vorausgeschaut und wenn alle
"`Zutaten"' da sind, werden diese ausgeführt. Prozessor kann also Befehle in
beliebiger Reihenfolge ausführen. Dabei gilt die Bedingung, dass dabei
dasselbe Ergebnis wie bei sequentieller Bearbeitung herauskommen muss. Das
nennt man \emph{Out-of-order Execution}. Hierfür braucht man viele Register
und eine komplexe interne Logik. Der Speedup ist hier bei kleiner 4 bis 5.
Eine weiterführende Idee ist, diese Logik auf den Compiler auszulagern. 

\emph{Long instruction word} beim Itanium waren das drei unabhängige Befehle
pro Takt. Damit ergibt sich ein Speedup von $\leq 3$.

\emph{Hyperthreading} bezeichnet die Idee, dass sich mehrere Threads die
Ressourcen eines Prozessors teilen.

\section{Klassifikation nach Flynn}
\begin{tabular}{l|l|l}
  & Single instruction & multiple instruction\\
  \toprule
  single data & SISD (von Neumann) & \\
  multiple data & SIMD (Vektorrechner) & MIMD (Multiprozessor)
\end{tabular}


Weiterhin kann man nach dem Speicher klassifizieren:
\begin{itemize}
  \item gemeinsamer Speicher (als symmetric multiprocessing (SMP) oder
  non-uniform memory access (NUMA))
 \item verteilter Speicher
\end{itemize}

\todo{Vorlesung vom 2007-05-07}

\todo{Vorlesung vom 2007-05-08}

Betrachten $\Phi(x)=\nicefrac{1}{2} x^{T}Ax-b^{T}x$. Wenn $A=A^{T}$ positiv
definit ist, dass ist das äquivalent zu $\nabla\Phi(x)=0\Leftrightarrow Ax=b$.
Die zweite Charakterisierung ist $A$-Orthogonalität: $\langle
p,Aq\rangle=0\Leftrightarrow p \perp_{A} q$ konjugiert. Wir minimieren
bezüglich eines ganzen Raumes, nämlich des Krylov-Raumes. Das Residuum ist
$r=Ax-b$. Dann reicht es bezüglich des Raumes $\{x, Ax, A^{2}x,
A^{3}x,\dotsc,\}$ zu minimieren. Man startet mit einem $x_{0}=Ax^{0}-b$ und
versucht diesbezüglich Lösungen zu berechnen. Zuerst kommt ein
Gradientenschritt. Nach dem ersten Schritt ist das orthogonal zum alten
Residuum. Im zweiten Raum kommt der Raum raus, der von $x$ und $Ax$
aufgespannt wird. Der Krylovraum steigt von Iteration zu Iteration.

Wir haben im CG-Verfahren Suchrichtungen. In einem Schritt ist das $p^{(k+1)}$
mit $\langle p^{(k+1)}, Ap^{(j)}\rangle=0$ für alle $j\leq k$. Die erste
Suchrichtung ist $p^{(0)}=r^{(0)}=Ax^{(0)}-b$. Weiter gilt dann, $p^{(k+1)} =
r^{(k+1)} -\beta_{k} p^{(k)}$, wobei für $r^{(k+1)}= r^{(k)}-\alpha_{k}
A p^{(k)}$ gilt.

Nehmen wir $K^{(0)}= \langle r^{(0)}\rangle$, $K^{(k+1)}= \langle K^{(k)},
Ap^{(k)}$. Es gilt $p^{(0)}=r^{(0)}\in K^{(0)}$ und $p^{(k+1)}, r^{(k+1)}\in
K^{(k+1)}$. Wenn man das iterativ macht, bekommt man eine neue Beschreibung:
$K^{(k)}= \langle r^{(0)}, Ar^{(0)}, \dotsc, A^{k}r^{(0)}\rangle$.
Das bezeichnet man als \highl{Krylovräume}.

Wegen der Eigenschaft der Krylovräume kann man schreiben: $y\in K^{(k)}
\Rightarrow y=\sum_{i=0}^{k} r_{k} A^{k} r^{(0)}$. Vergleiche dies mit dem
Polynom $z=\sum_{i=0}^{k} r_{k} x^{k}$. Sei nun $\abs{z(x)}<c$ für
$x\in[a,b]$. Wenn man das kann, kann man überlegen, was mit $A^{k}$ passiert.
Wenn die Eigenwerte von $A$ beschränkt sind ($a\leq EW(A)\leq b$), dann
erhalten wir eine Schranke für das obige $y$. Insgesamt erhält man sowas wie
$\norm{y}\leq c\norm{r^{(0)}}$. Solche Polynome erhält man als
\highl{Tschebyscheffpolynome}. Man kann also $y$ so konstruieren, dass es eine
Näherung des Gleichungssystems ist.

\paragraph{Konvergenz des CG-Verfahrens}
$\norm{e^{(k)}}_{A}\leq 2 \frac{c^{k}}{1+c^{2k}} \norm{e^{(0)}}_{A}$ mit
$c=\frac{\sqrt{\CK(A)}-1}{\sqrt{\CK(A)}+1}.

Vergleiche hierzu auch das Gradientenverfahren mit
$($\frac{\CK(A)-1}{\CK(A)+1})^{k}$. Bei exakter Rechnung ist man nach $n$
Schritten fertig.

Start mit $r^{(0)}=Ax^{(0)}-b, p^{(0)}=r^{(0)}$\\
Für $k=0,1,2,\dotsc$ führt man folgendes aus:
\begin{itemize}
  \item $\alpha_{k}=\frac{p^{(k)T}r^{(k)}}{p^{(k)T} AP^{(k)}}$
 \item $x^{(k+1)}= x^{(k)} +\alpha_{k} p^{(k)}$
 \item $r^{(k+1)}= r^{(k)} -\alpha_{k} Ap^{(k)}$
 \item $\beta_{k}= \frac{(Ap^{(k)})^{T} r^{(k+1)}}{(Ap^{(k)})^{T} p^{(k)}}$
 \item $p^{(k+1)= r^{(k+1)} -\beta_{k}p^{(k)}}$
\end{itemize}
Wobei die Matrximultiplation sehr teuer werden kann. Daher rechnet man
$Ap^{(k)}$ in jedem Schritt nur einmal aus.

\paragraph{Allgemeine Matrizen}
$A^{T}Ax=A^{T}b$. Im Allgemeinen gilt $A\neq A^{T}$ und $A$ hat positive wie
negative Eigenwerte. Angenommen $\CK(A^{T}A)=\CK^{2}(A)>\CK(A)$. Konjugiertes
Gradientenverfahren würde das Verfahren somit kaputt machen.

Multiplikation mit $A^{T}$ kann kompliziert sein, z.\,B. Randbedingungen.

Eine Variante mit $A^{T}A$ zu arbeiten, ist von Hestenes und Stiefel (1952).
Berechne $Ax=b$ und $A^{T}x=b$ mit dem BICG-Verfahren von Fletcher (1975).
Ohne $A^{T}$ heißt es CGS von Sonnefeld von 1989. Van der Vorst hat es weiter
verbessert und BICG-Stab genannt.

Ein weiterer Weg ist die Minimierung von $\norm{Ax-b}_{2}$ von Saad und
Schultz (1986). Es heißt GMRES. Daraus entstand dann die Quasiminimierung
(quasi minimal residual, QMR) von Freund und Nachtigall (1991). Letzteres
Verfahren wurde auch von BICG beeinflusst. Nun versuchte man wieder $A^{T}$ zu
entfernen und es entstand das TFQMR (transposed free QMR) wieder von Freund
(1993).

\paragraph{Modellbeispiel: Konvektion-Diffusion}
Die Idee ist: $-\epsilon\Delta u+ \beta\nabla u=0$ in $x\in(0,1)^{2}$ und
$u=g$ auf $\partial(0,1)^{2}$ mit $\beta\colon\Omega\rightarrow \R^{2}$ und
$\epsilon>0$.

\clearpage
\appendix
\begin{thebibliography}{99}
 \bibitem{tbd} wird noch benannt
\end{thebibliography}

\clearpage
\pdfbookmark[0]{Index}{index}
\printindex

\end{document}
