% Einige zusätzliche Informationen für rubber
%  rubber erkennt nicht, dass die Datei weg kann, daher sagen wir es ihm
% rubber: clean $base.thm
%  rubber soll nach änderungen an der Datei nochmal bauen
% rubber: watch $base.thm
% rubber: makeidx.tool      xindy
% rubber: makeidx.language  german-din
%
% scrreprt trifft am Besten die Bedürfnisse eines Skripts, das ganze wird
% zweiseitig (twoside), d.h. es wird zwischen linker und rechter Seite
% unterschieden, und wir verwenden zwischen den Absätzen einen Abstand
% von einer halben Zeile (halfparskip) und dafür keinen Absatzeinzug,
% wobei die letzte Zeile eines Absatzes zu min. 1/4 leer ist.

\RequirePackage[l2tabu,orthodox]{nag}  % nag überprüft den Text auf veraltete
                   % Befehle oder solche, die man nicht in LaTeX verwenden
                   % soll -- l2tabu-Checker in LaTeX

\documentclass[ngerman,draft,parskip=half*,twoside]{scrreprt}

\usepackage{ifthen}
\usepackage{index}
% \usepackage[final]{graphicx}  % Für Grafiken
\usepackage{xcolor}
\usepackage[draft=false,colorlinks,bookmarksnumbered,linkcolor=blue,breaklinks]{hyperref}

\usepackage[utf8]{inputenc}
\usepackage{babel}
% \usepackage{nicefrac}
% \usepackage{tabularx}

\usepackage{lmodern}		% Latin Modern
% \usepackage{type1ec}           % cm-super
\usepackage[T1]{fontenc}        % T1-Schriften notwendig für PDFs
\usepackage{textcomp}           % wird benötigt, damit der \textbullet
                                % für itemize in lmodern gefunden wird.

\usepackage[intlimits,leqno]{amsmath}
\usepackage[all,warning]{onlyamsmath}  % warnt bei Verwendung von nicht
                                       % amsmath-Umgebungen z.\,B. $$...$$
\usepackage{amssymb}     % wird für \R, \C,... gebraucht
\usepackage{fixmath}     % ISO-konforme griech. Buchstaben

\usepackage[amsmath,thmmarks,hyperref]{ntheorem} % für die Theorem-Umgebungen
                                                 % (satz, defini, bemerk)
\usepackage{xspace}      % wird weiter unten gebraucht
\usepackage{slashbox}    % für schräge Striche links oben in der
                         % Tabelle; s. texdoc slashbox

\usepackage{paralist}    % besseres enumerate und itemize und neue
                         % compactenum/compactitem; s. texdoc paralist

\usepackage{svn}         % Zum Auswerten und ordentlichen Darstellen der
                         % SVN-Schlüsselwörter (s. vor \begin{document})
                         % dafür muss in SVN noch das Flag svn:keywords
                         % auf "LastChangedRevision LastChangedDate"
                         % gesetzt werden
% \usepackage{ifpdf}       % Erkennung, ob PDF generiert wird; nützlich zur
                         % Unterscheidung bei Grafiken \input{XYZ.pdf_t}
\usepackage{ellipsis}    % Korrektur für \dots
\usepackage{fixltx2e}
\usepackage[final]{microtype} % Verbesserung der Typographie
\usepackage{nicefrac}
\usepackage[version=3]{mhchem}
\usepackage{wasysym}
\usepackage{bbm}
\usepackage{todonotes}


% Damit auch die Zeichen im Mathemode in überschriften fett sind
% <news:lzfyyvx3pt.fsf@tfkp12.physik.uni-erlangen.de>
\addtokomafont{sectioning}{\boldmath}

% nach dem Theoremkopf wird ein Zeilenumbruch eingefügt, die Schrift des
% Körpers ist normal und der Kopf wird fett gesetzt
\theoremstyle{break}
\theoremnumbering{arabic}
\theorembodyfont{\normalfont}
\theoremheaderfont{\normalfont\bfseries}

% Das Ende von Umgebungen, für die kein Beweis erbracht wurde, soll mit einer
% leeren Box gekennzeichnet werden. Wenn jedoch ein Beweis erbracht wurde,
% soll kein Zeichen ausgegeben werden (die ausgefüllte Box vom proof wird
% verwendet); man beachte die spezielle Definition von \theoremheaderfont für
% die Umgebung proof
% \newboolean{hasproof}
% \theoremheaderfont{\global\hasprooffalse\normalfont\bfseries}
% \theoremsymbol{\ifthenelse{\boolean{hasproof}}{}{\ensuremath{_\Box}}}

% Die folgenden Umgebungen werden einzeln nummeriert und am Ende jedes
% Kapitels zurückgesetzt
\newtheorem{satz}{Satz}[chapter]
\newtheorem{bemerk}{Bemerkung}[chapter]
\newtheorem{defini}{Definition}[chapter]
\newtheorem{bsp}{Beispiel}[chapter]
\newtheorem{festl}{Festlegung}[chapter]

% Die folgenden Theoremumgebungen bekommen keine Nummer
\theoremstyle{nonumberbreak}
\newtheorem{fakt}{Fakt}

% \theoremheaderfont{\global\hasprooftrue\scshape}
\theoremheaderfont{\scshape}
\theorembodyfont{\normalfont}
% Das Zeichen am Ende eines Beweises
\theoremsymbol{\ensuremath{_\blacksquare}}
% \theoremsymbol{q.\,e.\,d.}
\newtheorem{proof}{Beweis:}

% Hier die Definition, wie \autoref die Umgebungen nennen soll, die mit
% \newtheorem definiert wurden
\newcommand*{\satzautorefname}{Satz}
\newcommand*{\bemerkautorefname}{Bemerkung}
\newcommand*{\definiautorefname}{Definition}
\newcommand*{\bspautorefname}{Beispiel}
\newcommand*{\festlautorefname}{Festlegung}
% Zwischen Unter- und Unterunterabschnitten sollte nicht unterschieden
% werden.
\renewcommand*{\subsectionautorefname}{Abschnitt}
\renewcommand*{\subsubsectionautorefname}{Abschnitt}

\pagestyle{headings}

\newcommand*{\R}{\mathbb{R}}      % reelle Zahlen
\newcommand*{\C}{\mathbb{C}}      % komplexe Zahlen
\newcommand*{\N}{\mathbb{N}}      % natürliche Zahlen
\newcommand*{\Q}{\mathbb{Q}}      % gebrochene Zahlen
\newcommand*{\Z}{\mathbb{Z}}      % ganze Zahlen

% Wenn irgendwo Unklarheiten zum Inhalt im Skript auftreten, können sie
% einfach mit \help{Ich verstehe das nicht} hervorgehoben werden. Dies
% macht es leichter sie alle zu finden und auch ganz einfach
% auszublenden, indem man den Befehl einfach leer definiert
\newcommand*{\help}[1]{\textcolor{green}{help: #1}}

% \todo ist das gleiche wie \help nur für offene Aufgaben
% \newcommand*{\todo}[1]{\textcolor{red}{todo: #1}}

% Um wichtige Begriffe im Text überall gleich vorzuheben (gleiches
% Markup), sollte dieser Befehl verwendet werden. Das Argument wird
% automatisch als Indexeintrag verwendet. Dieser kann aber auch als
% optionales Argument selbst bestimmt werden.
\newcommand*{\highl}[2][]{\textbf{\boldmath{#2}}%
  \ifthenelse{\equal{#1}{}}{\index{#2}}{\index{#1}}%
}

% Befehl für die Darstellung der Gliederungsüberschriften im Index
\newcommand*{\lettergroup}[1]{\minisec{#1}}

% Für Leute, die nicht gern o.\,B.\,d.\,A. jedesmal eintippen wollen
\newcommand*{\obda}{o.\,B.\,d.\,A.\xspace}

% Diese Befehle sind dafür gedacht, dass die Symbole für "genau dann wenn"
% im ganzen Dokument gleich aussehen. Außerdem erlaubt es eine schnelle
% Veränderung aller Stellen, falls der Prof. doch nicht mehr gdw nimmt,
% sondern \Leftrightarrow.
\newcommand*{\gdw}{\ifthenelse{\boolean{mmode}}%
			       {\mspace{8mu}gdw\mspace{8mu}}%
			       {$gdw$\xspace}}
\newcommand*{\gdwdef}{\ifthenelse{\boolean{mmode}}%
			       {\mspace{8mu}gdw_{def}\mspace{8mu}}%
			       {$gdw_{def}$\xspace}}

% Um sicherzustellen, dass jeder Betrag-/jede Norm links und rechts die
% Striche bekommt, sind diese Befehle da. Damit kann man nicht die
% rechten Striche vergessen und es wird etwas übersichtlicher. (Vorschlag
% ist aus amsldoc) \abs[\big]{\abs{a}-\abs{b}} \leq \abs{a+b}
\newcommand*{\abs}[2][]{#1\lvert#2#1\rvert}
\newcommand*{\norm}[2][]{#1\lVert#2#1\rVert}

% Das original Epsilon sieht nicht so toll aus
\renewcommand*{\epsilon}{\varepsilon}
% ... und mancheinem gefällt auch das Phi nicht
\renewcommand*{\phi}{\varphi}

\newcommand*{\ID}{\mathbbm{1}}
\newcommand*{\E}{\mathbb{E}}



\newcommand*{\SL}{\mathcal{L}}

\DeclareMathOperator{\cov}{cov}

\makeindex

\SVN $LastChangedRevision$
\SVN $LastChangedDate$

\begin{document}

\title{Statistische Verfahren}
\author{Schumacher}
\date{Semester: WS 2008/09}
\maketitle

\clearpage
\chapter*{Vorwort}

{\itshape
  Dieses Dokument wurde als Skript für die auf der
  Titelseite genannte Vorlesung erstellt und wird jetzt im Rahmen des
  Projekts
  "`\href{http://uni-skripte.lug-jena.de/}
  {Vorlesungsskripte der Fakultät für Mathematik}
  \href{http://uni-skripte.lug-jena.de/}{und Informatik}"'
  weiter betreut. Das
  Dokument wurde nach bestem Wissen und Gewissen angefertigt. Dennoch
  garantiert weder der auf der Titelseite genannte Dozent, die Personen,
  die an dem Dokument mitgewirkt haben, noch die
  Mitglieder des Projekts für dessen Fehlerfreiheit. Für etwaige Fehler
  und dessen Folgen wird von keiner der genannten Personen eine Haftung
  übernommen. Es steht jeder Person frei, dieses Dokument zu lesen, zu
  verändern oder auf anderen Medien verfügbar zu machen, solange ein
  Verweis auf die Internetadresse des Projekts
  \url{http://uni-skripte.lug-jena.de/}
  enthalten ist.

  Diese Ausgabe trägt die Versionsnummer~\SVNLastChangedRevision{} und ist vom
  \SVNDate{}. Eine neue Ausgabe könnte auf der Webseite des Projekts verfügbar
  sein.

  Jeder ist dazu aufgerufen, Verbesserungen, Erweiterungen und
  Fehlerkorrekturen für das Skript einzureichen bzw. zu melden oder diese
  selbst einzupflegen -- einfach eine E-Mail an die
  \href{mailto:uni-skripte@lug-jena.de}{Mailingliste
  \nolinkurl{<uni-skripte@lug-jena.de>}} senden. Weitere Informationen
  sind unter der oben genannten Internetadresse verfügbar.

  Hiermit möchten wir allen Personen, die an diesem Skript mitgewirkt
  haben, vielmals danken:
  \begin{itemize}
   \item \href{mailto:jens@kubieziel.de}{Jens Kubieziel
    \nolinkurl{<jens@kubieziel.de>}} (2008)
  \end{itemize}
}

\clearpage
\pdfbookmark[0]{Inhaltsverzeichnis}{inhaltsverzeichnis}
\tableofcontents

\clearpage
\pdfbookmark[0]{Auflistung der Sätze}{theoremlist}
\chapter*{Auflistung der Theoreme}

\pdfbookmark[1]{Sätze}{satzlist}
\section*{Sätze}
\theoremlisttype{optname}
\listtheorems{satz}

\pdfbookmark[1]{Definitionen und Festlegungen}{definilist}
\section*{Definitionen und Festlegungen}
% \theoremlisttype{all}
\listtheorems{defini,festl}

\chapter{Einführung}

Der Studierende soll ein Gefühl für die statistische Modellierung bekommen. Es
sollen viele verschiedene Anwendungsgebiete gezeigt werden.

Die Webseite zur Vorlesung ist \url{http://www.stochastik.uni-jena.de/} unter
dem Stichpunkt "`Lehre"'. Derzeit ist dort eine Literaturliste zu finden.
Wir werden in mit dem Statistikpaket GNU R beschäftigen.

\begin{bsp}[Schätzung der Größe einer biologischen Population]
  Tiere kann man im Gegensatz zum Menschen nicht einfach abzählen. Daher
  werden hier statistische Verfahren benutzt. Beispielsweise wird hierfür das
  Fang"=Wiederfang"=Verfahren genutzt.

  Wir haben eine Population der Größe $N$. In der ersten Fangperiode werden
  Individuen markiert. Die Anzahl der markierten Individuen werde mit $m$
  bezeichnet. In der zweiten Fangperiode werden Individuen gefangen. Die
  Anzahl der gefangenen Individuen werde mit $c$ bezeichnet. Davon ist eine
  Anzahl $r$ markiert.

  Daraus kann man sich einen heuristischen Schätzer für die Populationsgröße
  überlegen. Es ist $\nicefrac{m}{N}\sim\nicefrac{r}{c}$.\todo{Etwa"=Zeichen
  prüfen} Die Formel wird nach $N$ umgestellt und es ergibt sich $\hat{N}=
  \frac{m\cdot c}{r}$. Der Schätzer heißt \highl{Peterson"=Lincoln"=Schätzer}.
\end{bsp}

\section{Statistische Modellierung}

Wir nutzen ein Urnenmodell mit $N$~Kugeln. Davon sind $m$ rot und es werden
$c$ Kugeln entnommen. Dabei ist $X$ die Anzahl der markierten Kugeln unter den
$c$ entnommenen.

Folgende Voraussetzungen müssen gegeben sein:
\begin{itemize}
 \item gute Durchmischung der Population
 \item Ziehen mit Zurücklegen, d.\,h. gefangene Tiere werden wieder zurück in
  die Population gegeben
 \item Population ist im Untersuchungszeitraum geschlossen (keine Änderung der
  Größe)
 \item kein Verlust der Markierung
\end{itemize}

Es ist $X$ mit den Parametern $c$ und $p=\nicefrac{m}{N}$ binomialverteilt.
Dann ist $P(X=r)= \binom{c}{r} (\nicefrac{m}{N})^{r}
(1-\nicefrac{m}{N})^{c-r}$. Um das $N$ zu erhalten, verwenden wir die
Maximum"=Likelihood"=Methode.

\section{Parameterschätzung}

Wir fassen $P(X=r)$ als Funktion des unbekannten Parameters $N$ auf. Dies
nennt sich \highl{Likelihood"=Funktion}: $\SL(N|r)= \binom{c}{r} (\nicefrac{m}{N})^{r}
(1-\nicefrac{m}{N})^{c-r}$. Das Maximum der Likelihood"=Funktion bestimmen wir
durch Ableitung nach $N$. Jedoch ist die Ableitung nicht unbedingt einfach.
Ein leichterer Weg ist durch Übergang zur Log"~Likelihood"=Funktion:
$\ell(N|r)=\log\binom{c}{r}+r\log(m)-r\log N+(c-r)\log(N-m)-(c-r)\log N$. Die
Ableitung ergibt: $\frac{\partial}{\partial N}\ell(N|r)= -\nicefrac{r}{N}+
\frac{(c-r)}{N-m}-\frac{(c-r)}{N}= \frac{(c-r)}{N-m}-\frac{c}{N}=0$. Durch
Umstellen ergibt sich $\hat{N}= \frac{m\cdot c}{r}$.

Neben dem Schätzer haben wir hier auch eine Aussage über die Verteilung
erhalten: $\hat{N}= \frac{m\cdot c}{X}$. Vom $X$ wissen wir, dass es
binomialverteilt ist. Somit ist $\hat{N}$ eine Zufallsvariable, deren
Verteilung eine Transformation der Binomialverteilung ist. Darin liegt der
Vorteil des statistischen Modells gegenüber der obigen heuristischen Variante.

Dadurch können wir prinzipiell statistische Eigenschaften des Schätzers
untersuchen, wie beispielsweise Erwartungstreue, Konfidenzintervalle.

\section{Aussagen über die Verteilung von Parameterschätzern}

Die Aussagen sind nicht immer exakt, sondern in vielen Fällen asymptotisch.
Wir betrachen allgemeine Aussagen zu Eigenschaften der
Maximum"=Likelihood"=Schätzer.

Das obige Beispiel kann erweitert werden. So kann es mehr als zwei
Fangperioden geben. Wie lassen sich nun drei Fangperioden statistisch
modellieren? Dazu verwendet man "`Fanggeschichten"'. Dies sind Folgen von
Nullen und Einsen, die jedes Individuum zugeordnet bekommt. Eine Geschichte
von $111$ bedeutet, dass das Individuum in allen drei Perioden gefangen wurde.
Ein Individuum mit der Markierung $001$ wurde nur in der letzten Periode
gefangen. Insgesamt existieren acht solcher Fanggeschichten.

\begin{align*}
  111 &=X_{1}\\
  110 &=X_{2}\\
  101 &=X_{3}\\
  011 &=X_{4}\\
  100 &=X_{5}\\
  010 &=X_{6}\\
  001 &=X_{7}\\
  000 &\quad\text{unbekannt}
\end{align*}

Wir kennen die Variablen $X_{1},\dotsc, X_{7}$, für $X_{8}= N-(X_{1}+\dotsb+
X_{7})$. Es gilt, $P((X_{1}=n_{1},\dotsc, X_{7}=n_{7}, X_{8}=n_{8}))=
\frac{N!}{n_{1}!\cdot\dotso \cdot n_{8}!} q_{1}^{n_{1}} q_{2}^{n_{2}}\dotso
q_{8}^{n_{8}}$. Dies bezeichnet man als \highl{Multinomialverteilung}. Dabei
ist $q_{i}$ die Wahrscheinlichkeit, dass ein zufällig gewähltes Individuumm
die Fanggeschichte $i$ hat. Die Likelihood"=Funktion dazu ist: $\SL(N,
q_{1},\dotsc, q_{8}| n_{1},\dotsc, n_{7})= \frac{N!}{n_{1}!\cdot\dotso \cdot
n_{7}! (N-n_{1}-\dotsb- n_{7})!} q_{1}^{n_{1}} q_{2}^{n_{2}}\dotso
q_{7}^{n_{7}} q_{8}^{N-n_{1}-\dotsb- n_{7}}$. Hier haben wir nun mehr
Parameter als Beobachtugen. Daher muss das Modell ein wenig reduziert werden.

Es ist $q_{1}$ die Wahrscheinlichkeit, dass das Individuumm die Fanggeschichte
$111$ hat. Wir nehmen an, dass $p$ die konstante Fangwahrscheinlichkeit für
alle Individuen in allen Fangperioden ist. Dann ist $q_{1}=p\cdot p\cdot p=
p^{3}, q_{2}= pp(1-p)=p^{2}(1-p), \dotsc$ und die Likelihood"=Funktion ist
$\SL(N,p| n_{1},\dotsc, n_{7})= \frac{N!}{n_{1}!,\dotsc,n_{7}!
(N-n_{1}-\dotsb- n_{7})!} p^{3n_{1}+2n_{2} +2n_{3} +2n_{4} +n_{5} +n_{6}
+n_{7}} (1-p)^{n_{2} +n_{3} +n_{4} +2n_{5} +2n_{6} +2n_{7} +3(N-n_{1}-\dotsb-
n_{7})}$. Hierfür gibt es jedoch \emph{keine} analytische Lösung. Das Modell
bezeichnet man als $M_{0}$.

Zur Verschärfung kann man die Annahme treffen, dass es drei unterschiedliche
Fangwahrscheinlichkeiten, je nach Fangperiode, gibt. Dann ist $q_{1}=
p_{1}p_{2}p_{3}, q_{2}= p_{1}p_{2}(1-p_{3}), q_{3}= p_{1}(1-p_{2})p_{3},
\dotsc$ und die Likelihood"=Funktion ist $\SL(N,p_{1}, p_{2}, p_{3}|
n_{1},\dotsc, n_{7})= \frac{N!}{n_{1}!,\dotsc,n_{7}!
(N-n_{1}-\dotsb- n_{7})!} p_{1}^{n_{1}+n_{2}+n_{3}+n_{5}} (1-p_{1})^{n_{4}
+n_{6} +n_{7} +(N-n_{1}-\dotsb- n_{7})} p_{2}^{n_{1} +n_{2} +n_{4} +n_{6}}
(1-p_{2})^{n_{3} +n_{5} +n_{7} +(N-n_{1}-\dotsb- n_{7})} p_{3}^{n_{1} +n_{3}
+n_{4} +n_{7}} (1-p_{3})^{n_{2} +n_{5} +n_{6} +(N-n_{1}-\dotsb- n_{7})}$. Das
Modell bezeichnet man als $M_{t}$.

Die Wahl des richtigen Modells steht an zentraler Stelle der statistischen
Modellierung.

\section{Test der Hypothesen}

Zum Abschluss steht der Test der Hypothesen.

%Vorlesung vom 2008-10-27
Also ergeben sich die folgenden sechs Punkte:
\begin{enumerate}
 \item Statistische Modellbildung
 \item Parameterschätzung
 \item Verteilung von Parameterschätzern
 \item Modellanpassung
 \item Test der Hypothesen
 \item Konfidenzintervalle/""Prognoseintervalle
\end{enumerate}

\section{Beispiele für statistische Modelle}

\begin{bsp}[Körpergewicht von Säuglingen]
  Man betrachtet das Körpergewicht von Säuglingen im ersten Lebensjahr. Also
  Ergebnis von Messungen ergeben sich Punktepaare $(x_{i}, y_{i})$ für
  $i=1,\dotsc,n$. Dabei steht das $x_{i}$ für das Alter in Tagen und das
  $y_{i}$ für das Körpergewicht. Wir fassen das $y_{i}$ als Realisierung einer
  zufälligen Größe $Y_{i}$ auf. Es ist
  $y_{i}=b_{1}+\beta_{2}x_{i}+\epsilon_{i}$ eine lineare Funktion. Das
  $\epsilon_{i}$ wird als \highl{Störterm} bezeichnet. Typischerweise nimmt
  man an, dass die $\epsilon_{i}$ unabhängig und identisch verteilt sind. Die
  Standardannahme für die Verteilung ist $\epsilon_{i}\sim N(O,\sigma^{2})$.
  Das Modell wird als \highl[Regression!einfache lineare]{einfache lineare
  Regression} bezeichnet.

  Die Zufallsgröße $Y_{i}$ hat einen Erwartungswert $\E
  Y_{i}=\mu_{i}=\beta_{1}+ \beta_{2}x_{i}$ (deterministischer Teil). Im
  statistischen Teil ergibt sich $Y_{i}\sim N(\mu_{i}, \sigma^{2})$.  
\end{bsp}

\begin{bsp}[\ce{SO2}"~Belastung der Luft]
  Wir haben $y_{i}$ als den \ce{SO2}"~Gehalt der Luft.
  Weiter ist $x_{i2}$ die mittlere Jahrestemperatur, $x_{i3}$ Anzahl der
  Betriebe mit mehr als 20~Beschäftigten, $x_{i4}$ Einwohnerzahl, $x_{i5}$
  mittlerer Jahresniederschlag, $x_{i6}$ mittlere Windgeschwindigkeit und
  $x_{i7}$ die mittlere Anzahl von Regentagen. Als Daten haben wir nun Angaben
  in Form von Vektoren $(y_{i}, x_{i2},\dotsc, x_{i7})$. Die Zufallsvariable
  ist im wesentlichen $Y_{i}= \beta_{1}+ \beta_{2}x_{i2}+\dotsb+\beta_{7}
  x_{i7}+\epsilon_{i}$. Die $\epsilon_{i}$ sind wieder unabhängig und
  identisch verteilt und es gilt $\epsilon_{i}\sim N(O,\sigma^{2})$.
\end{bsp}

\begin{bsp}[Geburtsgewicht von Säuglingen]
  Diese werden getrennt nach \male und \female. Es ist
  \begin{gather*}
    \mu_{i}=
       \begin{cases}
	 \beta_{11}+ \beta_{21}x_{i}& \text{für \male}\\
	 \beta_{12}+ \beta_{22}x_{i}& \text{für \female}
       \end{cases}
  \end{gather*}
  Eine typische Hypothese wäre $H_{0}\colon\beta_{21}= \beta_{22}$ oder
  $H_{0}\colon\beta_{11}= \beta_{12}$. Es wird eine so genannte Dummyvariable
  eingeführt. Das ist eine Indikatorvariable mit $\ID_{i}= \begin{cases}1 &
							    \text{falls \female}\\
							    0& \text{sonst}\end{cases}$.
  Damit folgt $\mu_{i}=\beta_{1}+\beta_{2}\ID_{i}+\beta_{3}x_{i}+
  \beta_{4}\ID_{i}x_{i}$, d.\,h.
  \begin{gather*}
    \mu_{i}=
       \begin{cases}
	 \beta_{1}+\beta_{3}& \text{für \male}\\
	 (\beta_{1}+\beta_{2})+(\beta_{3}+\beta_{4})x_{i}& \text{sonst}
       \end{cases}
  \end{gather*}
  Damit können wir die Hypothesen einfach übersetzen: $H_{0}\colon\beta_{4}=0$
  bzw. $H_{0}\colon\beta_{2}=0$. Das wird klassisch als
  \highl{Kovarianzanalyse} bezeichnet.
\end{bsp}

\begin{bsp}[Reaktionszeit von Busfahrern]
  Es wird die Reaktionszeit von Busfahrern auf unterschiedlichen Linien
  betrachtet. Das $y_{i}=\alpha_{k}+\epsilon_{ik}$ mit $k=1,\dotsc,K$ der
  Nummer der Linie und $i=1,\dotsc,n$ Numerierung der Busfahrer. Es ist $\E
  Y_{i}= \alpha_{k}= \begin{cases}\alpha_{1}& k=1\\
			\vdots& \vdots\\
			\alpha_{k}& k=K
		      \end{cases}$. Die Prüfung wird wiederum mit einer
  Dummyvariable vorgenommen. Es ist $\ID_{ik}=
  \begin{cases}
    1 & \text{Fahrer $i$ fährt Linie $k$}\\
    0 & \text{sonst}
  \end{cases}$.  Dann ist $Y_{i}=\sum_{k=1}^{K}
  \alpha_{k}\ID_{ik}+\epsilon_{i}$. Die Annahme für die Verteilung von
  $\epsilon_{i}$ ist $\epsilon_{i}\sim N(O,\sigma^{2})$ unabhängig und
  identisch verteilt. Es ist $\mu_{i}= \sum_{k=1}^{K} \alpha_{k}\ID_{ik}$. Es
  interessiert die Hypothese $H_{0}\colon\alpha_{1}=\dotsb=\alpha_{k}$. Dieser
  Ansatz heißt \highl{Varianzanalyse}.
\end{bsp}

\begin{bsp}[Vorkommen der blauflügligen Ödlandschrecke (Oedipoda caerulescens)]
  Die Zielgröße $y_{i}$ ist das Vorkommen. Das kann nur die Werte 0 oder 1
  annehmen. Weiter bezeichnet $x_{i}$ den Offenbodenanteil. Das bisherige
  Herangehen muss hier geändert werden. Denn das $y$ kann nur die Werte 0 oder
  1 annehmen. Der obige Ansatz kann aber immer beliebige Werte annehmen.

  Jetzt beginnen wir mit dem stochastischen Teil. Wir nutzen die
  Binomialverteilung $y_{i}\sim\text{Bin}(1,\mu_{i})$ mit $\mu_{i}\in(0,1)$.
  Im deterministischen Teil ergibt sich $\mu_{i}= h(\underbrace{\beta_{1}+
  \beta_{2}x_{i}}_{\text{\highl[Prädiktor!linearer]{linearer Prädiktor}}})$.
  Das $h$ heißt \highl{Responsefunktion}. Was wäre eine vernünftige
  Responsefunktion? Sie sollte monoton, stetig sein und Wert in $(0,1)$ haben.
  Vernünftige Kandidaten sind stetige Verteilungsfunktionen. Typisch wäre
  $h=\Phi(\cdot)$, also die Verteilungsfunktion der Standard"=Normalverteilung
  oder $h(x)=\frac{1}{1+e^{-x}}$ Verteilungsfunktion der logistischen
  Verteilung. Diese Klasse von Modellen werden als verallgemeinerte lineare
  Modelle bezeichnet.
\end{bsp}

\begin{bsp}[Entwicklung des Körpergewichts von mehreren Säuglingen im ersten
  Lebensjahr]
  Wir setzen $y_{ij}$ das Körpergewicht von Kind $i$ zum Zeitpunkt $x_{j}$.
  \missingfigure{Graf mit verschiedenen Gewichtspunkten, $x_{j}$ aufd x"~Achse
    und $y_{ij}$ auf y"~Achse}
  Es ist $y_{ij}= \beta_{1}+ \beta_{2}x_{j} +\epsilon_{ij}$. Dann ist nicht
  Anname, dass die $\epsilon_{ij}$ unabhängig und identisch verteilt sind,
  \emph{nicht vernünftig}. Wir haben eine Gruppierung der Daten. Das führt zu
  stochastischer Abhängigkeit. Die Einführung von Dummyvariablen birgt ein
  Problem. Es ist zwar für jedes Kind möglich. Aber wir wollen keine Aussage
  für \emph{jedes} Kind, sondern eine allgemeine Aussage wie sich die Kinder
  im ersten Lebensjahr entwickeln.

  Hierfür nutzt man gemischte Modelle. Dabei wird mehr Zufall eingeführt,
  indem man die individuellen Unterschiede als zufällig modellieren. Wir haben
  $y_{ij}= (\beta_{1}+ b_{1i})+ (\beta_{2}+b_{2i}) x_{ij} +\epsilon_{ij}$. In
  diesem Modell können wir nun sagen, $\epsilon_{ij}\sim N(O,\sigma^{2}),
  b_{1i}\sim N(O,\sigma^{2}_{1}), b_{2i}\sim N(O,\sigma^{2}_{2})$. Zwischen
  den Größen $b_{1i}$ und $b_{2i}$ gibt es eine Korrelation $\cov(b_{1i},
  b_{2i})= \rho\sigma_{1}\sigma_{2}$. Aber die $b_{1i}, b_{2i}$ sind
  unabhängig von den $\epsilon_{ij}$.
\end{bsp}

\chapter{Exponentialfamilien}
%def 2.1
\begin{defini}
  Ein Zufallsvektor $Y=(Y_{1},\dotsc, Y_{n})$ besitz eine Verteilung aus einer
  \highl{Exponentialfamilie}, falls er eine Dichte bzw. Wahrscheinlichkeitsfunktion
  besitzt, die sich in der Form
  \begin{gather*}
    f(y|\Theta)= f((y_{1},\dotsc, y_{n})|(\Theta_{1},\dotsc,\Theta_{n}))= h(y)
       \exp\{\sum_{i=1}^{k} \eta_{i}(\Theta) T_{i} (y)-c(\Theta)\}
  \end{gather*}
  darstellen lässt. Die Familie heißt
  \highl[Exponentialfamilie!$k$"~parametrige]{$k$"~parametrige
  Exponentialfamilie}, falls $k$ die kleinste Zahl, für die so eine
  Darstellung möglich ist, ist.
\end{defini}



\clearpage
\appendix

\chapter{Übungsaufgaben}

\begin{enumerate}
  %Übung vom 2008-10-27
 \item Überlegen Sie sich, welche Arten der Verteilung Sie kennen.
  \begin{itemize}
   \item Normalverteilung
   \item Exponentialverteilung
   \item Binomialverteilung
   \item Poissonverteilung
   \item Gleichverteilung
   \item Gammaverteilung
   \item hypergeometrische Verteilung
   \item Bernoulliverteilung
   \item $\chi^{2}$"~Verteilung
   \item logistische Verteilung
   \item Fischersche $F$"~Verteilung
   \item Studentsche $t$"~Verteilung
   \item Lorentzverteilung
   \item Erlangverteilung
   \item Weibullverteilung
   \item Boltzmannverteilung
   \item Multinomialverteilung
   \item geometrische Verteilung
  \end{itemize}
\end{enumerate}

\begin{thebibliography}{99}
 \bibitem{mathmode} Math mode von Herbert Voss,\\
  \url{http://www.dante.de/CTAN//info/math/voss/mathmode/Mathmode.pdf}

 \bibitem{shmathguide} Short Math Guide for \LaTeX{},\\
  \url{ftp://ftp.ams.org/pub/tex/doc/amsmath/short-math-guide.pdf}
\end{thebibliography}

\clearpage
\pdfbookmark[0]{Index}{index}
\printindex

\end{document}
