% Einige zusätzliche Informationen für rubber
%  rubber erkennt nicht, dass die Datei weg kann, daher sagen wir es ihm
% rubber: clean $base.thm
%  rubber soll nach Änderungen an der Datei nochmal bauen
% rubber: watch $base.thm
% rubber: index.tool      xindy
% rubber: index.language  german-din
%
% scrreprt trifft am Besten die Bedürfnisse eines Skripts, das ganze wird
% zweiseitig (twoside), d.h. es wird zwischen linker und rechter Seite
% unterschieden, und wir verwenden zwischen den Absätzen einen Abstand
% von einer halben Zeile (halfparskip) und dafür keinen Absatzeinzug,
% wobei die letzte Zeile eines Absatzes zu min. 1/4 leer ist.

\RequirePackage[l2tabu,orthodox]{nag}  % nag überprüft den Text auf veraltete
                   % Befehle oder solche, die man nicht in LaTeX verwenden
                   % soll -- l2tabu-Checker in LaTeX

\RequirePackage[ngerman=ngerman-x-latest]{hyphsubst} % einbinden der neuen
                   % Trennmuster, diese korrigieren einige Fehler der alten
                   % und bieten mehr Trennstellen

\documentclass[ngerman,draft,parskip=half*,twoside]{scrreprt}

\usepackage{ifthen}
\usepackage{index}
\usepackage{xcolor}
\usepackage[draft=false,colorlinks,bookmarksnumbered,linkcolor=blue,breaklinks]{hyperref}

\usepackage[utf8]{inputenc}
\usepackage{babel}
\usepackage{lmodern}		% Latin Modern
\usepackage[T1]{fontenc}        % T1-Schriften notwendig für PDFs
\usepackage[intlimits,leqno]{amsmath}
\usepackage[all,warning]{onlyamsmath}  % warnt bei Verwendung von nicht
                                       % amsmath-Umgebungen z.\,B. $$...$$
\usepackage{amssymb}     % wird für \R, \C,... gebraucht
\usepackage{fixmath}     % ISO-konforme griech. Buchstaben
\usepackage[euro]{isonums} % definiert Komma als Dezimaltrennzeichen

\usepackage[amsmath,thmmarks,hyperref]{ntheorem} % für die Theorem-Umgebungen
                                                 % (satz, defini, bemerk)
\usepackage{xspace}      % wird weiter unten gebraucht
\usepackage{slashbox}    % für schräge Striche links oben in der
                         % Tabelle; s. texdoc slashbox

\usepackage{paralist}    % besseres enumerate und itemize und neue
                         % compactenum/compactitem; s. texdoc paralist

\usepackage{svn}         % Zum Auswerten und ordentlichen Darstellen der
                         % SVN-Schlüsselwörter (s. vor \begin{document})
                         % dafür muss in SVN noch das Flag svn:keywords
                         % auf "LastChangedRevision LastChangedDate"
                         % gesetzt werden
\usepackage{ellipsis}    % Korrektur für \dots
\usepackage{fixltx2e}
\usepackage[final,babel]{microtype} % Verbesserung der Typographie
\usepackage[partialup]{kpfonts} % Das Paket kpfonts korrigiert die Darstellung
                                % von \partial. Das muss aufrecht gesetzt
                                % werden.

\usepackage{mathtools}   % Zur Definition von \abs und \norm
\usepackage{todonotes}   % definiert den Befehl \todo{} um sich leicht
                         % Markierungen für offene Aufgaben zu setzen; wird
                         % auch für \help (s.u.) verwendet
% Damit auch die Zeichen im Mathemode in Überschriften fett sind
% <news:lzfyyvx3pt.fsf@tfkp12.physik.uni-erlangen.de>
\usepackage{braket}
\usepackage{mathabx}
\usepackage{nicefrac}

\usepackage[text]{esdiff}


\addtokomafont{sectioning}{\boldmath}

% nach dem Theoremkopf wird ein Zeilenumbruch eingefügt, die Schrift des
% Körpers ist normal und der Kopf wird fett gesetzt
\theoremstyle{break}
\theoremnumbering{arabic}
\theorembodyfont{\normalfont}
\theoremheaderfont{\normalfont\bfseries}

% Das Ende von Umgebungen, für die kein Beweis erbracht wurde, soll mit einer
% leeren Box gekennzeichnet werden. Wenn jedoch ein Beweis erbracht wurde,
% soll kein Zeichen ausgegeben werden (die ausgefüllte Box vom proof wird
% verwendet); man beachte die spezielle Definition von \theoremheaderfont für
% die Umgebung proof
% \newboolean{hasproof}
% \theoremheaderfont{\global\hasprooffalse\normalfont\bfseries}
% \theoremsymbol{\ifthenelse{\boolean{hasproof}}{}{\ensuremath{_\Box}}}

% Die folgenden Umgebungen werden einzeln nummeriert und am Ende jedes
% Kapitels zurückgesetzt
\newtheorem{satz}{Satz}[chapter]
\newtheorem{bemerk}{Bemerkung}[chapter]
\newtheorem{defini}{Definition}[chapter]
\newtheorem{bsp}{Beispiel}[chapter]
\newtheorem{festl}{Festlegung}[chapter]
\newtheorem{folg}{Folgerung}[chapter]
\newtheorem{lemma}{Lemma}[chapter]

% Die folgenden Theoremumgebungen bekommen keine Nummer
\theoremstyle{nonumberbreak}
\newtheorem{fakt}{Fakt}

% \theoremheaderfont{\global\hasprooftrue\scshape}
\theoremheaderfont{\scshape}
\theorembodyfont{\normalfont}
% Das Zeichen am Ende eines Beweises
\theoremsymbol{\ensuremath{_\blacksquare}}
% \theoremsymbol{q.\,e.\,d.}
\newtheorem{proof}{Beweis:}

% Hier die Definition, wie \autoref die Umgebungen nennen soll, die mit
% \newtheorem definiert wurden
\newcommand*{\satzautorefname}{Satz}
\newcommand*{\bemerkautorefname}{Bemerkung}
\newcommand*{\definiautorefname}{Definition}
\newcommand*{\bspautorefname}{Beispiel}
\newcommand*{\festlautorefname}{Festlegung}
\newcommand*{\folgautorefname}{Folgerung}
\newcommand*{\lemmaautorefname}{Lemma}
% Zwischen Unter- und Unterunterabschnitten sollte nicht unterschieden
% werden.
\renewcommand*{\subsectionautorefname}{Abschnitt}
\renewcommand*{\subsubsectionautorefname}{Abschnitt}

\pagestyle{headings}

\newcommand*{\R}{\mathbb{R}}      % reelle Zahlen
\newcommand*{\C}{\mathbb{C}}      % komplexe Zahlen
\newcommand*{\N}{\mathbb{N}}      % natürliche Zahlen
\newcommand*{\Q}{\mathbb{Q}}      % gebrochene Zahlen
\newcommand*{\XX}{\mathbb{X}}
\newcommand*{\Z}{\mathbb{Z}}      % ganze Zahlen

% Wenn irgendwo Unklarheiten zum Inhalt im Skript auftreten, können sie
% einfach mit \help{Ich verstehe das nicht} hervorgehoben werden. Dies
% macht es leichter sie alle zu finden und auch ganz einfach
% auszublenden, indem man den Befehl einfach leer definiert
\newcommand*{\help}[1]{\todo[color=green!40]{#1}}

% Um wichtige Begriffe im Text überall gleich vorzuheben (gleiches
% Markup), sollte dieser Befehl verwendet werden. Das Argument wird
% automatisch als Indexeintrag verwendet. Dieser kann aber auch als
% optionales Argument selbst bestimmt werden.
\newcommand*{\highl}[2][]{\textbf{\boldmath{#2}}%
  \ifthenelse{\equal{#1}{}}{\index{#2}}{\index{#1}}%
}

% Befehl für die Darstellung der Gliederungsüberschriften im Index
\newcommand*{\lettergroup}[1]{\minisec{#1}}

% Für Leute, die nicht gern o.\,B.\,d.\,A. jedesmal eintippen wollen
\newcommand*{\obda}{o.\,B.\,d.\,A.\xspace}

% Diese Befehle sind dafür gedacht, dass die Symbole für "genau dann wenn"
% im ganzen Dokument gleich aussehen. Außerdem erlaubt es eine schnelle
% Veränderung aller Stellen, falls der Prof. doch nicht mehr gdw nimmt,
% sondern \Leftrightarrow.
\newcommand*{\gdw}{\ifthenelse{\boolean{mmode}}%
			       {\mspace{8mu}gdw\mspace{8mu}}%
			       {$gdw$\xspace}}
\newcommand*{\gdwdef}{\ifthenelse{\boolean{mmode}}%
			       {\mspace{8mu}gdw_{def}\mspace{8mu}}%
			       {$gdw_{def}$\xspace}}

% Um sicherzustellen, dass jeder Betrag/jede Norm links und rechts die
% Striche bekommt, sind diese Befehle da. Damit kann man nicht die
% rechten Striche vergessen und es wird etwas übersichtlicher. Aus
% mathtools.pdf, z. B. \abs[\big]{\abs{a}-\abs{b}} \leq \abs{a+b}
\DeclarePairedDelimiter{\abs}{\lvert}{\rvert}
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}

% Für die Gaußklammer empfiehlt sich ebenso eine Definition mit
% Benutzung von mathtools.
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}

% Das original Epsilon sieht nicht so toll aus
\renewcommand*{\epsilon}{\varepsilon}
% ... und mancheinem gefällt auch das Phi nicht
\renewcommand*{\phi}{\varphi}
\renewcommand*{\hat}{\widehat}

\newcommand*{\CA}{\mathcal{A}}
\newcommand*{\CL}{\mathcal{L}}
\newcommand*{\CM}{\mathcal{M}}

\newcommand*{\EE}{\mathbb{E}}
\newcommand*{\II}{\mathbb{I}}

\makeindex

\SVN $LastChangedRevision$
\SVN $LastChangedDate$

\begin{document}

\title{Statistische Verfahren}
\author{Jens Schumacher}
\date{Semester:  WS 2012/13}
\maketitle

\clearpage
\chapter*{Vorwort}

{\itshape
  Dieses Dokument wurde als Skript für die auf der
  Titelseite genannte Vorlesung erstellt und wird jetzt im Rahmen des
  Projekts
  "`\href{http://uni-skripte.lug-jena.de/}
  {Vorlesungsskripte der Fakultät für Mathematik}
  \href{http://uni-skripte.lug-jena.de/}{und Informatik}"'
  weiter betreut. Das
  Dokument wurde nach bestem Wissen und Gewissen angefertigt. Dennoch
  garantiert weder der auf der Titelseite genannte Dozent, die Personen,
  die an dem Dokument mitgewirkt haben, noch die
  Mitglieder des Projekts für dessen Fehlerfreiheit. Für etwaige Fehler
  und dessen Folgen wird von keiner der genannten Personen eine Haftung
  übernommen. Es steht jeder Person frei, dieses Dokument zu lesen, zu
  verändern oder auf anderen Medien verfügbar zu machen, solange ein
  Verweis auf die Internetadresse des Projekts
  \url{http://uni-skripte.lug-jena.de/}
  enthalten ist.

  Diese Ausgabe trägt die Versionsnummer~\SVNLastChangedRevision{} und ist vom
  \SVNDate{}. Eine neue Ausgabe könnte auf der Webseite des Projekts verfügbar
  sein.

  Jeder ist dazu aufgerufen, Verbesserungen, Erweiterungen und
  Fehlerkorrekturen für das Skript einzureichen bzw. zu melden oder diese
  selbst einzupflegen -- einfach eine E-Mail an die
  \href{mailto:uni-skripte@lug-jena.de}{Mailingliste
  \nolinkurl{<uni-skripte@lug-jena.de>}} senden. Weitere Informationen
  sind unter der oben genannten Internetadresse verfügbar.

  Hiermit möchten wir allen Personen, die an diesem Skript mitgewirkt
  haben, vielmals danken:
  \begin{itemize}
   \item \href{mailto:jens@kubieziel.de}{Jens Kubieziel
    \nolinkurl{<jens@kubieziel.de>}} (2012/3)
  \end{itemize}
}

\clearpage
\pdfbookmark[0]{Inhaltsverzeichnis}{inhaltsverzeichnis}
\tableofcontents

\clearpage
\pdfbookmark[0]{Auflistung der Sätze}{theoremlist}
\chapter*{Auflistung der Theoreme}

\pdfbookmark[1]{Sätze}{satzlist}
\section*{Sätze}
\theoremlisttype{optname}
\listtheorems{satz}

\pdfbookmark[1]{Definitionen und Festlegungen}{definilist}
\section*{Definitionen und Festlegungen}
% \theoremlisttype{all}
\listtheorems{defini,festl}

\chapter{Einführung}

In der Wahrscheinlichkeitstheorie gibt es einen Raum $(\Omega,\CA,P)$ mit der
nichtleeren Menge~$\Omega$, der $\sigma$-Algebra~$\CA$ und dem Maß~$P$. Dann
hat man eine Zufallsvariable~$Y$. Diese bildet die folgende Abbildung
$(\Omega,\CA,P)\xrightarrow{Y} (\Omega_{Y}, \CA_{Y}, P^{Y})$. Für das
Wahrscheinlichkeitsmaß gilt: $P^{Y}\colon \CA_{Y}\rightarrow[0,1]$.

\begin{bsp}
  Es kann $P^{Y}$ das Lebesgue-Maß auf $[0,1]$ sein. Dies entspricht der
  Dichtefunktion. Falls eine Dichtefunktion existiert, so gilt:
  \begin{gather*}
    P(\Set{\omega | Y(\omega)\in[a,b]})= \int_{a}^{b} f(y)\,dy\\
    P(a\leq Y\leq b)=\int_{a}^{b} f(y)\,dy
  \end{gather*}

  Für die Normalverteilung schreibt man $Y\sim N(\mu,\sigma^{2})$. Die
  Dichtefunktion ist
  \begin{gather*}
    f(y)=
       \frac{1}{\sqrt{2\pi\sigma^{2}}}e^{-\frac{(y-\mu)^{2}}{2\sigma^{2}}}=
       \phi_{\mu,\sigma^{2}}(y)
  \end{gather*}

  Die Poissonverteilung hat keine Dichtefunktion. Es ist $\Omega_{N}=\N$.
  \begin{gather*}
    P(\Set{\omega | Y(\omega)=k})=P(Y=k)=P^{Y}(\{k\})= \frac{\lambda^{k}}{k!}
       e^{-\lambda}\\
    P(Y\in[a,b])= \sum_{a\leq k\leq b} \frac{\lambda^{k}}{k!}e^{-\lambda}
  \end{gather*}
\end{bsp}

Wenn wir uns andererseits mit Statistik beschäftigen, ist nicht die »ideale
Situation« gegeben. Typischerweise hat man ein (statistisches) Experiment. Wie
schon oben bei der Wahrscheinlichkeitstheorie haben wir
$(\Omega,\CA,P)\xrightarrow{Y}(\Omega_{Y},\CA_{Y},\Set{P_{\theta} | \theta
\in\Theta})$.
Letzteres ist eine Familie von Wahrscheinlichkeitsmaßen, wobei der
Parameter~$\theta$ unbekannt ist.

\begin{defini}[Statistisches Experiment]
  $(Y,\Omega,\CA,\Set{P_{\theta} | \theta \in\Theta})$
  heißt \highl[Experiment!statistisches]{statistisches Experiment}.
\end{defini}

\begin{defini}[Schätzer]
  Ein \highl{Schätzer} ist eine messbare Abbildung $T\colon
  \Omega_{Y}\rightarrow \Theta$.
\end{defini}

\begin{bemerk}
  Vorschrift zur Berechnung eines Schätzwertes für unbekannte Parameter.
\end{bemerk}

\begin{defini}[Schätzung]
  Für eine konkrete Realisierung $y=Y(\omega)$ heißt $T(y)$ \highl{Schätzung}
  für den unbekannten Parameter~$\theta$.
\end{defini}

Es ist sinnvoll, die Definition des zentralen Grenzwertsatzes sowie die das
Poissonschen Grenzwertsatzes zu wiederholen.

\chapter{Konstruktion von Schätzern}

Zur Konstruktion von Schätzern verwenden wir in dieser Vorlesung zwei Methoden:
\begin{itemize}
 \item Momentenmethode
 \item Maximum"=Likelihood"=Methode
\end{itemize}

\begin{bsp}
  Poissonverteilung: Wir haben Beobachtungen $y_{1},\dotsc, y_{n}$. Diese
  werden als Realisierung von unabhängigen poissonverteilten Zufallsgrößen mit
  dem Parameter~$\lambda$  aufgefasst. Wir nennen die $Y_{1},\dotsc, Y_{n}$,
  d.\,h. das statistische Experiment sieht wie folgt aus:
  $(\underline{Y}=(Y_{1},\dotsc, Y_{n}), \Omega, \CA,
  \text{Poisson}(\lambda))$ mit $\lambda>0$. Eigentlich ist das Poissonmaß ein
  Produktmaß, wird also $n$"~mal multipliziert. Wenn der unbekannte
  Parameter~$\lambda$ bekannt wäre, könnte man alle interessierenden
  Wahrscheinlichkeiten ausrechnen: $P(Y_{1}=y_{1},\dotsc, Y_{n}=y_{n})$ ist
  wegen der Unabhängigkeit gleich dem Ausdruck $P(Y_{1}=y_{1})\cdot\dotso
  \cdot P(Y_{n}=y_{n})$. Dies ist aber:
  \begin{gather*}
    \frac{\lambda^{y_{1}}}{y_{1}!}e^{-\lambda}\cdot\dotso
       \cdot\frac{\lambda^{y_{n}}}{y_{n}!}e^{-\lambda}=
       \frac{\lambda^{y_{1}+\dotsb+ y_{n}}}{y_{1}!\cdot\dotso \cdot y_{n}!}
       e^{-n\lambda}
  \end{gather*}
\end{bsp}

Die Grundidee der Maximum"=Likelihood"=Methode ist es, als Schätzer für den
unbekannten Parameter denjenigen Wert zu wählen, der die Wahrscheinlichkeit
der beobachteten Daten maximiert.

Likelihood"=Funktion: Betrachte für konkrete Realisierungen (Beobachtungen)
$y_{1},\dotsc, y_{n}$ die Wahrscheinlichkeit $P(Y_{1}=y_{1},\dotsc,
Y_{n}=y_{n})$ als Funktion des unbekannten Parameters:
$\CL(\lambda|(y_{1},\dotsc, y_{n}))= \frac{\lambda^{y_{1}+\dotsb+
y_{n}}}{y_{1}!\cdot\dotso \cdot y_{n}!} e^{-n\lambda}$. Vor dem Ableiten und
Nullsetzen erfolgt der Übergang zur
Log"~Likelihood"=Funktion~$l(\lambda|(y_{1},\dotsc, y_{n}))=
\log(\CL(\lambda|(y_{1},\dotsc, y_{n})))= (y_{1}+\dotsb+
y_{n})\cdot\log\lambda-n\lambda -\log(y_{1}!\cdot\dotso y_{n}!)$. Die
Ableitung ist $\diffp{}{\lambda} l(\lambda|(y_{1},\dotsc,
y_{n}))= \frac{y_{1}+\dotsb+ y_{n}}{\lambda} -n=0\Rightarrow\hat{\lambda}
=\frac{y_{1}+\dotsb+ y_{n}}{n}$. Das ist die Maximum"=Likelihood"=Schätzung
für den unbekannten Parameter.

Welche Art von Modellen werden wir behandeln?
\begin{itemize}
 \item unabhängige Beobachtungen
 \item nicht notwendig identische Verteilung der Beobachtungen
\end{itemize}

\begin{bsp}[Körpergewicht eines Säuglings im ersten Lebensjahr]
  Beobachtungen: $y_{i}$ Körpergewicht und $x_{i}$ Alter für $i=1,\dotsc,n$;
  Insgesamt also $(y_{i}, x_{i})$\\
  Statistisches Modell: Wir sehen $x_{i}$ als fest an. Das $y_{i}$ ist die
  Realisierung einer Zufallsgröße~$Y_{i}$.\\
  deterministischer Teil: $\EE Y_{i}= f(x_{i})=
  \beta_{1}+\beta_{2}x_{i}=\colon\mu_{i}$\\
  stochastischer Teil: $Y_{i}\sim N(\mu_{i},\sigma^{2})$\\
  Dies ist ein einfaches lineares Regressionsmodell.

  % VL vom 16.10.2012
  Wir wollen uns überlegen, warum Maximum"=Likelihood"=Schätzung der Parameter
  $\beta_{1}$ und $\beta_{2}$ zum Erfolg führt. Die Likelihood"=Funktion,
  die entsprechende Log"~Likelihood"=Funktion sowie die partiellen Ableitungen
  sind:
  \begin{gather*}
    \CL(\beta_{1},\beta_{2}| y_{1},\dotsc, y_{n})= \prod_{i=1}^{n}
  \frac{1}{\sqrt{2\pi\sigma^{2}}} e^{-\frac{(y_{i}- (\beta_{1}+
  \beta_{2}x_{i}))^{2}}{2\sigma^{2}}}\\
    l(\beta_{1},\beta_{2}| y_{1},\dotsc, y_{n})= \sum_{i=1}^{n} -\frac{1}{2}
       \log(2\pi\sigma^{2}) -\frac{(y_{i}- (\beta_{1}+
       \beta_{2}x_{i}))^{2}}{2\sigma^{2}}\\
    \diffp{l(\beta_{1},\beta_{2})}{{\beta_{1}}}= \sum_{i=1}^{n} -\frac{2(y_{i}-
       (\beta_{1}+ \beta_{2}x_{i}))}{2\sigma^{2}}\cdot(-1)=
       \frac{1}{\sigma^{2}} \sum_{i=1}^{n} y_{i}-
       (\beta_{1}+\beta_{2}x_{i})= 0\\
    \diffp{l(\beta_{1},\beta_{2})}{{\beta_{2}}}= \sum_{i=1}^{n} -\frac{2(y_{i}+
       (\beta_{1}+\beta_{2}x_{i}))}{2\sigma^{2}} \cdot(-x_{i})=
       \frac{1}{\sigma^{2}} \sum_{i=1}^{n}
       x_{i}y_{i}-(\beta_{1}+\beta_{2}x_{i})x_{i}=0
  \end{gather*}

  Weiterhin haben wir:
  \begin{align*}
    \sum_{i=1}^{n} (y_{i}-\beta_{1}-\beta_{2}x_{i}) &= 0 &
    \sum_{i=1}^{n} y_{i}-n\beta_{1}-\beta_{2}\sum_{i=1}^{n}x_{i} &= 0\\
    \frac{1}{n} \sum_{i=1}^{n} y_{i}- \beta_{2}\frac{1}{n} \sum_{i=1}^{n}
       x_{i} &= \beta_{1} &
    \overline{y_{n}}-\beta_{2}\overline{x_{n}} &= \beta_{1}\\
    \intertext{Einsetzen ergibt}\\
    \sum_{i=1}^{n} (x_{i}y_{i}-( \overline{y_{n}} -\beta_{2}\overline{x_{n}}
       +\beta_{2}x_{i})x_{i}) &=0 &
    \sum_{i=1}^{n} x_{i}y_{i} -\overline{y_{n}} \sum_{i=1}^{n} x_{i}+
       \beta_{2} \overline{x_{n}} \sum_{i=1}^{n} x_{i}-\beta_{2}\sum_{i=1}^{n}
       x_{i}^{2} &= 0
   \end{align*}
  \begin{align*}
  \hat{\beta_{2}} &= \frac{\sum_{i=1}^{n} x_{i}y_{i} -\overline{y_{n}}
       \sum_{i=1}^{n} x_{i}}{\sum_{i=1}^{n} x_{i}^{2}- \overline{x_{n}}
       \sum_{i=1}^{n} x_{i}}= \frac{\frac{1}{n} \sum_{i=1}^{n} x_{i}y_{i} -\overline{x_{n}}
       \overline{y_{n}}}{\frac{1}{n} \sum_{i=1}^{n} x_{i}^{2}-
       \overline{x_{n}}^{2}}\\
    \hat{\beta_{1}} &= \overline{y_{n}}- \hat{\beta_{2}} \overline{x_{n}}
  \end{align*}
  Die $(\hat{\beta_{1}}, \hat{\beta_{2}})$ stellen das Maximum der
  Likelihood"=Funktion dar. Dazu müssen wir die zweite Ableitung untersuchen.
  Weiterhin ist $\hat{\beta_{2}}$ genau dann nicht eindeutig bestimmt, wenn
  $x_{1}= \dotsb= x_{n}= \overline{x_{n}}$.
\end{bsp}

\begin{bemerk}
  Die Maximum"=Likelihood"=Schätzung maximiert:
  \begin{gather*}
    \sum_{i=1}^{n} -(y_{i}+(\beta_{1}+\beta_{2}x_{i}))^{2}
  \end{gather*}
  also minimiert die Summe $\sum_{i=1}^{n}
  (y_{i}-(\beta_{1}+\beta_{2}x_{i}))^{2}$, d.\,h. Summe der quadratischen
  Abweichungen zwischen beobachteten Werten und vom Modell vorhergesagten
  Werten. Also ist der Maximum"=Likelihood"=Schätzer gleich dem Schätzer nach
  der Methode der kleinsten Quadrate.
\end{bemerk}

\begin{bsp}[Artenzahlen auf den Galapagos"=Inseln]
  \begin{itemize}
   \item nichtlinearer Zusammenhang
   \item Normalverteilung nicht sinnvoll, da
    \begin{itemize}
     \item diskrete Zielgröße
     \item nichtnegative Zielgröße
    \end{itemize}
   \item Variabilität der Zielgröße wächst mit steigender Inselgröße
  \end{itemize}

  Für den stochastischen Teil nehmen wir an, dass eine Poissonverteilung
  vorliegt: $Y_{i}\sim\text{Poisson}(\mu_{i})$. Im deterministischen Teil
  haben wir: $\mu_{i}= \EE Y_{i}= \beta_{1}+ \beta_{2}x_{i}$. Der lineare
  Ansatz kann zu unmöglichen Erwartungswerten führen.  Daher betrachten wir
  $\log(\mu_{i})= \log(\EE Y_{i})= \beta_{1}+\beta_{2}x_{i}$. Dies heißt dann
  \highl[Poissonregression!einfache]{einfache Poissonregression}.
  Die Varianz von $Y_{i}$ ist $\mu_{i}= e^{\beta_{1}+\beta_{2}x_{i}}$.

  Kann man mit der Maximum"=Likelihood"=Schätzer der Parameter zum Erfolg
  kommen? Die Likelihood"=Funktion ist
  \begin{gather*}
    \CL(\beta_{1},\beta_{2}| y_{1},\dotsc, y_{n})= \prod_{i=1}^{n}
       \frac{\mu_{i}^{y_{i}}}{y_{i}!} e^{-\mu_{i}}
  \end{gather*}
  Die Log"~Likelihood"=Funktion ist
  \begin{gather*}
    l(\beta_{1},\beta_{2}| y_{1},\dotsc, y_{n})= \sum_{i=1}^{n} y_{i} \log
       \mu_{i}- \log y_{i}!- \mu_{i}= \sum_{i=1}^{n}
       y_{i}(\beta_{1}+\beta_{2}x_{i}) -\log y_{i}!
       -e^{\beta_{1}+\beta_{2}x_{i}}
  \end{gather*}
  Die partiellen Ableitungen sind:
  \begin{align*}
    \diffp{l(\beta_{1},\beta_{2})}{{\beta_{1}}} &= \sum_{i=1}^{n} (y_{i}-
       e^{\beta_{1}+\beta_{2}x_{i}})=0\\
    \diffp{l(\beta_{1},\beta_{2})}{{\beta_{2}}} &= \sum_{i=1}^{n} (y_{i}x_{i}
       -e^{\beta_{1}+\beta_{2}x_{i}}\cdot x_{i})=0
  \end{align*}
  Dies ist ein nichtlineares Gleichungssystem in $\beta_{1}, \beta_{2}$. Zur
  Lösung müssen wir also numerische Lösungsverfahren des Gleichungssystems
  anwenden.
\end{bsp}

\begin{bsp}[Schwefeldioxidbelastung der Luft in amerikanischen Städten]
  Das $y_{i}$ stellt den Schwefeldioxidgehalt der Luft dar. Hier gibt es
  mehrere Einflussgrößen: $x_{i2}$ ist die mittlere Jahrestemperatur, $x_{i3}$
  ist die Anzahl der Betriebe mit mehr als 20~Beschäftigten, $x_{i4}$ die
  Einwohnerzahl, $x_{i5}$ mittlerer Jahresniederschlag, $x_{i6}$ mittlere
  Windgeschwindigkeit, $x_{i7}$ mittlere Anzahl der Regentage.

  Wenn wir ein Modell dafür bauen wollen, so soll es nicht zu kompliziert
  sein. Für den deterministischen Teil sagen wir, $y_{i}$ sei eine Realisierung
  einer Zufallsgröße $Y_{i}$ und $\EE Y_{i}= \beta_{1}+\beta_{2}x_{i2}+\dotsb+
  \beta_{7}x_{i7}=\mu_{i}$. Für den stochastischen Teil nehmen wir an, dass
  $Y_{i}\sim N(\mu_{i},\sigma^{2})$. Dies ist ein
  \highl[Regressionsmodell!multiples]{multiples lineares Regressionsmodell}. 
\end{bsp}

\begin{bsp}[Geburtsgewicht von Säuglingen]
  Das $x_{i}$ ist die Dauer der Schwangerschaft und $y_{i}$ ist das
  Geburtsgewicht. Letzteres fassen wir als Realisierung einer Zufallsgröße
  $Y_{i}$ auf. Im deterministischen Teil ist
  \begin{gather*}
    \EE Y_{i}= \mu_{i}=
       \begin{cases}
	 \beta_{11}+\beta_{21}x_{i} & \boy\\
	 \beta_{12}+\beta_{22}x_{i} & \girl
       \end{cases}
  \end{gather*}
  Eine interessante Hypothese wäre, dass die beiden Parameter
  $\beta_{21}=\beta_{22}$ gegen die Alternativhypothese
  $\beta_{21}\neq\beta_{22}$.

  Man kann ein gemeinsames Modell für Mädchen und Jungen mit Hilfe von
  \highl{Indikatorvariablen} (oder \highl{Dummyvariablen}). Es ist:
  \begin{gather*}
    \II_{i}=
       \begin{cases}
	 1 & \girl\\
	 0 & \boy
       \end{cases}\\
    \EE Y_{i}= \mu_{i}= \beta_{1}+ \beta_{2}\II_{i}+ \beta_{3}x_{i}+
       \beta_{4}x_{i}\II_{i}= \beta_{1}+\beta_{2}x_{i2}+
       \beta_{3}x_{i3}+ \beta_{4}x_{i4}
  \end{gather*}
  Dies ist ein multiples lineares Regressionsmodell mit sehr speziellen
  Einflussgrößen. Es ist
  \begin{gather*}
    \EE Y_{i}=
       \begin{cases}
	 \beta_{1}+\beta_{3}x_{i}& \boy\\
	 (\beta_{1}+\beta_{2})+ (\beta_{3}+\beta_{4})x_{i} & \girl
       \end{cases}
  \end{gather*}
  Die ursprüngliche Hypothese entspricht $H_{0}\colon\beta_{4}=0$.

  Für den stochastischen nehmen wir wieder an, dass $Y_{i}\sim
  N(\mu_{i},\sigma^{2})$. Aus historischen Gründen wird hier von einem
  \highl{Kovarianz-Analyse-Modell} oder \highl{Kovarianzanalyse} gesprochen.
\end{bsp}

\begin{bsp}[Beregnungsexperiment]\label{bsp:5}
  Die Einflussgröße sind vier unterschiedliche Beregnungsverfahren. Die
  Zielgröße ist der Ertrag einer Kartoffelsorte. Beim $Y_{ij}$ steht das $i$
  für ein Beregnungsverfahren und das $j$ für eine Parzelle. Es ist $\EE
  Y_{ij}= \mu_{i}$. Der Erwartungswert des Ertrags hängt vom
  Beregnungsverfahren ab. Der stochastische Teil ist $Y_{ij}\sim
  N(\mu_{i},\sigma^{2})$. Wir verwenden wieder Dummyvariablen
  \begin{align*}
    \II_{ij2} &=
       \begin{cases}
	 1 & i=2\\
	 0 & \text{sonst}
       \end{cases} &
       \II_{ij3} &=
       \begin{cases}
	 1 & i=3\\
	 0 & \text{sonst}
       \end{cases}&
    \II_{ij4} &=
       \begin{cases}
	 1& i=4\\
	 0& \text{sonst}
       \end{cases}
     \end{align*}
     \begin{gather*}
       \EE Y_{ij}= \beta_{1}+\beta_{2}\II_{ij2}+
       \beta_{3}\II_{ij3}+ \beta_{4}\II_{ij4}
       =
       \begin{cases}
	 \beta_{1} & i=1\\
	 \beta_{1}+\beta_{2} & i=2\\
	 \beta_{1}+\beta_{3} &i=3\\
	 \beta_{1}+\beta_{4}& i=4
       \end{cases}
     \end{gather*}
  Interessante Hypothese: $H_{0}\colon \mu_{1}=\mu_{2}=\mu_{3}=\mu_{4}$ bzw.
  $H_{0}\colon \beta_{2}=\beta_{3}=\beta_{4}$. Bei nur qualitativen
  Einflussgrößen spricht man von einer \highl{Varianzanalyse}.
\end{bsp}

% Vorlesung vom 22.10.2012
\begin{bsp}
  Wir haben nun zwei Einflussgrößen:
  \begin{itemize}
   \item Beregnungsverfahren
   \item Sorte
  \end{itemize}
  Die Zielgröße ist der Ertrag. Es ist naheliegend, dass man bei beobachteten
  Daten eine Mehrfachindizierung verwendet: $Y_{ijk}$. Dabei steht das $i$ für
  das Beregnungsverfahren, das $j$ für die Sorte und $k$ für die Wiederholung.
  Es sind $i=1,\dotsc,4$, $j=1,2$ und $k=1,\dotsc,n_{ij}$. Ds $y_{ijk}$ ist
  eine Realisierung einer Zufallsgröße $Y_{ijk}$. Der Erwartungswert $\EE
  Y_{ijk}= \mu_{ij}$ und es ist $Y_{ijk}\sim N(\mu_{ij}, \sigma^{2})$. Unser
  Ziel ist es, eine lineare Funktion von Einflussgrößen hinzuschreiben. Dazu
  müssen wir das \autoref{bsp:5} erweitern und eine zusätzliche Dummyvariable
  einführen.
  \begin{gather*}
    \II_{ijk,2}=
       \begin{cases}
	 1& \text{Beregnungsverfahren 2}\\
	 0
       \end{cases}\\
    \II_{ijk,l}=\delta_{il} \qquad l=2,3,4\\
    \II_{ijk,5}=
       \begin{cases}
	 1& j=2\\
	 0
       \end{cases}
  \end{gather*}
  Im Modell haben wir $\mu_{ij}= \EE Y_{ijk}= \beta_{1}+
  \beta_{2}\II_{ijk,2}+ \beta_{3}\II_{ijk,3}+
  \beta_{4}\II_{ijk,4}+ \beta_{5}\II_{ijk,5}$. Aufgesplittet
  ergibt das mit $b$ für das Beregnungsverfahren und $s$ für die Sorte:
  \begin{gather*}
    \mu_{ij}=
       \begin{cases}
	 \beta_{1}& b=1, s=1\\
	 \beta_{1}+\beta_{2} & b=2,s=1\\
	 \beta_{1}+\beta_{3} & b=3,s=1\\
	 \beta_{1}+\beta_{4} & b=4, s=1\\
	 \beta_{1}+ \beta_{5} & b=1, s=2\\
	 \beta_{1}+\beta_{2}+\beta_{5}& b=2,s=2\\
	 \beta_{1}+\beta_{3}+\beta_{5} & b=3,s=2\\
	 \beta_{1}+\beta_{4}+\beta_{5} & b=4,s=2
       \end{cases}
  \end{gather*}

  Wir können aber auch ein Modell mit Wechselwirkungen betrachten, d.\,h. der
  Effekt der Beregnungsverfahren ist nicht bei allen Sorten gleich. Formell
  multiplizieren wir die Indikatorvariablen für die Beregnung und Sorte. Das
  ergibt $\mu_{ij}= \beta_{1}+
  \beta_{2}\II_{ijk,2}+ \beta_{3}\II_{ijk,3}+
  \beta_{4}\II_{ijk,4}+ \beta_{5}\II_{ijk,5}+
  \beta_{6}\underbrace{\II_{ijk,2}\II_{ijk,5}}_{x_{ijk,6}}+
  \beta_{7}\underbrace{\II_{ijk,3}\II_{ijk,5}}_{x_{ijk,7}}+
  \beta_{8}\underbrace{\II_{ijk,4}\II_{ijk,5}}_{x_{ijk,8}}$.
  Eine interessante Hypothese wäre $H_{0}\colon\beta_{6}=\beta_{7}=\beta_{8}$
  (\emph{keine} Wechselwirkung). Allgemeine Anmerkungen zur Parameterzahl: $1+
  (a-1)+(b-1)+(a-1)(b-1)= 1+a-1+b-1+ab-a-b+1= ab$.

  Das Modell wird als \highl[Varianzanalyse!zweifache]{zweifache
  Varianzanalyse} mit oder ohne Wechselwirkung bezeichnet.
\end{bsp}

\begin{bsp}[Vorkommen der blauflügligen Ödlandschrecke]
  Die Einflussgröße ist der Offenbodenanteil. Die Zielgröße ist entweder $0$
  oder $1$, also Vorkommen bzw. Nichtvorkommen. Im stochastischen Teil ist die
  Normalverteilung nicht so sinnvoll. Die einzige Verteilung, die wir kennen,
  ist die Bernoulliverteilung. Diese können wir als Spezialfall der
  Binomialverteilung interpretieren. In dieser Form schreiben wir das auf:
  $Y_{i}\sim\text{Bin}(1,p_{i}=\mu_{i})$. Im deterministischen Teil geht es
  darum, diesen Erwartungswert der Zielgröße zu modellieren: $\EE Y_{i}=
  p_{i}=\mu_{i}= \beta_{1}+\beta_{2}x_{i}$. Der Ansatz ist nicht unbedingt
  sinnvoll, da man in Bereiche kommt, die kleiner als $0$ oder größer als $1$
  sind. Dies ist für relative Häufigkeiten nicht sinnvoll. Um dies zu beheben,
  fügen wir die \highl{Responsefunktion} $h$ ein. An die Funktion~$h$ stellen
  folgende Forderungen:
  \begin{itemize}
   \item Wertebereich $(0,1)$
   \item stetig differenzierbar
   \item bijektiv
   \item streng monoton steigend
  \end{itemize}
  Diese Forderungen werden von einer Verteilungsfunktion einer stetigen
  Zufallsgröße erfüllt. Hier bietet sich an, Verteilungsfunktion der
  Standardnormalverteilung zu benutzen: $h(x)=\Phi(x)$. Also haben wir $\EE
  Y_{i}= \Phi(\beta_{1}+\beta_{2}x_{i})$. Dieses Modell heißt
  \highl{Probitmodell}.

  Ein anderer Ansatz ist $h(x)=\frac{1}{1+e^{-x}}$. Diese Funktion ist die
  Verteilungsfunktion der logistischen Verteilung. Wir erhalten dann $\EE
  Y_{i}= \frac{1}{1+e^{-(\beta_{1}+\beta_{2}x_{i})}}$, das \highl{Logitmodell}.
\end{bsp}

Gemeinsamkeiten aller Beispiele:
\begin{itemize}
 \item Linearkombination von Einflussgrößen. Wir werden dies
  \highl[Prädiktor!linearen]{linearen Prädiktor} nennen.
 \item Verteilungsannahme aus einer »schönen« Klasse von
  Wahrscheinlichkeitsverteilungen. Diese heißen
  \highl{Exponential-Dispersionsfamilien}.
 \item linearer oder nichtlinearer Zusammenhang zwischen linearem Prädiktor
  und dem Erwartungswert der Zielgröße. Dies nennen wir später Responsefunktion.
 \item eine Zielgröße
\end{itemize}
\begin{gather*}
  \EE Y_{i}= h(\beta_{1}+\beta_{2}x_{i2}+\dotsb+ \beta_{k}x_{ik})=
     h(\underline{\beta}^{T}\underline{x})
\end{gather*}

Das nennt sich \highl[Modell!verallgemeinertes lineares]{verallgemeinerte
lineare Modelle}.

\chapter{Exponentialfamilien}

Das Ziel ist es, eine flexible Klasse von Wahrscheinlichkeitsverteilungen zu
haben. Diese sollen einheitlich theoretisch behandelt werden.

\begin{table}[htb]
  \centering
  \begin{tabular}{l|l}
    Normalverteilung $N(\mu,\sigma^{2})$ &
    Poissonverteilung $\text{Poisson}(\mu)$\\
    Gleichverteilung auf $[0,\theta]$ &  diskrete Verteilung auf
    $\{0,\dotsc,k\}$\\
    Exponentialverteilung $\text{Exp}(\lambda)$ &  Binomialverteilung
    $\text{Bin}(n,p)$\\
    $\chi^{2}$"~Verteilung $\chi^{2}(n)$ &  geometrische Verteilung
    $\text{geom}(p)$\\
    Gammaverteilung & hypergeometrische Verteilung
    $\text{hypgeo}(N,M,n)$\\
    Student"=Verteilung ($t$"~Verteilung)\\
    logistische Verteilung\\
    Fishersche $F$"~Verteilung
  \end{tabular}
  \caption{Verschiedene Verteilungen}
  \label{tab:verteilungen}
\end{table}

\begin{defini}[Natürliche oder lineare Exponentialfamilie]
  Eine Zufallsgröße~$Y$ besitzt eine Verteilung aus einer
  \highl[Exponentialfamilie!natürliche]{natürlichen Exponentialfamilie}, falls
  sich ihre Dichte bzw. Wahrscheinlichkeitsfunktion in der Gestalt $f_{Y}(y)=
  c(y) e^{\theta y-A(\theta)}$ für $\theta\in\Omega\subseteq\R$ darstellen
  lässt. Der Parameter~$\theta$ heißt
  \highl[Parameter!natürlicher]{natürlicher Parameter} oder
  \highl[Parameter!kanonischer]{kanonischer Parameter}.
\end{defini}

\begin{bemerk}
  Die Parametrisierung ist nicht eindeutig und die Menge
  \begin{gather*}
    \Omega^{\ast}=\Set{\theta\in\R | \int_{-\infty}^{\infty}
      c(y)e^{\theta y}\,dy<\infty}
  \end{gather*}
  heißt \highl[Parameterraum!natürlicher]{natürlicher
  Parameterraum}.
\end{bemerk}

\begin{defini}
  Ein Zufallsvektor $\underline{Y}= (Y_{1},\dotsc, Y_{n})$ besitzt eine
  Verteilung aus einer linearen Exponentialfamilie mit dem natürlichen
  Parameter $\underline{\theta}=(\theta_{1},\dotsc,\theta_{n})$, falls die
  Dichte die Gestalt $f_{Y}(y)= c(y)
  e^{\underline{\theta}^{T}\underline{y}-A(\underline{\theta})}$ besitzt.
\end{defini}

Wir gehen von den Zufallsgrößen $Y_{1},\dotsc, Y_{n}$ aus. Das sind
unabhängige Zufallsgrößen
aus Exponentialfamilie mit Parameter~$\theta_{1},\dotsc,\theta_{n}$. Wir
betrachten die gemeinsame Dichte, also die Dichtefunktion von $Y_{1},\dotsc,
Y_{n}$:
\begin{align*}
  f_{Y_{1},\dotsc, Y_{n}}(y_{1},\dotsc, y_{n}) &= \prod_{i=1}^{n}
  f_{Y_{i}}(y_{i})= \prod_{i=1}^{n} c(y_{i})
  e^{\theta_{i}y_{i}-A(\theta_{i})}\\
  &= \prod_{i=1}^{n} c(y_{i}) e^{\sum_{i=1}^{n} \theta_{i}y_{i}-
    \sum_{i=1}^{n} A(\theta_{i})}\\
  &= c^{*}(\underline{y}) e^{\underline{\theta}^{T}\underline{y}-A^{*}(\underline{\theta})}
\end{align*}

\begin{bsp}[Poissonverteilung]\label{bsp:3.1}
  Die Poissonverteilung hat die Wahrscheinlichkeitsfunktion $f_{Y}(y)=
  \frac{\mu^{y}}{y!} e^{-\mu}= \frac{1}{y!}e^{y\log\mu-\mu}$ mit
  $y=0,1,2,\dotsc$. Dabei ist $\log\mu=\theta$ der natürliche Parameter und
  $A(\theta)= \mu=e^{\theta}$.
\end{bsp}

\begin{bsp}[Exponentialverteilung]
  Die Wahrscheinlichkeitsfunktion der Exponentialverteilung ist
  $f_{Y}(y)= \lambda e^{-\lambda y}\II_{[0,\infty)}(y)=
  \II_{[0,\infty)}(y) e^{-\lambda y+\log\lambda}$. Hier ist $c(y)=
  \II_{[0,\infty)}(y)$, der natürliche Parameter ist $\theta=-\lambda$
  und $A(\theta)= -\log\lambda= -\log(-\theta)$.

  Die Exponentialverteilung ist eine spezielle Exponentialfamilie.
\end{bsp}

%Vorlesung vom 23.10.2012
\begin{bsp}[Gleichverteilung]
  Wir reden von der stetigen Gleichverteilung, d.\,h. $Y$ ist gleichverteilt
  auf dem Intervall $(0,\theta)$. Die Dichtefunktion hat die Gestalt:
  $f_{Y}(y)= \frac{1}{\theta}\II_{[0,\theta]}(y)$. Das $y$ und $\theta$
  sind untrennbar verbunden. Damit haben wir keine Chance eine Darstellung in
  der Exponentialform hinzukriegen.

  Allgemein lässt sich sagen, falls der Wertebereich (Träger) einer Verteilung
  vom Parameter~$\theta$ abhängt, dann liegt keine Exponentialfamilie vor.
\end{bsp}

\section{Konstruktion von Exponentialfamilien}

Wir betrachten eine Zufallsgröße~$Y$ mit der Dichtefunktion $h(y)$. Es
existiere der Erwartungswert $\EE e^{\theta y}=
\int_{-\infty}^{\infty} e^{\theta y}h(y)\,dy=
m(\theta)$. Die Funktion $m(\theta)$ heißt
\highl[Funktion!momentenerzeugende]{momentenerzeugende
  Funktion}\index{momentenerzeugend} der Zufallsgröße~$Y$.

\begin{defini}[Moment]
  Das $k$"~te \highl{Moment} einer Zufallsgröße ist $\EE Y^{k}=
  \int_{-\infty}^{\infty} y^{k}h(y)\,dy$. Das $k$"~te zentrale Moment ist
  $\EE(Y-\EE Y)^{k}= \int_{-\infty}^{\infty} (y-\EE Y)^{k} h(y)\,dy$. 
\end{defini}

\begin{satz}[Eigenschaften der momentenerzeugenden Funktion]
  Es sei $Y$ eine Zufallsgröße mit momentenerzeugender Funktion $m(\theta)$.
  Existiert ein $\theta_{0}>0$ derart, dass $m(\theta_{0})<\infty$ und
  $m(-\theta_{0})<\infty$, dann besitzt $m(\theta)$ eine Taylorentwicklung um
  $\theta=0$. Genauer gilt:
  \begin{gather*}
    m(\theta)=\sum_{k=0}^{\infty} \frac{\theta^{k}}{k!} \EE
       Y^{k}\qquad\abs{\theta}\leq\theta_{0}
  \end{gather*}
  Insbesondere folgt die Existenz sämtlicher Momente und
  \begin{gather*}
    \EE Y^{k}= m^{(k)}(0)\qquad\forall k\geq0
  \end{gather*}
\end{satz}

Wenn wir die Gleichung $m(\theta)=\int_{-\infty}^{\infty} e^{\theta
y}h(y)\,dy$ mit $\frac{1}{m(\theta)}$ multiplizieren, erhalten wir die
\highl[Exponentialfamilie!konjugierte]{konjugierte Exponentialfamilie}:
\begin{gather*}
  1=\int_{-\infty}^{\infty} h(y)e^{\theta y}\frac{1}{m(\theta)}\,dy=
     \int_{-\infty}^{\infty} h(y)e^{\theta y- \log m(\theta)}\,dy 
\end{gather*}

\section{Momente einer natürlichen Exponentialfamilie}

Wir haben eine Zufallsgröße $Y$ mit einer momentenerzeugenden Funktion
$m(\theta)$ und $Z$ aus der konjugierten Exponentialfamilie mit der Dichte
$f_{Z}(z)= h(z)e^{\theta z-\log m(\theta)}$. Die momentenerzeugende Funktion von
$Z$ ist:
\begin{align*}
  m_{Z}(t) &= \EE e^{tZ}= \int_{-\infty}^{\infty} e^{tz}h(z)e^{\theta
     z- \log m(\theta)}\,dz= \frac{1}{e^{\log m(\theta)}}
     \int_{-\infty}^{\infty} h(z) e^{tz+\theta z}\,dz\\
  &= \frac{1}{m(\theta)} \underbrace{\int_{-\infty}^{\infty}
     h(z) e^{(t+\theta)z}}_{\EE e^{(t+\theta)z}= m_{Y}(t+\theta)}\,dz=
     \frac{m_{Y}(t+\theta)}{m_{Y}(\theta)}\\
  \EE_{\theta}Z &= \left.\diff{}{t} \frac{m(t+\theta)}{m(\theta)}\right|_{t=0}
     = \left.\diff{}{t} \frac{e^{A(t+\theta)}}{e^{A(\theta)}}\right|_{t=0} =
     \left.\frac{e^{A(t+\theta)} A'(t+\theta)}{e^{A(\theta)}}\right|_{t=0}=
     A'(\theta)\\
  \intertext{Das zweite Moment ist}
  \EE_{\theta}Z^{2} &=\frac{e^{A(t+\theta)}(A'(t+\theta))^{2} +e^{A(t+\theta)}
  A''(t+\theta)}{e^{A(\theta)}}= A'(\theta)^{2}+A''(\theta)\\
  \intertext{Die Varianz ist}
  \EE_{\theta}(Z-\EE_{\theta}Z)^{2} &= \EE_{\theta}Z^{2}-(\EE_{\theta}Z)^{2}=
     A'(\theta)^{2}+ A''(\theta)- A'(\theta)^{2}= A''(\theta)
\end{align*}
\todo{Stimmt die obige Formel bzw. Herleitung?}

Die
Normierungskonstante $A(\theta)$ liefert auf einfache Weise Erwartungswert und
Varianz der Exponentialfamilie. Wir bezeichnen den Erwartungswert mit
$\mu=\mu(\theta)= \EE_{\theta}Z=A'(\theta)$ und die Varianz mit
$\sigma^{2}=\sigma^{2}(\theta)= \EE_{\theta}(Z-\EE_{\theta}Z)^{2}= A''(\theta)$.

Weiterhin ist die Varianz von $Z$ größer als $0$. Damit folgt, dass die zweite
Ableitung $A''(\theta)0$ größer als $0$ und dass $A(\theta)$ eine konvexe Funktion ist.
Daneben ist $\mu(\theta)= A'(\theta)=\tau(\theta)$ eine streng monoton
wachsende stetige Funktion. Also ist $\tau$ eine bijektive Abbildung des
Parameterraums~$\Omega$ in eine Teilmenge $\CM\subseteq\R$ (mean value space)
mit $\tau\colon\Theta\rightarrow\R$. Die Exponentialfamilie kann durch den
Erwartungswert parametrisiert werden: $\theta=\tau^{-1}(\mu)$. Insbesondere
kann die Varianz als Funktion des Erwartungswertes dargestellt werden
(\autoref{def:1-varfunkt}).

\begin{defini}[Varianzfunktion]\label{def:1-varfunkt}
  Die Funktion
  \begin{gather*}
    v(\mu)= A''(\tau^{-1}(\mu))
  \end{gather*}
  heißt \highl{Varianzfunktion} der Exponentialfamilie.
\end{defini}

Linkfunktionen im verallgemeinerten linearen Modell:
\begin{gather*}
  g(\EE Y_{i})= g(\beta_{1}+\beta_{2}x_{i2}+\dotsb+ \beta_{k}x_{ik})
\end{gather*}
Wir wählen $g(\mu)= \tau^{-1}(\mu)=
\tau^{-1}(\tau(\theta))=\theta=\underline{x}^{T}\underline{\beta}$, d.\,h. für
diese Wahl von $g$ ist der natürliche Parameter $\theta$ der
Exponentialfamilie eine Linearkombination der unbekannten Parameter. Man
bezeichnet $g(\mu)=\tau^{-1}(\mu)$ als \highl[Linkfunktion!kanonische]{kanonische Linkfunktion} oder
\highl[Linkfunktion!natürliche]{natürliche Linkfunktion}.

\begin{bsp}
  Exponentialverteilung $Y\sim\text{Exp}(\lambda)$ und $f_{Y}(y)=
  \II_{[0,\infty)}(y) e^{-\lambda y+\log\lambda}= c(y)e^{\theta
  y-(-\log(-\theta))}$. Die erste Ableitung ist $A'(\theta)=
  -\frac{1}{-\theta}\cdot(-1)=\frac{-1}{\theta}=\EE_{\theta} Y= \mu(\theta)$.
  Die zweite Ableitung ist $A''(\theta)= \frac{1}{\theta^{2}}$. Die
  Umkehrfunktion ist $\theta=\tau^{-1}(\mu)= -\frac{1}{\mu}$ und $v(\mu)=
  A''(\tau^{-1}(\mu))= \mu^{2}$.
\end{bsp}

\section{Exponential-Dispersionsfamilien}

\begin{bsp}[Normalverteilung mit bekanntem $\sigma^{2}$]
  Wir haben:
  \begin{align*}
    Y&\sim N(\mu,\sigma^{2})\\
    f_{Y}(y) &= \frac{1}{\sqrt{2\pi\sigma^{2}}}
       e^{-\frac{(y-\mu)^{2}}{2\sigma^{2}}} = \frac{1}{\sqrt{2\pi\sigma^{2}}}
       e^{-\frac{y^{2}}{2\sigma^{2}} +\frac{y\mu}{\sigma^{2}}-
       \frac{\mu^{2}}{2\sigma^{2}}} = \frac{1}{\sqrt{2\pi\sigma^{2}}}
       e^{-\frac{y^{2}}{2\sigma^{2}}} e^{y\frac{\mu}{\sigma^{2}}-
       \frac{\mu^{2}}{2\sigma^{2}}}
  \end{align*}
  Die erste Ableitung ist $A'(\theta)= \theta\sigma^{2}=
  \frac{\mu}{\sigma^{2}}=\sigma^{2}=\mu$ und die zweite
  $A''(\theta)=\sigma^{2}$. Für die Varianzfunktion haben wir
  $v(\mu)=\sigma^{2}$. Diese ist unabhängig von $\mu$.
\end{bsp}

Wir benötigen eine Verallgemeinerung der Exponentialfamilie, um einen
flexiblen Zusammenhang zwischen Erwartungswert und Varianz zu ermöglichen:
$\text{Var}(Y)= \phi\cdot v(\mu)$. Dies kann man durch eine entsprechende
Skalierung hinbekommen.
Dabei sei $Y$ eine Zufallsgröße mit der Dichte $f_{Y}(y)= c(y)e^{\theta y-
A^{*}(\theta)}$ und wir betrachten die skalierte Zufallsgröße $Z=\phi Y$ mit
$\phi\in(0,\infty)$. Wir rechnen die Dichtetransformation aus $P(Z\in B)=
P(\phi Y\in B)= P(Y\in\frac{B}{\phi})= \int_{\nicefrac{B}{\phi}} c(y)
e^{\theta y- A^{*}(\theta)}\,dy$. Wir ersetzen das $y$ durch
$\frac{z}{\phi}$ und erhalten $\int_{B} c(\frac{z}{\phi})e^{\frac{\theta
z}{\phi}- A^{*}(\theta)}\frac{1}{\theta}\,dz= \int_{B}
\underbrace{\frac{1}{\phi}c(\frac{z}{\phi})}_{c(z,\phi)} \underbrace{e^{\frac{\theta z-\phi
A^{*}(\theta)}{\phi}}}_{\phi A^{*}(\theta)=A(\theta)}\,dz$. Die Dichte von $Z$
ist $f_{Z}(z)= c(z,\phi)e^{\frac{\theta z-A(\theta)}{\phi}}$.

\begin{defini}
  Eine Zufallsgröße $Z$ besitzt eine Verteilung aus einer
  Exponential"=Dispersionsfamilie, falls die Dichtefunktion die Gestalt
  $f_{Z}(z)= c(\frac{z}{\phi}) e^{\frac{\theta z-A(\theta)}{\phi}}$ besitzt.
\end{defini}

\begin{bemerk}[Momente]
  Die momentenerzeugende Funktion ist
  \begin{align*}
    m(t)&= \EE e^{tY}=
  \int_{-\infty}^{\infty} e^{ty} c(y,\phi) e^{\frac{\theta
  y-A(\theta)}{\phi}}\,dy= \int_{-\infty}^{\infty} c(y,\phi) e^{\frac{\phi
       ty}{\phi}} e^{\frac{\theta
  y-A(\theta)}{\phi}}\,dy=\\
    &= \int_{-\infty}^{\infty} c(y,\phi) e^{\frac{y(\theta+\phi t)-
       A(\theta)}{\phi}}\,dy= \int_{-\infty}^{\infty} c(y,\phi)
  e^{\frac{y(\theta+\phi t)-A(\theta+\phi t)+A(\theta+\phi
  t)-A(\theta)}{\phi}}\,dy\\
    &= e^{\frac{A(\theta+\phi t)-A(\theta)}{\phi}}
  \int_{-\infty}^{\infty} c(y,\phi) e^{\frac{y(\theta+\phi t)-A(\theta+\phi
  t)}{\phi}}\,dy
  \end{align*}
  Also Integral ist die Dichtefunktion einer
  Exponential"=Dispersionsfamilie mit Parameter $\theta+\phi t$. Die erste
  Ableitung ist $m'(t)= e^{\frac{A(\theta+\phi
  t)-A(\theta)}{\phi}}\cdot\frac{A'(\theta+\phi t)}{\phi}\phi$ und
  $m'(0)=A'(\theta)=\mu$. Die zweite Ableitung ist $m''(t)=
  e^{\frac{A(\theta+\phi t)-A(\theta)}{\phi}}\cdot(A'(\theta+\phi t))^{2}+
  e^{\frac{A(\theta+\phi t)-A(\theta)}{\phi}}\cdot A''(\theta+\phi t)\phi$
  und $m''(0)= A'(\theta)^{2}+A''(\theta)\phi$. Schließlich ist die Varianz
  von $Y$ gleich $\phi A''(\theta)=\phi v(\mu)$.
\end{bemerk}

%Vorlesung vom 29.10.2012
\chapter{Die Maximum"=Likelihood"=Schätzung und Fisher"=Information}
Der Ausgangspunkt ist, dass wir eine parametrisierte Familie von
Wahrscheinlichkeitsverteilungen haben. In unserem Fall ist das immer eine
Exponential"=Dispersionsfamilie mit der Dichte $c(y,\phi)e^{\frac{\theta
y-A(\theta)}{\phi}}$. Auf der Grundlage konkreter Beobachtungen $y_{1},\dotsc,
y_{n}$ soll der unbekannte Parameter $\theta$ geschätzt werden. Im
statistischen Modell nehmen wir an, dass die $y_{1},\dotsc, y_{n}$
Realisierung von unabhängig und identisch verteilten Zufallsgrößen
$Y_{1},\dotsc, Y_{n}$ mit der Dichtefunktion $f_{Y}(y)= f(y; \theta)=
f_{\theta}(y)$ sind.

Damit können wir die Likelihood"=Funktion schreiben: $\CL(\theta|
y_{1},\dotsc, y_{n})= \prod_{i=1}^{n}
f_{\theta}(y_{i})$

\begin{bsp}\label{bsp:4.1}
  Nehmen wir poissonverteilte Zufallsgrößen mit $n=10$ und $y_{1}=4$,
  $y_{2}=4$, $y_{3}=5$, $y_{4}=8$, $y_{5}=3$, $y_{6}=8$, $y_{7}=9$, $y_{8}=6$,
  $y_{9}=6$, $y_{10}=2$. Die Likelihood"=Funktion ist dann $\CL(\theta|
  y_{1},\dotsc, y_{10})= \prod_{i=1}^{10} \frac{\mu^{y_{i}}}{y_{i}!} e^{-\mu}=
  e^{-10\mu}\cdot\mu^{\sum_{i=1}^{10} y_{i}} \prod_{i=1}^{10} \frac{1}{y_{i}!}$
\end{bsp}

\begin{defini}
  $\hat{\theta}=\hat{\theta}(y_{1},\dotsc, y_{n})$ heißt
  \highl{Maximum"=Likelihood"=Schätzung}, falls gilt,
  $\CL(\hat{\theta}|y_{1},\dotsc, y_{n})= \sup_{\theta\in\Theta}
  \CL(\theta|y_{1},\dotsc, y_{n})$.
\end{defini}

\section{Berechnung der Maximum"=Likelihood"=Schätzung}
Zunächst erfolgt der Übergang zur Log"~Likelihood"=Funktion
$l(\theta|y_{1},\dotsc, y_{n})= \log\CL(\theta|y_{1},\dotsc, y_{n})=
\log\prod_{i=1}^{n} f_{\theta}(y_{i})= \sum_{i=1}^{n} \log f_{\theta}(y_{i})$.

\begin{defini}
  Die Ableitung der Log"~Likelihood"=Funktion nach dem Parameter $\theta$:
  \begin{gather*}
    s(\theta|y_{1},\dotsc, y_{n})= \diffp{}{\theta} l(\theta|y_{1},\dotsc,
       y_{n})= \sum_{i=1}^{n} \diffp{}{\theta} (\log f_{\theta}(y_{i}))
  \end{gather*}
  heißt \highl{Scorefunktion}. Die Gleichung $s(\theta|y_{1},\dotsc, y_{n})=0$
  heißt \highl{Scoregleichung}.
\end{defini}

\begin{bsp}
  Weiterführung von \autoref{bsp:4.1}:
  \begin{align*}
    s(\theta|y_{1},\dotsc, y_{n}) &= \sum_{i=1}^{n} \diffp{}{\theta} (-\theta
       +y_{i}\log\theta-\log y_{i}!)= \sum_{i=1}^{n} (-1+\frac{y_{i}}{\theta})\\
    &= -n +\sum_{i=1}^{n} \frac{y_{i}}{\theta}
  \end{align*}
\end{bsp}

Wie gut ist nun die Maximum"=Likelihood"=Schätzung für den Parameter $\theta$?
Die Gestalt der Likelihood"=Funktion in der Umgebung der Maximalstelle liefert
ein Maß für die Genauigkeit der Maximum"=Likelihood"=Schätzung. Eine Idee ist
es, eine quadratische Approximation der Loh"~Likelihood"=Funktion in der
Umgebung der Maximalstelle zu machen:
\begin{align*}
  l(\theta|y_{1},\dotsc, y_{n}) &= \log\CL(\theta| y_{1},\dotsc, y_{n})\\
  &= l(\hat{\theta}|y_{1},\dotsc, y_{n})+ \underbrace{l'(\hat{\theta}|y_{1},\dotsc,
     y_{n})}_{s(\hat{\theta}|y_{1},\dotsc, y_{n})=0}(\theta-\hat{\theta})+
     \nicefrac{1}{2}l''(\hat{\theta}|y_{1},\dotsc, y_{n})
     (\theta-\hat{\theta})^{2}+R\\
  &= l(\hat{\theta}|y_{1},\dotsc, y_{n})+     \nicefrac{1}{2}l''(\hat{\theta}|y_{1},\dotsc, y_{n})
     (\theta-\hat{\theta})^{2}+R
\end{align*}

\begin{defini}
  Die Funktion $I(\theta|y_{1},\dotsc, y_{n})= -\diffp[2]{}{\theta}
  l(\theta|y_{1},\dotsc, y_{n})$ heißt \highl{Fisher"=Information}. Die Größe
  $I(\hat{\theta}|y_{1},\dotsc, y_{n})= -\diffp[2]{}{\theta}
  l(\theta|y_{1},\dotsc, y_{n})|_{\theta=\hat{\theta}}$ heißt
  \highl[Fisher-Information!beobachtete]{beobachtete Fisher"=Information}.
\end{defini}

\begin{bsp}
  Seien $Y_{1},\dotsc, Y_{n}$ unabhängig, identisch verteilte Zufallsgrößen
  mit $N(\mu,\sigma^{2})$ mit bekanntem $\sigma^{2}$. Die Beobachtungen sind
  $y_{1},\dotsc, y_{n}$. Die Likelihood"=Funktion ist:
  \begin{gather*}
    \CL(\theta|y_{1},\dotsc, y_{n}) = \prod_{i=1}^{n}
       \frac{1}{\sqrt{2\pi\sigma^{2}}} e^{-\frac{(y_{i}-\theta)}{2\sigma^{2}}}\\
    l(\theta|y_{1},\dotsc, y_{n})= \sum_{i=1}^{n} (-\frac{1}{2}
       \log(2\pi\sigma^{2})-\frac{(y_{i}-\theta)}{2\sigma^{2}})\\
    s(\theta|y_{1},\dotsc, y_{n})= \sum_{i=1}^{n}
       -\frac{2(y_{i}-\theta)}{2\sigma^{2}}\cdot(-1)= \frac{1}{\sigma^{2}}
       \sum_{i=1}^{n} (y_{i}-\theta)\\
    s(\theta|y_{1},\dotsc, y_{n})=  \frac{1}{\sigma^{2}}
       \sum_{i=1}^{n} (y_{i}-\theta)=0\Rightarrow\hat{\theta}=\frac{1}{n}
       \sum_{i=1}^{n} y_{i}\\
    I(\theta|y_{1},\dotsc, y_{n})= -\diffp[2]{}{\theta} l(\theta|y_{1},\dotsc,
       y_{n})= -\diffp{}{\theta}s(\theta|y_{1},\dotsc, y_{n})=
       -(-\frac{n}{\sigma^{2}})=\frac{n}{\sigma^{2}}=
       I(\hat{\theta}|y_{1},\dotsc, y_{n})
  \end{gather*}

  Andererseits: $\text{Var}(\hat{\theta})= \text{Var}(\frac{1}{n}
  \sum_{i=1}^{n} Y_{i})= \frac{1}{n^{2}}\text{Var}(\sum_{i=1}^{n} Y_{i})=
  \frac{1}{n^{2}} \sum_{i=1}^{n} \text{Var}(Y_{i})=
  \frac{1}{n^{2}}n\cdot\sigma^{2}= \frac{\sigma^{2}}{n}=
  \frac{1}{I(\hat{\theta})}$.
\end{bsp}

\begin{bsp}
  In dem Beispiel kommen wir wieder zur Poissonverteilung zurück. Dabei hatten
  wir $s(\theta|y_{1},\dotsc, y_{n})= -n+\frac{1}{\theta}\sum_{i=1}^{n} y_{i}$
  bestimmt. Es ist $n=\frac{1}{\theta}\sum_{i=1}^{n}y_{i}$, also
  $\hat{\theta}= \frac{1}{n} \sum_{i=1}^{n} y_{i}$. Weiterhin ist
  $I(\theta|y_{1},\dotsc, y_{n})= -\diffp{}{\theta} s(\theta|y_{1},\dotsc,
  y_{n})= \frac{1}{\theta^{2}} \sum_{i=1}^{n} y_{i}$. Schließlich haben wir
  $I(\hat{\theta}|y_{1},\dotsc, y_{n})= \frac{n^{2}}{(\sum_{i=1}^{n}
  y_{i})^{2}} \sum_{i=1}^{n} y_{i}= \frac{n^{2}}{\sum_{i=1}^{n} y_{i}}$.
\end{bsp}

Wir betrachten die eingeführten Begriffe jetzt nicht mehr für konkrete
Beobachtungen $y_{1},\dotsc, y_{n}$, sondern für Zufallsgrößen $Y_{1},\dotsc,
Y_{n}$.

Die Scorefunktion kann für unterschiedliche Beobachtungen jeweils verschiedene
Formen annehmen, d.\,h. $\hat{\theta}$ hat je nach Beobachtung verschiedene
Werte.

\begin{defini}
  Für jeden festen Wert $\theta$ heißt die Zufallsgröße
  $s(\theta|Y_{1},\dotsc, Y_{n})=S(\theta)$ \highl{Scorestatistik}.
\end{defini}

\begin{satz}
  Unter Regularitätsbedingungen, die die Vertauschung von Differentiation und
  Integration erlauben, gilt:
  \begin{gather*}
    \EE_{\theta} S(\theta)= 0
  \end{gather*}
  \begin{proof}
    Es ist $\EE_{\theta}S(\theta)= \EE_{\theta}\diffp{}{\theta}
    \log\CL(\theta|Y_{1},\dotsc, Y_{n})= \int \diffp{}{\theta}
    \log\CL(\theta|y_{1},\dotsc, y_{n})\cdot\prod_{i=1}^{n}
    f_{\theta}(y_{i})\,dy_{1}\dotso y_{n}=
    \int\frac{1}{\CL(\theta|y_{y},\dotsc, y_{n})}
    \diffp{}{\theta}\CL(\theta|y_{1},\dotsc, y_{n})\prod_{i=1}^{n}
    f_{\theta}(y_{i})\,dy_{1}\dotso y_{n}= \int\diffp{}{\theta}
    \CL(\theta|y_{1},\dotsc, y_{n})\,dy_{1}\dotso y_{n}= \diffp{}{\theta}\int
    \CL(\theta|y_{1},\dotsc, y_{n})\,dy_{1}\dotso y_{n}\diffp{}{\theta}1=0$.
  \end{proof}
\end{satz}

\begin{bemerk}
  Die Vertauschung von Differentiation und Integration ist insbesondere in den
  Exponential"=Dispersionsfamilien möglich. Für den unbekannten wahren
  Parameter $\theta$ schwanken die Werte der Scorestatistik bzw. der
  Scorefunktionen für unterschiedliche mögliche Beobachtungen $y_{1},\dotsc,
  y_{n}$ um $0$.
\end{bemerk}

Wir betrachten nun an Stelle der Fisher"=Information $I(\theta|y_{1},\dotsc,
y_{n})$ den Ausdruck $I(\theta|Y_{1},\dotsc, Y_{n})$. Dann erhalten wir für
jedes $\theta$ eine Zufallsgröße. Dann gehen wir wieder zum Erwartungswert über.

\begin{defini}
  Die Größe $F(\theta)= \EE_{\theta} I(\theta|Y_{1},\dotsc, Y_{n})=
  \EE_{\theta} -\diffp[2]{}{\theta} l(\theta|Y_{1},\dotsc, Y_{n})$ heißt
  \highl[Fisher"=Information!erwartete]{erwartete Fisher"=Information}.
\end{defini}

% Vorlesung vom 5.11.2012
\begin{bsp}[Poissonverteilung]
  Fisher"=Information: $I(\theta)= -\diffp[2]{l(\theta)}{\theta}=
  \frac{1}{\theta} \sum_{i=1}^{n} y_{i}$. Uns interessiert die beobachtete
  Fisher"=Information an der $\theta=\hat{\theta}= \frac{1}{n} \sum_{i=1}^{n}
  y_{i}$. Also ist $I(\hat{\theta})= \frac{n}{\sum_{i=1}^{n} y_{i}}$. Die
  erwartete Fisher"=Information ist $F(\theta)=
  \EE_{\theta}(I(\theta|Y_{1},\dotsc, Y_{n})=
  \EE_{\theta}-\diffp[2]{l(\theta|Y_{1},\dotsc, Y_{n})}{\theta})=
  \frac{1}{\theta^{2}} \EE_{\theta}\sum_{i=1}^{n} Y_{i}= \sum_{i=1}^{n}
  \EE_{\theta}Y_{i}= \frac{1}{\theta^{2}} n\theta= \frac{n}{\theta}$.
\end{bsp}

\chapter{Lineare Modelle}

\section{Statistisches Modell}

Wir gehen davon aus, dass wir Daten $y_{i}$ für $i=1,\dotsc,n$ haben. Dies
sind Beobachtungen der Zielgröße. Dazu haben wir ein Tupel $(x_{i2},\dotsc,
x_{ik})$ für $i=1,\dotsc,n$. Diese werden »erklärende Variablen« genannt.
Beide können wir zu dem $k$"~Tupel von Beobachtungen $(y_{i},x_{i2},\dotsc,
x_{ik})\in\R^{k}$ zusammenfassen.

Der Modellansatz ist nun $y_{i}=\beta_{1}+b_{2}x_{i2}+\dotsb+
\beta_{k}x_{ik}+u_{i}$. Das $u_{i}$ ist der \highl[Fehlerterm]{Fehler-} oder
\highl{Störterm} und ist nicht direkt beobachtbar. Die $\beta_{j}$ sind
unbekannte, aber als fest angenommene Regressionskoeffizienten. Weiterhin
machen wir Annahmen zu Abweichungen vom linearen Modellansatz. Das
statistische Modell  wäre $u_{i}$ ist eine Realisierung einer Zufallsgröße
$U_{i}$ mit Erwartungswert $0$, d.\,h. keine systematische Abweichung.
Weiterhin ist $U_{i}$ normalverteilt mit Varianz $\sigma^{2}$ ($U_{i}\sim
N(0,\sigma^{2})$, konstante Varianz). Die $y_{i}$ sind Realisierungen von
Zufallsgrößen $Y_{i}$ mit $Y_{i}\sim N(\beta_{1}+\beta_{2}x_{i2}+\dotsb+
\beta_{k}x_{ik}, \sigma^{2})$. Weiterhin wurde implizit eine weitere Annahme
gemacht. Nämlich $x_{i2},\dotsc, x_{ik}$ sind \emph{nicht} zufällig, sondern
fest. Schließlich nehmen wir an, dass die Beobachtungen unabhängig sind,
d.\,h. $Y_{i},\dotsc, Y_{n}$ sind unabhängige Zufallsgrößen.
Dann ergibt sich für das Modell
\begin{gather*}
  Y_{i}= \beta_{1}+\beta_{2}x_{i2}+\dotsb+ \beta kx_{ik}+ U_{i}\qquad
     Y_{i}\sim N(\beta_{1}+\dotsb+\beta_{k}x_{ik}, \sigma^{2}), \text{unabhängig}
\end{gather*}
Dies kann man in einen deterministischen Teil
\begin{gather*}
  \EE Y_{i}= \beta_{1}+\beta_{2}x_{i2}+\dotsb+ \beta_{k}x_{ik}=\colon\mu_{i}
\end{gather*}
und einen stochastischen Teil
\begin{gather*}
  Y_{i}\sim N(\mu_{i}, \sigma^{2}), \text{unabhängig}
\end{gather*}
trennen.

\begin{gather*}
  \underline{Y}=
     \begin{pmatrix}
       Y_{1}\\
       \vdots\\
       \vdots\\
       Y_{n}
     \end{pmatrix}=
     \begin{pmatrix}
       1& x_{12}& \dotso & x_{1k}\\
       1& x_{22}& \dotso & x_{2k}\\
       \vdots& \vdots& \ddots & \vdots\\
       1& x_{n2}& \dotso & x_{nk}
     \end{pmatrix}
     \begin{pmatrix}
       \beta_{1}\\
       \beta_{2}\\
       \vdots\\
       \beta_{k}
     \end{pmatrix}+
     \begin{pmatrix}
       U_{1}\\
       U_{2}\\
       \vdots\\
       U_{n}
     \end{pmatrix}\\
  \underline{Y}= \XX\underline{\beta}+ \underline{U}
\end{gather*}

Das $\XX$ sind alle Beobachtungen der Einflussgröße. Die erste Spalte
entspricht dem Absolutterm $\beta_{1}$ und ist üblicherweise enthalten. Die
Matrix heißt auch \highl{Designmatrix}.

\section{Zufallsvektoren und Transformationen}

Die Zufallsvektoren $\underline{Y}=(Y_{1},\dotsc, Y_{n})$ sind
Zusammenfassungen von einzelnen Zufallsgrößen zu einem Objekt.  Sie sind
charakterisiert durch Verteilungsfunktion $F_{\underline{Y}}(t_{1},\dotsc,
t_{n})= P(Y_{1}<t_{1}, Y_{2}<t_{2},\dotsc, Y_{n}yt_{n})=
P(\Set{\omega\in\Omega | Y_{1}(\omega)<t_{1}\wedge\dotsb\wedge
Y_{n}(\omega)<t_{n}})$. Die Abbildung 
$F_{\underline{Y}}\colon\R^{n}\rightarrow[0,1]$ ist monoton wachsend in jedem
Argument. Die Verteilungsdichte
$f_{\underline{Y}}\colon\R^{n}\rightarrow[0,\infty)$ derart, dass
$F_{\underline{Y}}(t_{1},\dotsc, t_{n})= \int_{-\infty}^{t_{1}} \dotso
\int_{-\infty}^{t_{n}} f_{\underline{Y}}(y_{1},\dotsc, y_{n})\,dy_{1}\dotso
dy_{n}$ und $P(\underline{Y}\in B)\subseteq\R^{n}= \iint_{B}
f_{\underline{Y}}(y_{1},\dotsc, y_{n})\,dy_{1}\dotso dy_{n}$

\begin{bsp}[$n$"~dimensionale Normalverteilung]
  Ein Zufallsvektor $\underline{Y}=(Y_{1},\dotsc, Y_{n})$ besitzt eine
  (reguläre) Normalverteilung, wenn er eine Verteilungsdichte der Form
  $f_{\underline{Y}}(t_{1},\dotsc, t_{n})= \frac{1}{(2\pi)^{\nicefrac{n}{2}}
  \sqrt{\det\Sigma}} \exp\{-\frac{1}{2} (\underline{t}-\underline{\mu})^{T}
  \Sigma^{-1}(\underline{t}-\underline{\mu})\}$ besitzt. Unabhängige
  normalverteilte Zufallsgrößen $Y_{i}\sim N(\mu_{i},\sigma^{2})$ ergeben
  damit $P(Y_{1}<t_{1},\dotsc, Y_{n}<t_{n})= P(Y_{1}<t_{1})\cdot\dotso \cdot
  P(Y_{n}<t_{n})$. Also ist $F_{\underline{Y}}(t_{1},\dotsc, t_{n})=
  \int_{-\infty}^{t_{1}}\dotso \int_{-\infty}^{t_{n}}
  \frac{1}{(2\pi)^{\nicefrac{n}{2}} (\sigma^{2})^{\nicefrac{n}{2}}}
  \exp\{-\frac{1}{2\sigma^{2}} \sum_{i=1}^{n}
  (y_{i}-\mu_{i})^{2}\}\,dy_{1}\dotso dy_{n}=   \int_{-\infty}^{t_{1}}\dotso \int_{-\infty}^{t_{n}}
  \frac{1}{(2\pi)^{\nicefrac{n}{2}} (\sigma^{2})^{\nicefrac{n}{2}}}
  \exp\{-\frac{1}{2\sigma^{2}} 
  (\underline{y}-\underline{\mu})^{T}\cdot\mathbb{I}_{n}\underline{y}-\underline{\mu})\}\,dy_{1}\dotso
  dy_{n}$. Aus weiterer Umstellung ergibt sich:
  \begin{gather*}
    \Sigma=
       \begin{pmatrix}
	 \sigma^{2}& & 0\\
	 & \ddots& \\
	 0& & \sigma^{2}
       \end{pmatrix}
  \end{gather*}
\end{bsp}

\begin{defini}[Erwartungswertvektor]
  Falls für die Komponenten $Y_{i}$ für $i=1,\dotsc,n$ der Erwartungswert $\EE
  Y_{i}$ existiert, dann heißt $\EE\underline{Y}$ \highl{Erwartungswertvektor}
  des Zufallsvektors $\underline{Y}$.
\end{defini}

\begin{defini}
  Falls für alle $Y_{i}$ der Erwartungswert von $Y_{i}$ endlich ist, dann
  heißt
  $\text{Cov}(\underline{Y})=\Sigma_{\underline{Y}}=(\text{cov}(Y_{i},Y_{j}))_{i=1,\dotsc,n,
  j=1,\dotsc,n}$ \highl{Kovarianzmatrix} des Zufallsvektors $\underline{Y}$.
\end{defini}

\begin{bemerk}
  Es ist $\text{cov}(Y_{i},Y_{j})= \EE (Y_{i}-\EE Y_{i})(Y_{j}-\EE Y_{j})$.

  Die Kovarianzmatrix wird manchmal auch nur als Varianz bezeichnet. 
\end{bemerk}

\begin{bsp}
  Für die $n$"~dimensionale Normalverteilung ist $\EE \underline{Y}=
  \underline{\mu}$ und $\text{Cov}(\underline{Y})=\Sigma$.
\end{bsp}

\begin{lemma}[Rechenregeln]
  Es sei $\underline{Y}$ ein Zufallsvektor mit existierenden
  Erwartungswertvektor $\EE\underline{Y}$ und Kovarianzmatrix
  $\Sigma\underline{Y}$. Ferner seien $A$ eine $m\times n$"~Matrix und
  \underline{b}$\in\R^{n}$. Dann gilt für $\underline{Z}=
  A\underline{Y}+\underline{b}$:
  \begin{itemize}
   \item $\EE\underline{Z}$ und Kovarianzmatrix existieren
   \item $\EE\underline{Z}= \EE(A\underline{Y}+\underline{b})=
    A(\EE\underline{Y}+\underline{b})$
   \item $\text{Cov}(\underline{Z})= \text{Cov}(A\underline{Y}+\underline{b})=
    A\Sigma_{\underline{Y}}A^{T}$
  \end{itemize}
\end{lemma}

Eigenschaften der Kovarianzmatrix
\begin{itemize}
 \item $\text{Cov}(\underline{Y})=(\text{cov}(Y_{i},Y_{j}))_{i=1,\dotsc,n,
  j=1,\dotsc,n}$ ist symmetrisch.
 \item ist positiv semidefinit.
\end{itemize}

\begin{satz}
  Sei $\underline{Y}\sim N(\underline{\mu},\Sigma)$ und $A$ eine reguläre
  $(n\times n)$"~Matrix und $\underline{b}\in\R^{n}$. Dann gilt für
  $\underline{Z}=A\underline{Y}+\underline{b}$:
  \begin{gather*}
    \underline{Z}\sim N(A\underline{\mu}+\underline{b}, A\Sigma A^{T})
  \end{gather*}
\end{satz}

\begin{folg}
  Sei $\underline{Y}\sim N(\underline{\mu},\Sigma)$. Dann existiert eine
  orthogonale Matrix $A_{0}$ derart, dass für $\underline{Z}=
  A_{0}\underline{Y}$ gilt, $\underline{Z}\sim N(A_{0}\underline{\mu},
  \begin{pmatrix}
    d_{1}& & 0\\
    & \ddots& \\
    0& & d_{n}
  \end{pmatrix})$. Hauptachsentransformation, Diagonalisierung der
  Kovarianzmatrix.
  \begin{proof}
    Wir wissen, die Kovarianzmatrix $\Sigma$ ist symmetrisch und positiv
    semidefinit. Die Eigenwerte der Matrix sind damit alle reell und größer
    oder gleich Null. Wir bezeichnen die Eigenwerte mit $d_{1},\dotsc, d_{n}$
    mit den Eigenvektoren $a^{(1)},\dotsc, a^{(n)}$. Die Vektoren können wir
    zu einer Matrix $A=(a^{(1)},\dotsc, a^{(n)})$ zusammenfassen. Es ist
    $\Sigma A= (\Sigma a^{(1)},\dotsc, \Sigma a^{(n)})= (d_{1}a^{(1)},\dotsc,
    d_{n} a^{(n)})$. Die Eigenvektoren der Matrix $A$ sind normiert und damit
    sind sie orthogonal. Die inverse Matrix $A^{-1}$ ist $A^{T}$ und
    $A^{-1}\Sigma A$ ist eine Diagonalmatrix mit den Eigenwerten auf der
    Hauptachse. Wir bezeichnen diese mit $D$, also ist
    $\Sigma=ADA^{-1}=ADA^{T}$ (Singulärwert- oder Spektralzerlegung).

    Wir wählen $A_{0}=A^{-1}=A^{T}$ und erhalten $\underline{Z}=
    A_{0}\underline{Y}= A^{T}\underline{Y}\sim N(A^{T}\underline{\mu},
    A^{T}\Sigma A)= N(A^{T}\underline{\mu},
    A^{T}ADA^{T}A)=N(A^{T}\underline{\mu}, D)$.
  \end{proof}
\end{folg}

\section{Maximum"=Likelihood"=Schätzung im linearen Modell}

Wir haben $\EE Y_{i}= \beta_{1}+\beta_{2}x_{i2}+\dotsb+
\beta_{k}x_{ik}=\colon\mu_{i}$ und $Y_{i}\sim N(\mu_{i},\sigma^{2})$
unabhängig. Das $\underline{\beta}=(\beta_{1},\dotsc,\beta_{k})^{T}$ ist der
Vektor der unbekannten Regressionskoeffizienten. In Matrixschreibweise:
$\EE\underline{Y}= \XX\cdot\underline{\beta}=\colon\underline{\mu}$ und
$\underline{Y}\sim N(\underline{\mu}, \sigma^{2}\II_{n})$. Wir haben konkrete
Beobachtungen $(y_{1},\dotsc, y_{n})$ und suchen eine Schätzung für
$\underline{\beta}$.

Wir beginnen mit der Likelihood"=Funktion:
$\CL(\underline{\beta}|y_{1},\dotsc, y_{n})= \prod_{i=1}^{n}
\frac{1}{\sqrt{2\pi\sigma^{2}}} e^{-\frac{1}{2\sigma^{2}}
  (y_{i}-\mu_{i})^{2}}= \frac{1}{(2\pi)^{\nicefrac{n}{2}}
(\sigma^{2})^{\nicefrac{n}{2}}} e^{-\frac{1}{2\sigma^{2}} \sum_{i=1}^{n}
(y_{i}-\mu_{i})^{2}}=  \frac{1}{(2\pi)^{\nicefrac{n}{2}}
(\sigma^{2})^{\nicefrac{n}{2}}} e^{-\frac{1}{2\sigma^{2}} \sum_{i=1}^{n}
(y_{i}-\underline{x}_{(i)}^{T}\underline{\beta})^{2}}$.
Die Log"~Likelihood"=Funktion ist $l(\underline{\beta}|y_{1},\dotsc, y_{n})=
-\frac{n}{2} \log(2\pi) -\frac{n}{2} \log(\sigma^{2})-\frac{1}{2\sigma^{2}}
\sum_{i=1}^{n} (y_{i}- \underline{x}_{(i)}^{T}\underline{\beta})^{2}$.
Schließlich müssen wir die Scorefunktionen ermitteln:
$\diffp{l(\underline{\beta}|y_{1},\dotsc, y_{n})}{{\beta_{j}}}=
-\frac{1}{2\sigma^{2}} \sum_{i=1}^{n}
2(y_{i}-\underline{x}_{(i)}^{T}\underline{\beta})(-x_{ij})=
\frac{1}{\sigma^{2}} \sum_{i=1}^{n}
(y_{i}-\underline{x}_{(i)}^{T}\underline{\beta})x_{ij}$. Wenn wir dies
zusammenfassen, ergibt sich
$\diffp{l(\underline{\beta}|y_{1},\dotsc,y_{n})}{{\underline{\beta}}}=
(\diffp{l}{{\beta_{1}}},\dotsc,\diffp{l}{{\beta_{k}}})$.
Die Log"~Likelihood"=Funktion in Matrixschreibweise:
$l(\underline{\beta}|y_{1},\dotsc, y_{n})=
-\frac{n}{2}\log(2\pi)-\frac{n}{2}\log\sigma^{2}- \frac{1}{2\sigma^{2}}
(\underline{y}-
\XX\underline{\beta})^{T}(\underline{y}-\XX\underline{\beta})=
-\frac{n}{2}\log(2\pi)-\frac{n}{2}\log\sigma^{2}-
\frac{1}{2\sigma^{2}}(\underline{y}^{T}\underline{y}-2\underline{y}^{T}\XX\underline{\beta}+
\underline{\beta}^{T}\XX^{T}\XX\underline{\beta})$. Schließlich
haben wir $\diffp{l(\underline{\beta}|y_{1},\dotsc,
y_{n})}{{\underline{\beta}}}= -\frac{1}{2\sigma^{2}}
(-2\XX^{T}\underline{y}+ 2\XX^{T}\XX\underline{\beta})$.
Das Score"=Gleichungssystem ist dann $ -\frac{1}{2\sigma^{2}}
(-2\XX^{T}\underline{y}+
2\XX^{T}\XX\underline{\beta})=0$. Umstellung ergibt
$\hat{\underline{\beta}}=
(\XX^{T}\XX)^{-1}\XX^{T}\underline{y}$. Dies ist die
Maximum"=Likelihood"=Schätzung für den unbekannten Parameter"=Vektor
$\underline{\beta}$ bei gegebenen Beobachtungen $y_{1},\dotsc, y_{n}$ der
Zielgröße. Die Inverse $(\XX^{T}\XX)^{-1}$ existiert genau dann,
wenn $\XX$ vollen Spaltenrang hat.

Wenn wir annehmen, dass $\XX$ \emph{nicht} den vollen Spaltenrang
besitzt, dann ist $\underline{x}^{(k)}= \sum_{i=1}^{k-1}
c_{i}\underline{x}^{(i)}$ und $\underline{\mu}= \XX\underline{\beta}=
(\underline{x}^{(1)},\dotsc,\underline{x}^{(k)})\underline{\beta}=
\beta_{1}\underline{x}^{(1)}+\dotsb+\beta_{k-1}\underline{x}^{(k-1)})+(\beta_{k}+\epsilon)x^{(k)}-\epsilon(c_{1}\underline{x}^{(1)}+\dotsb+
c_{k-1}\underline{x}^{(k-1)})$. Damit ist $\underline{\beta}$ nicht eindeutig
identifizierbar. Das lineare Score"=Gleichungssystem ist unterbestimmt.

Daher machen wir iin Zukunft immer eine zusätzliche Annahme: Der Rang von
$\XX$ soll gleich $k$ sein. Das bedeutet, $n\geq k$.

\section{Eigenschaften des Maximum"=Likelihood"=Schätzers im linearen Modell}

Der Maximum"=Likelihood"=Schätzer ist $\hat{\underline{\beta}}=
(\XX^{T}\XX)^{-1}\XX^{T}\underline{Y}$ und ist eine
lineare Transformation eines Zufallsvektors $\underline{Y}$.

\begin{satz}
  Im linearen Modell $\EE\underline{Y}=\XX\underline{y}$,
  $\underline{Y}\sim N(\XX\underline{\beta}, \sigma^{2}\II_{n})$ mit
  dem Rang von $\XX$ gleich $k$ gilt für den
  Maximum"=Likelihood"=Schätzer $\hat{\underline{\beta}}=
(\XX^{T}\XX)^{-1}\XX^{T}\underline{Y}$:
  \begin{gather*}
    \hat{\underline{\beta}}\sim N(\underline{\beta},
       \sigma^{2}(\XX^{T}\XX)^{-1})
  \end{gather*}
  \begin{proof}
    \begin{align*}
      \EE\hat{\underline{\beta}} &=
	 \EE((\XX^{T}\XX)^{-1}\XX^{T})\underline{Y})=
	 (\XX^{T}\XX)^{-1})\XX^{T} \EE\underline{Y}\\
      &=	 (\XX^{T}\XX)^{-1})\XX^{T}
	 \XX\underline{\beta}= \underline{\beta}
    \end{align*}
    Damit ist $\hat{\underline{\beta}}$ ein erwartungstreuer Schätzer für
    $\underline{\beta}$. Die Kovarianzmatrix ist
    $\text{Cov}(\hat{\underline{\beta}})= \Sigma_{\hat{\underline{\beta}}}=
    \Sigma_{(\XX^{T}\XX)^{-1}\XX^{T}\underline{Y}}=\dotsb=
    \sigma^{2}(\XX^{T}\XX)^{-1}$.
  \end{proof}
\end{satz}

\begin{bemerk}
  $(\XX^{T}\XX)^{-1}$ ist im Allgemeinen \emph{keine}
  Diagonalmatrix. Das heißt, die Schätzer $\hat{\beta_{i}}$ und
  $\hat{\beta_{j}}$ sind im Allgemeinen nicht unabhängig. Falls (im
  Experiment) die Designmatrix frei gewählt werden kann, ist es häufig
  erstrebenswert, dass $(\XX^{T}\XX)^{-1}$ eine Diagonalmatrix
  ist.
\end{bemerk}

Die Log"~Likelihood"=Funktion hängt auch vom unbekannten Wert $\sigma^{2}$ ab:
$l(\underline{\beta}|y_{1},\dotsc, y_{n})= -\frac{n}{2} \log(2\pi)- \frac{n}{2} \log\sigma^{2}
- \frac{1}{2\sigma^{2}} \sum_{i=1}^{n}
(y_{i}-\underline{x}_{(i)}^{T}\underline{\beta})^{2}$. Die Score"=Gleichung
für $\sigma^{2}$ ist: $\diffp{l(\underline{\beta},\sigma^{2}|y_{1},\dotsc,
y_{n})}{{\sigma^{2}}}= -\frac{n}{2}\frac{1}{\sigma^{2}} -(-1)
\frac{1}{2\sigma^{4}} \sum_{i=1}^{n}
(y_{i}-\underline{x}_{(i)}^{T}\underline{\beta})^{2}=0$. Umstellen der
Gleichung ergibt: $\hat{\sigma^{2}}= \frac{1}{n} \sum_{i=1}^{n} (y_{i}-
\underline{x}_{(i)}^{T}\hat{\underline{\beta}})^{2}= \frac{1}{n}
(\underline{y}-
\XX\hat{\underline{\beta}})^{T}(\underline{y}-\XX\hat{\underline{\beta}})$.

\section{Eigenschaften des Maximum"=Likelihood"=Schätzers für $\sigma^{2}$}

Es ist $\hat{\sigma^{2}}= \frac{1}{n} (\underline{Y}-
\XX\hat{\underline{\beta}})^{T}(\underline{Y}-\XX\hat{\underline{\beta}})$=
$\frac{1}{n}
(\underline{Y}-\XX(\XX^{T}\XX)^{-1}\XX^{T}\underline{Y})^{T}
(\underline{Y}-
\XX(\XX^{T}\XX)^{-1}\XX^{T}\underline{Y})=
\frac{1}{n}
\underline{Y}^{T}(\II_{n}-\XX(\XX^{T}\XX)^{-1}\XX)^{T}
(\II_{n}-\XX(\XX^{T}\XX)^{-1}\XX)\underline{Y}$.
Welche Eigenschaften hat nun $P\coloneqq\II_{n}-
\XX(\XX^{T}\XX)^{-1}\XX^{T}$? $P$ ist symmetrisch
und $PP= P$ (idempotent). Das heißt, $P$ beschreibt eine Orthogonalprojektion
im linearen Teilraum. 


\todo[inline]{Vorlesung vom 19.\,11.2012}
% Vorlesung vom 26.11.2012
\begin{bemerk}
  \begin{itemize}
   \item $\alpha=0,05$ ist in Anwendungen üblich (allerdings gibt es hierfür
    keine theoretische Begründung)
   \item Die berechnete Überschreitungswahrscheinlichkeit wird auch als
    »erreichtes Signifikanzniveau« bezeichnet $\rightarrow$ kleinstes
    Signifikanzniveau $\alpha$, für das die Nullhypothese für die \todo{Wort
    nicht lesbar} abgelehnt werden würden
   \item Die Überschreitungswahrscheinlichkeit ist eine
    Wahrscheinlichkeit, die unter der Annahme, das $H_{0}$ richtig ist,
    berechnet wird. Sie ist \emph{nicht} die Wahrscheinlichkeit, dass $H_{0}$
    korrekt ist.
  \end{itemize}
\end{bemerk}

Im folgenden betrachten wir einige wichtige Spezialfälle: $\underline{c}=
\underline{e}_{j}= (0,\dotsc,0,1,0,\dotsc,0)^{T}\Rightarrow\underline{c}^{T}
\underline{\hat{\beta}}= \hat{\beta}_{j}$. Es ist $H_{0}\colon\beta_{j}=0$ und
die Teststatistik ergibt sich:
\begin{gather*}
  T(\underline{Y})= \frac{\hat{\beta}_{j}-0}{\sqrt{\underline{e}_{j}^{T}
     (\XX^{T}\XX)^{-1}\underline{e}_{j} \tilde{\sigma}^{2}}}=
     \frac{\hat{\beta}_{j}}{\sqrt{(\XX^{T}\XX)^{-1}_{jj}
     \tilde{\sigma}^{2}}}
\end{gather*}

\section{Konfidenz- und Prognoseintervall}

\begin{gather*}
  \frac{\underline{c}^{T}\underline{\hat{\beta}}-
    \underline{c}^{T}\underline{\beta}}{\sqrt{\underline{c}^{T}
     (\XX^{T}\XX)^{-1}\underline{c}\tilde{\sigma}^{2}}}\sim t_{n-k}
\end{gather*}
Somit gilt für alle $\beta\in\R^{k}$:
\begin{align*}
  1-\alpha &= P\left(-t_{n-k, 1-\frac{\alpha}{2}} <
     \frac{\underline{c}^{T}\underline{\hat{\beta}}-
       \underline{c}^{T}\underline{\beta}}{\sqrt{\underline{c}^{T}
     (\XX^{T}\XX)^{-1}\underline{c}\tilde{\sigma}^{2}}} <t_{n-k, 1-\frac{\alpha}{2}}\right)\\
  &= P\left(-t_{n-k, 1-\frac{\alpha}{2}}
     \frac{\underline{c}^{T}\underline{\hat{\beta}}-
       \underline{c}^{T}\underline{\beta}}{\sqrt{\underline{c}^{T}
     (\XX^{T}\XX)^{-1}\underline{c}\tilde{\sigma}^{2}}}
     <\underline{c}^{T}\underline{\hat{\beta}}-\underline{c}^{T}\beta
     <t_{n-k, 1-\frac{\alpha}{2}} \frac{\underline{c}^{T}\underline{\hat{\beta}}-
       \underline{c}^{T}\underline{\beta}}{\sqrt{\underline{c}^{T}
     (\XX^{T}\XX)^{-1}\underline{c}\tilde{\sigma}^{2}}}\right)\\
  &= P\left(\underline{c}^{T}\underline{\hat{\beta}} -t_{n-k,
     1-\frac{\alpha}{2}} \frac{\underline{c}^{T}\underline{\hat{\beta}}-
       \underline{c}^{T}\underline{\beta}}{\sqrt{\underline{c}^{T}
     (\XX^{T}\XX)^{-1}\underline{c}\tilde{\sigma}^{2}}} <
     \underline{c}^{T}\underline{\beta}
     <\underline{c}^{T}\underline{\hat{\beta}} + t_{n-k, 1-\frac{\alpha}{2}} 
     \frac{\underline{c}^{T}\underline{\hat{\beta}}-
       \underline{c}^{T}\underline{\beta}}{\sqrt{\underline{c}^{T}
     (\XX^{T}\XX)^{-1}\underline{c}\tilde{\sigma}^{2}}} \right)\\
\end{align*}

\begin{defini}
  Ein zufälliges Intervall $(L(\underline{Y}), U(\underline{Y}))$ heißt
  \highl{Konfidenzintervall} zum Konfidenzintervall $1-\alpha$ für den
  unbekannten Parameter $\sigma$, falls gilt:
  \begin{gather*}
    P(\sigma\in(L(\underline{Y}), U(\underline{Y})))= 1-\alpha
  \end{gather*}
\end{defini}

\begin{bemerk}
  Das Konfidenzintervall überdeckt den unbekannten Parameter mit
  Wahrscheinlichkeit $1-\alpha$.
\end{bemerk}

Im linearen Modell ist das zufällige Intervall
$(\underline{c}^{T}\underline{\hat{\beta}}- t_{n-k, 1-\frac{1}{\alpha}}
\sqrt{\underline{c}^{T} (\XX^{T}\XX)^{-1}\underline{c}\tilde{\sigma}^{2}},
\underline{c}^{T}\underline{\hat{\beta}}+ t_{n-k, 1-\frac{1}{\alpha}} 
\sqrt{\underline{c}^{T} (\XX^{T}\XX)^{-1}\underline{c}\tilde{\sigma}^{2}})$
ein $(1-\alpha)$"~Konfidenzintervall.

\begin{bemerk}
  Es ist $\sqrt{\underline{c}^{T}\underline{\beta}- \underline{c}^{T}
  \underline{\hat{\beta}}\tilde{\sigma}^{2}}$ die geschätzte
  Standardabweichung (Standardfehler) von
  $\underline{c}^{T}\underline{\hat{\beta}}$.

  Als Faustregel können wir sagen: Da $t_{n-k, 1-\frac{1}{\alpha}}\approx2$,
  kann das Konfidenzintervall näherungsweise als Schätzwert
  $\pm2$"~Standardfehler bestimmt werden.
\end{bemerk}

Wir betrachten nun die zwei Spezialfälle: $\underline{c}=e_{j}$ und
$\underline{c}= \underline{x}_{\text{neu}}$. Im ersten Fall ist ein
$(1-\alpha)$"~Konfidenzintervall für $\beta_{j}$ durch $(\hat{\beta}_{j}-
t_{n-k, 1-\frac{\alpha}{2}} \sqrt{(\XX^{T}\XX)^{-1}\tilde{\sigma}^{2}},
\underline{\hat{\beta}}_{j}+ t_{n-k, 1-\frac{\alpha}{2}}
\sqrt{(\XX^{T}\XX)^{-1}\tilde{\sigma}^{2}})$. Für den zweiten Fall ergibt sich
$\underline{c}^{T}\underline{\beta}= \underline{x}_{\text{neu}}
\underline{\beta}= \EE Y_{\text{neu}}$. Letzteres ist der Erwartungswert der
Zielgröße für neuen Beobachtungsvektor und das entspricht der Prognose des
erwarteten Wertes der Zielgröße. Somit ist das also das
$(1-\alpha)$"~Konfidenzintervall für den Erwartungswert der Zielgröße
$(\underline{x}^{T}_{\text{neu}} \underline{\hat{\beta}}- t_{n-k,
1-\frac{\alpha}{2}} \sqrt{\underline{x}^{T}_{\text{neu}} (\XX^{T}\XX)^{-1}
\underline{x}_{\text{neu}} \tilde{\sigma}^{2}}, \underline{x}^{T}_{\text{neu}} \underline{\hat{\beta}}- t_{n-k,
1-\frac{\alpha}{2}} \sqrt{\underline{x}^{T}_{\text{neu}} (\XX^{T}\XX)^{-1}
\underline{x}_{\text{neu}} \tilde{\sigma}^{2}})$.

\begin{bemerk}
  Die Breite des Konfidenzintervalls hängt von $\underline{x}_{\text{neu}}$ ab.
\end{bemerk}

\section{Prognoseintervalle}

Es ist nicht nur die Vorhersage der Erwartungswertes der Zielgröße
interessant, sondern auch die Vorhersage eines Bereiches, in dem zukünftige
Beobachtungen liegen.

Wir hatten $P(\underline{x}^{T}_{\text{neu}} \underline{\hat{\beta}}- t_{n-k,
1-\frac{\alpha}{2}} \sqrt{\underline{x}_{\text{neu}} (\XX^{T}\XX)^{-1}
\underline{x}_{\text{neu}} \tilde{\sigma}^{2}}< \EE Y_{\text{neu}} <
\underline{x}^{T}_{\text{neu}} \underline{\hat{\beta}}+ t_{n-k,
1-\frac{\alpha}{2}} \sqrt{\underline{x}_{\text{neu}} (\XX^{T}\XX)^{-1}
\underline{x}_{\text{neu}} \tilde{\sigma}^{2}})= 1-\alpha$. Wir suchen
$P(L(Y)< Y_{\text{neu}}< U(Y))= 1-\alpha$. Dazu betrachten wir
$Y_{\text{neu}}= \underline{x}^{T}_{\text{neu}} \underline{\hat{\beta}}+
U_{\text{neu}}$. Dabei sind $\underline{\hat{\beta}}$ ein Zufallsvektor mit
$\underline{\hat{\beta}}\sim N(\underline{\beta},
\sigma^{2}(\XX^{T}\XX)^{-1})$ und $U_{\text{neu}}$ eine Zufallsvariable mit
$U_{\text{neu}} \sim N(0,\sigma^{2})$. Diese sind unabhängig, weil
$\underline{\hat{\beta}}$ neue, unabhängige Beobachtungen enthält und
$U_{\text{neu}}$ auf beobachteten Daten beruht. Damit ist $Y_{\text{neu}}\sim
N(\underline{x}^{T}_{\text{neu}} \underline{\hat{\beta}},
\underline{x}^{T}_{\text{neu}}(\XX^{T}\XX)^{-1}\underline{x}_{\text{neu}}
\sigma^{2}+\sigma^{2})$. Weiterhin folgt, $\frac{Y_{\text{neu}}
-\underline{x}^{T}_{\text{neu}}
\underline{\hat{\beta}}}{\sqrt{(\underline{x}^{T}_{\text{neu}}
(\XX^{T}\XX)^{-1} \underline{x}_{\text{neu}} +1)\sigma^{2}}}\sim N(0,1)$. Das
$\sigma^{2}$ muss durch den $\tilde{\sigma}^{2}$ ersetzt werden. Mit der
gleichen Argumentation wie oben gilt:
\begin{align*}
  \frac{Y_{\text{neu}}
    -x^{T}_{\text{neu}}\underline{\hat{\beta}}}{\sqrt{(\underline{x}^{T}_{\text{neu}}
     (\XX^{T}\XX)^{-1} \underline{x}_{\text{neu}} +1)\tilde{\sigma}^{2}}}
     &\sim t_{n-k}\\
  \Rightarrow P\left(\underline{x}^{T}_{\text{neu}} \underline{\hat{\beta}}-
     t_{n-k, 1-\frac{\alpha}{2}} \sqrt{(\underline{x}^{T}_{\text{neu}}
     (\XX^{T}\XX)^{-1} \underline{x}_{\text{neu}} +1) \tilde{\sigma}^{2}}
     <Y_{\text{neu}}\right.\\
  < \left.\underline{x}^{T}_{\text{neu}} \underline{\hat{\beta}}+
     t_{n-k, 1-\frac{\alpha}{2}} \sqrt{(\underline{x}^{T}_{\text{neu}}
     (\XX^{T}\XX)^{-1} \underline{x}_{\text{neu}} +1) \tilde{\sigma}^{2}}\right) &= 1-\alpha
\end{align*}
Damit haben wir ein $(1-\alpha)$-Prognoseintervall für neue Beobachtungen.

\section{Asymptotische Aussage in der Statistik}

Dieser Abschnitt ist nur ein Einschub. Er zeigt nochmal eventuell schon
bekannte Aussagen.

\begin{satz}[Schwaches Gesetz der großen Zahlen]
  Seien $Y_{1}, Y_{2},\dotsc$ unabhängige und identisch verteilte
  Zufallsgrößen mit dem Erwartungswert $\mu$ und der Varianz
  $\sigma^{2}<\infty$. Dann gilt:
  \begin{gather*}
    \lim_{n\rightarrow\infty} P\left(\abs[\bigg]{\frac{1}{n} \sum_{i=1}^{n}
       Y_{i}-\mu}<\epsilon\right)=1\qquad\forall\epsilon>0
  \end{gather*}
\end{satz}

\begin{satz}[Zentraler Grenzwertsatz]
  Seien $Y_{1}, Y_{2},\dotsc$ unabhängige und identisch verteilte
  Zufallsgrößen mit dem Erwartungswert $\mu$ und der Varianz
  $\sigma^{2}$. Dann gilt:
  \begin{gather*}
    \sqrt{n} \left(\sum_{i=1}^{n} Y_{i}-n\mu\right)= \sqrt{n}
       \left(\left(\frac{1}{n} \sum_{i=1}^{n} Y_{i}\right)
       -\mu\right)\xrightarrow[n\rightarrow\infty]{d} N(0,\sigma^{2})\\
    P\left(\sqrt{n} \left(\left(\frac{1}{n} \sum_{i=1}^{n} Y_{i}\right)-\mu\right)\in
       A\right)\xrightarrow[n\rightarrow\infty] \Phi_{0,\sigma^{2}} (A)=
       P(Z\in A)\qquad\forall A\in\mathcal{B}(\R)
  \end{gather*}
\end{satz}

%Vorlesung vom 3.12.2012
\begin{satz}[Lemma von Slutsky]
  Seien $\{X_{n}\}$, $\{Y_{n}\}$ und $\{Z_{n}\}$ Folgen von Zufallsgrößen mit
  $X_{n}\xrightarrow[n\rightarrow\infty]{P} a\in\R$, d.\,h.
  $P(\abs{X_{n}-a}>\epsilon)\xrightarrow[n\rightarrow\infty] 0$,
  $Y_{n}\xrightarrow[n\rightarrow\infty]{P} b\in\R$ und
  $Z_{n}\xrightarrow[n\rightarrow\infty]{d} Z$ (Zufallsgröße), d.\,h.
  $P(Z_{n}\in A)\xrightarrow[n\rightarrow\infty] P(Z\in A)$. Dann gilt:
  \begin{gather*}
    X_{n}\cdot Z_{n}+Y_{n}\xrightarrow[n\rightarrow\infty]{d} aZ+b
  \end{gather*}
\end{satz}

\begin{satz}[continuous mapping theorem]
  Falls $g\colon\R^{1}\rightarrow\R^{1}$ eine stetige Funktion ist, so gilt:
  \begin{itemize}
   \item Aus $Y_{n}\xrightarrow[n\rightarrow\infty]{d}Y$ folgt,
    $g(Y_{n})\xrightarrow[n\rightarrow\infty]{d} g(Y)$.
   \item Aus $Y_{n}\xrightarrow[n\rightarrow\infty]{P} Y$ folgt,
    $g(Y_{n})\xrightarrow[n\rightarrow\infty]{P} g(Y)$, d.\,h.
    $P(\abs{g(Y_{n})-g(Y)}>\epsilon)\xrightarrow[n\rightarrow\infty] 0$.
  \end{itemize}
\end{satz}


\begin{satz}[Deltamethode]
  Sei $\{Y_{n}\}$ eine Folge von Zufallsgrößen mit
  \begin{gather*}
    \sqrt{n} (Y_{n}-\mu)\xrightarrow[n\rightarrow\infty]{d} N(0,\sigma^{2})
  \end{gather*}
  Ferner sei $g$ eine in $\mu$ stetig differenzierbare Funktion. Dann gilt:
  \begin{gather*}
    \sqrt{n}(g(Y_{n})-g(\mu))\xrightarrow[n\rightarrow\infty]{d}
       N(0,g'(\mu)\sigma^{2})
  \end{gather*}
  \begin{proof}
    Beweisidee: Taylorentwicklung von $g$ um $\mu$:
    $g(y)=g(\mu)+g'(\mu)(y-\mu)+R(y)\approx g(\mu)+g'(\mu)(y-\mu)$.
  \end{proof}
\end{satz}

\begin{bsp}
  Die Zufallsgrößen $Y_{1},\dotsc, Y_{n}$ sind unabhängig und identisch
  verteilt mit dem Erwartungswert $\mu$ und der Varianz $\sigma^{2}$. Der
  Erwartungswert und Varianz sind unbekannt und sollen aus Beobachtungen
  geschätzt werden.
  \begin{itemize}
   \item $\hat{\mu}=\frac{1}{n} \sum_{i=1}^{n}
    Y_{i}\xrightarrow[n\rightarrow\infty]{P} \mu$, d.\,h. arithmetisches
    Mittel ist ein konsistenter Schätzer für $\mu$.
   \item $\hat{\sigma}^{2}= \frac{1}{n-1} \sum_{i=1}^{n}
    (Y_{i}-\hat{\mu})^{2}\xrightarrow[n\rightarrow\infty]{P} \sigma^{2}$,
    d.\,h. $\sigma^{2}$ ist ein konsistenter Schätzer für $\sigma^{2}$
   \item Continuous Mapping Theorem: $\hat{\sigma}= \sqrt{\frac{1}{n-1} \sum_{i=1}^{n}
    (Y_{i}-\hat{\mu})^{2}}\xrightarrow[n\rightarrow\infty]{P} \sigma$
   \item Znetraler Grenzwertsatz: $\sqrt{n} (\frac{1}{n} \sum_{i=1}^{n}
    Y_{i}-\mu)\xrightarrow[n\rightarrow\infty]{d} N(0,\sigma^{2})\Rightarrow
    \sqrt{n} \frac{(\frac{1}{n} \sum_{i=1}^{n}
    Y_{i}-\mu)}{\sigma}\xrightarrow[n\rightarrow\infty]{d} N(0,1)$
   \item $\sigma$ ersetzen durch konsistenten Schätzer.
    \begin{enumerate}[1.\,Schr{i}tt]
     \item $\hat{\sigma}= \sqrt{\frac{1}{n-1} \sum_{i=1}^{n}
      (Y_{i}-\hat{\mu})^{2}}\xrightarrow[n\rightarrow\infty]{P} \sigma$ und
      dann das Continuous Mapping Theorem mit $g(Y)=\frac{1}{Y}$ ergibt:
      $\frac{1}{\hat{\sigma}} \xrightarrow[n\rightarrow\infty]{P} \frac{1}{\sigma}$
     \item Slutsky"=Lemma ergibt $X_{n}= \frac{1}{\hat{\sigma}}=
      \frac{1}{\sqrt{\frac{1}{n-1} \sum_{i=1}^{n} (Y_{i}-\hat{\mu})}}
      \xrightarrow[n\rightarrow\infty]{P} \frac{1}{\sigma}$ und $Z_{n}=
      \sqrt{n} (\frac{1}{n} \sum_{i=1}^{n}
      Y_{i}-\mu)\xrightarrow[n\rightarrow\infty]{d} N(0,\sigma^{2})\Rightarrow
      X_{n}\cdot Z_{n}\xrightarrow[n\rightarrow\infty]{d}
      N(0,\sigma^{2})\cdot\frac{1}{\sigma}= N(0,1)$
    \end{enumerate}
   \item $\sqrt{n} \frac{(\frac{1}{n} \sum_{i=1}^{n}
    (Y_{i}-\hat{\mu})^{2}-\mu)}{\hat{\sigma}}\xrightarrow[n\rightarrow\infty]{d}
    N(0,1))$. Nun wenden wir das Continuous Mapping Theorem mit $g(y)=y^{2}$
    und erhalten: $n\frac{(\frac{1}{n} \sum_{i=1}^{n}
    (Y_{i}-\hat{\mu})^{2}-\mu)^{2}}{\hat{\sigma}^{2}}\xrightarrow[n\rightarrow\infty]{d}
    N(0,1)^{2}\sim\chi_{1}^{2}$
  \end{itemize}
\end{bsp}

\chapter{Das verallgemeinerte lineare Modell}

\section{Die binäre Regression}

Wir haben Daten $(y_{i},x_{i1},\dotsc, x_{ik})$ für $i=1,\dotsc,n$. Die
Zielgröße $y_{i}$ ist binär. Die naheliegende Idee ist, $y_{i}$ als
Realisierung einer binomialverteilten Zufallsgröße
$Y_{i}\sim\text{Bin}(1,p_{i})$ aufzufassen. Wir modellieren den
Erwartungswert: $\EE Y_{i}= \mu_{i}= p_{i}= P(Y_{i}=1)=
P(Y_{i}=1|x_{i2},\dotsc, x_{ik})= f(x_{i2},\dotsc, x_{ik})$. Der lineare
Ansatz ist $\mu_{i}= \beta_{1}+\beta_{2}x_{i2}+\dotsb+ \beta_{k} x_{ik}$. Das
verletzt jedoch die Bedingung $\mu_{i}\in[0,1]$.

Ein alternativer Ansatz wäre $\mu_{i}= h(\beta_{1}+\beta_{2}x_{i2}+\dotsb+
\beta_{k} x_{ik})= h(\eta_{i})$. Wir nennen $\eta_{i}$ den linearen Prädikor.
Die Funktion $h$ heißt Responsefunktion und ist eine nichtlineare, streng
monotone differenzierbare Funktion mit Wertebereich $[0,1]$. Das ist also eine
Verteilungsfunktion einer stetigen Zufallsgröße.

Ein Weg geht über das Probitmodell: $h(x)= \Phi_{0,1}(x)$. Dies ist die
Verteilungsfunktion der Standardnormalverteilung. Es ist $\EE Y_{i}= \mu_{i}=
\Phi_{0,1}(\eta_{i})$. Für diese Verteilungsfunktion existiert jedoch keine
einfache analytische Darstellung. Damit haben wir Schwierigkeiten bei der
Interpretation der Paramter $\beta_{j}$.

Das Logitmodell behebt diese Schwierigkeiten. Wir setzen $N$ als
Populationsgröße und erhalten $\diff{N}{t}= \frac{rN(K-N)}{K}$. Dabei ist $K$
die Kapazität. Wir normieren $x=\frac{N}{K}$ und bekommen $\diff{x}{t}=
rx(1-x)$. Lösung der Differenzialgleichung: $x(t)=
\frac{1}{1+(\frac{1}{x_{0}}-1)e^{-rt}}$. Die Lösung ist die
Verteilungsfunktion der logistischen Verteilung. Wir wählen als
Responsefunktion: $h(x)= \frac{1}{1+e^{-x}}= \frac{e^{x}}{1+e^{x}}$. Im Modell
haben wir $\mu_{i}= \frac{1}{1+e^{-\underline{x}_{(i)}^{T}\underline{\beta}}}$.

Schauen wir uns nun die Umkerhfunktion an: $\mu_{i}=h(\eta_{i})=
\frac{1}{1+e^{- \eta_{i}}}= \frac{e^{\eta_{i}}}{1+e^{\eta_{i}}}$. Umstellen
ergibt $\mu_{i}(1+^{\eta_{i}})= e^{\eta_{i}}$. Nach weiteren Schritten kommen
wir zu $\eta_{i}= \log\frac{\mu_{i}}{1-\mu_{i}}$, dem so genannten
logarithmiertem Chancenverhältnis. Die Schritte werden als
Logit"=Transformation bezeichnet.

Nun können wir die Parameter $\beta_{j}$ interpretieren:
$\frac{\mu_{i}}{1-\mu_{i}}= e^{\eta_{i}}= e^{\beta_{1}}
e^{\beta_{2}x_{i2}}\cdot\dotso \cdot e^{\beta_{k}x_{ik}}$. Das heißt, wir
haben ein multiplikatives Modell für das Chancenverhältnis. Erhöhen wir nun
die Einflussgröße um $1$: $x_{ij}^{*}= x_{ij}+1$ ergibt:
$\frac{\mu_{i}^{*}}{1-\mu_{i}^{*}}= e^{\beta_{1}}
e^{\beta_{j}(x_{ij}+1)}\cdot\dotso \cdot e^{\beta_{k}x_{ik}}= e^{\beta_{j}}
\frac{\mu_{i}}{1-\mu_{i}}$

Im folgenden wollen wir uns das komplementäre Log"~Log"~Modell anschauen.Wir
wählen als Responsefunktion die Verteilungsfunktion der Gumbel-Verteilung
(Grenzverteilung des Minimums von unabhängig identisch verteilten
Zufallsgrößen). Damit will man eine nichtsymmetrische Verteilung abdecken.
Wir haben $\mu_{i}= h(\eta_{i})= 1-e^{-e^{\eta_{i}}}$. Die Umkehrfunktion ist
$1-\mu_{i}= e^{-e^{\eta_{i}}}$ und $\eta_{i}= \log(-\log(1-\mu_{i}))$. Daher
stammt die Bezeichnung des Modells.

Das Logit- und das Probit"=Modell liefern sehr unterschiedliche Schätzwerte
für $\beta_{j}$. Aber die geschätzten Werte $\mu_{i}$ sind typischerweise sehr
ähnlich. Mit dem so genannten Rescaling wählen wir $\Phi_{0,\sigma^{2}}$ statt
$\Phi_{0,1}$ und erhalten $\mu_{i}= \Phi_{0,\sigma^{2}}(\eta_{i})= P(Z\sim
N(0,\sigma^{1})= P(\frac{Z-\mu}{\sigma}\leq\frac{\eta_{i}-\mu}{\sigma})=
\Phi_{0,1}(\frac{\eta_{i}}{\sigma})$. Wir wählen das $\sigma$ derart, dass die
Varianz der logistischen Verteilungsfunktion angenommen wird: $\sigma^{2}=
\frac{\pi^{2}}{3}$. Die Normalverteilung und die logistische
Verteilungsfunktion sind kaum unterscheidbar. Parameterschätzer aus Logit- und
Probit-Modell unterscheiden sich etwa um den Faktor $\frac{\pi}{\sqrt{3}}$.

% Vorlesung vom 10.12.2012
\section{Binäre Regressionsmodelle als Schwellenwertmodelle}

Wir nehmen an, dass wir eine unbeobachtbare (latente) Variable $\tilde{Y}$
haben, für die ein lineares Modell gilt. Das heißt, $\EE\tilde{Y}_{i}=
\underline{x}_{i}^{T} \underline{\beta}$ oder $\tilde{Y}_{i}=
\underline{x}_{i}^{T} \underline{\beta}+ U_{i}$. Wir beobachten: $Y_{i}=
\begin{cases}
  1& \tilde{Y}_{i}\geq0\\
  0& \tilde{Y}_{i}<0
\end{cases}$.
Wir brauchen ein Modell für den Erwartungswert von $Y_{i}$. Das ist $\EE
Y_{i}= \mu_{i}= P(Y_{i}=1)= P(\tilde{Y}_{i}\geq0)= P(\underline{x}_{i}^{T}
\underline{\beta}+ U_{i}\geq0)
P(U_{i}\geq-\underline{x}_{i}^{T}\underline{\beta})=
1-F(\underline{x}_{i}^{T}\underline{\beta})$, wobei $F$ die
Verteilungsfunktion der Zufallsgröße $U_{i}$ ist.

Sei beispielsweise $F=\Phi$ die Standardnormalverteilungsfunktion. Dann haben
wir $1-\Phi(\underline{x}_{i}^{T}\underline{\beta})=
\Phi(\underline{x}_{i}^{T}\underline{\beta})$. Das entspricht dem oben
besprochenen Probit"=Modell.

Annahme über die Verteilung der zufälligen Störterme im latenten linearen
Modell führt zu unterschiedlichen Response"=Funktionen im binären
Regressionsmodell.

\section{Gruppierte Daten im binären Regressionsmodell}

\begin{bsp}[Infektionen nach Sectio caesarea]
  Die Zielgröße ist $Y_{i}$. Die ist $1$, wenn eine Infektion auftritt und
  sonst $0$. Die Einflussgrößen sind $x_{i2}$ und $x_{i3}$. Die erste gibt an,
  ob die Sectio geplant war und die letzte zeigt, ob Risikofaktoren vorhanden
  waren. Schließlich haben wir noch die Einflussgröße $x_{i4}$, die angibt, ob
  Antibiotika"=Prophylaxe erfolgte.

  \begin{tabular}{c|c|c|l|l}
    $x_{2}$ & $x_{3}$ & $x_{4}$ & $Y_{p}$ & $Y_{n}$\\
    1& 1& 1 & 1 & 17\\
    1& 1& 0 & 0 & 2\\
    1& 0& 1 \\
    1& 0& 0 \\
    0& 1& 1\\
    0& 1& 0\\
    0& 0& 1\\
    0& 0& 0
  \end{tabular}
  Die letzte Spalte ist die Gesamtzahl der Erfolge ($p$) oder Misserfolge
  ($n$) als Information.

  Zunächst schreiben wir die Likelihood"=Funktion auf: $\CL(\underline{\beta}|
  y_{1},\dotsc, y_{n})= \prod_{i=1}^{n} f(y_{i}|
  \underline{\beta}\underline{x}_{i})= \prod_{i=1}^{n} \mu_{i}^{y_{i}}
  (1-\mu_{i})^{1-y_{i}}= \prod_{i=1}^{n} h(\underline{x}_{i}^{T}
  \underline{\beta})^{y_{i}}
  (1-h(\underline{x}_{i}^{T}\underline{\beta})^{1-y_{i}}$. Nun gehen wir zur
  Log"~Likelihood"=Funktion über: $l(\underline{\beta}|
  y_{1},\dotsc, y_{n})= \sum_{i=1}^{n} y_{i}\log\mu_{i}+ (1-y_{i})
  \log(1-y_{i})= \sum_{i=1}^{n} y_{i}\log\frac{\mu_{i}}{1-\mu_{i}}+
  \log(1-\mu_{i})$. Es ist $\theta_{i}=\log\frac{\mu_{i}}{1-\mu_{i}}$ der
  Exponential"=Dispersionsfamilie.

  Wir betrachten die einfachste Situation: $\log\frac{\mu_{i}}{1-\mu_{i}}=
  \theta_{i}= \underline{x}_{i}^{T}\underline{\beta}$. Wir können das
  umstellen: $\mu_{i}= \frac{e^{\underline{x}_{i}^{T} \underline{\beta}}}{1+
  e^{\underline{x}_{i}^{T} \underline{\beta}}}$.  Dies entspricht dem
  Logit"=Modell.

  Damit folgt, dass $l(\underline{\beta}| y_{1},\dotsc, y_{n})= \sum_{i=1}^{n}
  y_{i} (\underline{x}_{i}^{T}\underline{\beta})-
  \log(1+e^{\underline{x}_{i}^{T} \underline{\beta}})$. Das leiten wir ab und
  erhalten die Scorefunktionen: $S_{j}(\underline{\beta})=
  \diffp{l(\underline{\beta})}{{(\beta_{j})}}= \sum_{i=1}^{n} y_{i}x_{ij}-
  \frac{1}{1+e^{\eta_{i}}} e^{\eta_{i}} x_{ij}= \sum_{i=1}^{n}
  (y_{i}-\mu_{i})x_{ij}$ für $j=1,\dotsc,k$. Dies ist eine nichtlineare
  Funktion des Parametervektors $\underline{\beta}$, da $\mu_{i}=
  h(\underline{x}_{i}^{T} \underline{\beta})$ und das $h$ ist die logistische
  Verteilungsfunktion.

  Aber, wenn wir betrachten $\EE_{\underline{\beta}} S(\underline{\beta})= \sum_{i=1}^{n}
  (\EE Y_{i}-\mu_{i})\underline{x}_{i}=\underline{0}_{k}$. Die
  Scoregleichungen werden wie folgt geschrieben: $S(\underline{\beta})=
  \sum_{i=1}^{n} (y_{i}-\mu_{i})\underline{x}_{i}= \underline{0}_{k}$. Das ist
  ein nichtlineares Gleichungssystem in $\underline{\beta}$. Wir müssen das
  also numerisch behandeln.
\end{bsp}

% Original 5.2
\section{Allgemeine Formulierung des verallgemeinerten linearen Modells}
Die Zielgröße ist $Y_{i}$. Wir fordern, dass die einer Verteilung aus einer
Exponential"=Dispersionsfamilie genügt. Die hat die Dichtefunktion
$f(y_{i}|\theta, \phi)= c(y_{i}, \phi) \exp\{\frac{y_{i}
\theta_{i}-A(\theta_{i})}{\phi}\}$. Weiter fordern wir, dass wir unabhängige
Beobachten haben. Damit können wir Erwartungswert und Varianz vergleichsweise
einfach bestimmen: $\EE Y_{i}= A'(\theta_{i})$ und $\text{Var}(Y_{i})= \phi
A''(\theta_{i})$. Obiges ist der stochastische Teil des Modells. Der
deterministische Teil ergibt sich durch die Modellierung des Erwartungswertes
als Funktion von Einflussgrößen. Mann kann sagen, $\mu_{i}= f(x_{i2},\dotsc,
x_{ik}|\underline{\beta})$. Wir lassen nicht alles zu, was denkbar ist und
behalten ein wenig Linearität, genauer $\mu_{i}= h(\underline{x}_{i}^{T}
\underline{\beta})= h(\beta_{1}+ \beta_{2}x_{i2}+\dotsb+ \beta_{k} x_{ik}=
h(\eta_{i}))$. Die Funktion $h$ heißt Response"=Funktion. Diese ist
möglicherweise nichtlinear. Sie sollte streng monoton, stetig und hinreichend
oft differenzierbar (meist reicht zweimal) sein. Also ist sie invertierbar.
Wir bezeichnen die inverse Funktion mit $g\coloneqq h^{-1}$ und haben
$g(\mu_{i})= \eta_{i}$. Die Funktion $g$ wird als Linkfunktion bezeichnet.

Spezialfall: $g(\mu_{i})= \eta_{i}= \theta_{i}$. Dies heißt dann kanonische
Linkfunktion.

\begin{bsp}
  Klassisches lineares Modell:
  \begin{tabular}{l|l}
    Deterministischer Teil & Stochastischer Teil\\
    $\EE Y_{i}= \underline{x}_{i}^{T} \underline{\beta}= \mu_{i}$ & $Y_{i}\sim
       N(\mu_{i}, \sigma^{2})$\\
  \end{tabular}

  Binäre Regressionsmodelle: det. Teil: $\mu_{i}= \EE Y_{i}=
  h(\underline{x}_{i}^{T} \underline{\beta})$ mit Probit- und Logit"=Modell und dem stoch. Teil:
  $Y_{i}\sim\text{Bin}(1,\mu_{i})$.

  Poission"=Regression: det. Teil: $\mu_{i}= \EE Y_{i}=
  h(\underline{x}_{i}^{T} \underline{\beta})$ mit $h= e^{\eta}$ sowie der
  kanonischen Linkfunktion $g(\mu)= \log\mu$, weiter geht auch $h(\eta)=\eta$
  oder $h(\eta)=\eta^{2}$ und stoch. Teil:
  $Y_{i}\sim\text{Poisson}(\mu_{i})$
\end{bsp}

\section{Maximum"=Likelihood"=Schätzung im verallgemeinerten linearen Modell}

Die Likelihood"=Funktion ist $\CL(\underline{\beta}|y_{1},\dotsc, y_{n})=
\prod_{i=1}^{n} c(y_{i}, \phi) \exp\{\frac{y_{i}
\theta_{i}-A(\theta_{i})}{\phi}\}$ und die Log"~Likelihood"=Funktion:
$l(\underline{\beta}|y_{1},\dotsc, y_{n})= \sum_{i=1}^{n} \left(\log c(y_{i},\phi) + \frac{y_{i}
\theta_{i}-A(\theta_{i})}{\phi}\right)$. Nun kommen wir zur Scorefunktion
$S_{j}(\underline{\beta})= \diffp{l(\underline{\beta})}{{\beta_{j}}}=
\frac{1}{\phi} \sum_{i=1}^{n} y_{i} \diffp{{\theta_{i}
(\underline{\beta})}}{{\beta_{j}}} - A'(\theta_{i}(\underline{\beta}) \diffp{{\theta_{i}
(\underline{\beta})}}{{\beta_{j}}}=\frac{1}{\phi} \sum_{i=1}^{n} (y_{i}-
A'(\theta_{i}(\underline{\beta}))\diffp{{\theta_{i}
(\underline{\beta})}}{{\beta_{j}}}=\frac{1}{\phi} \sum_{i=1}^{n}
(y_{i}- \mu_{i}) \diffp{{\theta_{i}
(\underline{\beta})}}{{\beta_{j}}}$.

Wir betrachten nun $\diffp{{\theta_{i}
(\underline{\beta})}}{{\beta_{j}}}$ und wissen $\mu_{i}=
A'(\theta_{i}(\underline{\beta}))= h(\underline{x}_{i}^{T}
\underline{\beta})$. Damit folgt, $A''(\theta_{i}(\underline{\beta})) \diffp{{\theta_{i}
(\underline{\beta})}}{{\beta_{j}}}= h'(\underline{x}_{i}^{T}
\underline{\beta}) x_{ij}$. Umstellen ergibt $\diffp{{\theta_{i}
(\underline{\beta})}}{{\beta_{j}}}= \frac{h'(\underline{x}_{i}^{T}
\underline{\beta})}{A''(\theta_{i}(\underline{\beta}))} x_{ij}= \frac{h'(\underline{x}_{i}^{T}
\underline{\beta})}{\nicefrac{\text{Var}(Y_{i})}{\phi}} x_{ij}$. Für die
Scorefunktion ergibt sich $S_{j}(\underline{\beta})=
\diffp{l(\underline{\beta})}{{\beta_{j}}}= \sum_{i=1}^{n} \frac{y_{i}-
\mu_{i}}{\text{Var}(Y_{i})} h'(\underline{x}_{i}^{T} \underline{\beta})
x_{ij}$. Dann ist $S(\underline{\beta})=
\diffp{l(\underline{\beta})}{{\underline{\beta}}}= \sum_{i=1}^{n}
\frac{y_{i}-\mu_{i}}{\text{Var}(Y_{i})} h'(\underline{x}_{i}^{T}
\underline{\beta}) \underline{x}_{i}$.

Nun betrachten wir noch den Spezialfall der kanonischen Linkfunktion: Die
Scorefunktion ist exakt die gleiche wie für den obigen Spezialfall. Die
Scorefunktionen sehen für alle verallgemeinerten linearen Modelle mit
kanonischer Linkfunktion identisch aus. Unterschiede entstehen durch die
verschiedenen Modellierungen von $\mu_{i}$.

Die Fisher"=Informationsmatrix:  $I(\underline{\beta})=
\left(-\diffp[2]{l(\underline{\beta})}{{\beta_{i}\beta_{j}}}\right)_{i,j=1,\dotsc,k}$
sowie die beobachtete Fisher"=Informationsmatrix $I(\hat{\underline{\beta}})$.




\clearpage
\appendix
\chapter{Übungsaufgaben}
\section{Berechnungen zu diversen Verteilungen}
\subsection{Bernoulliverteilung}
\begin{tabular}{l|l}
  Notation &  $\text{Bernoulli}(p)$\\
  Dichtefunktion & $p^{y}(1-p)^{1-y}$\\
  natürlicher Parameter $\theta$& $\log \frac{p}{1-p}$\\
  $A(\theta)$& $-\log(1-p)= \log(1+e^{\theta})$\\
  Erwartungswert $\mu=\tau(\theta)$&
     $p=\frac{e^{\theta}}{1+e^{\theta}}=\frac{1}{1+e^{-\theta}}$\\
  Kanonische Linkfunktion $\tau^{-1}(\mu)$& $\log\frac{p}{1-p}$\\
  Dispersionsparamter $\phi$& $1$\\
  $c(y,\phi)$& $1$\\
  Varianzfunktion $v(\mu)$& $\mu(1-\mu)$
\end{tabular}
\subsection{Binomialverteilung}
\begin{tabular}{l|l}
  Notation &  $\text{Bin}(N,p)$\\
  Dichtefunktion & $\binom{N}{y} p^{y}(1-p)^{N-y}$\\
  natürlicher Parameter $\theta$& $y$\\
  $A(\theta)$& $(1-y)\log(1-p)$\\
  Erwartungswert $\mu=\tau(\theta)$& $\frac{1}{1-p}$\\
  Kanonische Linkfunktion $\tau^{-1}(\mu)$& $1-\frac{1}{\mu}$\\
  Dispersionsparamter $\phi$& \\
  $c(y,\phi)$& \\
  Varianzfunktion $v(\mu)$&$\mu^{2}$
\end{tabular}
\subsection{Geometrische Verteilung}
\begin{tabular}{l|l}
  Notation &  $\text{Geom}(p)$\\
  Dichtefunktion & $(1-p)^{y-1}p=e^{(y-1)\log(1-p)+\log p}=
     e^{y\log(1-p)+\log\frac{p}{1-p}}$\\
  natürlicher Parameter $\theta$& $\log (1-p)$\\
  $A(\theta)$& $\log\frac{1-p}{p}=\theta-\log(1-e^{\theta})$\\
  Erwartungswert $\mu=\tau(\theta)$& $\frac{1}{1-e^{\theta}}$\\
  Kanonische Linkfunktion $\tau^{-1}(\mu)$& $\log\frac{\mu-1}{\mu}$\\
  Dispersionsparamter $\phi$& $1$\\
  $c(y,\phi)$& $1$\\
  Varianzfunktion $v(\mu)$& 
\end{tabular}
\subsection{Poissonverteilung}
\begin{tabular}{l|l}
  Notation &  $\text{Poisson}(\mu)$\\
  Dichtefunktion & $\frac{\mu^{y}}{y!} e^{-\mu}$\\
  natürlicher Parameter $\theta$& $\log\mu$ (siehe \autoref{bsp:3.1})\\
  $A(\theta)$& $e^{\theta}=\mu$ (siehe \autoref{bsp:3.1})\\
  Erwartungswert $\mu=\tau(\theta)$& \\
  Kanonische Linkfunktion $\tau^{-1}(\mu)$& \\
  Dispersionsparamter $\phi$& \\
  $c(y,\phi)$& \\
  Varianzfunktion $v(\mu)$&
\end{tabular}
\subsection{Normalverteilung}
\begin{tabular}{l|l}
  Notation &  $N(\mu,\sigma^{2})$\\
  Dichtefunktion & $\frac{1}{\sqrt{2\pi\sigma^{2}}}
     \exp\{-\frac{1}{2\sigma^{2}}(y-\mu)^{2}\}$\\
  natürlicher Parameter $\theta$& \\
  $A(\theta)$& \\
  Erwartungswert $\mu=\tau(\theta)$& \\
  Kanonische Linkfunktion $\tau^{-1}(\mu)$& \\
  Dispersionsparamter $\phi$& \\
  $c(y,\phi)$& \\
  Varianzfunktion $v(\mu)$&
\end{tabular}
\subsection{Exponentialverteilung}
\begin{tabular}{l|l}
  Notation &  $\text{Exp}(\lambda)$\\
  Dichtefunktion & $\lambda e^{-\lambda y}$\\
  natürlicher Parameter $\theta$& \\
  $A(\theta)$& \\
  Erwartungswert $\mu=\tau(\theta)$& \\
  Kanonische Linkfunktion $\tau^{-1}(\mu)$& \\
  Dispersionsparamter $\phi$& \\
  $c(y,\phi)$& \\
  Varianzfunktion $v(\mu)$&
\end{tabular}
\subsection{Gammaverteilung}
\begin{tabular}{l|l}
  Notation &  $\Gamma(a,s)$\\
  Dichtefunktion & $\frac{1}{s^{a}\Gamma(a)} y^{(a-1)} e^{-\nicefrac{y}{s}}\II_{[0,\infty)}=
     e^{-\nicefrac{y}{s}+ (a-1)\log y-a\log s-\log\Gamma(a)} \II_{[0,\infty)}=
     e^{\frac{- \frac{y}{as} - \log s}{\frac{1}{a}} +(a-1)\log
     y-\log\Gamma(a)}= \frac{y^{a-1}}{\Gamma(a)} e^{\frac{-\frac{y}{as}
     -\log(as)-\log a}{\frac{1}{a}}}$\\
  natürlicher Parameter $\theta$& $-\frac{1}{as}$\\
  $A(\theta)$& \\
  Erwartungswert $\mu=\tau(\theta)$& \\
  Kanonische Linkfunktion $\tau^{-1}(\mu)$& \\
  Dispersionsparamter $\phi$& \\
  $c(y,\phi)$& \\
  Varianzfunktion $v(\mu)$&
\end{tabular}
\subsection{$\chi^{2}$"~Verteilung}
\begin{tabular}{l|l}
  Notation &  $\chi^{2}(m)$\\
  Dichtefunktion & $\frac{1}{2^{\nicefrac{m}{2}}}
     \Gamma(\nicefrac{m}{2})y^{\nicefrac{m}{2}-1} e^{-\nicefrac{y}{2}}$\\
  natürlicher Parameter $\theta$& \\
  $A(\theta)$& \\
  Erwartungswert $\mu=\tau(\theta)$& \\
  Kanonische Linkfunktion $\tau^{-1}(\mu)$& \\
  Dispersionsparamter $\phi$& \\
  $c(y,\phi)$& \\
  Varianzfunktion $v(\mu)$&
\end{tabular}
\subsection{t"~Verteilung}
\begin{tabular}{l|l}
  Notation &  $t(m)$\\
  Dichtefunktion & $\frac{1}{\sqrt{m\pi}}
     \frac{\Gamma(\frac{m+1}{2})}{\Gamma(\frac{m}{2})}
     \left(1+\frac{y^{2}}{m}\right)^{-\frac{m+1}{2}}$\\
  natürlicher Parameter $\theta$& \\
  $A(\theta)$& \\
  Erwartungswert $\mu=\tau(\theta)$& \\
  Kanonische Linkfunktion $\tau^{-1}(\mu)$& \\
  Dispersionsparamter $\phi$& \\
  $c(y,\phi)$& \\
  Varianzfunktion $v(\mu)$&
\end{tabular}
\subsection{Inverse Gaußverteilung}
\begin{tabular}{l|l}
  Notation &  $\text{Inv}(\mu,\lambda)$\\
  Dichtefunktion & $\left(\frac{\lambda}{2\pi y^{3}}\right)^{\nicefrac{1}{2}}
     e^{-\frac{\lambda(y-\mu)^{2}}{2\mu^{2}y}}$\\
  natürlicher Parameter $\theta$& \\
  $A(\theta)$& \\
  Erwartungswert $\mu=\tau(\theta)$& \\
  Kanonische Linkfunktion $\tau^{-1}(\mu)$& \\
  Dispersionsparamter $\phi$& \\
  $c(y,\phi)$& \\
  Varianzfunktion $v(\mu)$&
\end{tabular}


% \begin{thebibliography}{99}
%  \bibitem{shmathguide} Short Math Guide for \LaTeX{},\\
%   \url{ftp://ftp.ams.org/pub/tex/doc/amsmath/short-math-guide.pdf}
% \end{thebibliography}

\clearpage
\pdfbookmark[0]{Index}{index}
% Behebt das Problem der vielen "`overfull \hbox"' im Index
% <news:3419172.ueajl5DJLB@mjk.komascript.de>
\setlength{\parfillskip}{0pt plus 1fil}
\printindex

\end{document}
